<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns:mda="urn:oasis:names:tc:xliff:metadata:2.0" srcLang="en-US" trgLang="zh-cn" version="2.0" xml:space="default" xmlns="urn:oasis:names:tc:xliff:document:2.0">
  <file id="1">
    <mda:metadata>
      <mda:metaGroup>
        <mda:meta type="oltranslationpriority">
        </mda:meta>
      </mda:metaGroup>
    </mda:metadata>
    <mda:metadata>
      <mda:metaGroup>
        <mda:meta type="olfilepath">windows-apps-src\input-and-devices\multiple-input-design-guidelines.md</mda:meta>
      </mda:metaGroup>
    </mda:metadata>
    <mda:metadata>
      <mda:metaGroup>
        <mda:meta type="olfilehash">20af1cbfd4d390a1128b96b24c687fd481db1f5c</mda:meta>
      </mda:metaGroup>
    </mda:metadata>
    <mda:metadata>
      <mda:metaGroup>
        <mda:meta type="tool-id">mdxliff</mda:meta>
        <mda:meta type="tool-name">mdxliff</mda:meta>
        <mda:meta type="tool-version">1.0-781aacf</mda:meta>
        <mda:meta type="tool-company">Microsoft</mda:meta>
      </mda:metaGroup>
    </mda:metadata>
    <group id="content">
      <unit id="101">
        <segment state="initial">
          <source>Just as people use a combination of voice and gesture when communicating with each other, multiple types and modes of input can also be useful when interacting with an app.</source>
          <target>Just as people use a combination of voice and gesture when communicating with each other, multiple types and modes of input can also be useful when interacting with an app.</target>
        </segment>
      </unit>
      <unit id="102">
        <segment state="initial">
          <source>Multiple inputs design guidelines</source>
          <target>Multiple inputs design guidelines</target>
        </segment>
      </unit>
      <unit id="103">
        <segment state="initial">
          <source>Multiple inputs</source>
          <target>Multiple inputs</target>
        </segment>
      </unit>
      <unit id="104">
        <segment state="initial">
          <source>Just as people use a combination of voice and gesture when communicating with each other, multiple types and modes of input can also be useful when interacting with an app.</source>
          <target>Just as people use a combination of voice and gesture when communicating with each other, multiple types and modes of input can also be useful when interacting with an app.</target>
        </segment>
      </unit>
      <unit id="105">
        <segment state="initial">
          <source>To accommodate as many users and devices as possible, we recommend that you design your apps to work with as many input types as possible (gesture, speech, touch, touchpad, mouse, and keyboard).</source>
          <target>To accommodate as many users and devices as possible, we recommend that you design your apps to work with as many input types as possible (gesture, speech, touch, touchpad, mouse, and keyboard).</target>
        </segment>
      </unit>
      <unit id="106">
        <segment state="initial">
          <source>Doing so will maximize flexibility, usability, and accessibility.</source>
          <target>Doing so will maximize flexibility, usability, and accessibility.</target>
        </segment>
      </unit>
      <unit id="107">
        <segment state="initial">
          <source>To begin, consider the various scenarios in which your app handles input.</source>
          <target>To begin, consider the various scenarios in which your app handles input.</target>
        </segment>
      </unit>
      <unit id="108">
        <segment state="initial">
          <source>Try to be consistent throughout your app, and remember that the platform controls provide built-in support for multiple input types.</source>
          <target>Try to be consistent throughout your app, and remember that the platform controls provide built-in support for multiple input types.</target>
        </segment>
      </unit>
      <unit id="109">
        <segment state="initial">
          <source>Can users interact with the application through multiple input devices?</source>
          <target>Can users interact with the application through multiple input devices?</target>
        </segment>
      </unit>
      <unit id="110">
        <segment state="initial">
          <source>Are all input methods supported at all times?</source>
          <target>Are all input methods supported at all times?</target>
        </segment>
      </unit>
      <unit id="111">
        <segment state="initial">
          <source>With certain controls?</source>
          <target>With certain controls?</target>
        </segment>
      </unit>
      <unit id="112">
        <segment state="initial">
          <source>At specific times or circumstances?</source>
          <target>At specific times or circumstances?</target>
        </segment>
      </unit>
      <unit id="113">
        <segment state="initial">
          <source>Does one input method take priority?</source>
          <target>Does one input method take priority?</target>
        </segment>
      </unit>
      <unit id="114">
        <segment state="initial">
          <source>Single (or exclusive)-mode interactions</source>
          <target>Single (or exclusive)-mode interactions</target>
        </segment>
      </unit>
      <unit id="115">
        <segment state="initial">
          <source>With single-mode interactions, multiple input types are supported, but only one can be used per action.</source>
          <target>With single-mode interactions, multiple input types are supported, but only one can be used per action.</target>
        </segment>
      </unit>
      <unit id="116">
        <segment state="initial">
          <source>For example, speech recognition for commands, and gestures for navigation; or, text entry using touch or gestures, depending on proximity.</source>
          <target>For example, speech recognition for commands, and gestures for navigation; or, text entry using touch or gestures, depending on proximity.</target>
        </segment>
      </unit>
      <unit id="117">
        <segment state="initial">
          <source>Multimodal interactions</source>
          <target>Multimodal interactions</target>
        </segment>
      </unit>
      <unit id="118">
        <segment state="initial">
          <source>With multimodal interactions, multiple input methods in sequence are used to complete a single action.</source>
          <target>With multimodal interactions, multiple input methods in sequence are used to complete a single action.</target>
        </segment>
      </unit>
      <unit id="119">
        <segment state="initial">
          <source>Speech + gesture</source>
          <target>Speech + gesture</target>
        </segment>
      </unit>
      <unit id="120">
        <segment state="initial">
          <source>The user points to a product, and then says “Add to cart.”</source>
          <target>The user points to a product, and then says “Add to cart.”</target>
        </segment>
      </unit>
      <unit id="121">
        <segment state="initial">
          <source>Speech + touch</source>
          <target>Speech + touch</target>
        </segment>
      </unit>
      <unit id="122">
        <segment state="initial">
          <source>The user selects a photo using press and hold, and then says “Send photo.”</source>
          <target>The user selects a photo using press and hold, and then says “Send photo.”</target>
        </segment>
      </unit>
    </group>
  </file>
</xliff>