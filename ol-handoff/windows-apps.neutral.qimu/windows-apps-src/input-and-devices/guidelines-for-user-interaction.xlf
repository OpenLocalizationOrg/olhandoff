<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns:mda="urn:oasis:names:tc:xliff:metadata:2.0" srcLang="en-US" trgLang="zh-cn" version="2.0" xml:space="default" xmlns="urn:oasis:names:tc:xliff:document:2.0">
  <file id="1">
    <mda:metadata>
      <mda:metaGroup>
        <mda:meta type="oltranslationpriority">
        </mda:meta>
      </mda:metaGroup>
    </mda:metadata>
    <mda:metadata>
      <mda:metaGroup>
        <mda:meta type="olfilepath">windows-apps-src\input-and-devices\guidelines-for-user-interaction.md</mda:meta>
      </mda:metaGroup>
    </mda:metadata>
    <mda:metadata>
      <mda:metaGroup>
        <mda:meta type="olfilehash">67b851ce854c803934c2b97dbe7519e2916383a3</mda:meta>
      </mda:metaGroup>
    </mda:metadata>
    <mda:metadata>
      <mda:metaGroup>
        <mda:meta type="tool-id">mdxliff</mda:meta>
        <mda:meta type="tool-name">mdxliff</mda:meta>
        <mda:meta type="tool-version">1.0-781aacf</mda:meta>
        <mda:meta type="tool-company">Microsoft</mda:meta>
      </mda:metaGroup>
    </mda:metadata>
    <group id="content">
      <unit id="101">
        <segment state="initial">
          <source>Create Universal Windows Platform (UWP) apps with intuitive and distinctive user interaction experiences that are optimized for touch but functionally consistent across input devices.</source>
          <target>Create Universal Windows Platform (UWP) apps with intuitive and distinctive user interaction experiences that are optimized for touch but functionally consistent across input devices.</target>
        </segment>
      </unit>
      <unit id="102">
        <segment state="initial">
          <source>Touch design guidelines</source>
          <target>Touch design guidelines</target>
        </segment>
      </unit>
      <unit id="103">
        <segment state="initial">
          <source>Touch design guidelines</source>
          <target>Touch design guidelines</target>
        </segment>
      </unit>
      <unit id="104">
        <segment state="initial">
          <source>Create Universal Windows Platform (UWP) apps with intuitive and distinctive user interaction experiences that are optimized for touch but functionally consistent across input devices.</source>
          <target>Create Universal Windows Platform (UWP) apps with intuitive and distinctive user interaction experiences that are optimized for touch but functionally consistent across input devices.</target>
        </segment>
      </unit>
      <unit id="105">
        <segment state="initial">
          <source>Dos and don'ts</source>
          <target>Dos and don'ts</target>
        </segment>
      </unit>
      <unit id="106">
        <segment state="initial">
          <source>Design applications with touch interaction as the primary expected input method.</source>
          <target>Design applications with touch interaction as the primary expected input method.</target>
        </segment>
      </unit>
      <unit id="107">
        <segment state="initial">
          <source>Provide visual feedback for interactions of all types (touch, pen, stylus, mouse, etc.)</source>
          <target>Provide visual feedback for interactions of all types (touch, pen, stylus, mouse, etc.)</target>
        </segment>
      </unit>
      <unit id="108">
        <segment state="initial">
          <source>Optimize targeting by adjusting touch target size, contact geometry, scrubbing and rocking.</source>
          <target>Optimize targeting by adjusting touch target size, contact geometry, scrubbing and rocking.</target>
        </segment>
      </unit>
      <unit id="109">
        <segment state="initial">
          <source>Optimize accuracy through the use of snap points and directional "rails".</source>
          <target>Optimize accuracy through the use of snap points and directional "rails".</target>
        </segment>
      </unit>
      <unit id="110">
        <segment state="initial">
          <source>Provide tooltips and handles to help improve touch accuracy for tightly packed UI items.</source>
          <target>Provide tooltips and handles to help improve touch accuracy for tightly packed UI items.</target>
        </segment>
      </unit>
      <unit id="111">
        <segment state="initial">
          <source>Don't use timed interactions whenever possible (example of appropriate use: touch and hold).</source>
          <target>Don't use timed interactions whenever possible (example of appropriate use: touch and hold).</target>
        </segment>
      </unit>
      <unit id="112">
        <segment state="initial">
          <source>Don't use the number of fingers used to distinguish the manipulation whenever possible.</source>
          <target>Don't use the number of fingers used to distinguish the manipulation whenever possible.</target>
        </segment>
      </unit>
      <unit id="113">
        <segment state="initial">
          <source>Additional usage guidance</source>
          <target>Additional usage guidance</target>
        </segment>
      </unit>
      <unit id="114">
        <segment state="initial">
          <source>First and foremost, design your app with the expectation that touch will be the primary input method of your users.</source>
          <target>First and foremost, design your app with the expectation that touch will be the primary input method of your users.</target>
        </segment>
      </unit>
      <unit id="115">
        <segment state="initial">
          <source>If you use the platform controls, support for touchpad, mouse, and pen/stylus requires no additional programming, because Windows 8 provides this for free.</source>
          <target>If you use the platform controls, support for touchpad, mouse, and pen/stylus requires no additional programming, because Windows 8 provides this for free.</target>
        </segment>
      </unit>
      <unit id="116">
        <segment state="initial">
          <source>However, keep in mind that a UI optimized for touch is not always superior to a traditional UI.</source>
          <target>However, keep in mind that a UI optimized for touch is not always superior to a traditional UI.</target>
        </segment>
      </unit>
      <unit id="117">
        <segment state="initial">
          <source>Both provide advantages and disadvantages that are unique to a technology and application.</source>
          <target>Both provide advantages and disadvantages that are unique to a technology and application.</target>
        </segment>
      </unit>
      <unit id="118">
        <segment state="initial">
          <source>In the move to a touch-first UI, it is important to understand the core differences between touch (including touchpad), pen/stylus, mouse, and keyboard input.</source>
          <target>In the move to a touch-first UI, it is important to understand the core differences between touch (including touchpad), pen/stylus, mouse, and keyboard input.</target>
        </segment>
      </unit>
      <unit id="119">
        <segment state="initial">
          <source>Do not take familiar input device properties and behaviors for granted, as touch in Windows 8 does more than simply emulate that functionality.</source>
          <target>Do not take familiar input device properties and behaviors for granted, as touch in Windows 8 does more than simply emulate that functionality.</target>
        </segment>
      </unit>
      <unit id="120">
        <segment state="initial">
          <source>You will find throughout these guidelines that touch input requires a different approach to UI design.</source>
          <target>You will find throughout these guidelines that touch input requires a different approach to UI design.</target>
        </segment>
      </unit>
      <unit id="121">
        <segment state="initial">
          <source>Compare touch interaction requirements</source>
          <target>Compare touch interaction requirements</target>
        </segment>
      </unit>
      <unit id="122">
        <segment state="initial">
          <source>The following table shows some of the differences between input devices that you should consider when you design touch-optimized Windows Store apps.</source>
          <target>The following table shows some of the differences between input devices that you should consider when you design touch-optimized Windows Store apps.</target>
        </segment>
      </unit>
      <unit id="123">
        <segment state="initial">
          <source>Factor Touch interactions Mouse, keyboard, pen/stylus interactions Touchpad Precision The contact area of a fingertip is greater than a single x-y coordinate, which increases the chances of unintended command activations.</source>
          <target>Factor Touch interactions Mouse, keyboard, pen/stylus interactions Touchpad Precision The contact area of a fingertip is greater than a single x-y coordinate, which increases the chances of unintended command activations.</target>
        </segment>
      </unit>
      <unit id="124">
        <segment state="initial">
          <source>The mouse and pen/stylus supply a precise x-y coordinate.</source>
          <target>The mouse and pen/stylus supply a precise x-y coordinate.</target>
        </segment>
      </unit>
      <unit id="125">
        <segment state="initial">
          <source>Same as mouse.</source>
          <target>Same as mouse.</target>
        </segment>
      </unit>
      <unit id="126">
        <segment state="initial">
          <source>The shape of the contact area changes throughout the movement.</source>
          <target>The shape of the contact area changes throughout the movement.</target>
        </segment>
      </unit>
      <unit id="127">
        <segment state="initial">
          <source>Mouse movements and pen/stylus strokes supply precise x-y coordinates.</source>
          <target>Mouse movements and pen/stylus strokes supply precise x-y coordinates.</target>
        </segment>
      </unit>
      <unit id="128">
        <segment state="initial">
          <source>Keyboard focus is explicit.</source>
          <target>Keyboard focus is explicit.</target>
        </segment>
      </unit>
      <unit id="129">
        <segment state="initial">
          <source>Same as mouse.</source>
          <target>Same as mouse.</target>
        </segment>
      </unit>
      <unit id="130">
        <segment state="initial">
          <source>There is no mouse cursor to assist with targeting.</source>
          <target>There is no mouse cursor to assist with targeting.</target>
        </segment>
      </unit>
      <unit id="131">
        <segment state="initial">
          <source>The mouse cursor, pen/stylus cursor, and keyboard focus all assist with targeting.</source>
          <target>The mouse cursor, pen/stylus cursor, and keyboard focus all assist with targeting.</target>
        </segment>
      </unit>
      <unit id="132">
        <segment state="initial">
          <source>Same as mouse.</source>
          <target>Same as mouse.</target>
        </segment>
      </unit>
      <unit id="133">
        <segment state="initial">
          <source>Human anatomy Fingertip movements are imprecise, because a straight-line motion with one or more fingers is difficult.</source>
          <target>Human anatomy Fingertip movements are imprecise, because a straight-line motion with one or more fingers is difficult.</target>
        </segment>
      </unit>
      <unit id="134">
        <segment state="initial">
          <source>This is due to the curvature of hand joints and the number of joints involved in the motion.</source>
          <target>This is due to the curvature of hand joints and the number of joints involved in the motion.</target>
        </segment>
      </unit>
      <unit id="135">
        <segment state="initial">
          <source>It's easier to perform a straight-line motion with the mouse or pen/stylus because the hand that controls them travels a shorter physical distance than the cursor on the screen.</source>
          <target>It's easier to perform a straight-line motion with the mouse or pen/stylus because the hand that controls them travels a shorter physical distance than the cursor on the screen.</target>
        </segment>
      </unit>
      <unit id="136">
        <segment state="initial">
          <source>Same as mouse.</source>
          <target>Same as mouse.</target>
        </segment>
      </unit>
      <unit id="137">
        <segment state="initial">
          <source>Some areas on the touch surface of a display device can be difficult to reach due to finger posture and the user's grip on the device.</source>
          <target>Some areas on the touch surface of a display device can be difficult to reach due to finger posture and the user's grip on the device.</target>
        </segment>
      </unit>
      <unit id="138">
        <segment state="initial">
          <source>The mouse and pen/stylus can reach any part of the screen while any control should be accessible by the keyboard through tab order.</source>
          <target>The mouse and pen/stylus can reach any part of the screen while any control should be accessible by the keyboard through tab order.</target>
        </segment>
      </unit>
      <unit id="139">
        <segment state="initial">
          <source>Finger posture and grip can be an issue.</source>
          <target>Finger posture and grip can be an issue.</target>
        </segment>
      </unit>
      <unit id="140">
        <segment state="initial">
          <source>Objects might be obscured by one or more fingertips or the user's hand.</source>
          <target>Objects might be obscured by one or more fingertips or the user's hand.</target>
        </segment>
      </unit>
      <unit id="141">
        <segment state="initial">
          <source>This is known as occlusion.</source>
          <target>This is known as occlusion.</target>
        </segment>
      </unit>
      <unit id="142">
        <segment state="initial">
          <source>Indirect input devices do not cause occlusion.</source>
          <target>Indirect input devices do not cause occlusion.</target>
        </segment>
      </unit>
      <unit id="143">
        <segment state="initial">
          <source>Same as mouse.</source>
          <target>Same as mouse.</target>
        </segment>
      </unit>
      <unit id="144">
        <segment state="initial">
          <source>Object state Touch uses a two-state model: the touch surface of a display device is either touched (on) or not (off).</source>
          <target>Object state Touch uses a two-state model: the touch surface of a display device is either touched (on) or not (off).</target>
        </segment>
      </unit>
      <unit id="145">
        <segment state="initial">
          <source>There is no hover state that can trigger additional visual feedback.</source>
          <target>There is no hover state that can trigger additional visual feedback.</target>
        </segment>
      </unit>
      <unit id="146">
        <segment state="initial">
          <source>A mouse, pen/stylus, and keyboard all expose a three-state model: up (off), down (on), and hover (focus).</source>
          <target>A mouse, pen/stylus, and keyboard all expose a three-state model: up (off), down (on), and hover (focus).</target>
        </segment>
      </unit>
      <unit id="147">
        <segment state="initial">
          <source>Hover lets users explore and learn through tooltips associated with UI elements.</source>
          <target>Hover lets users explore and learn through tooltips associated with UI elements.</target>
        </segment>
      </unit>
      <unit id="148">
        <segment state="initial">
          <source>Hover and focus effects can relay which objects are interactive and also help with targeting.</source>
          <target>Hover and focus effects can relay which objects are interactive and also help with targeting.</target>
        </segment>
      </unit>
      <unit id="149">
        <segment state="initial">
          <source>Same as mouse.</source>
          <target>Same as mouse.</target>
        </segment>
      </unit>
      <unit id="150">
        <segment state="initial">
          <source>Rich interaction Supports multi-touch: multiple input points (fingertips) on a touch surface.</source>
          <target>Rich interaction Supports multi-touch: multiple input points (fingertips) on a touch surface.</target>
        </segment>
      </unit>
      <unit id="151">
        <segment state="initial">
          <source>Supports a single input point.</source>
          <target>Supports a single input point.</target>
        </segment>
      </unit>
      <unit id="152">
        <segment state="initial">
          <source>Same as touch.</source>
          <target>Same as touch.</target>
        </segment>
      </unit>
      <unit id="153">
        <segment state="initial">
          <source>Supports direct manipulation of objects through gestures such as tapping, dragging, sliding, pinching, and rotating.</source>
          <target>Supports direct manipulation of objects through gestures such as tapping, dragging, sliding, pinching, and rotating.</target>
        </segment>
      </unit>
      <unit id="154">
        <segment state="initial">
          <source>No support for direct manipulation as mouse, pen/stylus, and keyboard are indirect input devices.</source>
          <target>No support for direct manipulation as mouse, pen/stylus, and keyboard are indirect input devices.</target>
        </segment>
      </unit>
      <unit id="155">
        <segment state="initial">
          <source>Same as mouse.</source>
          <target>Same as mouse.</target>
        </segment>
      </unit>
      <unit id="156">
        <segment state="initial">
          <source>Note</source>
          <target>Note</target>
        </segment>
      </unit>
      <unit id="157">
        <segment state="initial">
          <source>Indirect input has had the benefit of more than 25 years of refinement.</source>
          <target>Indirect input has had the benefit of more than 25 years of refinement.</target>
        </segment>
      </unit>
      <unit id="158">
        <segment state="initial">
          <source>Features such as hover-triggered tooltips have been designed to solve UI exploration specifically for touchpad, mouse, pen/stylus, and keyboard input.</source>
          <target>Features such as hover-triggered tooltips have been designed to solve UI exploration specifically for touchpad, mouse, pen/stylus, and keyboard input.</target>
        </segment>
      </unit>
      <unit id="159">
        <segment state="initial">
          <source>UI features like this have been re-designed for the rich experience provided by touch input, without compromising the user experience for these other devices.</source>
          <target>UI features like this have been re-designed for the rich experience provided by touch input, without compromising the user experience for these other devices.</target>
        </segment>
      </unit>
      <unit id="160">
        <segment state="initial">
          <source>Use touch feedback</source>
          <target>Use touch feedback</target>
        </segment>
      </unit>
      <unit id="161">
        <segment state="initial">
          <source>Appropriate visual feedback during interactions with your app helps users recognize, learn, and adapt to how their interactions are interpreted by both the app and Windows 8.</source>
          <target>Appropriate visual feedback during interactions with your app helps users recognize, learn, and adapt to how their interactions are interpreted by both the app and Windows 8.</target>
        </segment>
      </unit>
      <unit id="162">
        <segment state="initial">
          <source>Visual feedback can indicate successful interactions, relay system status, improve the sense of control, reduce errors, help users understand the system and input device, and encourage interaction.</source>
          <target>Visual feedback can indicate successful interactions, relay system status, improve the sense of control, reduce errors, help users understand the system and input device, and encourage interaction.</target>
        </segment>
      </unit>
      <unit id="163">
        <segment state="initial">
          <source>Visual feedback is critical when the user relies on touch input for activities that require accuracy and precision based on location.</source>
          <target>Visual feedback is critical when the user relies on touch input for activities that require accuracy and precision based on location.</target>
        </segment>
      </unit>
      <unit id="164">
        <segment state="initial">
          <source>Display feedback whenever and wherever touch input is detected, to help the user understand any custom targeting rules that are defined by your app and its controls.</source>
          <target>Display feedback whenever and wherever touch input is detected, to help the user understand any custom targeting rules that are defined by your app and its controls.</target>
        </segment>
      </unit>
      <unit id="165">
        <segment state="initial">
          <source>Create an immersive interaction experience</source>
          <target>Create an immersive interaction experience</target>
        </segment>
      </unit>
      <unit id="166">
        <segment state="initial">
          <source>The following techniques enhance the immersive experience of Windows Store apps.</source>
          <target>The following techniques enhance the immersive experience of Windows Store apps.</target>
        </segment>
      </unit>
      <unit id="167">
        <segment state="initial">
          <source>Targeting</source>
          <target>Targeting</target>
        </segment>
      </unit>
      <unit id="168">
        <segment state="initial">
          <source>Targeting is optimized through:</source>
          <target>Targeting is optimized through:</target>
        </segment>
      </unit>
      <unit id="169">
        <segment state="initial">
          <source>Touch target sizes</source>
          <target>Touch target sizes</target>
        </segment>
      </unit>
      <unit id="170">
        <segment state="initial">
          <source>Clear size guidelines ensure that applications provide a comfortable UI that contains objects and controls that are easy and safe to target.</source>
          <target>Clear size guidelines ensure that applications provide a comfortable UI that contains objects and controls that are easy and safe to target.</target>
        </segment>
      </unit>
      <unit id="171">
        <segment state="initial">
          <source>Contact geometry</source>
          <target>Contact geometry</target>
        </segment>
      </unit>
      <unit id="172">
        <segment state="initial">
          <source>The entire contact area of the finger determines the most likely target object.</source>
          <target>The entire contact area of the finger determines the most likely target object.</target>
        </segment>
      </unit>
      <unit id="173">
        <segment state="initial">
          <source>Scrubbing</source>
          <target>Scrubbing</target>
        </segment>
      </unit>
      <unit id="174">
        <segment state="initial">
          <source>Items within a group are easily re-targeted by dragging the finger between them (for example, radio buttons).</source>
          <target>Items within a group are easily re-targeted by dragging the finger between them (for example, radio buttons).</target>
        </segment>
      </unit>
      <unit id="175">
        <segment state="initial">
          <source>The current item is activated when the touch is released.</source>
          <target>The current item is activated when the touch is released.</target>
        </segment>
      </unit>
      <unit id="176">
        <segment state="initial">
          <source>Rocking</source>
          <target>Rocking</target>
        </segment>
      </unit>
      <unit id="177">
        <segment state="initial">
          <source>Densely packed items (for example, hyperlinks) are easily re-targeted by pressing the finger down and, without sliding, rocking it back and forth over the items.</source>
          <target>Densely packed items (for example, hyperlinks) are easily re-targeted by pressing the finger down and, without sliding, rocking it back and forth over the items.</target>
        </segment>
      </unit>
      <unit id="178">
        <segment state="initial">
          <source>Due to occlusion, the current item is identified through a tooltip or the status bar and is activated when the touch is released.</source>
          <target>Due to occlusion, the current item is identified through a tooltip or the status bar and is activated when the touch is released.</target>
        </segment>
      </unit>
      <unit id="179">
        <segment state="initial">
          <source>Accuracy</source>
          <target>Accuracy</target>
        </segment>
      </unit>
      <unit id="180">
        <segment state="initial">
          <source>Design for sloppy interactions by using:</source>
          <target>Design for sloppy interactions by using:</target>
        </segment>
      </unit>
      <unit id="181">
        <segment state="initial">
          <source>Snap-points that can make it easier to stop at desired locations when users interact with content.</source>
          <target>Snap-points that can make it easier to stop at desired locations when users interact with content.</target>
        </segment>
      </unit>
      <unit id="182">
        <segment state="initial">
          <source>Directional "rails" that can assist with vertical or horizontal panning, even when the hand moves in a slight arc.</source>
          <target>Directional "rails" that can assist with vertical or horizontal panning, even when the hand moves in a slight arc.</target>
        </segment>
      </unit>
      <unit id="183">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](guidelines-for-panning.md)</data>
        </originalData>
        <segment state="initial">
          <source>For more information, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Guidelines for panning</pc>.</source>
          <target>For more information, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Guidelines for panning</pc>.</target>
        </segment>
      </unit>
      <unit id="184">
        <segment state="initial">
          <source>Occlusion</source>
          <target>Occlusion</target>
        </segment>
      </unit>
      <unit id="185">
        <segment state="initial">
          <source>Finger and hand occlusion is avoided through:</source>
          <target>Finger and hand occlusion is avoided through:</target>
        </segment>
      </unit>
      <unit id="186">
        <segment state="initial">
          <source>Size and positioning of UI</source>
          <target>Size and positioning of UI</target>
        </segment>
      </unit>
      <unit id="187">
        <segment state="initial">
          <source>Make UI elements big enough so that they cannot be completely covered by a fingertip contact area.</source>
          <target>Make UI elements big enough so that they cannot be completely covered by a fingertip contact area.</target>
        </segment>
      </unit>
      <unit id="188">
        <segment state="initial">
          <source>Position menus and pop-ups above the contact area whenever possible.</source>
          <target>Position menus and pop-ups above the contact area whenever possible.</target>
        </segment>
      </unit>
      <unit id="189">
        <segment state="initial">
          <source>Tooltips</source>
          <target>Tooltips</target>
        </segment>
      </unit>
      <unit id="190">
        <segment state="initial">
          <source>Show tooltips when a user maintains finger contact on an object.</source>
          <target>Show tooltips when a user maintains finger contact on an object.</target>
        </segment>
      </unit>
      <unit id="191">
        <segment state="initial">
          <source>This is useful for describing object functionality.</source>
          <target>This is useful for describing object functionality.</target>
        </segment>
      </unit>
      <unit id="192">
        <segment state="initial">
          <source>The user can drag the fingertip off the object to avoid invoking the tooltip.</source>
          <target>The user can drag the fingertip off the object to avoid invoking the tooltip.</target>
        </segment>
      </unit>
      <unit id="193">
        <segment state="initial">
          <source>For small objects, offset tooltips so they are not covered by the fingertip contact area.</source>
          <target>For small objects, offset tooltips so they are not covered by the fingertip contact area.</target>
        </segment>
      </unit>
      <unit id="194">
        <segment state="initial">
          <source>This is helpful for targeting.</source>
          <target>This is helpful for targeting.</target>
        </segment>
      </unit>
      <unit id="195">
        <segment state="initial">
          <source>Handles for precision</source>
          <target>Handles for precision</target>
        </segment>
      </unit>
      <unit id="196">
        <segment state="initial">
          <source>Where precision is required (for example, text selection), provide selection handles that are offset to improve accuracy.</source>
          <target>Where precision is required (for example, text selection), provide selection handles that are offset to improve accuracy.</target>
        </segment>
      </unit>
      <unit id="197">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](guidelines-for-textselection.md)</data>
        </originalData>
        <segment state="initial">
          <source>For more information, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Guidelines for selecting text and images (Windows Runtime apps)</pc>.</source>
          <target>For more information, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Guidelines for selecting text and images (Windows Runtime apps)</pc>.</target>
        </segment>
      </unit>
      <unit id="198">
        <segment state="initial">
          <source>Timing</source>
          <target>Timing</target>
        </segment>
      </unit>
      <unit id="199">
        <segment state="initial">
          <source>Avoid timed mode changes in favor of direct manipulation.</source>
          <target>Avoid timed mode changes in favor of direct manipulation.</target>
        </segment>
      </unit>
      <unit id="200">
        <segment state="initial">
          <source>Direct manipulation simulates the direct, real-time physical handling of an object.</source>
          <target>Direct manipulation simulates the direct, real-time physical handling of an object.</target>
        </segment>
      </unit>
      <unit id="201">
        <segment state="initial">
          <source>The object responds as the fingers are moved.</source>
          <target>The object responds as the fingers are moved.</target>
        </segment>
      </unit>
      <unit id="202">
        <segment state="initial">
          <source>A timed interaction, on the other hand, occurs after a touch interaction.</source>
          <target>A timed interaction, on the other hand, occurs after a touch interaction.</target>
        </segment>
      </unit>
      <unit id="203">
        <segment state="initial">
          <source>Timed interactions typically depend on invisible thresholds like time, distance, or speed to determine what command to perform.</source>
          <target>Timed interactions typically depend on invisible thresholds like time, distance, or speed to determine what command to perform.</target>
        </segment>
      </unit>
      <unit id="204">
        <segment state="initial">
          <source>Timed interactions have no visual feedback until the system performs the action.</source>
          <target>Timed interactions have no visual feedback until the system performs the action.</target>
        </segment>
      </unit>
      <unit id="205">
        <segment state="initial">
          <source>Direct manipulation provides a number of benefits over timed interactions:</source>
          <target>Direct manipulation provides a number of benefits over timed interactions:</target>
        </segment>
      </unit>
      <unit id="206">
        <segment state="initial">
          <source>Instant visual feedback during interactions make users feel more engaged, confident, and in control.</source>
          <target>Instant visual feedback during interactions make users feel more engaged, confident, and in control.</target>
        </segment>
      </unit>
      <unit id="207">
        <segment state="initial">
          <source>Direct manipulations make it safer to explore a system because they are reversible—users can easily step back through their actions in a logical and intuitive manner.</source>
          <target>Direct manipulations make it safer to explore a system because they are reversible—users can easily step back through their actions in a logical and intuitive manner.</target>
        </segment>
      </unit>
      <unit id="208">
        <segment state="initial">
          <source>Interactions that directly affect objects and mimic real world interactions are more intuitive, discoverable, and memorable.</source>
          <target>Interactions that directly affect objects and mimic real world interactions are more intuitive, discoverable, and memorable.</target>
        </segment>
      </unit>
      <unit id="209">
        <segment state="initial">
          <source>They don't rely on obscure or abstract interactions.</source>
          <target>They don't rely on obscure or abstract interactions.</target>
        </segment>
      </unit>
      <unit id="210">
        <segment state="initial">
          <source>Timed interactions can be difficult to perform, as users must reach arbitrary and invisible thresholds.</source>
          <target>Timed interactions can be difficult to perform, as users must reach arbitrary and invisible thresholds.</target>
        </segment>
      </unit>
      <unit id="211">
        <segment state="initial">
          <source>In addition, the following are strongly recommended:</source>
          <target>In addition, the following are strongly recommended:</target>
        </segment>
      </unit>
      <unit id="212">
        <segment state="initial">
          <source>Manipulations should not be distinguished by the number of fingers used.</source>
          <target>Manipulations should not be distinguished by the number of fingers used.</target>
        </segment>
      </unit>
      <unit id="213">
        <segment state="initial">
          <source>Interactions should support compound manipulations.</source>
          <target>Interactions should support compound manipulations.</target>
        </segment>
      </unit>
      <unit id="214">
        <segment state="initial">
          <source>For example, pinch to zoom while dragging the fingers to pan.</source>
          <target>For example, pinch to zoom while dragging the fingers to pan.</target>
        </segment>
      </unit>
      <unit id="215">
        <segment state="initial">
          <source>Interactions should not be distinguished by time.</source>
          <target>Interactions should not be distinguished by time.</target>
        </segment>
      </unit>
      <unit id="216">
        <segment state="initial">
          <source>The same interaction should have the same outcome regardless of the time taken to perform it.</source>
          <target>The same interaction should have the same outcome regardless of the time taken to perform it.</target>
        </segment>
      </unit>
      <unit id="217">
        <segment state="initial">
          <source>Time-based activations introduce mandatory delays for users and detract from both the immersive nature of direct manipulation and the perception of system responsiveness.</source>
          <target>Time-based activations introduce mandatory delays for users and detract from both the immersive nature of direct manipulation and the perception of system responsiveness.</target>
        </segment>
      </unit>
      <unit id="218">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source>
            <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>  An exception to this is where you use specific timed interactions to assist in learning and exploration (for example, press and hold).</source>
          <target>
            <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>  An exception to this is where you use specific timed interactions to assist in learning and exploration (for example, press and hold).</target>
        </segment>
      </unit>
      <unit id="219">
        <segment state="initial">
          <source>Appropriate descriptions and visual cues have a great effect on the use of advanced interactions.</source>
          <target>Appropriate descriptions and visual cues have a great effect on the use of advanced interactions.</target>
        </segment>
      </unit>
      <unit id="220">
        <segment state="initial">
          <source>Related articles</source>
          <target>Related articles</target>
        </segment>
      </unit>
      <unit id="221">
        <segment state="initial">
          <source>For developers (XAML)</source>
          <target>For developers (XAML)</target>
        </segment>
      </unit>
      <unit id="222">
        <segment state="initial">
          <source>Touch interactions</source>
          <target>Touch interactions</target>
        </segment>
      </unit>
      <unit id="223">
        <segment state="initial">
          <source>Custom user interactions</source>
          <target>Custom user interactions</target>
        </segment>
      </unit>
    </group>
  </file>
</xliff>