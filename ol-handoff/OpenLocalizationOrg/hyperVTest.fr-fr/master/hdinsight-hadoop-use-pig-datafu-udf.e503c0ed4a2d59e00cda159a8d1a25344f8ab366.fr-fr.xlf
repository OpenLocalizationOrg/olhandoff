<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="fr-fr">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Use DataFu with Pig on HDInsight</source>
          <target state="new">Use DataFu with Pig on HDInsight</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>DataFu is a collection of libraries for use with Hadoop.</source>
          <target state="new">DataFu is a collection of libraries for use with Hadoop.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Learn how you can use DataFu with Pig on your HDInsight cluster.</source>
          <target state="new">Learn how you can use DataFu with Pig on your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Use DataFu with pig on HDInsight</source>
          <target state="new">Use DataFu with pig on HDInsight</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>DataFu is a collection of Open Source libraries for use with Hadoop.</source>
          <target state="new">DataFu is a collection of Open Source libraries for use with Hadoop.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>In this document, you will learn how to use DataFu on your HDInsight cluster, and how to use DataFu User Defined Functions (UDF) with Pig.</source>
          <target state="new">In this document, you will learn how to use DataFu on your HDInsight cluster, and how to use DataFu User Defined Functions (UDF) with Pig.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Prerequisites</source>
          <target state="new">Prerequisites</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>An Azure subscription.</source>
          <target state="new">An Azure subscription.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>An Azure HDInsight cluster (Linux or Windows based)</source>
          <target state="new">An Azure HDInsight cluster (Linux or Windows based)</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>A basic familiarity with <bpt id="p1">[</bpt>using Pig on HDInsight<ept id="p1">](hdinsight-use-pig.md)</ept></source>
          <target state="new">A basic familiarity with <bpt id="p1">[</bpt>using Pig on HDInsight<ept id="p1">](hdinsight-use-pig.md)</ept></target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Install DataFu on Linux-based HDInsight</source>
          <target state="new">Install DataFu on Linux-based HDInsight</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source><ph id="ph2">[AZURE.NOTE]</ph><ph id="ph3" /> DataFu is pre-installed on Windows-based HDInsight clusters.</source>
          <target state="new"><ph id="ph2">[AZURE.NOTE]</ph><ph id="ph3" /> DataFu is pre-installed on Windows-based HDInsight clusters.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>If you are using a Windows-based cluster, skip this section.</source>
          <target state="new">If you are using a Windows-based cluster, skip this section.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>DataFu can be downloaded and installed from the Maven repository.</source>
          <target state="new">DataFu can be downloaded and installed from the Maven repository.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Use the following steps to add DataFu to your HDInsight cluster:</source>
          <target state="new">Use the following steps to add DataFu to your HDInsight cluster:</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Connect to your Linux-based HDInsight cluster using SSH.</source>
          <target state="new">Connect to your Linux-based HDInsight cluster using SSH.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>For more information on using SSH with HDInsight, see one of the following documents:</source>
          <target state="new">For more information on using SSH with HDInsight, see one of the following documents:</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source><bpt id="p2">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, OS X, and Unix<ept id="p2">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept></source>
          <target state="new"><bpt id="p2">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, OS X, and Unix<ept id="p2">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept></target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p3">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id="p3">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept></source>
          <target state="new"><bpt id="p3">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id="p3">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept></target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Use the following command to download the DataFu jar file using the wget utility, or copy and paste the link into your browser to begin the download.</source>
          <target state="new">Use the following command to download the DataFu jar file using the wget utility, or copy and paste the link into your browser to begin the download.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Next, upload the file to default storage for your HDInsight cluster.</source>
          <target state="new">Next, upload the file to default storage for your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>This makes the file available to all nodes in the cluster, and the file will stay in storage even if you delete and recreate the cluster.</source>
          <target state="new">This makes the file available to all nodes in the cluster, and the file will stay in storage even if you delete and recreate the cluster.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source><ph id="ph4">[AZURE.NOTE]</ph><ph id="ph5" /> The above example stores the jar in <ph id="ph6">`wasb:///example/jars`</ph><ph id="ph7" /> since this directory already exists on the cluster storage.</source>
          <target state="new"><ph id="ph4">[AZURE.NOTE]</ph><ph id="ph5" /> The above example stores the jar in <ph id="ph6">`wasb:///example/jars`</ph><ph id="ph7" /> since this directory already exists on the cluster storage.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>You can use any location you wish on HDInsight cluster storage.</source>
          <target state="new">You can use any location you wish on HDInsight cluster storage.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Use DataFu With Pig</source>
          <target state="new">Use DataFu With Pig</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>The steps in this section assume that you are familiar with using Pig on HDInsight, and only provide the Pig Latin statements, not the steps on how to use them with the cluster.</source>
          <target state="new">The steps in this section assume that you are familiar with using Pig on HDInsight, and only provide the Pig Latin statements, not the steps on how to use them with the cluster.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>For more information on using Pig with HDInsight, see <bpt id="p4">[</bpt>Use Pig with HDInsight<ept id="p4">](hdinsight-use-pig.md)</ept>.</source>
          <target state="new">For more information on using Pig with HDInsight, see <bpt id="p4">[</bpt>Use Pig with HDInsight<ept id="p4">](hdinsight-use-pig.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source><ph id="ph8">[AZURE.IMPORTANT]</ph><ph id="ph9" /> When using DataFu from Pig on a Linux-based HDInsight cluster, you must first register the jar file using the following Pig Latin statement:</source>
          <target state="new"><ph id="ph8">[AZURE.IMPORTANT]</ph><ph id="ph9" /> When using DataFu from Pig on a Linux-based HDInsight cluster, you must first register the jar file using the following Pig Latin statement:</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>DataFu is registered by default on Windows-based HDInsight clusters.</source>
          <target state="new">DataFu is registered by default on Windows-based HDInsight clusters.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>You will usually define an alias for DataFu functions.</source>
          <target state="new">You will usually define an alias for DataFu functions.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>For example:</source>
          <target state="new">For example:</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>This defines an alias named <ph id="ph11">`SHA`</ph><ph id="ph12" /> for the SHA hashing function.</source>
          <target state="new">This defines an alias named <ph id="ph11">`SHA`</ph><ph id="ph12" /> for the SHA hashing function.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>You can then use this in a Pig Latin script to generate a hash for the input data.</source>
          <target state="new">You can then use this in a Pig Latin script to generate a hash for the input data.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>For example, the following replaces the names in the input data with a hash value:</source>
          <target state="new">For example, the following replaces the names in the input data with a hash value:</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>If this is used with the following input data:</source>
          <target state="new">If this is used with the following input data:</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>It will generate the following output:</source>
          <target state="new">It will generate the following output:</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>For more information on DataFu or Pig, see the following documents:</source>
          <target state="new">For more information on DataFu or Pig, see the following documents:</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source><bpt id="p5">[</bpt>Apache DataFu Pig Guide<ept id="p5">](http://datafu.incubator.apache.org/docs/datafu/guide.html)</ept>.</source>
          <target state="new"><bpt id="p5">[</bpt>Apache DataFu Pig Guide<ept id="p5">](http://datafu.incubator.apache.org/docs/datafu/guide.html)</ept>.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source><bpt id="p6">[</bpt>Use Pig with HDInsight<ept id="p6">](hdinsight-use-pig.md)</ept></source>
          <target state="new"><bpt id="p6">[</bpt>Use Pig with HDInsight<ept id="p6">](hdinsight-use-pig.md)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">67063ab5683fd33e720dc9e65b9431a07001fef7</xliffext:olfilehash>
  </header>
</xliff>