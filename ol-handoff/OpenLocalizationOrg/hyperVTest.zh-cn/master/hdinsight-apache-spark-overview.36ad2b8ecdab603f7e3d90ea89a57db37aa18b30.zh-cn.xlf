<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="zh-cn">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>An overview of Apache Spark in HDInsight | Microsoft Azure</source>
          <target state="new">An overview of Apache Spark in HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>An introduction to Apache Spark in HDInsight and scenarios in which to use Spark on HDInsight in your applications.</source>
          <target state="new">An introduction to Apache Spark in HDInsight and scenarios in which to use Spark on HDInsight in your applications.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Overview: Apache Spark on Azure HDInsight (Linux)</source>
          <target state="new">Overview: Apache Spark on Azure HDInsight (Linux)</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Apache Spark</source>
          <target state="new">Apache Spark</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</source>
          <target state="new">is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Spark processing engine is built for speed, ease of use, and sophisticated analytics.</source>
          <target state="new">Spark processing engine is built for speed, ease of use, and sophisticated analytics.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations.</source>
          <target state="new">Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Spark is also compatible with Azure Blob storage (WASB) so your existing data stored in Azure can easily be processed via Spark.</source>
          <target state="new">Spark is also compatible with Azure Blob storage (WASB) so your existing data stored in Azure can easily be processed via Spark.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>When you create a Spark cluster in HDInsight, you create Azure compute resources with Spark installed and configured.</source>
          <target state="new">When you create a Spark cluster in HDInsight, you create Azure compute resources with Spark installed and configured.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>It only takes about ten minutes to create a Spark cluster in HDInsight.</source>
          <target state="new">It only takes about ten minutes to create a Spark cluster in HDInsight.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>The data to be processed is stored in Azure Blob storage.</source>
          <target state="new">The data to be processed is stored in Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Use Azure Blob Storage with HDInsight<ept id="p1">][hdinsight-storage]</ept>.</source>
          <target state="new">See <bpt id="p1">[</bpt>Use Azure Blob Storage with HDInsight<ept id="p1">][hdinsight-storage]</ept>.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source><ph id="ph2">![</ph>Apache Spark on Azure HDInsight<ph id="ph3">](./media/hdinsight-apache-spark-overview/hdispark.architecture.png  "Apache Spark on Azure HDInsight")</ph></source>
          <target state="new"><ph id="ph2">![</ph>Apache Spark on Azure HDInsight<ph id="ph3">](./media/hdinsight-apache-spark-overview/hdispark.architecture.png  "Apache Spark on Azure HDInsight")</ph></target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source><bpt id="p2">**</bpt>Want to get started with Apache Spark on Azure HDInsight?<ept id="p2">**</ept><ph id="ph4" /> See <bpt id="p3">[</bpt>QuickStart: create a Spark cluster on HDInsight Linux and run sample applications using Jupyter<ept id="p3">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.</source>
          <target state="new"><bpt id="p2">**</bpt>Want to get started with Apache Spark on Azure HDInsight?<ept id="p2">**</ept><ph id="ph4" /> See <bpt id="p3">[</bpt>QuickStart: create a Spark cluster on HDInsight Linux and run sample applications using Jupyter<ept id="p3">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source><ph id="ph5">[AZURE.NOTE]</ph><ph id="ph6" /> For a list of known issues and limitations with the current release, see <bpt id="p4">[</bpt>Known issues of Apache Spark in Azure HDInsight (Linux)<ept id="p4">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.</source>
          <target state="new"><ph id="ph5">[AZURE.NOTE]</ph><ph id="ph6" /> For a list of known issues and limitations with the current release, see <bpt id="p4">[</bpt>Known issues of Apache Spark in Azure HDInsight (Linux)<ept id="p4">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Why use Spark on Azure HDInsight?</source>
          <target state="new">Why use Spark on Azure HDInsight?</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Azure HDInsight offers a fully managed Spark service.</source>
          <target state="new">Azure HDInsight offers a fully managed Spark service.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Benefits of using Spark on HDInsight are:</source>
          <target state="new">Benefits of using Spark on HDInsight are:</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Feature</source>
          <target state="new">Feature</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Description</source>
          <target state="new">Description</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Ease of creating</source>
          <target state="new">Ease of creating</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>You can create a new Spark cluster on HDInsight in minutes using the Azure Management Portal, Azure PowerShell, or the HDInsight .NET SDK.</source>
          <target state="new">You can create a new Spark cluster on HDInsight in minutes using the Azure Management Portal, Azure PowerShell, or the HDInsight .NET SDK.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>See <bpt id="p5">[</bpt>Get started with Spark cluster in HDInsight<ept id="p5">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept></source>
          <target state="new">See <bpt id="p5">[</bpt>Get started with Spark cluster in HDInsight<ept id="p5">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept></target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Ease of use</source>
          <target state="new">Ease of use</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Spark in HDInsight clusters includes Jupyter notebooks pre-configured.</source>
          <target state="new">Spark in HDInsight clusters includes Jupyter notebooks pre-configured.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>You can use these for interactive data processing and visualization.</source>
          <target state="new">You can use these for interactive data processing and visualization.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>The URLs for the is https://CLUSTERNAME.azurehdinsight.net/jupyter.</source>
          <target state="new">The URLs for the is https://CLUSTERNAME.azurehdinsight.net/jupyter.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Replace <bpt id="p6">__</bpt>CLUSTERNAME<ept id="p6">__</ept><ph id="ph7" /> with the name of your Spark HDInsight cluster.</source>
          <target state="new">Replace <bpt id="p6">__</bpt>CLUSTERNAME<ept id="p6">__</ept><ph id="ph7" /> with the name of your Spark HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>REST APIs</source>
          <target state="new">REST APIs</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Spark in HDInsight includes <bpt id="p7">[</bpt>Livy<ept id="p7">](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)</ept>, a REST-API based Spark job server to remotely submit and monitor running jobs.</source>
          <target state="new">Spark in HDInsight includes <bpt id="p7">[</bpt>Livy<ept id="p7">](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)</ept>, a REST-API based Spark job server to remotely submit and monitor running jobs.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>Concurrent Queries</source>
          <target state="new">Concurrent Queries</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Spark in HDInsight supports concurrent queries.</source>
          <target state="new">Spark in HDInsight supports concurrent queries.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>This enables multiple queries from one user or multiple queries from various users and applications to share the same cluster resources.</source>
          <target state="new">This enables multiple queries from one user or multiple queries from various users and applications to share the same cluster resources.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Caching on SSDs</source>
          <target state="new">Caching on SSDs</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>You can choose to cache data either in memory or in SSDs attached to the cluster nodes.</source>
          <target state="new">You can choose to cache data either in memory or in SSDs attached to the cluster nodes.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Caching in memory provides the best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without the need to create a cluster of a size that is required to fit the entire dataset in memory.</source>
          <target state="new">Caching in memory provides the best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without the need to create a cluster of a size that is required to fit the entire dataset in memory.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Integration with Azure services</source>
          <target state="new">Integration with Azure services</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Spark on HDInsight comes with a connector to Azure Event Hubs.</source>
          <target state="new">Spark on HDInsight comes with a connector to Azure Event Hubs.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Customers can build streaming applications using the Event Hubs, in addition to <bpt id="p8">[</bpt>Kafka<ept id="p8">](http://kafka.apache.org/)</ept>, which is already available as part of Spark.</source>
          <target state="new">Customers can build streaming applications using the Event Hubs, in addition to <bpt id="p8">[</bpt>Kafka<ept id="p8">](http://kafka.apache.org/)</ept>, which is already available as part of Spark.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Integration with BI Tools</source>
          <target state="new">Integration with BI Tools</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Spark for HDInsight provides connectors for popular BI tools such as <bpt id="p9">[</bpt>Power BI<ept id="p9">](http://www.powerbi.com/)</ept><ph id="ph8" /> and <bpt id="p10">[</bpt>Tableau<ept id="p10">](http://www.tableau.com/products/desktop)</ept><ph id="ph9" /> for data analytics.</source>
          <target state="new">Spark for HDInsight provides connectors for popular BI tools such as <bpt id="p9">[</bpt>Power BI<ept id="p9">](http://www.powerbi.com/)</ept><ph id="ph8" /> and <bpt id="p10">[</bpt>Tableau<ept id="p10">](http://www.tableau.com/products/desktop)</ept><ph id="ph9" /> for data analytics.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Pre-loaded Anaconda libraries</source>
          <target state="new">Pre-loaded Anaconda libraries</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>Spark clusters on HDInsight come with Anaconda libraries pre-installed.</source>
          <target state="new">Spark clusters on HDInsight come with Anaconda libraries pre-installed.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source><bpt id="p11">[</bpt>Anaconda<ept id="p11">](http://docs.continuum.io/anaconda/)</ept><ph id="ph10" /> provides close to 200 libraries for machine learning, data analysis, visualization, etc.</source>
          <target state="new"><bpt id="p11">[</bpt>Anaconda<ept id="p11">](http://docs.continuum.io/anaconda/)</ept><ph id="ph10" /> provides close to 200 libraries for machine learning, data analysis, visualization, etc.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Scalability</source>
          <target state="new">Scalability</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match workload.</source>
          <target state="new">Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match workload.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>All HDInsight clusters allow you to change the number of nodes in the cluster.</source>
          <target state="new">All HDInsight clusters allow you to change the number of nodes in the cluster.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Also, Spark clusters can be dropped with no loss of data since all the data is stored in Azure Blob Storage.</source>
          <target state="new">Also, Spark clusters can be dropped with no loss of data since all the data is stored in Azure Blob Storage.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>24/7 Support</source>
          <target state="new">24/7 Support</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Spark on HDInsight comes with  enterprise-level 24/7 support and an SLA of 99.9% up-time.</source>
          <target state="new">Spark on HDInsight comes with  enterprise-level 24/7 support and an SLA of 99.9% up-time.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>What are the use cases for Spark on HDInsight?</source>
          <target state="new">What are the use cases for Spark on HDInsight?</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Apache Spark in HDInsight enables the following key scenarios.</source>
          <target state="new">Apache Spark in HDInsight enables the following key scenarios.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>Interactive data analysis and BI</source>
          <target state="new">Interactive data analysis and BI</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source><bpt id="p12">[</bpt>Look at a tutorial<ept id="p12">](hdinsight-apache-spark-use-bi-tools.md)</ept></source>
          <target state="new"><bpt id="p12">[</bpt>Look at a tutorial<ept id="p12">](hdinsight-apache-spark-use-bi-tools.md)</ept></target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Apache Spark in HDInsight stores data in Azure Blobs.</source>
          <target state="new">Apache Spark in HDInsight stores data in Azure Blobs.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI to build interactive reports from the analyzed data.</source>
          <target state="new">Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI to build interactive reports from the analyzed data.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Analysts can start from unstructured/semi structured data in Azure storage, define a schema for the data using notebooks and then build data models using Microsoft Power BI.</source>
          <target state="new">Analysts can start from unstructured/semi structured data in Azure storage, define a schema for the data using notebooks and then build data models using Microsoft Power BI.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>Spark in HDInsight also supports a number of third party BI tools such as Tableau, Qlikview, and SAP Lumira making it an ideal platform for data analysts, business experts, and key decision makers.</source>
          <target state="new">Spark in HDInsight also supports a number of third party BI tools such as Tableau, Qlikview, and SAP Lumira making it an ideal platform for data analysts, business experts, and key decision makers.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Iterative Machine Learning</source>
          <target state="new">Iterative Machine Learning</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source><bpt id="p13">[</bpt>Look at a tutorial: Predict building temperatures uisng HVAC data<ept id="p13">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept></source>
          <target state="new"><bpt id="p13">[</bpt>Look at a tutorial: Predict building temperatures uisng HVAC data<ept id="p13">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept></target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source><bpt id="p14">[</bpt>Look at a tutorial: Predict food inspection results<ept id="p14">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept></source>
          <target state="new"><bpt id="p14">[</bpt>Look at a tutorial: Predict food inspection results<ept id="p14">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept></target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>Apache Spark comes with <bpt id="p15">[</bpt>MLlib<ept id="p15">](http://spark.apache.org/mllib/)</ept>, a machine learning library built on top of Spark.</source>
          <target state="new">Apache Spark comes with <bpt id="p15">[</bpt>MLlib<ept id="p15">](http://spark.apache.org/mllib/)</ept>, a machine learning library built on top of Spark.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>In addition to this, Spark on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.</source>
          <target state="new">In addition to this, Spark on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>Couple this with a built-in support for Jupyter notebooks, and you have a top-of-the-line environment for creating machine learning applications.</source>
          <target state="new">Couple this with a built-in support for Jupyter notebooks, and you have a top-of-the-line environment for creating machine learning applications.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Streaming and real-time data analysis</source>
          <target state="new">Streaming and real-time data analysis</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source><bpt id="p16">[</bpt>Look at a tutorial<ept id="p16">](hdinsight-apache-spark-eventhub-streaming.md)</ept></source>
          <target state="new"><bpt id="p16">[</bpt>Look at a tutorial<ept id="p16">](hdinsight-apache-spark-eventhub-streaming.md)</ept></target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Real-time data analysis is used for scenarios ranging from reducing time to data insight by processing data as it lands, to building a true streaming solution.</source>
          <target state="new">Real-time data analysis is used for scenarios ranging from reducing time to data insight by processing data as it lands, to building a true streaming solution.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Spark in HDInsight offers a rich support for building real-time analytics solutions.</source>
          <target state="new">Spark in HDInsight offers a rich support for building real-time analytics solutions.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>While Spark already has connectors to ingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.</source>
          <target state="new">While Spark already has connectors to ingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Event Hubs are the most widely used queuing service on Azure.</source>
          <target state="new">Event Hubs are the most widely used queuing service on Azure.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Having an out-of-the-box support for Event Hubs makes Spark in HDInsight an ideal platform for building real time analytics pipeline.</source>
          <target state="new">Having an out-of-the-box support for Event Hubs makes Spark in HDInsight an ideal platform for building real time analytics pipeline.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>What components are included as part of a Spark cluster?</source>
          <target state="new">What components are included as part of a Spark cluster?</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>Spark in HDInsight includes the following components that are available on the clusters by default.</source>
          <target state="new">Spark in HDInsight includes the following components that are available on the clusters by default.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source><bpt id="p17">[</bpt>Spark Core<ept id="p17">](https://spark.apache.org/docs/1.5.1/)</ept>.</source>
          <target state="new"><bpt id="p17">[</bpt>Spark Core<ept id="p17">](https://spark.apache.org/docs/1.5.1/)</ept>.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.</source>
          <target state="new">Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source><bpt id="p18">[</bpt>Anaconda<ept id="p18">](http://docs.continuum.io/anaconda/)</ept></source>
          <target state="new"><bpt id="p18">[</bpt>Anaconda<ept id="p18">](http://docs.continuum.io/anaconda/)</ept></target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source><bpt id="p19">[</bpt>Livy<ept id="p19">](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)</ept></source>
          <target state="new"><bpt id="p19">[</bpt>Livy<ept id="p19">](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)</ept></target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source><bpt id="p20">[</bpt>Jupyter Notebook<ept id="p20">](https://jupyter.org)</ept></source>
          <target state="new"><bpt id="p20">[</bpt>Jupyter Notebook<ept id="p20">](https://jupyter.org)</ept></target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>Spark in HDInsight also provides an <bpt id="p21">[</bpt>ODBC driver<ept id="p21">](http://go.microsoft.com/fwlink/?LinkId=616229)</ept><ph id="ph11" /> for connectivity to Spark clusters in HDInsight from BI tools such as Microsoft Power BI and Tableau.</source>
          <target state="new">Spark in HDInsight also provides an <bpt id="p21">[</bpt>ODBC driver<ept id="p21">](http://go.microsoft.com/fwlink/?LinkId=616229)</ept><ph id="ph11" /> for connectivity to Spark clusters in HDInsight from BI tools such as Microsoft Power BI and Tableau.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>Where do I start?</source>
          <target state="new">Where do I start?</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>Start with creating a Spark cluster on HDInsight Linux.</source>
          <target state="new">Start with creating a Spark cluster on HDInsight Linux.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>See <bpt id="p22">[</bpt>QuickStart: create a Spark cluster on HDInsight Linux and run sample applications using Jupyter<ept id="p22">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.</source>
          <target state="new">See <bpt id="p22">[</bpt>QuickStart: create a Spark cluster on HDInsight Linux and run sample applications using Jupyter<ept id="p22">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>Next Steps</source>
          <target state="new">Next Steps</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>Scenarios</source>
          <target state="new">Scenarios</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source><bpt id="p23">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id="p23">](hdinsight-apache-spark-use-bi-tools.md)</ept></source>
          <target state="new"><bpt id="p23">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id="p23">](hdinsight-apache-spark-use-bi-tools.md)</ept></target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source><bpt id="p24">[</bpt>Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data<ept id="p24">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept></source>
          <target state="new"><bpt id="p24">[</bpt>Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data<ept id="p24">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept></target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source><bpt id="p25">[</bpt>Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results<ept id="p25">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept></source>
          <target state="new"><bpt id="p25">[</bpt>Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results<ept id="p25">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept></target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source><bpt id="p26">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id="p26">](hdinsight-apache-spark-eventhub-streaming.md)</ept></source>
          <target state="new"><bpt id="p26">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id="p26">](hdinsight-apache-spark-eventhub-streaming.md)</ept></target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source><bpt id="p27">[</bpt>Website log analysis using Spark in HDInsight<ept id="p27">](hdinsight-apache-spark-custom-library-website-log-analysis.md)</ept></source>
          <target state="new"><bpt id="p27">[</bpt>Website log analysis using Spark in HDInsight<ept id="p27">](hdinsight-apache-spark-custom-library-website-log-analysis.md)</ept></target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>Create and run applications</source>
          <target state="new">Create and run applications</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source><bpt id="p28">[</bpt>Create a standalone application using Scala<ept id="p28">](hdinsight-apache-spark-create-standalone-application.md)</ept></source>
          <target state="new"><bpt id="p28">[</bpt>Create a standalone application using Scala<ept id="p28">](hdinsight-apache-spark-create-standalone-application.md)</ept></target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source><bpt id="p29">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id="p29">](hdinsight-apache-spark-livy-rest-interface.md)</ept></source>
          <target state="new"><bpt id="p29">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id="p29">](hdinsight-apache-spark-livy-rest-interface.md)</ept></target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>Tools and extensions</source>
          <target state="new">Tools and extensions</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source><bpt id="p30">[</bpt>Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons<ept id="p30">](hdinsight-apache-spark-intellij-tool-plugin.md)</ept></source>
          <target state="new"><bpt id="p30">[</bpt>Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons<ept id="p30">](hdinsight-apache-spark-intellij-tool-plugin.md)</ept></target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source><bpt id="p31">[</bpt>Use Zeppelin notebooks with a Spark cluster on HDInsight<ept id="p31">](hdinsight-apache-spark-use-zeppelin-notebook.md)</ept></source>
          <target state="new"><bpt id="p31">[</bpt>Use Zeppelin notebooks with a Spark cluster on HDInsight<ept id="p31">](hdinsight-apache-spark-use-zeppelin-notebook.md)</ept></target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source><bpt id="p32">[</bpt>Kernels available for Jupyter notebook in Spark cluster for HDInsight<ept id="p32">](hdinsight-apache-spark-jupyter-notebook-kernels.md)</ept></source>
          <target state="new"><bpt id="p32">[</bpt>Kernels available for Jupyter notebook in Spark cluster for HDInsight<ept id="p32">](hdinsight-apache-spark-jupyter-notebook-kernels.md)</ept></target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>Manage resources</source>
          <target state="new">Manage resources</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source><bpt id="p33">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id="p33">](hdinsight-apache-spark-resource-manager.md)</ept></source>
          <target state="new"><bpt id="p33">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id="p33">](hdinsight-apache-spark-resource-manager.md)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">48765c06ad6c27d53a5b997601fda17377bb1a28</xliffext:olfilehash>
  </header>
</xliff>