<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="ko-kr">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>The Cortana Analytics Process in action: using SQL Server | Microsoft Azure</source>
          <target state="new">The Cortana Analytics Process in action: using SQL Server | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Advanced Analytics Process and Technology in Action</source>
          <target state="new">Advanced Analytics Process and Technology in Action</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>The Cortana Analytics Process in action: using SQL Server</source>
          <target state="new">The Cortana Analytics Process in action: using SQL Server</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>In this tutorial, you walkthrough building and deploying a model using a publicly available dataset -- the <bpt id="p1">[</bpt>NYC Taxi Trips<ept id="p1">](http://www.andresmh.com/nyctaxitrips/)</ept><ph id="ph2" /> dataset.</source>
          <target state="new">In this tutorial, you walkthrough building and deploying a model using a publicly available dataset -- the <bpt id="p1">[</bpt>NYC Taxi Trips<ept id="p1">](http://www.andresmh.com/nyctaxitrips/)</ept><ph id="ph2" /> dataset.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>The procedure follows the Cortana Analytics Process (CAP) workflow.</source>
          <target state="new">The procedure follows the Cortana Analytics Process (CAP) workflow.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>NYC Taxi Trips Dataset Description</source>
          <target state="new">NYC Taxi Trips Dataset Description</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>The NYC Taxi Trip data is about 20GB of compressed CSV files (~48GB uncompressed), comprising more than 173 million individual trips and the fares paid for each trip.</source>
          <target state="new">The NYC Taxi Trip data is about 20GB of compressed CSV files (~48GB uncompressed), comprising more than 173 million individual trips and the fares paid for each trip.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Each trip record includes the pickup and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</source>
          <target state="new">Each trip record includes the pickup and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>The data covers all trips in the year 2013 and is provided in the following two datasets for each month:</source>
          <target state="new">The data covers all trips in the year 2013 and is provided in the following two datasets for each month:</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>The 'trip_data' CSV contains trip details, such as number of passengers, pickup and dropoff points, trip duration, and trip length.</source>
          <target state="new">The 'trip_data' CSV contains trip details, such as number of passengers, pickup and dropoff points, trip duration, and trip length.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Here are a few sample records:</source>
          <target state="new">Here are a few sample records:</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>The 'trip_fare' CSV contains details of the fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and the total amount paid.</source>
          <target state="new">The 'trip_fare' CSV contains details of the fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and the total amount paid.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Here are a few sample records:</source>
          <target state="new">Here are a few sample records:</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>The unique key to join trip\_data and trip\_fare is composed of the fields: medallion, hack\_licence and pickup\_datetime.</source>
          <target state="new">The unique key to join trip\_data and trip\_fare is composed of the fields: medallion, hack\_licence and pickup\_datetime.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Examples of Prediction Tasks</source>
          <target state="new">Examples of Prediction Tasks</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>We will formulate three prediction problems based on the <bpt id="p2">*</bpt>tip\_amount<ept id="p2">*</ept>, namely:</source>
          <target state="new">We will formulate three prediction problems based on the <bpt id="p2">*</bpt>tip\_amount<ept id="p2">*</ept>, namely:</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Binary classification: Predict whether or not a tip was paid for a trip, i.e. a <bpt id="p3">*</bpt>tip\_amount<ept id="p3">*</ept><ph id="ph3" /> that is greater than $0 is a positive example, while a <bpt id="p4">*</bpt>tip\_amount<ept id="p4">*</ept><ph id="ph4" /> of $0 is a negative example.</source>
          <target state="new">Binary classification: Predict whether or not a tip was paid for a trip, i.e. a <bpt id="p3">*</bpt>tip\_amount<ept id="p3">*</ept><ph id="ph3" /> that is greater than $0 is a positive example, while a <bpt id="p4">*</bpt>tip\_amount<ept id="p4">*</ept><ph id="ph4" /> of $0 is a negative example.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Multiclass classification: To predict the range of tip paid for the trip.</source>
          <target state="new">Multiclass classification: To predict the range of tip paid for the trip.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>We divide the <bpt id="p5">*</bpt>tip\_amount<ept id="p5">*</ept><ph id="ph5" /> into five bins or classes:</source>
          <target state="new">We divide the <bpt id="p5">*</bpt>tip\_amount<ept id="p5">*</ept><ph id="ph5" /> into five bins or classes:</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Regression task: To predict the amount of tip paid for a trip.</source>
          <target state="new">Regression task: To predict the amount of tip paid for a trip.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Setting Up the Azure data science environment for advanced analytics</source>
          <target state="new">Setting Up the Azure data science environment for advanced analytics</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>As you can see from the <bpt id="p6">[</bpt>Plan Your Environment<ept id="p6">](machine-learning-data-science-plan-your-environment.md)</ept><ph id="ph6" /> guide, there are several options to work with the NYC Taxi Trips dataset in Azure:</source>
          <target state="new">As you can see from the <bpt id="p6">[</bpt>Plan Your Environment<ept id="p6">](machine-learning-data-science-plan-your-environment.md)</ept><ph id="ph6" /> guide, there are several options to work with the NYC Taxi Trips dataset in Azure:</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Work with the data in Azure blobs then model in Azure Machine Learning</source>
          <target state="new">Work with the data in Azure blobs then model in Azure Machine Learning</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Load the data into a SQL Server database then model in Azure Machine Learning</source>
          <target state="new">Load the data into a SQL Server database then model in Azure Machine Learning</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>In this tutorial we will demonstrate parallel bulk import of the data to a SQL Server, data exploration, feature engineering and down sampling using SQL Server Management Studio as well as using IPython Notebook.</source>
          <target state="new">In this tutorial we will demonstrate parallel bulk import of the data to a SQL Server, data exploration, feature engineering and down sampling using SQL Server Management Studio as well as using IPython Notebook.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source><bpt id="p7">[</bpt>Sample scripts<ept id="p7">](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/DataScienceProcess/DataScienceScripts)</ept><ph id="ph7" /> and <bpt id="p8">[</bpt>IPython notebooks<ept id="p8">](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/DataScienceProcess/iPythonNotebooks)</ept><ph id="ph8" /> are shared in GitHub.</source>
          <target state="new"><bpt id="p7">[</bpt>Sample scripts<ept id="p7">](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/DataScienceProcess/DataScienceScripts)</ept><ph id="ph7" /> and <bpt id="p8">[</bpt>IPython notebooks<ept id="p8">](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/DataScienceProcess/iPythonNotebooks)</ept><ph id="ph8" /> are shared in GitHub.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>A sample IPython notebook to work with the data in Azure blobs is also available in the same location.</source>
          <target state="new">A sample IPython notebook to work with the data in Azure blobs is also available in the same location.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>To set up your Azure Data Science environment:</source>
          <target state="new">To set up your Azure Data Science environment:</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source><bpt id="p9">[</bpt>Create a storage account<ept id="p9">](../storage-create-storage-account.md)</ept></source>
          <target state="new"><bpt id="p9">[</bpt>Create a storage account<ept id="p9">](../storage-create-storage-account.md)</ept></target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source><bpt id="p10">[</bpt>Create an Azure ML workspace<ept id="p10">](machine-learning-create-workspace.md)</ept></source>
          <target state="new"><bpt id="p10">[</bpt>Create an Azure ML workspace<ept id="p10">](machine-learning-create-workspace.md)</ept></target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><bpt id="p11">[</bpt>Provision a Data Science Virtual Machine<ept id="p11">](machine-learning-data-science-setup-sql-server-virtual-machine.md)</ept>, which will serve as a SQL Server as well an IPython Notebook server.</source>
          <target state="new"><bpt id="p11">[</bpt>Provision a Data Science Virtual Machine<ept id="p11">](machine-learning-data-science-setup-sql-server-virtual-machine.md)</ept>, which will serve as a SQL Server as well an IPython Notebook server.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source><ph id="ph9">[AZURE.NOTE]</ph><ph id="ph10" /> The sample scripts and IPython notebooks will be downloaded to your Data Science virtual machine during the setup process.</source>
          <target state="new"><ph id="ph9">[AZURE.NOTE]</ph><ph id="ph10" /> The sample scripts and IPython notebooks will be downloaded to your Data Science virtual machine during the setup process.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>When the VM post-installation script completes, the samples will be in your VM's Documents library:</source>
          <target state="new">When the VM post-installation script completes, the samples will be in your VM's Documents library:</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Sample Scripts: <ph id="ph11">`C:\Users\&lt;user_name&gt;\Documents\Data Science Scripts`</ph></source>
          <target state="new">Sample Scripts: <ph id="ph11">`C:\Users\&lt;user_name&gt;\Documents\Data Science Scripts`</ph></target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Sample IPython Notebooks: <ph id="ph12">`C:\Users\&lt;user_name&gt;\Documents\IPython Notebooks\DataScienceSamples`</ph><ph id="ph13" />  
where <ph id="ph14">`&lt;user_name&gt;`</ph><ph id="ph15" /> is your VM's Windows login name.</source>
          <target state="new">Sample IPython Notebooks: <ph id="ph12">`C:\Users\&lt;user_name&gt;\Documents\IPython Notebooks\DataScienceSamples`</ph><ph id="ph13" />  
where <ph id="ph14">`&lt;user_name&gt;`</ph><ph id="ph15" /> is your VM's Windows login name.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>We will refer to the sample folders as <bpt id="p12">**</bpt>Sample Scripts<ept id="p12">**</ept><ph id="ph16" /> and <bpt id="p13">**</bpt>Sample IPython Notebooks<ept id="p13">**</ept>.</source>
          <target state="new">We will refer to the sample folders as <bpt id="p12">**</bpt>Sample Scripts<ept id="p12">**</ept><ph id="ph16" /> and <bpt id="p13">**</bpt>Sample IPython Notebooks<ept id="p13">**</ept>.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Based on the dataset size, data source location, and the selected Azure target environment, this scenario is similar to <bpt id="p14">[</bpt>Scenario \#5: Large dataset in a local files, target SQL Server in Azure VM<ept id="p14">](../machine-learning-data-science-plan-sample-scenarios.md#largelocaltodb)</ept>.</source>
          <target state="new">Based on the dataset size, data source location, and the selected Azure target environment, this scenario is similar to <bpt id="p14">[</bpt>Scenario \#5: Large dataset in a local files, target SQL Server in Azure VM<ept id="p14">](../machine-learning-data-science-plan-sample-scenarios.md#largelocaltodb)</ept>.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Get the Data from Public Source</source>
          <target state="new">Get the Data from Public Source</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>To get the <bpt id="p15">[</bpt>NYC Taxi Trips<ept id="p15">](http://www.andresmh.com/nyctaxitrips/)</ept><ph id="ph17" /> dataset from its public location, you may use any of the methods described in <bpt id="p16">[</bpt>Move Data to and from Azure Blob Storage<ept id="p16">](machine-learning-data-science-move-azure-blob.md)</ept><ph id="ph18" /> to copy the data to your new virtual machine.</source>
          <target state="new">To get the <bpt id="p15">[</bpt>NYC Taxi Trips<ept id="p15">](http://www.andresmh.com/nyctaxitrips/)</ept><ph id="ph17" /> dataset from its public location, you may use any of the methods described in <bpt id="p16">[</bpt>Move Data to and from Azure Blob Storage<ept id="p16">](machine-learning-data-science-move-azure-blob.md)</ept><ph id="ph18" /> to copy the data to your new virtual machine.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>To copy the data using AzCopy:</source>
          <target state="new">To copy the data using AzCopy:</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Log in to your virtual machine (VM)</source>
          <target state="new">Log in to your virtual machine (VM)</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Create a new directory in the VM's data disk (Note: Do not use the Temporary Disk which comes with the VM as a Data Disk).</source>
          <target state="new">Create a new directory in the VM's data disk (Note: Do not use the Temporary Disk which comes with the VM as a Data Disk).</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>In a Command Prompt window, run the following Azcopy command line, replacing &lt;path_to_data_folder&gt; with your data folder created in (2):</source>
          <target state="new">In a Command Prompt window, run the following Azcopy command line, replacing &lt;path_to_data_folder&gt; with your data folder created in (2):</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>When the AzCopy completes, a total of 24 zipped CSV files (12 for trip\_data and 12 for trip\_fare) should be in the data folder.</source>
          <target state="new">When the AzCopy completes, a total of 24 zipped CSV files (12 for trip\_data and 12 for trip\_fare) should be in the data folder.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Unzip the downloaded files. Note</source>
          <target state="new">Unzip the downloaded files. Note</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>the folder where the uncompressed files reside. This</source>
          <target state="new">the folder where the uncompressed files reside. This</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>folder will be referred to as the &lt;path\_to\_data\_files\&gt;.</source>
          <target state="new">folder will be referred to as the &lt;path\_to\_data\_files\&gt;.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Bulk Import Data into SQL Server Database</source>
          <target state="new">Bulk Import Data into SQL Server Database</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>The performance of loading/transferring large amounts of data to an SQL database and subsequent queries can be improved by using <bpt id="p17">_</bpt>Partitioned Tables and Views<ept id="p17">_</ept>.</source>
          <target state="new">The performance of loading/transferring large amounts of data to an SQL database and subsequent queries can be improved by using <bpt id="p17">_</bpt>Partitioned Tables and Views<ept id="p17">_</ept>.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>In this section, we will follow the instructions described in <bpt id="p18">[</bpt>Parallel Bulk Data Import Using SQL Partition Tables<ept id="p18">](machine-learning-data-science-parallel-load-sql-partitioned-tables.md)</ept><ph id="ph19" /> to create a new database and load the data into partitioned tables in parallel.</source>
          <target state="new">In this section, we will follow the instructions described in <bpt id="p18">[</bpt>Parallel Bulk Data Import Using SQL Partition Tables<ept id="p18">](machine-learning-data-science-parallel-load-sql-partitioned-tables.md)</ept><ph id="ph19" /> to create a new database and load the data into partitioned tables in parallel.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>While logged in to your VM, start <bpt id="p19">**</bpt>SQL Server Management Studio<ept id="p19">**</ept>.</source>
          <target state="new">While logged in to your VM, start <bpt id="p19">**</bpt>SQL Server Management Studio<ept id="p19">**</ept>.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Connect using Windows Authentication.</source>
          <target state="new">Connect using Windows Authentication.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source><ph id="ph20">![</ph>SSMS Connect<ph id="ph21">][12]</ph></source>
          <target state="new"><ph id="ph20">![</ph>SSMS Connect<ph id="ph21">][12]</ph></target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>If you have not yet changed the SQL Server authentication mode and created a new SQL login user, open the script file named <bpt id="p20">**</bpt>change\_auth.sql<ept id="p20">**</ept><ph id="ph22" /> in the <bpt id="p21">**</bpt>Sample Scripts<ept id="p21">**</ept><ph id="ph23" /> folder.</source>
          <target state="new">If you have not yet changed the SQL Server authentication mode and created a new SQL login user, open the script file named <bpt id="p20">**</bpt>change\_auth.sql<ept id="p20">**</ept><ph id="ph22" /> in the <bpt id="p21">**</bpt>Sample Scripts<ept id="p21">**</ept><ph id="ph23" /> folder.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Change the  default user name and password.</source>
          <target state="new">Change the  default user name and password.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p22">**</bpt>!Execute<ept id="p22">**</ept><ph id="ph24" /> in the toolbar to run the script.</source>
          <target state="new">Click <bpt id="p22">**</bpt>!Execute<ept id="p22">**</ept><ph id="ph24" /> in the toolbar to run the script.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source><ph id="ph25">![</ph>Execute Script<ph id="ph26">][13]</ph></source>
          <target state="new"><ph id="ph25">![</ph>Execute Script<ph id="ph26">][13]</ph></target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>Verify and/or change the SQL Server default database and log folders to ensure that newly created databases will be stored in a Data Disk.</source>
          <target state="new">Verify and/or change the SQL Server default database and log folders to ensure that newly created databases will be stored in a Data Disk.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>The SQL Server VM image that is optimized for datawarehousing loads is pre-configured with data and log disks.</source>
          <target state="new">The SQL Server VM image that is optimized for datawarehousing loads is pre-configured with data and log disks.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>If your VM did not include a Data Disk and you added new virtual hard disks during the VM setup process, change the default folders as follows:</source>
          <target state="new">If your VM did not include a Data Disk and you added new virtual hard disks during the VM setup process, change the default folders as follows:</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Right-click the SQL Server name in the left panel and click <bpt id="p23">**</bpt>Properties<ept id="p23">**</ept>.</source>
          <target state="new">Right-click the SQL Server name in the left panel and click <bpt id="p23">**</bpt>Properties<ept id="p23">**</ept>.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source><ph id="ph27">![</ph>SQL Server Properties<ph id="ph28">][14]</ph></source>
          <target state="new"><ph id="ph27">![</ph>SQL Server Properties<ph id="ph28">][14]</ph></target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p24">**</bpt>Database Settings<ept id="p24">**</ept><ph id="ph29" /> from the <bpt id="p25">**</bpt>Select a page<ept id="p25">**</ept><ph id="ph30" /> list to the left.</source>
          <target state="new">Select <bpt id="p24">**</bpt>Database Settings<ept id="p24">**</ept><ph id="ph29" /> from the <bpt id="p25">**</bpt>Select a page<ept id="p25">**</ept><ph id="ph30" /> list to the left.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>Verify and/or change the <bpt id="p26">**</bpt>Database default locations<ept id="p26">**</ept><ph id="ph31" /> to the <bpt id="p27">**</bpt>Data Disk<ept id="p27">**</ept><ph id="ph32" /> locations of your choice.</source>
          <target state="new">Verify and/or change the <bpt id="p26">**</bpt>Database default locations<ept id="p26">**</ept><ph id="ph31" /> to the <bpt id="p27">**</bpt>Data Disk<ept id="p27">**</ept><ph id="ph32" /> locations of your choice.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>This is where new databases reside if created with the default location settings.</source>
          <target state="new">This is where new databases reside if created with the default location settings.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source><ph id="ph33">![</ph>SQL Database Defaults<ph id="ph34">][15]</ph></source>
          <target state="new"><ph id="ph33">![</ph>SQL Database Defaults<ph id="ph34">][15]</ph></target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>To create a new database and a set of filegroups to hold the partitioned tables, open the sample script <bpt id="p28">**</bpt>create\_db\_default.sql<ept id="p28">**</ept>.</source>
          <target state="new">To create a new database and a set of filegroups to hold the partitioned tables, open the sample script <bpt id="p28">**</bpt>create\_db\_default.sql<ept id="p28">**</ept>.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>The script will create a new database named <bpt id="p29">**</bpt>TaxiNYC<ept id="p29">**</ept><ph id="ph35" /> and 12 filegroups in the default data location.</source>
          <target state="new">The script will create a new database named <bpt id="p29">**</bpt>TaxiNYC<ept id="p29">**</ept><ph id="ph35" /> and 12 filegroups in the default data location.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Each filegroup will hold one month of trip\_data and trip\_fare data.</source>
          <target state="new">Each filegroup will hold one month of trip\_data and trip\_fare data.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Modify the database name, if desired.</source>
          <target state="new">Modify the database name, if desired.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p30">**</bpt>!Execute<ept id="p30">**</ept><ph id="ph36" /> to run the script.</source>
          <target state="new">Click <bpt id="p30">**</bpt>!Execute<ept id="p30">**</ept><ph id="ph36" /> to run the script.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>Next, create two partition tables, one for the trip\_data and another for the trip\_fare.</source>
          <target state="new">Next, create two partition tables, one for the trip\_data and another for the trip\_fare.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Open the sample script <bpt id="p31">**</bpt>create\_partitioned\_table.sql<ept id="p31">**</ept>, which will:</source>
          <target state="new">Open the sample script <bpt id="p31">**</bpt>create\_partitioned\_table.sql<ept id="p31">**</ept>, which will:</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>Create a partition function to split the data by month.</source>
          <target state="new">Create a partition function to split the data by month.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>Create a partition scheme to map each month's data to a different filegroup.</source>
          <target state="new">Create a partition scheme to map each month's data to a different filegroup.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Create two partitioned tables mapped to the partition scheme: <bpt id="p32">**</bpt>nyctaxi\_trip<ept id="p32">**</ept><ph id="ph37" /> will hold the trip\_data and <bpt id="p33">**</bpt>nyctaxi\_fare<ept id="p33">**</ept><ph id="ph38" /> will hold the trip\_fare data.</source>
          <target state="new">Create two partitioned tables mapped to the partition scheme: <bpt id="p32">**</bpt>nyctaxi\_trip<ept id="p32">**</ept><ph id="ph37" /> will hold the trip\_data and <bpt id="p33">**</bpt>nyctaxi\_fare<ept id="p33">**</ept><ph id="ph38" /> will hold the trip\_fare data.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p34">**</bpt>!Execute<ept id="p34">**</ept><ph id="ph39" /> to run the script and create the partitioned tables.</source>
          <target state="new">Click <bpt id="p34">**</bpt>!Execute<ept id="p34">**</ept><ph id="ph39" /> to run the script and create the partitioned tables.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p35">**</bpt>Sample Scripts<ept id="p35">**</ept><ph id="ph40" /> folder, there are two sample PowerShell scripts provided to demonstrate parallel bulk imports of data to SQL Server tables.</source>
          <target state="new">In the <bpt id="p35">**</bpt>Sample Scripts<ept id="p35">**</ept><ph id="ph40" /> folder, there are two sample PowerShell scripts provided to demonstrate parallel bulk imports of data to SQL Server tables.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source><bpt id="p36">**</bpt>bcp\_parallel\_generic.ps1<ept id="p36">**</ept><ph id="ph41" /> is a generic script to parallel bulk import data into a table.</source>
          <target state="new"><bpt id="p36">**</bpt>bcp\_parallel\_generic.ps1<ept id="p36">**</ept><ph id="ph41" /> is a generic script to parallel bulk import data into a table.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>Modify this script to set the input and target variables as indicated in the comment lines in the script.</source>
          <target state="new">Modify this script to set the input and target variables as indicated in the comment lines in the script.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source><bpt id="p37">**</bpt>bcp\_parallel\_nyctaxi.ps1<ept id="p37">**</ept><ph id="ph42" /> is a pre-configured version of the generic script and can be used to to load both tables for the NYC Taxi Trips data.</source>
          <target state="new"><bpt id="p37">**</bpt>bcp\_parallel\_nyctaxi.ps1<ept id="p37">**</ept><ph id="ph42" /> is a pre-configured version of the generic script and can be used to to load both tables for the NYC Taxi Trips data.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>Right-click the <bpt id="p38">**</bpt>bcp\_parallel\_nyctaxi.ps1<ept id="p38">**</ept><ph id="ph43" /> script name and click <bpt id="p39">**</bpt>Edit<ept id="p39">**</ept><ph id="ph44" /> to open it in PowerShell.</source>
          <target state="new">Right-click the <bpt id="p38">**</bpt>bcp\_parallel\_nyctaxi.ps1<ept id="p38">**</ept><ph id="ph43" /> script name and click <bpt id="p39">**</bpt>Edit<ept id="p39">**</ept><ph id="ph44" /> to open it in PowerShell.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>Review the preset variables and modify according to your selected database name, input data folder, target log folder, and paths to the  sample format files <bpt id="p40">**</bpt>nyctaxi_trip.xml<ept id="p40">**</ept><ph id="ph45" /> and <bpt id="p41">**</bpt>nyctaxi\_fare.xml<ept id="p41">**</ept><ph id="ph46" /> (provided in the <bpt id="p42">**</bpt>Sample Scripts<ept id="p42">**</ept><ph id="ph47" /> folder).</source>
          <target state="new">Review the preset variables and modify according to your selected database name, input data folder, target log folder, and paths to the  sample format files <bpt id="p40">**</bpt>nyctaxi_trip.xml<ept id="p40">**</ept><ph id="ph45" /> and <bpt id="p41">**</bpt>nyctaxi\_fare.xml<ept id="p41">**</ept><ph id="ph46" /> (provided in the <bpt id="p42">**</bpt>Sample Scripts<ept id="p42">**</ept><ph id="ph47" /> folder).</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source><ph id="ph48">![</ph>Bulk Import Data<ph id="ph49">][16]</ph></source>
          <target state="new"><ph id="ph48">![</ph>Bulk Import Data<ph id="ph49">][16]</ph></target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>You may also select the authentication mode, default is Windows Authentication.</source>
          <target state="new">You may also select the authentication mode, default is Windows Authentication.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>Click the green arrow in the toolbar to run.</source>
          <target state="new">Click the green arrow in the toolbar to run.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>The script will launch 24 bulk import operations in parallel, 12 for each partitioned table.</source>
          <target state="new">The script will launch 24 bulk import operations in parallel, 12 for each partitioned table.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>You may monitor the data import progress by opening the SQL Server default data folder as set above.</source>
          <target state="new">You may monitor the data import progress by opening the SQL Server default data folder as set above.</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>The PowerShell script reports the starting and ending times.</source>
          <target state="new">The PowerShell script reports the starting and ending times.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>When all bulk imports complete, the ending time is reported.</source>
          <target state="new">When all bulk imports complete, the ending time is reported.</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>Check the target log folder to verify that the bulk imports were successful, i.e., no errors reported in the target log folder.</source>
          <target state="new">Check the target log folder to verify that the bulk imports were successful, i.e., no errors reported in the target log folder.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>Your database is now ready for exploration, feature engineering, and other operations as desired.</source>
          <target state="new">Your database is now ready for exploration, feature engineering, and other operations as desired.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>Since the tables are partitioned according to the <bpt id="p43">**</bpt>pickup\_datetime<ept id="p43">**</ept><ph id="ph50" /> field, queries which include <bpt id="p44">**</bpt>pickup\_datetime<ept id="p44">**</ept><ph id="ph51" /> conditions in the <bpt id="p45">**</bpt>WHERE<ept id="p45">**</ept><ph id="ph52" /> clause will benefit from the partition scheme.</source>
          <target state="new">Since the tables are partitioned according to the <bpt id="p43">**</bpt>pickup\_datetime<ept id="p43">**</ept><ph id="ph50" /> field, queries which include <bpt id="p44">**</bpt>pickup\_datetime<ept id="p44">**</ept><ph id="ph51" /> conditions in the <bpt id="p45">**</bpt>WHERE<ept id="p45">**</ept><ph id="ph52" /> clause will benefit from the partition scheme.</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>In <bpt id="p46">**</bpt>SQL Server Management Studio<ept id="p46">**</ept>, explore the provided sample script <bpt id="p47">**</bpt>sample\_queries.sql<ept id="p47">**</ept>.</source>
          <target state="new">In <bpt id="p46">**</bpt>SQL Server Management Studio<ept id="p46">**</ept>, explore the provided sample script <bpt id="p47">**</bpt>sample\_queries.sql<ept id="p47">**</ept>.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>To run any of the sample queries, highlight the query lines then click <bpt id="p48">**</bpt>!Execute<ept id="p48">**</ept><ph id="ph53" /> in the toolbar.</source>
          <target state="new">To run any of the sample queries, highlight the query lines then click <bpt id="p48">**</bpt>!Execute<ept id="p48">**</ept><ph id="ph53" /> in the toolbar.</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>The NYC Taxi Trips data is loaded in two separate tables.</source>
          <target state="new">The NYC Taxi Trips data is loaded in two separate tables.</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>To improve join operations, it is highly recommended to index the tables.</source>
          <target state="new">To improve join operations, it is highly recommended to index the tables.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>The sample script <bpt id="p49">**</bpt>create\_partitioned\_index.sql<ept id="p49">**</ept><ph id="ph54" /> creates partitioned indexes on the composite join key <bpt id="p50">**</bpt>medallion, hack\_license, and pickup\_datetime<ept id="p50">**</ept>.</source>
          <target state="new">The sample script <bpt id="p49">**</bpt>create\_partitioned\_index.sql<ept id="p49">**</ept><ph id="ph54" /> creates partitioned indexes on the composite join key <bpt id="p50">**</bpt>medallion, hack\_license, and pickup\_datetime<ept id="p50">**</ept>.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>Data Exploration and Feature Engineering in SQL Server</source>
          <target state="new">Data Exploration and Feature Engineering in SQL Server</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>In this section, we will perform data exploration and feature generation by running SQL queries directly in the <bpt id="p51">**</bpt>SQL Server Management Studio<ept id="p51">**</ept><ph id="ph55" /> using the SQL Server database created earlier.</source>
          <target state="new">In this section, we will perform data exploration and feature generation by running SQL queries directly in the <bpt id="p51">**</bpt>SQL Server Management Studio<ept id="p51">**</ept><ph id="ph55" /> using the SQL Server database created earlier.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>A sample script named <bpt id="p52">**</bpt>sample\_queries.sql<ept id="p52">**</ept><ph id="ph56" /> is provided in the <bpt id="p53">**</bpt>Sample Scripts<ept id="p53">**</ept><ph id="ph57" /> folder.</source>
          <target state="new">A sample script named <bpt id="p52">**</bpt>sample\_queries.sql<ept id="p52">**</ept><ph id="ph56" /> is provided in the <bpt id="p53">**</bpt>Sample Scripts<ept id="p53">**</ept><ph id="ph57" /> folder.</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>Modify the script to change the database name, if it is different from the default: <bpt id="p54">**</bpt>TaxiNYC<ept id="p54">**</ept>.</source>
          <target state="new">Modify the script to change the database name, if it is different from the default: <bpt id="p54">**</bpt>TaxiNYC<ept id="p54">**</ept>.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>In this exercise, we will:</source>
          <target state="new">In this exercise, we will:</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>Connect to <bpt id="p55">**</bpt>SQL Server Management Studio<ept id="p55">**</ept><ph id="ph58" /> using either Windows Authentication or using SQL Authentication and the SQL login name and password.</source>
          <target state="new">Connect to <bpt id="p55">**</bpt>SQL Server Management Studio<ept id="p55">**</ept><ph id="ph58" /> using either Windows Authentication or using SQL Authentication and the SQL login name and password.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>Explore data distributions of a few fields in varying time windows.</source>
          <target state="new">Explore data distributions of a few fields in varying time windows.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>Investigate data quality of the longitude and latitude fields.</source>
          <target state="new">Investigate data quality of the longitude and latitude fields.</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>Generate binary and multiclass classification labels based on the <bpt id="p56">**</bpt>tip\_amount<ept id="p56">**</ept>.</source>
          <target state="new">Generate binary and multiclass classification labels based on the <bpt id="p56">**</bpt>tip\_amount<ept id="p56">**</ept>.</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>Generate features and compute/compare trip distances.</source>
          <target state="new">Generate features and compute/compare trip distances.</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>Join the two tables and extract a random sample that will be used to build models.</source>
          <target state="new">Join the two tables and extract a random sample that will be used to build models.</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>When you are ready to proceed to Azure Machine Learning, you may either:</source>
          <target state="new">When you are ready to proceed to Azure Machine Learning, you may either:</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>Save the final SQL query to extract and sample the data and copy-paste the query directly into a [Reader][reader] module in Azure Machine Learning, or</source>
          <target state="new">Save the final SQL query to extract and sample the data and copy-paste the query directly into a [Reader][reader] module in Azure Machine Learning, or</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>Persist the sampled and engineered data you plan to use for model building in a new database table and use the new table in the [Reader][reader] module in Azure Machine Learning.</source>
          <target state="new">Persist the sampled and engineered data you plan to use for model building in a new database table and use the new table in the [Reader][reader] module in Azure Machine Learning.</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>In this section we will save the final query to extract and sample the data.</source>
          <target state="new">In this section we will save the final query to extract and sample the data.</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>The second method is demonstrated in the <bpt id="p57">[</bpt>Data Exploration and Feature Engineering in IPython Notebook<ept id="p57">](#ipnb)</ept><ph id="ph59" /> section.</source>
          <target state="new">The second method is demonstrated in the <bpt id="p57">[</bpt>Data Exploration and Feature Engineering in IPython Notebook<ept id="p57">](#ipnb)</ept><ph id="ph59" /> section.</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>For a quick verification of the number of rows and columns in the tables populated earlier using parallel bulk import,</source>
          <target state="new">For a quick verification of the number of rows and columns in the tables populated earlier using parallel bulk import,</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>Exploration: Trip distribution by medallion</source>
          <target state="new">Exploration: Trip distribution by medallion</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>This example identifies the medallion (taxi numbers) with more than 100 trips within a given time period.</source>
          <target state="new">This example identifies the medallion (taxi numbers) with more than 100 trips within a given time period.</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>The query would benefit from the partitioned table access since it is conditioned by the partition scheme of <bpt id="p58">**</bpt>pickup\_datetime<ept id="p58">**</ept>.</source>
          <target state="new">The query would benefit from the partitioned table access since it is conditioned by the partition scheme of <bpt id="p58">**</bpt>pickup\_datetime<ept id="p58">**</ept>.</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>Querying the full dataset will also make use of the partitioned table and/or index scan.</source>
          <target state="new">Querying the full dataset will also make use of the partitioned table and/or index scan.</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>Exploration: Trip distribution by medallion and hack_license</source>
          <target state="new">Exploration: Trip distribution by medallion and hack_license</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>Data Quality Assessment: Verify records with incorrect longitude and/or latitude</source>
          <target state="new">Data Quality Assessment: Verify records with incorrect longitude and/or latitude</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>This example investigates if any of the longitude and/or latitude fields either contain an invalid value (radian degrees should be between -90 and 90), or have (0, 0) coordinates.</source>
          <target state="new">This example investigates if any of the longitude and/or latitude fields either contain an invalid value (radian degrees should be between -90 and 90), or have (0, 0) coordinates.</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>Exploration: Tipped vs. Not Tipped Trips distribution</source>
          <target state="new">Exploration: Tipped vs. Not Tipped Trips distribution</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>This example finds the number of trips that were tipped vs. not tipped in a given time period (or in the full dataset if covering the full year).</source>
          <target state="new">This example finds the number of trips that were tipped vs. not tipped in a given time period (or in the full dataset if covering the full year).</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>This distribution reflects the binary label distribution to be later used for binary classification modeling.</source>
          <target state="new">This distribution reflects the binary label distribution to be later used for binary classification modeling.</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>Exploration: Tip Class/Range Distribution</source>
          <target state="new">Exploration: Tip Class/Range Distribution</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>This example computes the distribution of tip ranges in a given time period (or in the full dataset if covering the full year).</source>
          <target state="new">This example computes the distribution of tip ranges in a given time period (or in the full dataset if covering the full year).</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>This is the distribution of the label classes that will be used later for multiclass classification modeling.</source>
          <target state="new">This is the distribution of the label classes that will be used later for multiclass classification modeling.</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>Exploration: Compute and Compare Trip Distance</source>
          <target state="new">Exploration: Compute and Compare Trip Distance</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>This example converts the pickup and drop-off longitude and latitude to SQL geography points, computes the trip distance using SQL geography points difference, and returns a random sample of the results for comparison.</source>
          <target state="new">This example converts the pickup and drop-off longitude and latitude to SQL geography points, computes the trip distance using SQL geography points difference, and returns a random sample of the results for comparison.</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>The example limits the results to valid coordinates only using the data quality assessment query covered earlier.</source>
          <target state="new">The example limits the results to valid coordinates only using the data quality assessment query covered earlier.</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>Feature Engineering in SQL Queries</source>
          <target state="new">Feature Engineering in SQL Queries</target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source>The label generation and geography conversion exploration queries can also be used to generate labels/features by removing the counting part.</source>
          <target state="new">The label generation and geography conversion exploration queries can also be used to generate labels/features by removing the counting part.</target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source>Additional feature engineering SQL examples are provided in the <bpt id="p59">[</bpt>Data Exploration and Feature Engineering in IPython Notebook<ept id="p59">](#ipnb)</ept><ph id="ph60" /> section.</source>
          <target state="new">Additional feature engineering SQL examples are provided in the <bpt id="p59">[</bpt>Data Exploration and Feature Engineering in IPython Notebook<ept id="p59">](#ipnb)</ept><ph id="ph60" /> section.</target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>It is more efficient to run the feature generation queries on the full dataset or a large subset of it using SQL queries which run directly on the SQL Server database instance.</source>
          <target state="new">It is more efficient to run the feature generation queries on the full dataset or a large subset of it using SQL queries which run directly on the SQL Server database instance.</target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>The queries may be executed in <bpt id="p60">**</bpt>SQL Server Management Studio<ept id="p60">**</ept>, IPython Notebook or any development tool/environment which can access the database locally or remotely.</source>
          <target state="new">The queries may be executed in <bpt id="p60">**</bpt>SQL Server Management Studio<ept id="p60">**</ept>, IPython Notebook or any development tool/environment which can access the database locally or remotely.</target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>Preparing Data for Model Building</source>
          <target state="new">Preparing Data for Model Building</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>The following query joins the <bpt id="p61">**</bpt>nyctaxi\_trip<ept id="p61">**</ept><ph id="ph61" /> and <bpt id="p62">**</bpt>nyctaxi\_fare<ept id="p62">**</ept><ph id="ph62" /> tables, generates a binary classification label <bpt id="p63">**</bpt>tipped<ept id="p63">**</ept>, a multi-class classification label <bpt id="p64">**</bpt>tip\_class<ept id="p64">**</ept>, and extracts a 1% random sample from the full joined dataset.</source>
          <target state="new">The following query joins the <bpt id="p61">**</bpt>nyctaxi\_trip<ept id="p61">**</ept><ph id="ph61" /> and <bpt id="p62">**</bpt>nyctaxi\_fare<ept id="p62">**</ept><ph id="ph62" /> tables, generates a binary classification label <bpt id="p63">**</bpt>tipped<ept id="p63">**</ept>, a multi-class classification label <bpt id="p64">**</bpt>tip\_class<ept id="p64">**</ept>, and extracts a 1% random sample from the full joined dataset.</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source>This query can be copied then pasted directly in the <bpt id="p65">[</bpt>Azure Machine Learning Studio<ept id="p65">](https://studio.azureml.net)</ept><ph id="ph63" /> [Reader][reader] module for direct data ingestion from the SQL Server database instance in Azure.</source>
          <target state="new">This query can be copied then pasted directly in the <bpt id="p65">[</bpt>Azure Machine Learning Studio<ept id="p65">](https://studio.azureml.net)</ept><ph id="ph63" /> [Reader][reader] module for direct data ingestion from the SQL Server database instance in Azure.</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>The query excludes records with incorrect (0, 0) coordinates.</source>
          <target state="new">The query excludes records with incorrect (0, 0) coordinates.</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>Data Exploration and Feature Engineering in IPython Notebook</source>
          <target state="new">Data Exploration and Feature Engineering in IPython Notebook</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>In this section, we will perform data exploration and feature generation
using both Python and SQL queries against the SQL Server database created earlier.</source>
          <target state="new">In this section, we will perform data exploration and feature generation
using both Python and SQL queries against the SQL Server database created earlier.</target>
        </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>A sample IPython notebook named <bpt id="p66">**</bpt>machine-Learning-data-science-process-sql-story.ipynb<ept id="p66">**</ept><ph id="ph64" /> is provided in the <bpt id="p67">**</bpt>Sample IPython Notebooks<ept id="p67">**</ept><ph id="ph65" /> folder.</source>
          <target state="new">A sample IPython notebook named <bpt id="p66">**</bpt>machine-Learning-data-science-process-sql-story.ipynb<ept id="p66">**</ept><ph id="ph64" /> is provided in the <bpt id="p67">**</bpt>Sample IPython Notebooks<ept id="p67">**</ept><ph id="ph65" /> folder.</target>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>This notebook is also available on <bpt id="p68">[</bpt>GitHub<ept id="p68">](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/DataScienceProcess/iPythonNotebooks)</ept>.</source>
          <target state="new">This notebook is also available on <bpt id="p68">[</bpt>GitHub<ept id="p68">](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/DataScienceProcess/iPythonNotebooks)</ept>.</target>
        </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>The recommended sequence when working with big data is the following:</source>
          <target state="new">The recommended sequence when working with big data is the following:</target>
        </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source>Read in a small sample of the data into an in-memory data frame.</source>
          <target state="new">Read in a small sample of the data into an in-memory data frame.</target>
        </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source>Perform some visualizations and explorations using the sampled data.</source>
          <target state="new">Perform some visualizations and explorations using the sampled data.</target>
        </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source>Experiment with feature engineering using the sampled data.</source>
          <target state="new">Experiment with feature engineering using the sampled data.</target>
        </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>For larger data exploration, data manipulation and feature engineering, use Python to issue SQL Queries directly against the SQL Server database in the Azure VM.</source>
          <target state="new">For larger data exploration, data manipulation and feature engineering, use Python to issue SQL Queries directly against the SQL Server database in the Azure VM.</target>
        </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>Decide the sample size to use for Azure Machine Learning model building.</source>
          <target state="new">Decide the sample size to use for Azure Machine Learning model building.</target>
        </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve">
          <source>When ready to proceed to Azure Machine Learning, you may either:</source>
          <target state="new">When ready to proceed to Azure Machine Learning, you may either:</target>
        </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve">
          <source>Save the final SQL query to extract and sample the data and copy-paste the query directly into a [Reader][reader] module in Azure Machine Learning.</source>
          <target state="new">Save the final SQL query to extract and sample the data and copy-paste the query directly into a [Reader][reader] module in Azure Machine Learning.</target>
        </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve">
          <source>This method is demonstrated in the <bpt id="p69">[</bpt>Building Models in Azure Machine Learning<ept id="p69">](#mlmodel)</ept><ph id="ph66" /> section.</source>
          <target state="new">This method is demonstrated in the <bpt id="p69">[</bpt>Building Models in Azure Machine Learning<ept id="p69">](#mlmodel)</ept><ph id="ph66" /> section.</target>
        </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve">
          <source>Persist the sampled and engineered data you plan to use for model building in a new database table, then use the new table in the [Reader][reader] module.</source>
          <target state="new">Persist the sampled and engineered data you plan to use for model building in a new database table, then use the new table in the [Reader][reader] module.</target>
        </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve">
          <source>The following are a few data exploration, data visualization, and feature engineering examples.</source>
          <target state="new">The following are a few data exploration, data visualization, and feature engineering examples.</target>
        </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source>For more examples, see the sample SQL IPython notebook in the <bpt id="p70">**</bpt>Sample IPython Notebooks<ept id="p70">**</ept><ph id="ph67" /> folder.</source>
          <target state="new">For more examples, see the sample SQL IPython notebook in the <bpt id="p70">**</bpt>Sample IPython Notebooks<ept id="p70">**</ept><ph id="ph67" /> folder.</target>
        </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>Initialize Database Credentials</source>
          <target state="new">Initialize Database Credentials</target>
        </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve">
          <source>Initialize your database connection settings in the following variables:</source>
          <target state="new">Initialize your database connection settings in the following variables:</target>
        </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve">
          <source>Create Database Connection</source>
          <target state="new">Create Database Connection</target>
        </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve">
          <source>Report number of rows and columns in table nyctaxi_trip</source>
          <target state="new">Report number of rows and columns in table nyctaxi_trip</target>
        </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve">
          <source>Total number of rows = 173179759</source>
          <target state="new">Total number of rows = 173179759</target>
        </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve">
          <source>Total number of columns = 14</source>
          <target state="new">Total number of columns = 14</target>
        </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve">
          <source>Read-in a small data sample from the SQL Server Database</source>
          <target state="new">Read-in a small data sample from the SQL Server Database</target>
        </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve">
          <source>Time to read the sample table is 6.492000 seconds  
<ph id="ph68" />Number of rows and columns retrieved = (84952, 21)</source>
          <target state="new">Time to read the sample table is 6.492000 seconds  
<ph id="ph68" />Number of rows and columns retrieved = (84952, 21)</target>
        </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve">
          <source>Descriptive Statistics</source>
          <target state="new">Descriptive Statistics</target>
        </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve">
          <source>Now are ready to explore the sampled data.</source>
          <target state="new">Now are ready to explore the sampled data.</target>
        </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve">
          <source>We start with
looking at descriptive statistics for the <bpt id="p71">**</bpt>trip\_distance<ept id="p71">**</ept><ph id="ph69" /> (or any other) field(s):</source>
          <target state="new">We start with
looking at descriptive statistics for the <bpt id="p71">**</bpt>trip\_distance<ept id="p71">**</ept><ph id="ph69" /> (or any other) field(s):</target>
        </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve">
          <source>Visualization: Box Plot Example</source>
          <target state="new">Visualization: Box Plot Example</target>
        </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve">
          <source>Next we look at the box plot for the trip distance to visualize the quantiles</source>
          <target state="new">Next we look at the box plot for the trip distance to visualize the quantiles</target>
        </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve">
          <source><ph id="ph70">![</ph>Plot #1<ph id="ph71">][1]</ph></source>
          <target state="new"><ph id="ph70">![</ph>Plot #1<ph id="ph71">][1]</ph></target>
        </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve">
          <source>Visualization: Distribution Plot Example</source>
          <target state="new">Visualization: Distribution Plot Example</target>
        </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve">
          <source><ph id="ph72">![</ph>Plot #2<ph id="ph73">][2]</ph></source>
          <target state="new"><ph id="ph72">![</ph>Plot #2<ph id="ph73">][2]</ph></target>
        </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve">
          <source>Visualization: Bar and Line Plots</source>
          <target state="new">Visualization: Bar and Line Plots</target>
        </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve">
          <source>In this example, we bin the trip distance into five bins and visualize the binning results.</source>
          <target state="new">In this example, we bin the trip distance into five bins and visualize the binning results.</target>
        </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve">
          <source>We can plot the above bin distribution in a bar or line plot as below</source>
          <target state="new">We can plot the above bin distribution in a bar or line plot as below</target>
        </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve">
          <source><ph id="ph74">![</ph>Plot #3<ph id="ph75">][3]</ph></source>
          <target state="new"><ph id="ph74">![</ph>Plot #3<ph id="ph75">][3]</ph></target>
        </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve">
          <source><ph id="ph76">![</ph>Plot #4<ph id="ph77">][4]</ph></source>
          <target state="new"><ph id="ph76">![</ph>Plot #4<ph id="ph77">][4]</ph></target>
        </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve">
          <source>Visualization: Scatterplot Example</source>
          <target state="new">Visualization: Scatterplot Example</target>
        </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve">
          <source>We show scatter plot between <bpt id="p72">**</bpt>trip\_time\_in\_secs<ept id="p72">**</ept><ph id="ph78" /> and <bpt id="p73">**</bpt>trip\_distance<ept id="p73">**</ept><ph id="ph79" /> to see if there
is any correlation</source>
          <target state="new">We show scatter plot between <bpt id="p72">**</bpt>trip\_time\_in\_secs<ept id="p72">**</ept><ph id="ph78" /> and <bpt id="p73">**</bpt>trip\_distance<ept id="p73">**</ept><ph id="ph79" /> to see if there
is any correlation</target>
        </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve">
          <source><ph id="ph80">![</ph>Plot #6<ph id="ph81">][6]</ph></source>
          <target state="new"><ph id="ph80">![</ph>Plot #6<ph id="ph81">][6]</ph></target>
        </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve">
          <source>Similarly we can check the relationship between <bpt id="p74">**</bpt>rate\_code<ept id="p74">**</ept><ph id="ph82" /> and <bpt id="p75">**</bpt>trip\_distance<ept id="p75">**</ept>.</source>
          <target state="new">Similarly we can check the relationship between <bpt id="p74">**</bpt>rate\_code<ept id="p74">**</ept><ph id="ph82" /> and <bpt id="p75">**</bpt>trip\_distance<ept id="p75">**</ept>.</target>
        </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve">
          <source><ph id="ph83">![</ph>Plot #8<ph id="ph84">][8]</ph></source>
          <target state="new"><ph id="ph83">![</ph>Plot #8<ph id="ph84">][8]</ph></target>
        </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve">
          <source>Sub-Sampling the Data in SQL</source>
          <target state="new">Sub-Sampling the Data in SQL</target>
        </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve">
          <source>When preparing data for model building in <bpt id="p76">[</bpt>Azure Machine Learning Studio<ept id="p76">](https://studio.azureml.net)</ept>, you may either decide on the <bpt id="p77">**</bpt>SQL query to use directly in the Reader module<ept id="p77">**</ept><ph id="ph85" /> or persist the engineered and sampled data in a new table, which you could use in the [Reader][reader] module with a simple <bpt id="p78">**</bpt>SELECT * FROM &lt;your\_new\_table\_name&gt;<ept id="p78">**</ept>.</source>
          <target state="new">When preparing data for model building in <bpt id="p76">[</bpt>Azure Machine Learning Studio<ept id="p76">](https://studio.azureml.net)</ept>, you may either decide on the <bpt id="p77">**</bpt>SQL query to use directly in the Reader module<ept id="p77">**</ept><ph id="ph85" /> or persist the engineered and sampled data in a new table, which you could use in the [Reader][reader] module with a simple <bpt id="p78">**</bpt>SELECT * FROM &lt;your\_new\_table\_name&gt;<ept id="p78">**</ept>.</target>
        </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve">
          <source>In this section we will create a new table to hold the sampled and engineered data.</source>
          <target state="new">In this section we will create a new table to hold the sampled and engineered data.</target>
        </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve">
          <source>An example of a direct SQL query for model building is provided in the <bpt id="p79">[</bpt>Data Exploration and Feature Engineering in SQL Server<ept id="p79">](#dbexplore)</ept><ph id="ph86" /> section.</source>
          <target state="new">An example of a direct SQL query for model building is provided in the <bpt id="p79">[</bpt>Data Exploration and Feature Engineering in SQL Server<ept id="p79">](#dbexplore)</ept><ph id="ph86" /> section.</target>
        </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve">
          <source>Create a Sample Table and Populate with 1% of the Joined Tables.</source>
          <target state="new">Create a Sample Table and Populate with 1% of the Joined Tables.</target>
        </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve">
          <source>Drop Table First if it Exists.</source>
          <target state="new">Drop Table First if it Exists.</target>
        </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve">
          <source>In this section, we join the tables <bpt id="p80">**</bpt>nyctaxi\_trip<ept id="p80">**</ept><ph id="ph87" /> and <bpt id="p81">**</bpt>nyctaxi\_fare<ept id="p81">**</ept>, extract a 1% random sample, and persist the sampled data in a new table name <bpt id="p82">**</bpt>nyctaxi\_one\_percent<ept id="p82">**</ept>:</source>
          <target state="new">In this section, we join the tables <bpt id="p80">**</bpt>nyctaxi\_trip<ept id="p80">**</ept><ph id="ph87" /> and <bpt id="p81">**</bpt>nyctaxi\_fare<ept id="p81">**</ept>, extract a 1% random sample, and persist the sampled data in a new table name <bpt id="p82">**</bpt>nyctaxi\_one\_percent<ept id="p82">**</ept>:</target>
        </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve">
          <source>Data Exploration using SQL Queries in IPython Notebook</source>
          <target state="new">Data Exploration using SQL Queries in IPython Notebook</target>
        </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve">
          <source>In this section, we explore data distributions using the 1% sampled data which is persisted in the new table we created above.</source>
          <target state="new">In this section, we explore data distributions using the 1% sampled data which is persisted in the new table we created above.</target>
        </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve">
          <source>Note that similar explorations can be performed using the original tables, optionally using <bpt id="p83">**</bpt>TABLESAMPLE<ept id="p83">**</ept><ph id="ph88" /> to limit the exploration sample or by limiting the results to a given time period using the <bpt id="p84">**</bpt>pickup\_datetime<ept id="p84">**</ept><ph id="ph89" /> partitions, as illustrated in the <bpt id="p85">[</bpt>Data Exploration and Feature Engineering in SQL Server<ept id="p85">](#dbexplore)</ept><ph id="ph90" /> section.</source>
          <target state="new">Note that similar explorations can be performed using the original tables, optionally using <bpt id="p83">**</bpt>TABLESAMPLE<ept id="p83">**</ept><ph id="ph88" /> to limit the exploration sample or by limiting the results to a given time period using the <bpt id="p84">**</bpt>pickup\_datetime<ept id="p84">**</ept><ph id="ph89" /> partitions, as illustrated in the <bpt id="p85">[</bpt>Data Exploration and Feature Engineering in SQL Server<ept id="p85">](#dbexplore)</ept><ph id="ph90" /> section.</target>
        </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve">
          <source>Exploration: Daily distribution of trips</source>
          <target state="new">Exploration: Daily distribution of trips</target>
        </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve">
          <source>Exploration: Trip distribution per medallion</source>
          <target state="new">Exploration: Trip distribution per medallion</target>
        </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve">
          <source>Feature Generation Using SQL Queries in IPython Notebook</source>
          <target state="new">Feature Generation Using SQL Queries in IPython Notebook</target>
        </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve">
          <source>In this section we will generate new labels and features directly using SQL queries, operating on the 1% sample table we created in the previous section.</source>
          <target state="new">In this section we will generate new labels and features directly using SQL queries, operating on the 1% sample table we created in the previous section.</target>
        </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve">
          <source>Label Generation: Generate Class Labels</source>
          <target state="new">Label Generation: Generate Class Labels</target>
        </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve">
          <source>In the following example, we generate two sets of labels to use for modeling:</source>
          <target state="new">In the following example, we generate two sets of labels to use for modeling:</target>
        </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve">
          <source>Binary Class Labels <bpt id="p86">**</bpt>tipped<ept id="p86">**</ept><ph id="ph91" /> (predicting if a tip will be given)</source>
          <target state="new">Binary Class Labels <bpt id="p86">**</bpt>tipped<ept id="p86">**</ept><ph id="ph91" /> (predicting if a tip will be given)</target>
        </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve">
          <source>Multiclass Labels <bpt id="p87">**</bpt>tip\_class<ept id="p87">**</ept><ph id="ph92" /> (predicting the tip bin or range)</source>
          <target state="new">Multiclass Labels <bpt id="p87">**</bpt>tip\_class<ept id="p87">**</ept><ph id="ph92" /> (predicting the tip bin or range)</target>
        </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve">
          <source>Feature Engineering: Count Features for Categorical Columns</source>
          <target state="new">Feature Engineering: Count Features for Categorical Columns</target>
        </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve">
          <source>This example transforms a categorical field into a numeric field by replacing each category with the count of its occurrences in the data.</source>
          <target state="new">This example transforms a categorical field into a numeric field by replacing each category with the count of its occurrences in the data.</target>
        </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve">
          <source>Feature Engineering: Bin features for Numerical Columns</source>
          <target state="new">Feature Engineering: Bin features for Numerical Columns</target>
        </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve">
          <source>This example transforms a continuous numeric field into preset category ranges, i.e., transform numeric field into a categorical field.</source>
          <target state="new">This example transforms a continuous numeric field into preset category ranges, i.e., transform numeric field into a categorical field.</target>
        </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve">
          <source>Feature Engineering: Extract Location Features from Decimal Latitude/Longitude</source>
          <target state="new">Feature Engineering: Extract Location Features from Decimal Latitude/Longitude</target>
        </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve">
          <source>This example breaks down the decimal representation of a latitude and/or longitude field into multiple region fields of different granularity, such as, country, city, town, block, etc. Note that the new geo-fields are not mapped to actual locations.</source>
          <target state="new">This example breaks down the decimal representation of a latitude and/or longitude field into multiple region fields of different granularity, such as, country, city, town, block, etc. Note that the new geo-fields are not mapped to actual locations.</target>
        </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve">
          <source>For information on mapping geocode locations, see <bpt id="p88">[</bpt>Bing Maps REST Services<ept id="p88">](https://msdn.microsoft.com/library/ff701710.aspx)</ept>.</source>
          <target state="new">For information on mapping geocode locations, see <bpt id="p88">[</bpt>Bing Maps REST Services<ept id="p88">](https://msdn.microsoft.com/library/ff701710.aspx)</ept>.</target>
        </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve">
          <source>Verify the final form of the featurized table</source>
          <target state="new">Verify the final form of the featurized table</target>
        </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve">
          <source>We are now ready to proceed to model building and model deployment in <bpt id="p89">[</bpt>Azure Machine Learning<ept id="p89">](https://studio.azureml.net)</ept>.</source>
          <target state="new">We are now ready to proceed to model building and model deployment in <bpt id="p89">[</bpt>Azure Machine Learning<ept id="p89">](https://studio.azureml.net)</ept>.</target>
        </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve">
          <source>The data is ready for any of the prediction problems identified earlier, namely:</source>
          <target state="new">The data is ready for any of the prediction problems identified earlier, namely:</target>
        </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve">
          <source>Binary classification: To predict whether or not a tip was paid for a trip.</source>
          <target state="new">Binary classification: To predict whether or not a tip was paid for a trip.</target>
        </trans-unit>
        <trans-unit id="312" translate="yes" xml:space="preserve">
          <source>Multiclass classification: To predict the range of tip paid, according to the previously defined classes.</source>
          <target state="new">Multiclass classification: To predict the range of tip paid, according to the previously defined classes.</target>
        </trans-unit>
        <trans-unit id="313" translate="yes" xml:space="preserve">
          <source>Regression task: To predict the amount of tip paid for a trip.</source>
          <target state="new">Regression task: To predict the amount of tip paid for a trip.</target>
        </trans-unit>
        <trans-unit id="314" translate="yes" xml:space="preserve">
          <source>Building Models in Azure Machine Learning</source>
          <target state="new">Building Models in Azure Machine Learning</target>
        </trans-unit>
        <trans-unit id="315" translate="yes" xml:space="preserve">
          <source>To begin the modeling exercise, log in to your Azure Machine Learning workspace.</source>
          <target state="new">To begin the modeling exercise, log in to your Azure Machine Learning workspace.</target>
        </trans-unit>
        <trans-unit id="316" translate="yes" xml:space="preserve">
          <source>If you have not yet created a machine learning workspace, see <bpt id="p90">[</bpt>Create an Azure ML workspace<ept id="p90">](machine-learning-create-workspace.md)</ept>.</source>
          <target state="new">If you have not yet created a machine learning workspace, see <bpt id="p90">[</bpt>Create an Azure ML workspace<ept id="p90">](machine-learning-create-workspace.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="317" translate="yes" xml:space="preserve">
          <source>To get started with Azure Machine Learning, see <bpt id="p91">[</bpt>What is Azure Machine Learning Studio?<ept id="p91">](machine-learning-what-is-ml-studio.md)</ept></source>
          <target state="new">To get started with Azure Machine Learning, see <bpt id="p91">[</bpt>What is Azure Machine Learning Studio?<ept id="p91">](machine-learning-what-is-ml-studio.md)</ept></target>
        </trans-unit>
        <trans-unit id="318" translate="yes" xml:space="preserve">
          <source>Log in to <bpt id="p92">[</bpt>Azure Machine Learning Studio<ept id="p92">](https://studio.azureml.net)</ept>.</source>
          <target state="new">Log in to <bpt id="p92">[</bpt>Azure Machine Learning Studio<ept id="p92">](https://studio.azureml.net)</ept>.</target>
        </trans-unit>
        <trans-unit id="319" translate="yes" xml:space="preserve">
          <source>The Studio Home page provides a wealth of information, videos, tutorials, links to the Modules Reference, and other resources.</source>
          <target state="new">The Studio Home page provides a wealth of information, videos, tutorials, links to the Modules Reference, and other resources.</target>
        </trans-unit>
        <trans-unit id="320" translate="yes" xml:space="preserve">
          <source>Fore more information about Azure Machine Learning, consult the <bpt id="p93">[</bpt>Azure Machine Learning Documentation Center<ept id="p93">](https://azure.microsoft.com/documentation/services/machine-learning/)</ept>.</source>
          <target state="new">Fore more information about Azure Machine Learning, consult the <bpt id="p93">[</bpt>Azure Machine Learning Documentation Center<ept id="p93">](https://azure.microsoft.com/documentation/services/machine-learning/)</ept>.</target>
        </trans-unit>
        <trans-unit id="321" translate="yes" xml:space="preserve">
          <source>A typical training experiment consists of the following:</source>
          <target state="new">A typical training experiment consists of the following:</target>
        </trans-unit>
        <trans-unit id="322" translate="yes" xml:space="preserve">
          <source>Create a <bpt id="p94">**</bpt>+NEW<ept id="p94">**</ept><ph id="ph93" /> experiment.</source>
          <target state="new">Create a <bpt id="p94">**</bpt>+NEW<ept id="p94">**</ept><ph id="ph93" /> experiment.</target>
        </trans-unit>
        <trans-unit id="323" translate="yes" xml:space="preserve">
          <source>Get the data to Azure ML.</source>
          <target state="new">Get the data to Azure ML.</target>
        </trans-unit>
        <trans-unit id="324" translate="yes" xml:space="preserve">
          <source>Pre-process, transform and manipulate the data as needed.</source>
          <target state="new">Pre-process, transform and manipulate the data as needed.</target>
        </trans-unit>
        <trans-unit id="325" translate="yes" xml:space="preserve">
          <source>Generate features as needed.</source>
          <target state="new">Generate features as needed.</target>
        </trans-unit>
        <trans-unit id="326" translate="yes" xml:space="preserve">
          <source>Split the data into training/validation/testing datasets(or have separate datasets for each).</source>
          <target state="new">Split the data into training/validation/testing datasets(or have separate datasets for each).</target>
        </trans-unit>
        <trans-unit id="327" translate="yes" xml:space="preserve">
          <source>Select one or more machine learning algorithms depending on the learning problem to solve.</source>
          <target state="new">Select one or more machine learning algorithms depending on the learning problem to solve.</target>
        </trans-unit>
        <trans-unit id="328" translate="yes" xml:space="preserve">
          <source>E.g., binary classification, multiclass classification, regression.</source>
          <target state="new">E.g., binary classification, multiclass classification, regression.</target>
        </trans-unit>
        <trans-unit id="329" translate="yes" xml:space="preserve">
          <source>Train one or more models using the training dataset.</source>
          <target state="new">Train one or more models using the training dataset.</target>
        </trans-unit>
        <trans-unit id="330" translate="yes" xml:space="preserve">
          <source>Score the validation dataset using the trained model(s).</source>
          <target state="new">Score the validation dataset using the trained model(s).</target>
        </trans-unit>
        <trans-unit id="331" translate="yes" xml:space="preserve">
          <source>Evaluate the model(s) to compute the relevant metrics for the learning problem.</source>
          <target state="new">Evaluate the model(s) to compute the relevant metrics for the learning problem.</target>
        </trans-unit>
        <trans-unit id="332" translate="yes" xml:space="preserve">
          <source>Fine tune the model(s) and select the best model to deploy.</source>
          <target state="new">Fine tune the model(s) and select the best model to deploy.</target>
        </trans-unit>
        <trans-unit id="333" translate="yes" xml:space="preserve">
          <source>In this exercise, we have already explored and engineered the data in SQL Server, and decided on the sample size to ingest in Azure ML.</source>
          <target state="new">In this exercise, we have already explored and engineered the data in SQL Server, and decided on the sample size to ingest in Azure ML.</target>
        </trans-unit>
        <trans-unit id="334" translate="yes" xml:space="preserve">
          <source>To build one or more of the prediction models we decided:</source>
          <target state="new">To build one or more of the prediction models we decided:</target>
        </trans-unit>
        <trans-unit id="335" translate="yes" xml:space="preserve">
          <source>Get the data to Azure ML using the [Reader][reader] module, available in the <bpt id="p95">**</bpt>Data Input and Output<ept id="p95">**</ept><ph id="ph94" /> section.</source>
          <target state="new">Get the data to Azure ML using the [Reader][reader] module, available in the <bpt id="p95">**</bpt>Data Input and Output<ept id="p95">**</ept><ph id="ph94" /> section.</target>
        </trans-unit>
        <trans-unit id="336" translate="yes" xml:space="preserve">
          <source>For more information, see the [Reader][reader] module reference page.</source>
          <target state="new">For more information, see the [Reader][reader] module reference page.</target>
        </trans-unit>
        <trans-unit id="337" translate="yes" xml:space="preserve">
          <source><ph id="ph95">![</ph>Azure ML Reader<ph id="ph96">][17]</ph></source>
          <target state="new"><ph id="ph95">![</ph>Azure ML Reader<ph id="ph96">][17]</ph></target>
        </trans-unit>
        <trans-unit id="338" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p96">**</bpt>Azure SQL Database<ept id="p96">**</ept><ph id="ph97" /> as the <bpt id="p97">**</bpt>Data source<ept id="p97">**</ept><ph id="ph98" /> in the <bpt id="p98">**</bpt>Properties<ept id="p98">**</ept><ph id="ph99" /> panel.</source>
          <target state="new">Select <bpt id="p96">**</bpt>Azure SQL Database<ept id="p96">**</ept><ph id="ph97" /> as the <bpt id="p97">**</bpt>Data source<ept id="p97">**</ept><ph id="ph98" /> in the <bpt id="p98">**</bpt>Properties<ept id="p98">**</ept><ph id="ph99" /> panel.</target>
        </trans-unit>
        <trans-unit id="339" translate="yes" xml:space="preserve">
          <source>Enter the database DNS name in the <bpt id="p99">**</bpt>Database server name<ept id="p99">**</ept><ph id="ph100" /> field.</source>
          <target state="new">Enter the database DNS name in the <bpt id="p99">**</bpt>Database server name<ept id="p99">**</ept><ph id="ph100" /> field.</target>
        </trans-unit>
        <trans-unit id="340" translate="yes" xml:space="preserve">
          <source>Format: <ph id="ph101">`tcp:&lt;your_virtual_machine_DNS_name&gt;,1433`</ph></source>
          <target state="new">Format: <ph id="ph101">`tcp:&lt;your_virtual_machine_DNS_name&gt;,1433`</ph></target>
        </trans-unit>
        <trans-unit id="341" translate="yes" xml:space="preserve">
          <source>Enter the <bpt id="p100">**</bpt>Database name<ept id="p100">**</ept><ph id="ph102" /> in the corresponding field.</source>
          <target state="new">Enter the <bpt id="p100">**</bpt>Database name<ept id="p100">**</ept><ph id="ph102" /> in the corresponding field.</target>
        </trans-unit>
        <trans-unit id="342" translate="yes" xml:space="preserve">
          <source>Enter the <bpt id="p101">**</bpt>SQL user name<ept id="p101">**</ept><ph id="ph103" /> in the **Server user aqccount name, and the password in the <bpt id="p102">**</bpt>Server user account password<ept id="p102">**</ept>.</source>
          <target state="new">Enter the <bpt id="p101">**</bpt>SQL user name<ept id="p101">**</ept><ph id="ph103" /> in the **Server user aqccount name, and the password in the <bpt id="p102">**</bpt>Server user account password<ept id="p102">**</ept>.</target>
        </trans-unit>
        <trans-unit id="343" translate="yes" xml:space="preserve">
          <source>Check <bpt id="p103">**</bpt>Accept any server certificate<ept id="p103">**</ept><ph id="ph104" /> option.</source>
          <target state="new">Check <bpt id="p103">**</bpt>Accept any server certificate<ept id="p103">**</ept><ph id="ph104" /> option.</target>
        </trans-unit>
        <trans-unit id="344" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p104">**</bpt>Database query<ept id="p104">**</ept><ph id="ph105" /> edit text area, paste the query which extracts the necessary database fields (including any computed fields such as the labels) and down samples the data to the desired sample size.</source>
          <target state="new">In the <bpt id="p104">**</bpt>Database query<ept id="p104">**</ept><ph id="ph105" /> edit text area, paste the query which extracts the necessary database fields (including any computed fields such as the labels) and down samples the data to the desired sample size.</target>
        </trans-unit>
        <trans-unit id="345" translate="yes" xml:space="preserve">
          <source>An example of a binary classification experiment reading data directly from the SQL Server database is in the figure below.</source>
          <target state="new">An example of a binary classification experiment reading data directly from the SQL Server database is in the figure below.</target>
        </trans-unit>
        <trans-unit id="346" translate="yes" xml:space="preserve">
          <source>Similar experiments can be constructed for multiclass classification and regression problems.</source>
          <target state="new">Similar experiments can be constructed for multiclass classification and regression problems.</target>
        </trans-unit>
        <trans-unit id="347" translate="yes" xml:space="preserve">
          <source><ph id="ph106">![</ph>Azure ML Train<ph id="ph107">][10]</ph></source>
          <target state="new"><ph id="ph106">![</ph>Azure ML Train<ph id="ph107">][10]</ph></target>
        </trans-unit>
        <trans-unit id="348" translate="yes" xml:space="preserve">
          <source><ph id="ph108">[AZURE.IMPORTANT]</ph><ph id="ph109" /> In the modeling data extraction and sampling query examples provided in previous sections, <bpt id="p105">**</bpt>all labels for the three modeling exercises are included in the query<ept id="p105">**</ept>.</source>
          <target state="new"><ph id="ph108">[AZURE.IMPORTANT]</ph><ph id="ph109" /> In the modeling data extraction and sampling query examples provided in previous sections, <bpt id="p105">**</bpt>all labels for the three modeling exercises are included in the query<ept id="p105">**</ept>.</target>
        </trans-unit>
        <trans-unit id="349" translate="yes" xml:space="preserve">
          <source>An important (required) step in each of the modeling exercises is to <bpt id="p106">**</bpt>exclude<ept id="p106">**</ept><ph id="ph110" /> the unnecessary labels for the other two problems, and any other <bpt id="p107">**</bpt>target leaks<ept id="p107">**</ept>.</source>
          <target state="new">An important (required) step in each of the modeling exercises is to <bpt id="p106">**</bpt>exclude<ept id="p106">**</ept><ph id="ph110" /> the unnecessary labels for the other two problems, and any other <bpt id="p107">**</bpt>target leaks<ept id="p107">**</ept>.</target>
        </trans-unit>
        <trans-unit id="350" translate="yes" xml:space="preserve">
          <source>For e.g., when using binary classification, use the label <bpt id="p108">**</bpt>tipped<ept id="p108">**</ept><ph id="ph111" /> and exclude the fields <bpt id="p109">**</bpt>tip\_class<ept id="p109">**</ept>, <bpt id="p110">**</bpt>tip\_amount<ept id="p110">**</ept>, and <bpt id="p111">**</bpt>total\_amount<ept id="p111">**</ept>.</source>
          <target state="new">For e.g., when using binary classification, use the label <bpt id="p108">**</bpt>tipped<ept id="p108">**</ept><ph id="ph111" /> and exclude the fields <bpt id="p109">**</bpt>tip\_class<ept id="p109">**</ept>, <bpt id="p110">**</bpt>tip\_amount<ept id="p110">**</ept>, and <bpt id="p111">**</bpt>total\_amount<ept id="p111">**</ept>.</target>
        </trans-unit>
        <trans-unit id="351" translate="yes" xml:space="preserve">
          <source>The latter are target leaks since they imply the tip paid.</source>
          <target state="new">The latter are target leaks since they imply the tip paid.</target>
        </trans-unit>
        <trans-unit id="352" translate="yes" xml:space="preserve">
          <source>To exclude unnecessary columns and/or target leaks, you may use the [Project Columns][project-columns] module or the [Metadata Editor][metadata-editor].</source>
          <target state="new">To exclude unnecessary columns and/or target leaks, you may use the [Project Columns][project-columns] module or the [Metadata Editor][metadata-editor].</target>
        </trans-unit>
        <trans-unit id="353" translate="yes" xml:space="preserve">
          <source>For more information, see [Project Columns][project-columns] and [Metadata Editor][metadata-editor] reference pages.</source>
          <target state="new">For more information, see [Project Columns][project-columns] and [Metadata Editor][metadata-editor] reference pages.</target>
        </trans-unit>
        <trans-unit id="354" translate="yes" xml:space="preserve">
          <source>Deploying Models in Azure Machine Learning</source>
          <target state="new">Deploying Models in Azure Machine Learning</target>
        </trans-unit>
        <trans-unit id="355" translate="yes" xml:space="preserve">
          <source>When your model is ready, you can easily deploy it as a web service directly from the experiment.</source>
          <target state="new">When your model is ready, you can easily deploy it as a web service directly from the experiment.</target>
        </trans-unit>
        <trans-unit id="356" translate="yes" xml:space="preserve">
          <source>For more information about deploying Azure ML web services, see <bpt id="p112">[</bpt>Deploy an Azure Machine Learning web service<ept id="p112">](machine-learning-publish-a-machine-learning-web-service.md)</ept>.</source>
          <target state="new">For more information about deploying Azure ML web services, see <bpt id="p112">[</bpt>Deploy an Azure Machine Learning web service<ept id="p112">](machine-learning-publish-a-machine-learning-web-service.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="357" translate="yes" xml:space="preserve">
          <source>To deploy a new web service, you need to:</source>
          <target state="new">To deploy a new web service, you need to:</target>
        </trans-unit>
        <trans-unit id="358" translate="yes" xml:space="preserve">
          <source>Create a scoring experiment.</source>
          <target state="new">Create a scoring experiment.</target>
        </trans-unit>
        <trans-unit id="359" translate="yes" xml:space="preserve">
          <source>Deploy the web service.</source>
          <target state="new">Deploy the web service.</target>
        </trans-unit>
        <trans-unit id="360" translate="yes" xml:space="preserve">
          <source>To create a scoring experiment from a <bpt id="p113">**</bpt>Finished<ept id="p113">**</ept><ph id="ph112" /> training experiment, click <bpt id="p114">**</bpt>CREATE SCORING EXPERIMENT<ept id="p114">**</ept><ph id="ph113" /> in the lower action bar.</source>
          <target state="new">To create a scoring experiment from a <bpt id="p113">**</bpt>Finished<ept id="p113">**</ept><ph id="ph112" /> training experiment, click <bpt id="p114">**</bpt>CREATE SCORING EXPERIMENT<ept id="p114">**</ept><ph id="ph113" /> in the lower action bar.</target>
        </trans-unit>
        <trans-unit id="361" translate="yes" xml:space="preserve">
          <source><ph id="ph114">![</ph>Azure Scoring<ph id="ph115">][18]</ph></source>
          <target state="new"><ph id="ph114">![</ph>Azure Scoring<ph id="ph115">][18]</ph></target>
        </trans-unit>
        <trans-unit id="362" translate="yes" xml:space="preserve">
          <source>Azure Machine Learning will attempt to create a scoring experiment based on the components of the training experiment.</source>
          <target state="new">Azure Machine Learning will attempt to create a scoring experiment based on the components of the training experiment.</target>
        </trans-unit>
        <trans-unit id="363" translate="yes" xml:space="preserve">
          <source>In particular, it will:</source>
          <target state="new">In particular, it will:</target>
        </trans-unit>
        <trans-unit id="364" translate="yes" xml:space="preserve">
          <source>Save the trained model and remove the model training modules.</source>
          <target state="new">Save the trained model and remove the model training modules.</target>
        </trans-unit>
        <trans-unit id="365" translate="yes" xml:space="preserve">
          <source>Identify a logical <bpt id="p115">**</bpt>input port<ept id="p115">**</ept><ph id="ph116" /> to represent the expected input data schema.</source>
          <target state="new">Identify a logical <bpt id="p115">**</bpt>input port<ept id="p115">**</ept><ph id="ph116" /> to represent the expected input data schema.</target>
        </trans-unit>
        <trans-unit id="366" translate="yes" xml:space="preserve">
          <source>Identify a logical <bpt id="p116">**</bpt>output port<ept id="p116">**</ept><ph id="ph117" /> to represent the expected web service output schema.</source>
          <target state="new">Identify a logical <bpt id="p116">**</bpt>output port<ept id="p116">**</ept><ph id="ph117" /> to represent the expected web service output schema.</target>
        </trans-unit>
        <trans-unit id="367" translate="yes" xml:space="preserve">
          <source>When the scoring experiment is created, review it and adjust as needed.</source>
          <target state="new">When the scoring experiment is created, review it and adjust as needed.</target>
        </trans-unit>
        <trans-unit id="368" translate="yes" xml:space="preserve">
          <source>A typical adjustment is to replace the input dataset and/or query with one which excludes label fields, as these will not be available when the service is called.</source>
          <target state="new">A typical adjustment is to replace the input dataset and/or query with one which excludes label fields, as these will not be available when the service is called.</target>
        </trans-unit>
        <trans-unit id="369" translate="yes" xml:space="preserve">
          <source>It is also a good practice to reduce the size of the input dataset and/or query to a few records, just enough to indicate the input schema.</source>
          <target state="new">It is also a good practice to reduce the size of the input dataset and/or query to a few records, just enough to indicate the input schema.</target>
        </trans-unit>
        <trans-unit id="370" translate="yes" xml:space="preserve">
          <source>For the output port, it is common to exclude all input fields and only include the <bpt id="p117">**</bpt>Scored Labels<ept id="p117">**</ept><ph id="ph118" /> and <bpt id="p118">**</bpt>Scored Probabilities<ept id="p118">**</ept><ph id="ph119" /> in the output using the [Project Columns][project-columns] module.</source>
          <target state="new">For the output port, it is common to exclude all input fields and only include the <bpt id="p117">**</bpt>Scored Labels<ept id="p117">**</ept><ph id="ph118" /> and <bpt id="p118">**</bpt>Scored Probabilities<ept id="p118">**</ept><ph id="ph119" /> in the output using the [Project Columns][project-columns] module.</target>
        </trans-unit>
        <trans-unit id="371" translate="yes" xml:space="preserve">
          <source>A sample scoring experiment is in the figure below.</source>
          <target state="new">A sample scoring experiment is in the figure below.</target>
        </trans-unit>
        <trans-unit id="372" translate="yes" xml:space="preserve">
          <source>When ready to deploy, click the <bpt id="p119">**</bpt>PUBLISH WEB SERVICE<ept id="p119">**</ept><ph id="ph120" /> button in the lower action bar.</source>
          <target state="new">When ready to deploy, click the <bpt id="p119">**</bpt>PUBLISH WEB SERVICE<ept id="p119">**</ept><ph id="ph120" /> button in the lower action bar.</target>
        </trans-unit>
        <trans-unit id="373" translate="yes" xml:space="preserve">
          <source><ph id="ph121">![</ph>Azure ML Publish<ph id="ph122">][11]</ph></source>
          <target state="new"><ph id="ph121">![</ph>Azure ML Publish<ph id="ph122">][11]</ph></target>
        </trans-unit>
        <trans-unit id="374" translate="yes" xml:space="preserve">
          <source>To recap, in this walkthrough tutorial, you have created an Azure data science environment, worked with a large public dataset all the way from data acquisition to model training and deploying of an Azure Machine Learning web service.</source>
          <target state="new">To recap, in this walkthrough tutorial, you have created an Azure data science environment, worked with a large public dataset all the way from data acquisition to model training and deploying of an Azure Machine Learning web service.</target>
        </trans-unit>
        <trans-unit id="375" translate="yes" xml:space="preserve">
          <source>License Information</source>
          <target state="new">License Information</target>
        </trans-unit>
        <trans-unit id="376" translate="yes" xml:space="preserve">
          <source>This sample walkthrough and its accompanying scripts and IPython notebook(s) are shared by Microsoft under the MIT license.</source>
          <target state="new">This sample walkthrough and its accompanying scripts and IPython notebook(s) are shared by Microsoft under the MIT license.</target>
        </trans-unit>
        <trans-unit id="377" translate="yes" xml:space="preserve">
          <source>Please check the LICENSE.txt file in in the directory of the sample code on GitHub for more details.</source>
          <target state="new">Please check the LICENSE.txt file in in the directory of the sample code on GitHub for more details.</target>
        </trans-unit>
        <trans-unit id="378" translate="yes" xml:space="preserve">
          <source>References</source>
          <target state="new">References</target>
        </trans-unit>
        <trans-unit id="379" translate="yes" xml:space="preserve">
          <source>•   <bpt id="p120">[</bpt>Andrés Monroy NYC Taxi Trips Download Page<ept id="p120">](http://www.andresmh.com/nyctaxitrips/)</ept><ph id="ph123" />  
•   <bpt id="p121">[</bpt>FOILing NYC’s Taxi Trip Data by Chris Whong<ept id="p121">](http://chriswhong.com/open-data/foil_nyc_taxi/)</ept><ph id="ph124" />   
•   <bpt id="p122">[</bpt>NYC Taxi and Limousine Commission Research and Statistics<ept id="p122">](https://www1.nyc.gov/html/tlc/html/about/statistics.shtml)</ept></source>
          <target state="new">•   <bpt id="p120">[</bpt>Andrés Monroy NYC Taxi Trips Download Page<ept id="p120">](http://www.andresmh.com/nyctaxitrips/)</ept><ph id="ph123" />  
•   <bpt id="p121">[</bpt>FOILing NYC’s Taxi Trip Data by Chris Whong<ept id="p121">](http://chriswhong.com/open-data/foil_nyc_taxi/)</ept><ph id="ph124" />   
•   <bpt id="p122">[</bpt>NYC Taxi and Limousine Commission Research and Statistics<ept id="p122">](https://www1.nyc.gov/html/tlc/html/about/statistics.shtml)</ept></target>
        </trans-unit>
        <trans-unit id="380" translate="yes" xml:space="preserve">
          <source>[metadata-editor]: https://msdn.microsoft.com/library/azure/370b6676-c11c-486f-bf73-35349f842a66/
[project-columns]: https://msdn.microsoft.com/library/azure/1ec722fa-b623-4e26-a44e-a50c6d726223/
[reader]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/</source>
          <target state="new">[metadata-editor]: https://msdn.microsoft.com/library/azure/370b6676-c11c-486f-bf73-35349f842a66/
[project-columns]: https://msdn.microsoft.com/library/azure/1ec722fa-b623-4e26-a44e-a50c6d726223/
[reader]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">a05e6dcadcbf0147d9cd10aaaedff5fda6f4dabb</xliffext:olfilehash>
  </header>
</xliff>