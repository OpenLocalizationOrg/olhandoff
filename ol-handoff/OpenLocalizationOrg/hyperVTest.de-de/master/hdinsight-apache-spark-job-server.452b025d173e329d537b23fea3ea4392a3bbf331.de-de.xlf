<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="de-de">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Apache Spark Job Server on HDInsight | Microsoft Azure</source>
          <target state="new">Apache Spark Job Server on HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to use the Spark Job Server to remotely submit and manage jobs on a Spark cluster.</source>
          <target state="new">Learn how to use the Spark Job Server to remotely submit and manage jobs on a Spark cluster.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Spark Job Server on Azure HDInsight clusters (Windows)</source>
          <target state="new">Spark Job Server on Azure HDInsight clusters (Windows)</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source><ph id="ph2">[AZURE.NOTE]</ph><ph id="ph3" /> HDInsight now provides Spark clusters on Linux, which uses Livy to submit jobs remotely to a Spark cluster.</source>
          <target state="new"><ph id="ph2">[AZURE.NOTE]</ph><ph id="ph3" /> HDInsight now provides Spark clusters on Linux, which uses Livy to submit jobs remotely to a Spark cluster.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>For information on how to use Livy with HDInsight Spark clusters on Linux, see <bpt id="p1">[</bpt>Submit Spark jobs remotely using Livy with Spark clusters on HDInsight (Linux)<ept id="p1">](hdinsight-apache-spark-livy-rest-interface.md)</ept>.</source>
          <target state="new">For information on how to use Livy with HDInsight Spark clusters on Linux, see <bpt id="p1">[</bpt>Submit Spark jobs remotely using Livy with Spark clusters on HDInsight (Linux)<ept id="p1">](hdinsight-apache-spark-livy-rest-interface.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Apache Spark cluster on Azure HDInight packages the Spark Job Server as part of the cluster deployment.</source>
          <target state="new">Apache Spark cluster on Azure HDInight packages the Spark Job Server as part of the cluster deployment.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Spark Job Server provides REST APIs to create Spark context, submit Spark application to context, check job status, kill context, etc. This article provides some examples on how to use Curl to perform some common tasks on a Spark cluster using a Job Server.</source>
          <target state="new">Spark Job Server provides REST APIs to create Spark context, submit Spark application to context, check job status, kill context, etc. This article provides some examples on how to use Curl to perform some common tasks on a Spark cluster using a Job Server.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source><ph id="ph4">[AZURE.NOTE]</ph><ph id="ph5" /> For complete documentation for the Spark Job Server, see <bpt id="p2">[</bpt>https://github.com/spark-jobserver/spark-jobserver<ept id="p2">](https://github.com/spark-jobserver/spark-jobserver)</ept>.</source>
          <target state="new"><ph id="ph4">[AZURE.NOTE]</ph><ph id="ph5" /> For complete documentation for the Spark Job Server, see <bpt id="p2">[</bpt>https://github.com/spark-jobserver/spark-jobserver<ept id="p2">](https://github.com/spark-jobserver/spark-jobserver)</ept>.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Upload a jar to a Spark cluster</source>
          <target state="new">Upload a jar to a Spark cluster</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Example:</source>
          <target state="new">Example:</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Create new persistent context in job server</source>
          <target state="new">Create new persistent context in job server</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Example:</source>
          <target state="new">Example:</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Submit an application to the cluster</source>
          <target state="new">Submit an application to the cluster</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Example:</source>
          <target state="new">Example:</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>where mypostdata.txt defines your application.</source>
          <target state="new">where mypostdata.txt defines your application.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Delete a job</source>
          <target state="new">Delete a job</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Example:</source>
          <target state="new">Example:</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>See also</source>
          <target state="new">See also</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source><bpt id="p3">[</bpt>Overview: Apache Spark on Azure HDInsight<ept id="p3">](hdinsight-apache-spark-overview-v1.md)</ept></source>
          <target state="new"><bpt id="p3">[</bpt>Overview: Apache Spark on Azure HDInsight<ept id="p3">](hdinsight-apache-spark-overview-v1.md)</ept></target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source><bpt id="p4">[</bpt>Create a Spark on HDInsight cluster<ept id="p4">](hdinsight-apache-spark-provision-clusters.md)</ept></source>
          <target state="new"><bpt id="p4">[</bpt>Create a Spark on HDInsight cluster<ept id="p4">](hdinsight-apache-spark-provision-clusters.md)</ept></target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source><bpt id="p5">[</bpt>Perform interactive data analysis using Spark in HDInsight with BI tools<ept id="p5">](hdinsight-apache-spark-use-bi-tools-v1.md)</ept></source>
          <target state="new"><bpt id="p5">[</bpt>Perform interactive data analysis using Spark in HDInsight with BI tools<ept id="p5">](hdinsight-apache-spark-use-bi-tools-v1.md)</ept></target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source><bpt id="p6">[</bpt>Use Spark in HDInsight for building machine learning applications<ept id="p6">](hdinsight-apache-spark-ipython-notebook-machine-learning-v1.md)</ept></source>
          <target state="new"><bpt id="p6">[</bpt>Use Spark in HDInsight for building machine learning applications<ept id="p6">](hdinsight-apache-spark-ipython-notebook-machine-learning-v1.md)</ept></target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source><bpt id="p7">[</bpt>Use Spark in HDInsight for building real-time streaming applications<ept id="p7">](hdinsight-apache-spark-csharp-apache-zeppelin-eventhub-streaming.md)</ept></source>
          <target state="new"><bpt id="p7">[</bpt>Use Spark in HDInsight for building real-time streaming applications<ept id="p7">](hdinsight-apache-spark-csharp-apache-zeppelin-eventhub-streaming.md)</ept></target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source><bpt id="p8">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id="p8">](hdinsight-apache-spark-resource-manager.md)</ept></source>
          <target state="new"><bpt id="p8">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id="p8">](hdinsight-apache-spark-resource-manager.md)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d827eec3917b8606315c036d8173e617da4a4e08</xliffext:olfilehash>
  </header>
</xliff>