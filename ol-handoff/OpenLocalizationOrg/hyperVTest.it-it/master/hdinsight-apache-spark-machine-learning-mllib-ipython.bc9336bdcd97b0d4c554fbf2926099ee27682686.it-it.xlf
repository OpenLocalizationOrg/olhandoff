<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="it-it">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Use Apache Spark to build machine learning applications on HDInsight | Microsoft Azure</source>
          <target state="new">Use Apache Spark to build machine learning applications on HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Step-by-step instructions on how to use notebooks with Apache Spark to build machine learning applications</source>
          <target state="new">Step-by-step instructions on how to use notebooks with Apache Spark to build machine learning applications</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Machine learning: Predictive analysis on food inspection data using MLlib with Spark on HDInsight (Linux)</source>
          <target state="new">Machine learning: Predictive analysis on food inspection data using MLlib with Spark on HDInsight (Linux)</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source><ph id="ph2">[AZURE.TIP]</ph><ph id="ph3" /> This tutorial is also available as a Jupyter notebook on a Spark (Linux) cluster that you create in HDInsight.</source>
          <target state="new"><ph id="ph2">[AZURE.TIP]</ph><ph id="ph3" /> This tutorial is also available as a Jupyter notebook on a Spark (Linux) cluster that you create in HDInsight.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>The notebook experience lets you run the Python snippets from the notebook itself.</source>
          <target state="new">The notebook experience lets you run the Python snippets from the notebook itself.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>To perform the tutorial from within a notebook, create a Spark cluster, launch a Jupyter notebook (<ph id="ph4">`https://CLUSTERNAME.azurehdinsight.net/jupyter`</ph>), and then run the notebook <bpt id="p1">**</bpt>Spark Machine Learning - Predictive analysis on food inspection data using MLLib.ipynb<ept id="p1">**</ept><ph id="ph5" /> under the <bpt id="p2">**</bpt>Python<ept id="p2">**</ept><ph id="ph6" /> folder.</source>
          <target state="new">To perform the tutorial from within a notebook, create a Spark cluster, launch a Jupyter notebook (<ph id="ph4">`https://CLUSTERNAME.azurehdinsight.net/jupyter`</ph>), and then run the notebook <bpt id="p1">**</bpt>Spark Machine Learning - Predictive analysis on food inspection data using MLLib.ipynb<ept id="p1">**</ept><ph id="ph5" /> under the <bpt id="p2">**</bpt>Python<ept id="p2">**</ept><ph id="ph6" /> folder.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>This article demonstrates how to use <bpt id="p3">**</bpt>MLLib<ept id="p3">**</ept>, Spark's built-in machine learning libraries, to perform a simple predictive analysis on an open dataset.</source>
          <target state="new">This article demonstrates how to use <bpt id="p3">**</bpt>MLLib<ept id="p3">**</ept>, Spark's built-in machine learning libraries, to perform a simple predictive analysis on an open dataset.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>MLLib is a core Spark library that provides a number of utilities that are useful for machine learning tasks, including utilities that are suitable for:</source>
          <target state="new">MLLib is a core Spark library that provides a number of utilities that are useful for machine learning tasks, including utilities that are suitable for:</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Classification</source>
          <target state="new">Classification</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Regression</source>
          <target state="new">Regression</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Clustering</source>
          <target state="new">Clustering</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Topic modeling</source>
          <target state="new">Topic modeling</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Singular value decomposition (SVD) and principal component analysis (PCA)</source>
          <target state="new">Singular value decomposition (SVD) and principal component analysis (PCA)</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Hypothesis testing and calculating sample statistics</source>
          <target state="new">Hypothesis testing and calculating sample statistics</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>This article presents a simple approach to <bpt id="p4">*</bpt>classification<ept id="p4">*</ept><ph id="ph7" /> through logistic regression.</source>
          <target state="new">This article presents a simple approach to <bpt id="p4">*</bpt>classification<ept id="p4">*</ept><ph id="ph7" /> through logistic regression.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>What are classification and logistic regression?</source>
          <target state="new">What are classification and logistic regression?</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source><bpt id="p5">*</bpt>Classification<ept id="p5">*</ept>, a very common machine learning task, is the process of sorting input data into categories.</source>
          <target state="new"><bpt id="p5">*</bpt>Classification<ept id="p5">*</ept>, a very common machine learning task, is the process of sorting input data into categories.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>It is the job of a classification algorithm to figure out how to assign "labels" to input data that you provide.</source>
          <target state="new">It is the job of a classification algorithm to figure out how to assign "labels" to input data that you provide.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>For example, you could think of a machine learning algorithm that accepts stock information as input and divides the stock into two categories: stocks which you should sell and stocks which you should retain.</source>
          <target state="new">For example, you could think of a machine learning algorithm that accepts stock information as input and divides the stock into two categories: stocks which you should sell and stocks which you should retain.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Logistic regression is the algorithm that you use for classification.</source>
          <target state="new">Logistic regression is the algorithm that you use for classification.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Spark's logistic regression API is useful for <bpt id="p6">*</bpt>binary classification<ept id="p6">*</ept>, or classifying input data into one of two groups.</source>
          <target state="new">Spark's logistic regression API is useful for <bpt id="p6">*</bpt>binary classification<ept id="p6">*</ept>, or classifying input data into one of two groups.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>For more information about logistic regressions, see <bpt id="p7">[</bpt>Wikipedia<ept id="p7">](https://en.wikipedia.org/wiki/Logistic_regression)</ept>.</source>
          <target state="new">For more information about logistic regressions, see <bpt id="p7">[</bpt>Wikipedia<ept id="p7">](https://en.wikipedia.org/wiki/Logistic_regression)</ept>.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>In summary, the process of logistic regression produces a <bpt id="p8">*</bpt>logistic function<ept id="p8">*</ept><ph id="ph8" /> that can be used to predict the probability that an input vector belongs in one group or the other.</source>
          <target state="new">In summary, the process of logistic regression produces a <bpt id="p8">*</bpt>logistic function<ept id="p8">*</ept><ph id="ph8" /> that can be used to predict the probability that an input vector belongs in one group or the other.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>What are we trying to accomplish in this article?</source>
          <target state="new">What are we trying to accomplish in this article?</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>You will use Spark to perform some predictive analysis on food inspection data (<bpt id="p9">**</bpt>Food_Inspections1.csv<ept id="p9">**</ept>) that was acquired through the <bpt id="p10">[</bpt>City of Chicago data portal<ept id="p10">](https://data.cityofchicago.org/)</ept>.</source>
          <target state="new">You will use Spark to perform some predictive analysis on food inspection data (<bpt id="p9">**</bpt>Food_Inspections1.csv<ept id="p9">**</ept>) that was acquired through the <bpt id="p10">[</bpt>City of Chicago data portal<ept id="p10">](https://data.cityofchicago.org/)</ept>.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>This dataset contains information about food inspections that were conducted in Chicago, including information about each food establishment that was inspected, the violations that were found (if any), and the results of the inspection.</source>
          <target state="new">This dataset contains information about food inspections that were conducted in Chicago, including information about each food establishment that was inspected, the violations that were found (if any), and the results of the inspection.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>In the steps below, you develop a model to see what it takes to pass or fail a food inspection.</source>
          <target state="new">In the steps below, you develop a model to see what it takes to pass or fail a food inspection.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Start building a machine learning application using Spark MLlib</source>
          <target state="new">Start building a machine learning application using Spark MLlib</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>From the <bpt id="p11">[</bpt>Azure Preview Portal<ept id="p11">](https://portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</source>
          <target state="new">From the <bpt id="p11">[</bpt>Azure Preview Portal<ept id="p11">](https://portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>You can also navigate to your cluster under <bpt id="p12">**</bpt>Browse All<ept id="p12">**</ept><ph id="ph9" /> &gt; <bpt id="p13">**</bpt>HDInsight Clusters<ept id="p13">**</ept>.</source>
          <target state="new">You can also navigate to your cluster under <bpt id="p12">**</bpt>Browse All<ept id="p12">**</ept><ph id="ph9" /> &gt; <bpt id="p13">**</bpt>HDInsight Clusters<ept id="p13">**</ept>.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>From the Spark cluster blade, click <bpt id="p14">**</bpt>Quick Links<ept id="p14">**</ept>, and then from the <bpt id="p15">**</bpt>Cluster Dashboard<ept id="p15">**</ept><ph id="ph10" /> blade, click <bpt id="p16">**</bpt>Jupyter Notebook<ept id="p16">**</ept>.</source>
          <target state="new">From the Spark cluster blade, click <bpt id="p14">**</bpt>Quick Links<ept id="p14">**</ept>, and then from the <bpt id="p15">**</bpt>Cluster Dashboard<ept id="p15">**</ept><ph id="ph10" /> blade, click <bpt id="p16">**</bpt>Jupyter Notebook<ept id="p16">**</ept>.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>If prompted, enter the admin credentials for the cluster.</source>
          <target state="new">If prompted, enter the admin credentials for the cluster.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source><ph id="ph11">[AZURE.NOTE]</ph><ph id="ph12" /> You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser.</source>
          <target state="new"><ph id="ph11">[AZURE.NOTE]</ph><ph id="ph12" /> You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Replace <bpt id="p17">__</bpt>CLUSTERNAME<ept id="p17">__</ept><ph id="ph13" /> with the name of your cluster:</source>
          <target state="new">Replace <bpt id="p17">__</bpt>CLUSTERNAME<ept id="p17">__</ept><ph id="ph13" /> with the name of your cluster:</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Create a new notebook.</source>
          <target state="new">Create a new notebook.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p18">**</bpt>New<ept id="p18">**</ept>, and then click <bpt id="p19">**</bpt>Python 2<ept id="p19">**</ept>.</source>
          <target state="new">Click <bpt id="p18">**</bpt>New<ept id="p18">**</ept>, and then click <bpt id="p19">**</bpt>Python 2<ept id="p19">**</ept>.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source><ph id="ph15">![</ph>Create a new Jupyter notebook<ph id="ph16">](./media/hdinsight-apache-spark-machine-learning-mllib-ipython/hdispark.note.jupyter.createnotebook.png "Create a new Jupyter notebook")</ph></source>
          <target state="new"><ph id="ph15">![</ph>Create a new Jupyter notebook<ph id="ph16">](./media/hdinsight-apache-spark-machine-learning-mllib-ipython/hdispark.note.jupyter.createnotebook.png "Create a new Jupyter notebook")</ph></target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>A new notebook is created and opened with the name Untitled.pynb.</source>
          <target state="new">A new notebook is created and opened with the name Untitled.pynb.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Click the notebook name at the top, and enter a friendly name.</source>
          <target state="new">Click the notebook name at the top, and enter a friendly name.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source><ph id="ph17">![</ph>Provide a name for the notebook<ph id="ph18">](./media/hdinsight-apache-spark-machine-learning-mllib-ipython/hdispark.note.jupyter.notebook.name.png "Provide a name for the notebook")</ph></source>
          <target state="new"><ph id="ph17">![</ph>Provide a name for the notebook<ph id="ph18">](./media/hdinsight-apache-spark-machine-learning-mllib-ipython/hdispark.note.jupyter.notebook.name.png "Provide a name for the notebook")</ph></target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Start building your machine learning application.</source>
          <target state="new">Start building your machine learning application.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>You should start by by setting up the Pyspark environment.</source>
          <target state="new">You should start by by setting up the Pyspark environment.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>To do so, place the cursor in the cell and press <bpt id="p20">**</bpt>SHIFT + ENTER<ept id="p20">**</ept>.</source>
          <target state="new">To do so, place the cursor in the cell and press <bpt id="p20">**</bpt>SHIFT + ENTER<ept id="p20">**</ept>.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Construct an input dataframe</source>
          <target state="new">Construct an input dataframe</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>We already have a SQLContext that we can use to perform transformations on structured data.</source>
          <target state="new">We already have a SQLContext that we can use to perform transformations on structured data.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>The first task is to load the sample data ((<bpt id="p21">**</bpt>Food_Inspections1.csv<ept id="p21">**</ept>)) into a Spark SQL <bpt id="p22">*</bpt>dataframe<ept id="p22">*</ept>.</source>
          <target state="new">The first task is to load the sample data ((<bpt id="p21">**</bpt>Food_Inspections1.csv<ept id="p21">**</ept>)) into a Spark SQL <bpt id="p22">*</bpt>dataframe<ept id="p22">*</ept>.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>The snippets below assume that the data is already uploaded to the default storage container associated with the Spark cluster.</source>
          <target state="new">The snippets below assume that the data is already uploaded to the default storage container associated with the Spark cluster.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Because the raw data is in a CSV format, we need to use the Spark context to pull every line of the file into memory as unstructured text; then, you use Python's CSV library to parse each line individually.</source>
          <target state="new">Because the raw data is in a CSV format, we need to use the Spark context to pull every line of the file into memory as unstructured text; then, you use Python's CSV library to parse each line individually.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>We now have the CSV file as an RDD.</source>
          <target state="new">We now have the CSV file as an RDD.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Let us retrieve one row from the RDD to understand the schema of the data.</source>
          <target state="new">Let us retrieve one row from the RDD to understand the schema of the data.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>The above output gives us an idea of the schema of the input file; the file includes the name of every establishment, the type of establishment, the address, the data of the inspections, and the location, among other things.</source>
          <target state="new">The above output gives us an idea of the schema of the input file; the file includes the name of every establishment, the type of establishment, the address, the data of the inspections, and the location, among other things.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Let's select a few columns that will be useful for our predictive analysis and group the results as a dataframe.</source>
          <target state="new">Let's select a few columns that will be useful for our predictive analysis and group the results as a dataframe.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>We now have a <bpt id="p23">*</bpt>dataframe<ept id="p23">*</ept>, <ph id="ph19">`df`</ph><ph id="ph20" /> on which we can perform our analysis.</source>
          <target state="new">We now have a <bpt id="p23">*</bpt>dataframe<ept id="p23">*</ept>, <ph id="ph19">`df`</ph><ph id="ph20" /> on which we can perform our analysis.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>We've included 4 columns of interest in the dataframe: <bpt id="p24">**</bpt>id<ept id="p24">**</ept>, <bpt id="p25">**</bpt>name<ept id="p25">**</ept>, <bpt id="p26">**</bpt>results<ept id="p26">**</ept>, and <bpt id="p27">**</bpt>violations<ept id="p27">**</ept>.</source>
          <target state="new">We've included 4 columns of interest in the dataframe: <bpt id="p24">**</bpt>id<ept id="p24">**</ept>, <bpt id="p25">**</bpt>name<ept id="p25">**</ept>, <bpt id="p26">**</bpt>results<ept id="p26">**</ept>, and <bpt id="p27">**</bpt>violations<ept id="p27">**</ept>.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Let's get a small sample of the data:</source>
          <target state="new">Let's get a small sample of the data:</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Understand the data</source>
          <target state="new">Understand the data</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Let's start to get a sense of what our dataset contains.</source>
          <target state="new">Let's start to get a sense of what our dataset contains.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>For example, what are the different values in the <bpt id="p28">**</bpt>results<ept id="p28">**</ept><ph id="ph21" /> column?</source>
          <target state="new">For example, what are the different values in the <bpt id="p28">**</bpt>results<ept id="p28">**</ept><ph id="ph21" /> column?</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>You should see an output like the following:</source>
          <target state="new">You should see an output like the following:</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>A quick visualization can help us reason about the distribution of these outcomes.</source>
          <target state="new">A quick visualization can help us reason about the distribution of these outcomes.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>You should see an output like the following:</source>
          <target state="new">You should see an output like the following:</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source><ph id="ph22">![</ph>Result output<ph id="ph23">](./media/hdinsight-apache-spark-machine-learning-mllib-ipython/output_13_1.png)</ph></source>
          <target state="new"><ph id="ph22">![</ph>Result output<ph id="ph23">](./media/hdinsight-apache-spark-machine-learning-mllib-ipython/output_13_1.png)</ph></target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>You can see that there are 5 distinct results that an inspection can have</source>
          <target state="new">You can see that there are 5 distinct results that an inspection can have</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>Business not located</source>
          <target state="new">Business not located</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Fail</source>
          <target state="new">Fail</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Pass</source>
          <target state="new">Pass</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Pss w/ conditions, and</source>
          <target state="new">Pss w/ conditions, and</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Out of Business</source>
          <target state="new">Out of Business</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Let us develop a model that can guess the outcome of a food inspection, given the violations.</source>
          <target state="new">Let us develop a model that can guess the outcome of a food inspection, given the violations.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Since logistic regression is a binary classification method, it makes sense to group our data into two categories: <bpt id="p29">**</bpt>Fail<ept id="p29">**</ept><ph id="ph24" /> and <bpt id="p30">**</bpt>Pass<ept id="p30">**</ept>.</source>
          <target state="new">Since logistic regression is a binary classification method, it makes sense to group our data into two categories: <bpt id="p29">**</bpt>Fail<ept id="p29">**</ept><ph id="ph24" /> and <bpt id="p30">**</bpt>Pass<ept id="p30">**</ept>.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>A "Pass w/ Conditions" is still a Pass, so when we train the model, we will consider the two results equivalent.</source>
          <target state="new">A "Pass w/ Conditions" is still a Pass, so when we train the model, we will consider the two results equivalent.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>Data with the other results ("Business Not Located", "Out of Business") are not useful so we will remove them from our training set.</source>
          <target state="new">Data with the other results ("Business Not Located", "Out of Business") are not useful so we will remove them from our training set.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>This should be okay since these two categories make up a very small percentage of the results anyway.</source>
          <target state="new">This should be okay since these two categories make up a very small percentage of the results anyway.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>Let us go ahead and convert our existing dataframe(<ph id="ph25">`df`</ph>) into a new dataframe where each inspection is represented as a label-violations pair.</source>
          <target state="new">Let us go ahead and convert our existing dataframe(<ph id="ph25">`df`</ph>) into a new dataframe where each inspection is represented as a label-violations pair.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>In our case, a label of <ph id="ph26">`0.0`</ph><ph id="ph27" /> represents a failure, a label of <ph id="ph28">`1.0`</ph><ph id="ph29" /> represents a success, and a label of <ph id="ph30">`-1.0`</ph><ph id="ph31" /> represents some results besides those two.</source>
          <target state="new">In our case, a label of <ph id="ph26">`0.0`</ph><ph id="ph27" /> represents a failure, a label of <ph id="ph28">`1.0`</ph><ph id="ph29" /> represents a success, and a label of <ph id="ph30">`-1.0`</ph><ph id="ph31" /> represents some results besides those two.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>We will filter those other results out when computing the new data frame.</source>
          <target state="new">We will filter those other results out when computing the new data frame.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>Let's retrieve one row from the labeled data to see what it looks like.</source>
          <target state="new">Let's retrieve one row from the labeled data to see what it looks like.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>You should see an output like the following:</source>
          <target state="new">You should see an output like the following:</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>Create a logistic regression model from the input dataframe</source>
          <target state="new">Create a logistic regression model from the input dataframe</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>Our final task is to convert the labeled data into a format that can be analyzed by logistic regression.</source>
          <target state="new">Our final task is to convert the labeled data into a format that can be analyzed by logistic regression.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>The input to a logistic regression algorithm should be a set of <bpt id="p31">*</bpt>label-feature vector pairs<ept id="p31">*</ept>, where the "feature vector" is a vector of numbers that represents the input point in some way.</source>
          <target state="new">The input to a logistic regression algorithm should be a set of <bpt id="p31">*</bpt>label-feature vector pairs<ept id="p31">*</ept>, where the "feature vector" is a vector of numbers that represents the input point in some way.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>So, we need a way to convert the "violations" column, which is semi-structured and contains a lot of comments in free-text, to an array of real numbers that a machine could easily understand.</source>
          <target state="new">So, we need a way to convert the "violations" column, which is semi-structured and contains a lot of comments in free-text, to an array of real numbers that a machine could easily understand.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>One standard machine learning approach for processing natural language is to assign each distinct word an "index", and then pass a vector to the machine learning algorithm such that each index's value contains the relative frequency of that word in the text string.</source>
          <target state="new">One standard machine learning approach for processing natural language is to assign each distinct word an "index", and then pass a vector to the machine learning algorithm such that each index's value contains the relative frequency of that word in the text string.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>MLLib provides an easy way to perform this operation.</source>
          <target state="new">MLLib provides an easy way to perform this operation.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>First, we'll "tokenize" each violations string to get the individual words in each string, and then we'll use a <ph id="ph32">`HashingTF`</ph><ph id="ph33" /> to convert each set of tokens into a feature vector which can then be passed to the logistic regression algorithm to construct a model.</source>
          <target state="new">First, we'll "tokenize" each violations string to get the individual words in each string, and then we'll use a <ph id="ph32">`HashingTF`</ph><ph id="ph33" /> to convert each set of tokens into a feature vector which can then be passed to the logistic regression algorithm to construct a model.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>We'll conduct all of these steps in sequence using a "pipeline".</source>
          <target state="new">We'll conduct all of these steps in sequence using a "pipeline".</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>Evaluate the model on a separate test dataset</source>
          <target state="new">Evaluate the model on a separate test dataset</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>We can use the model we created earlier to <bpt id="p32">*</bpt>predict<ept id="p32">*</ept><ph id="ph34" /> what the results of new inspections will be, based on the violations that were observed.</source>
          <target state="new">We can use the model we created earlier to <bpt id="p32">*</bpt>predict<ept id="p32">*</ept><ph id="ph34" /> what the results of new inspections will be, based on the violations that were observed.</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>We trained this model on the dataset <bpt id="p33">**</bpt>Food_Inspections1.csv<ept id="p33">**</ept>.</source>
          <target state="new">We trained this model on the dataset <bpt id="p33">**</bpt>Food_Inspections1.csv<ept id="p33">**</ept>.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>Let us use a second dataset, <bpt id="p34">**</bpt>Food_Inspections2.csv<ept id="p34">**</ept>, to <bpt id="p35">*</bpt>evaluate<ept id="p35">*</ept><ph id="ph35" /> the strength of this model on new data.</source>
          <target state="new">Let us use a second dataset, <bpt id="p34">**</bpt>Food_Inspections2.csv<ept id="p34">**</ept>, to <bpt id="p35">*</bpt>evaluate<ept id="p35">*</ept><ph id="ph35" /> the strength of this model on new data.</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>This second data set (<bpt id="p36">**</bpt>Food_Inspections2.csv<ept id="p36">**</ept>) should already be in the default storage container associated with the cluster.</source>
          <target state="new">This second data set (<bpt id="p36">**</bpt>Food_Inspections2.csv<ept id="p36">**</ept>) should already be in the default storage container associated with the cluster.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>The snippet below creates a new dataframe, <bpt id="p37">**</bpt>predictionsDf<ept id="p37">**</ept><ph id="ph36" /> that contains the prediction generated by the model.</source>
          <target state="new">The snippet below creates a new dataframe, <bpt id="p37">**</bpt>predictionsDf<ept id="p37">**</ept><ph id="ph36" /> that contains the prediction generated by the model.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>You should see an output like the following:</source>
          <target state="new">You should see an output like the following:</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>Look at one of the predictions.</source>
          <target state="new">Look at one of the predictions.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>Run this snippet:</source>
          <target state="new">Run this snippet:</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>You will see the prediction for the first entry in the test data set.</source>
          <target state="new">You will see the prediction for the first entry in the test data set.</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>The <ph id="ph37">`model.transform()`</ph><ph id="ph38" /> method will apply the same transformation to any new data with the same schema, and arrive at a prediction of how to classify the data.</source>
          <target state="new">The <ph id="ph37">`model.transform()`</ph><ph id="ph38" /> method will apply the same transformation to any new data with the same schema, and arrive at a prediction of how to classify the data.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>We can do some simple statistics to get a sense of how accurate our predictions were:</source>
          <target state="new">We can do some simple statistics to get a sense of how accurate our predictions were:</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>The output looks like the following:</source>
          <target state="new">The output looks like the following:</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>Using logistic regression with Spark gives us an accurate model of the relationship between violations descriptions in English and whether a given bussiness would pass or fail a food inspection.</source>
          <target state="new">Using logistic regression with Spark gives us an accurate model of the relationship between violations descriptions in English and whether a given bussiness would pass or fail a food inspection.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>We can construct a final visualization to help us reason about the results of this test:</source>
          <target state="new">We can construct a final visualization to help us reason about the results of this test:</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>You should see the following output.</source>
          <target state="new">You should see the following output.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source><ph id="ph39">![</ph>Prediction output<ph id="ph40">](./media/hdinsight-apache-spark-machine-learning-mllib-ipython/output_26_1.png)</ph></source>
          <target state="new"><ph id="ph39">![</ph>Prediction output<ph id="ph40">](./media/hdinsight-apache-spark-machine-learning-mllib-ipython/output_26_1.png)</ph></target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>In this chart, a "positive" result refers to the failed food inspection, while a negative result refers to a passed inspection.</source>
          <target state="new">In this chart, a "positive" result refers to the failed food inspection, while a negative result refers to a passed inspection.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>This corresponds (roughly) to a 12.6% false negative rate and a 16.0% false positive rate.</source>
          <target state="new">This corresponds (roughly) to a 12.6% false negative rate and a 16.0% false positive rate.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>Shut down the notebook</source>
          <target state="new">Shut down the notebook</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>After you have finished running the application, you should shutdown the notebook to release the resources.</source>
          <target state="new">After you have finished running the application, you should shutdown the notebook to release the resources.</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>To do so, from the <bpt id="p38">**</bpt>File<ept id="p38">**</ept><ph id="ph41" /> menu on the notebook, click <bpt id="p39">**</bpt>Close and Halt<ept id="p39">**</ept>.</source>
          <target state="new">To do so, from the <bpt id="p38">**</bpt>File<ept id="p38">**</ept><ph id="ph41" /> menu on the notebook, click <bpt id="p39">**</bpt>Close and Halt<ept id="p39">**</ept>.</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>This will shutdown and close the notebook.</source>
          <target state="new">This will shutdown and close the notebook.</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>See also</source>
          <target state="new">See also</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source><bpt id="p40">[</bpt>Overview: Apache Spark on Azure HDInsight<ept id="p40">](hdinsight-apache-spark-overview.md)</ept></source>
          <target state="new"><bpt id="p40">[</bpt>Overview: Apache Spark on Azure HDInsight<ept id="p40">](hdinsight-apache-spark-overview.md)</ept></target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>Scenarios</source>
          <target state="new">Scenarios</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source><bpt id="p41">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id="p41">](hdinsight-apache-spark-use-bi-tools.md)</ept></source>
          <target state="new"><bpt id="p41">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id="p41">](hdinsight-apache-spark-use-bi-tools.md)</ept></target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source><bpt id="p42">[</bpt>Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data<ept id="p42">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept></source>
          <target state="new"><bpt id="p42">[</bpt>Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data<ept id="p42">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept></target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source><bpt id="p43">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id="p43">](hdinsight-apache-spark-eventhub-streaming.md)</ept></source>
          <target state="new"><bpt id="p43">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id="p43">](hdinsight-apache-spark-eventhub-streaming.md)</ept></target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source><bpt id="p44">[</bpt>Website log analysis using Spark in HDInsight<ept id="p44">](hdinsight-apache-spark-custom-library-website-log-analysis.md)</ept></source>
          <target state="new"><bpt id="p44">[</bpt>Website log analysis using Spark in HDInsight<ept id="p44">](hdinsight-apache-spark-custom-library-website-log-analysis.md)</ept></target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>Create and run applications</source>
          <target state="new">Create and run applications</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source><bpt id="p45">[</bpt>Create a standalone application using Scala<ept id="p45">](hdinsight-apache-spark-create-standalone-application.md)</ept></source>
          <target state="new"><bpt id="p45">[</bpt>Create a standalone application using Scala<ept id="p45">](hdinsight-apache-spark-create-standalone-application.md)</ept></target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source><bpt id="p46">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id="p46">](hdinsight-apache-spark-livy-rest-interface.md)</ept></source>
          <target state="new"><bpt id="p46">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id="p46">](hdinsight-apache-spark-livy-rest-interface.md)</ept></target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>Tools and extensions</source>
          <target state="new">Tools and extensions</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source><bpt id="p47">[</bpt>Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons<ept id="p47">](hdinsight-apache-spark-intellij-tool-plugin.md)</ept></source>
          <target state="new"><bpt id="p47">[</bpt>Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons<ept id="p47">](hdinsight-apache-spark-intellij-tool-plugin.md)</ept></target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source><bpt id="p48">[</bpt>Use Zeppelin notebooks with a Spark cluster on HDInsight<ept id="p48">](hdinsight-apache-spark-use-zeppelin-notebook.md)</ept></source>
          <target state="new"><bpt id="p48">[</bpt>Use Zeppelin notebooks with a Spark cluster on HDInsight<ept id="p48">](hdinsight-apache-spark-use-zeppelin-notebook.md)</ept></target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source><bpt id="p49">[</bpt>Kernels available for Jupyter notebook in Spark cluster for HDInsight<ept id="p49">](hdinsight-apache-spark-jupyter-notebook-kernels.md)</ept></source>
          <target state="new"><bpt id="p49">[</bpt>Kernels available for Jupyter notebook in Spark cluster for HDInsight<ept id="p49">](hdinsight-apache-spark-jupyter-notebook-kernels.md)</ept></target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>Manage resources</source>
          <target state="new">Manage resources</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source><bpt id="p50">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id="p50">](hdinsight-apache-spark-resource-manager.md)</ept></source>
          <target state="new"><bpt id="p50">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id="p50">](hdinsight-apache-spark-resource-manager.md)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1a8b7e0556383c8ba7db0eb8d46108fda9a30eaa</xliffext:olfilehash>
  </header>
</xliff>