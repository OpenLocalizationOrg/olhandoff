<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Introduction to Apache Storm on HDInsight | Microsoft Azure</source>
          <target state="new">Introduction to Apache Storm on HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Get an introduction to Apache Storm, and learn how you can use Storm on HDInsight to build real-time data analytics solutions in the cloud.</source>
          <target state="new">Get an introduction to Apache Storm, and learn how you can use Storm on HDInsight to build real-time data analytics solutions in the cloud.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Introduction to Apache Storm on HDInsight: Real-time analytics for Hadoop</source>
          <target state="new">Introduction to Apache Storm on HDInsight: Real-time analytics for Hadoop</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Apache Storm on HDInsight allows you to create distributed, real-time analytics solutions in the Azure environment by using <bpt id="p1">[</bpt>Apache Hadoop<ept id="p1">](http://hadoop.apache.org)</ept>.</source>
          <target state="new">Apache Storm on HDInsight allows you to create distributed, real-time analytics solutions in the Azure environment by using <bpt id="p1">[</bpt>Apache Hadoop<ept id="p1">](http://hadoop.apache.org)</ept>.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>What is Apache Storm?</source>
          <target state="new">What is Apache Storm?</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Apache Storm is a distributed, fault-tolerant, open-source computation system that allows you to process data in real-time with Hadoop.</source>
          <target state="new">Apache Storm is a distributed, fault-tolerant, open-source computation system that allows you to process data in real-time with Hadoop.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Storm solutions can also provide guaranteed processing of data, with the ability to replay data that was not successfully processed the first time.</source>
          <target state="new">Storm solutions can also provide guaranteed processing of data, with the ability to replay data that was not successfully processed the first time.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Why use Storm on HDInsight?</source>
          <target state="new">Why use Storm on HDInsight?</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Apache Storm on HDInsight is a managed cluster integrated into the Azure environment.</source>
          <target state="new">Apache Storm on HDInsight is a managed cluster integrated into the Azure environment.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>It provides the following key benefits:</source>
          <target state="new">It provides the following key benefits:</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Performs as a managed service with an SLA of 99.9% up time</source>
          <target state="new">Performs as a managed service with an SLA of 99.9% up time</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Use the language of your choice: Provides support for Storm components written in <bpt id="p2">**</bpt>Java<ept id="p2">**</ept>, <bpt id="p3">**</bpt>C#<ept id="p3">**</ept>, and <bpt id="p4">**</bpt>Python<ept id="p4">**</ept></source>
          <target state="new">Use the language of your choice: Provides support for Storm components written in <bpt id="p2">**</bpt>Java<ept id="p2">**</ept>, <bpt id="p3">**</bpt>C#<ept id="p3">**</ept>, and <bpt id="p4">**</bpt>Python<ept id="p4">**</ept></target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Supports a mix of programming languages: Read data using Java, then process it using C</source>
          <target state="new">Supports a mix of programming languages: Read data using Java, then process it using C</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source><ph id="ph2">[AZURE.NOTE]</ph><ph id="ph3" /> C# topologies are only supported on Windows-based HDInsight clusters.</source>
          <target state="new"><ph id="ph2">[AZURE.NOTE]</ph><ph id="ph3" /> C# topologies are only supported on Windows-based HDInsight clusters.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Use the <bpt id="p5">**</bpt>Trident<ept id="p5">**</ept><ph id="ph4" /> Java interface to create Storm topologies that support "exactly once" processing of messages, "transactional" datastore persistence, and a set of common stream analytics operations</source>
          <target state="new">Use the <bpt id="p5">**</bpt>Trident<ept id="p5">**</ept><ph id="ph4" /> Java interface to create Storm topologies that support "exactly once" processing of messages, "transactional" datastore persistence, and a set of common stream analytics operations</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Includes built-in scale-up and scale-down features: Scale an HDInsight cluster with no impact to running Storm topologies</source>
          <target state="new">Includes built-in scale-up and scale-down features: Scale an HDInsight cluster with no impact to running Storm topologies</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Integrate with other Azure services, including Event Hub, Azure Virtual Network, SQL Database, Blob storage, and DocumentDB</source>
          <target state="new">Integrate with other Azure services, including Event Hub, Azure Virtual Network, SQL Database, Blob storage, and DocumentDB</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Combine the capabilities of multiple HDInsight clusters by using Azure Virtual Network: Create analytic pipelines that use HDInsight, HBase, or Hadoop clusters</source>
          <target state="new">Combine the capabilities of multiple HDInsight clusters by using Azure Virtual Network: Create analytic pipelines that use HDInsight, HBase, or Hadoop clusters</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>For a list of companies that are using Apache Storm for their real-time analytics solutions, see <bpt id="p6">[</bpt>Companies Using Apache Storm<ept id="p6">](https://storm.apache.org/documentation/Powered-By.html)</ept>.</source>
          <target state="new">For a list of companies that are using Apache Storm for their real-time analytics solutions, see <bpt id="p6">[</bpt>Companies Using Apache Storm<ept id="p6">](https://storm.apache.org/documentation/Powered-By.html)</ept>.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>To get started using Storm, see <bpt id="p7">[</bpt>Get started with Storm on HDInsight<ept id="p7">][gettingstarted]</ept>.</source>
          <target state="new">To get started using Storm, see <bpt id="p7">[</bpt>Get started with Storm on HDInsight<ept id="p7">][gettingstarted]</ept>.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Ease of provisioning</source>
          <target state="new">Ease of provisioning</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>You can provision a new Storm on HDInsight cluster in minutes.</source>
          <target state="new">You can provision a new Storm on HDInsight cluster in minutes.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Specify the cluster name, size, administrator account, and the storage account.</source>
          <target state="new">Specify the cluster name, size, administrator account, and the storage account.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Azure will create the cluster, including sample topologies and a web-management dashboard.</source>
          <target state="new">Azure will create the cluster, including sample topologies and a web-management dashboard.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source><ph id="ph5">[AZURE.NOTE]</ph><ph id="ph6" /> You can also provision Storm clusters by using the <bpt id="p8">[</bpt>Azure CLI<ept id="p8">](../xplat-cli-install.md)</ept><ph id="ph7" /> or <bpt id="p9">[</bpt>Azure PowerShell<ept id="p9">](../powershell-install-configure.md)</ept>.</source>
          <target state="new"><ph id="ph5">[AZURE.NOTE]</ph><ph id="ph6" /> You can also provision Storm clusters by using the <bpt id="p8">[</bpt>Azure CLI<ept id="p8">](../xplat-cli-install.md)</ept><ph id="ph7" /> or <bpt id="p9">[</bpt>Azure PowerShell<ept id="p9">](../powershell-install-configure.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Within 15 minutes of submitting the request, you will have a new Storm cluster running and ready for your first real-time analytics pipeline.</source>
          <target state="new">Within 15 minutes of submitting the request, you will have a new Storm cluster running and ready for your first real-time analytics pipeline.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Ease of use</source>
          <target state="new">Ease of use</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source><bpt id="p10">__</bpt>For Linux-based Storm on HDInsight clusters<ept id="p10">__</ept>, you can connect to the cluster using SSH and use the <ph id="ph8">`storm`</ph><ph id="ph9" /> command to start and manage topologies.</source>
          <target state="new"><bpt id="p10">__</bpt>For Linux-based Storm on HDInsight clusters<ept id="p10">__</ept>, you can connect to the cluster using SSH and use the <ph id="ph8">`storm`</ph><ph id="ph9" /> command to start and manage topologies.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Additionally, you can use Ambari to monitor the Storm service and the Storm UI to monitor and manage running topologies.</source>
          <target state="new">Additionally, you can use Ambari to monitor the Storm service and the Storm UI to monitor and manage running topologies.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>For more information on working with Linux-based Storm clusters, see <bpt id="p11">[</bpt>Get started with Apache Storm on Linux-based HDInsight<ept id="p11">](hdinsight-apache-storm-tutorial-get-started-linux.md)</ept>.</source>
          <target state="new">For more information on working with Linux-based Storm clusters, see <bpt id="p11">[</bpt>Get started with Apache Storm on Linux-based HDInsight<ept id="p11">](hdinsight-apache-storm-tutorial-get-started-linux.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><bpt id="p12">__</bpt>For Windows-based Storm on HDInsight clusters<ept id="p12">__</ept>, the HDInsight Tools for Visual Studio allow you to create C# and hybrid C#/Java topologies, and then submit them to your Storm on HDInsight cluster.</source>
          <target state="new"><bpt id="p12">__</bpt>For Windows-based Storm on HDInsight clusters<ept id="p12">__</ept>, the HDInsight Tools for Visual Studio allow you to create C# and hybrid C#/Java topologies, and then submit them to your Storm on HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source><ph id="ph10">![</ph>Storm Project creation<ph id="ph11">](./media/hdinsight-storm-overview/createproject.png)</ph></source>
          <target state="new"><ph id="ph10">![</ph>Storm Project creation<ph id="ph11">](./media/hdinsight-storm-overview/createproject.png)</ph></target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>HDInsight Tools for Visual Studio also provides an interface that allows you to monitor and manage Storm topologies on a cluster.</source>
          <target state="new">HDInsight Tools for Visual Studio also provides an interface that allows you to monitor and manage Storm topologies on a cluster.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source><ph id="ph12">![</ph>Storm management<ph id="ph13">](./media/hdinsight-storm-overview/stormview.png)</ph></source>
          <target state="new"><ph id="ph12">![</ph>Storm management<ph id="ph13">](./media/hdinsight-storm-overview/stormview.png)</ph></target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>For an example of using the HDInsight Tools to create a Storm application, see <bpt id="p13">[</bpt>Develop C# Storm topologies with the HDInsight Tools for Visual Studio<ept id="p13">](hdinsight-storm-develop-csharp-visual-studio-topology.md)</ept>.</source>
          <target state="new">For an example of using the HDInsight Tools to create a Storm application, see <bpt id="p13">[</bpt>Develop C# Storm topologies with the HDInsight Tools for Visual Studio<ept id="p13">](hdinsight-storm-develop-csharp-visual-studio-topology.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>For more information about the HDInsight Tools for Visual Studio, see <bpt id="p14">[</bpt>Get started using the HDInsight Tools for Visual Studio<ept id="p14">](../HDInsight/hdinsight-hadoop-visual-studio-tools-get-started.md)</ept>.</source>
          <target state="new">For more information about the HDInsight Tools for Visual Studio, see <bpt id="p14">[</bpt>Get started using the HDInsight Tools for Visual Studio<ept id="p14">](../HDInsight/hdinsight-hadoop-visual-studio-tools-get-started.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Each Storm on HDInsight cluster also provides a web-based Storm Dashboard that allows you to submit, monitor, and manage Storm topologies running on the cluster.</source>
          <target state="new">Each Storm on HDInsight cluster also provides a web-based Storm Dashboard that allows you to submit, monitor, and manage Storm topologies running on the cluster.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source><ph id="ph14">![</ph>Storm dashboard<ph id="ph15">](./media/hdinsight-storm-overview/dashboard.png)</ph></source>
          <target state="new"><ph id="ph14">![</ph>Storm dashboard<ph id="ph15">](./media/hdinsight-storm-overview/dashboard.png)</ph></target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>For more information about using the Storm Dashboard, see <bpt id="p15">[</bpt>Deploy and manage Apache Storm topologies on HDInsight<ept id="p15">](hdinsight-storm-deploy-monitor-topology.md)</ept>.</source>
          <target state="new">For more information about using the Storm Dashboard, see <bpt id="p15">[</bpt>Deploy and manage Apache Storm topologies on HDInsight<ept id="p15">](hdinsight-storm-deploy-monitor-topology.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Storm on HDInsight also provides easy integration with Azure Event Hubs through the <bpt id="p16">**</bpt>Event Hub Spout<ept id="p16">**</ept>.</source>
          <target state="new">Storm on HDInsight also provides easy integration with Azure Event Hubs through the <bpt id="p16">**</bpt>Event Hub Spout<ept id="p16">**</ept>.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>This is available on each storm cluster at <bpt id="p17">**</bpt>%STORM_HOME%\examples\eventhubspout\eventhubs-storm-spout-0.9-jar-with-dependencies.jar<ept id="p17">**</ept>.</source>
          <target state="new">This is available on each storm cluster at <bpt id="p17">**</bpt>%STORM_HOME%\examples\eventhubspout\eventhubs-storm-spout-0.9-jar-with-dependencies.jar<ept id="p17">**</ept>.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>For examples of using this spout in a Storm topology, see the following documents:</source>
          <target state="new">For examples of using this spout in a Storm topology, see the following documents:</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source><bpt id="p18">[</bpt>Develop a C# topology that uses Azure Event Hubs<ept id="p18">](hdinsight-storm-develop-csharp-event-hub-topology.md)</ept></source>
          <target state="new"><bpt id="p18">[</bpt>Develop a C# topology that uses Azure Event Hubs<ept id="p18">](hdinsight-storm-develop-csharp-event-hub-topology.md)</ept></target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source><bpt id="p19">[</bpt>Develop a Java topology that uses Azure Event Hubs<ept id="p19">](hdinsight-storm-develop-java-event-hub-topology.md)</ept></source>
          <target state="new"><bpt id="p19">[</bpt>Develop a Java topology that uses Azure Event Hubs<ept id="p19">](hdinsight-storm-develop-java-event-hub-topology.md)</ept></target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Reliability</source>
          <target state="new">Reliability</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Apache Storm always guarantees that each incoming message will be fully processed, even when the data analysis is spread over hundreds of nodes.</source>
          <target state="new">Apache Storm always guarantees that each incoming message will be fully processed, even when the data analysis is spread over hundreds of nodes.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>The <bpt id="p20">**</bpt>Nimbus node<ept id="p20">**</ept><ph id="ph16" /> provides similar functionality to the Hadoop JobTracker, and it assigns tasks to other nodes in the cluster through <bpt id="p21">**</bpt>Zookeeper<ept id="p21">**</ept>.</source>
          <target state="new">The <bpt id="p20">**</bpt>Nimbus node<ept id="p20">**</ept><ph id="ph16" /> provides similar functionality to the Hadoop JobTracker, and it assigns tasks to other nodes in the cluster through <bpt id="p21">**</bpt>Zookeeper<ept id="p21">**</ept>.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Zookeeper nodes provide coordination for the cluster and facilitate communication between Nimbus and the <bpt id="p22">**</bpt>Supervisor<ept id="p22">**</ept><ph id="ph17" /> process on the worker nodes.</source>
          <target state="new">Zookeeper nodes provide coordination for the cluster and facilitate communication between Nimbus and the <bpt id="p22">**</bpt>Supervisor<ept id="p22">**</ept><ph id="ph17" /> process on the worker nodes.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>If one processing node goes down, the Nimbus node is informed, and it assigns the task and associated data to another node.</source>
          <target state="new">If one processing node goes down, the Nimbus node is informed, and it assigns the task and associated data to another node.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>The default configuration for Apache Storm is to have only one Nimbus node.</source>
          <target state="new">The default configuration for Apache Storm is to have only one Nimbus node.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>Storm on HDInsight runs two Nimbus nodes.</source>
          <target state="new">Storm on HDInsight runs two Nimbus nodes.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>If the primary node fails, the HDInsight cluster will switch to the secondary node while the primary node is recovered.</source>
          <target state="new">If the primary node fails, the HDInsight cluster will switch to the secondary node while the primary node is recovered.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source><ph id="ph18">![</ph>Diagram of nimbus, zookeeper, and supervisor<ph id="ph19">](./media/hdinsight-storm-overview/nimbus.png)</ph></source>
          <target state="new"><ph id="ph18">![</ph>Diagram of nimbus, zookeeper, and supervisor<ph id="ph19">](./media/hdinsight-storm-overview/nimbus.png)</ph></target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>Scale</source>
          <target state="new">Scale</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match workload.</source>
          <target state="new">Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match workload.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>All HDInsight clusters allow you to change the number of nodes in the cluster, even while processing data.</source>
          <target state="new">All HDInsight clusters allow you to change the number of nodes in the cluster, even while processing data.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source><ph id="ph20">[AZURE.NOTE]</ph><ph id="ph21" /> To take advantage of new nodes added through scaling, you will need to rebalance topologies started before the cluster size was increased.</source>
          <target state="new"><ph id="ph20">[AZURE.NOTE]</ph><ph id="ph21" /> To take advantage of new nodes added through scaling, you will need to rebalance topologies started before the cluster size was increased.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>Support</source>
          <target state="new">Support</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Storm on HDInsight comes with full enterprise-level 24/7 support.</source>
          <target state="new">Storm on HDInsight comes with full enterprise-level 24/7 support.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Storm on HDInsight also has an SLA of 99.9%.</source>
          <target state="new">Storm on HDInsight also has an SLA of 99.9%.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>That means we guarantee that the cluster will have external connectivity at least 99.9% of the time.</source>
          <target state="new">That means we guarantee that the cluster will have external connectivity at least 99.9% of the time.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>Common use cases for real-time analytics</source>
          <target state="new">Common use cases for real-time analytics</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>The following are some common scenarios for which you might use Apache storm on HDInsight.</source>
          <target state="new">The following are some common scenarios for which you might use Apache storm on HDInsight.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>For information about real-world scenarios, read <bpt id="p23">[</bpt>How companies are using Storm<ept id="p23">](https://storm.incubator.apache.org/documentation/Powered-By.html)</ept>.</source>
          <target state="new">For information about real-world scenarios, read <bpt id="p23">[</bpt>How companies are using Storm<ept id="p23">](https://storm.incubator.apache.org/documentation/Powered-By.html)</ept>.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Internet of Things (IoT)</source>
          <target state="new">Internet of Things (IoT)</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Fraud detection</source>
          <target state="new">Fraud detection</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Social analytics</source>
          <target state="new">Social analytics</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Extract, Transform, Load (ETL)</source>
          <target state="new">Extract, Transform, Load (ETL)</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Network monitoring</source>
          <target state="new">Network monitoring</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Search</source>
          <target state="new">Search</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Mobile engagement</source>
          <target state="new">Mobile engagement</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>How is data in HDInsight Storm processed?</source>
          <target state="new">How is data in HDInsight Storm processed?</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Apache Storm runs <bpt id="p24">**</bpt>topologies<ept id="p24">**</ept><ph id="ph22" /> instead of the MapReduce jobs that you may be familiar with in HDInsight or Hadoop.</source>
          <target state="new">Apache Storm runs <bpt id="p24">**</bpt>topologies<ept id="p24">**</ept><ph id="ph22" /> instead of the MapReduce jobs that you may be familiar with in HDInsight or Hadoop.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>A Storm on HDInsight cluster contains two types of nodes: head nodes that run <bpt id="p25">**</bpt>Nimbus<ept id="p25">**</ept><ph id="ph23" /> and worker nodes that run <bpt id="p26">**</bpt>Supervisor<ept id="p26">**</ept>.</source>
          <target state="new">A Storm on HDInsight cluster contains two types of nodes: head nodes that run <bpt id="p25">**</bpt>Nimbus<ept id="p25">**</ept><ph id="ph23" /> and worker nodes that run <bpt id="p26">**</bpt>Supervisor<ept id="p26">**</ept>.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source><bpt id="p27">**</bpt>Nimbus<ept id="p27">**</ept>: Similar to the JobTracker in Hadoop, it is responsible for distributing code throughout the cluster, assigning tasks to virtual machines, and monitoring for failure.</source>
          <target state="new"><bpt id="p27">**</bpt>Nimbus<ept id="p27">**</ept>: Similar to the JobTracker in Hadoop, it is responsible for distributing code throughout the cluster, assigning tasks to virtual machines, and monitoring for failure.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>HDInsight provides two Nimbus nodes, so there is no single point of failure for Storm on HDInsight</source>
          <target state="new">HDInsight provides two Nimbus nodes, so there is no single point of failure for Storm on HDInsight</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source><bpt id="p28">**</bpt>Supervisor<ept id="p28">**</ept>: The supervisor for each worker node is responsible for starting and stopping <bpt id="p29">**</bpt>worker processes<ept id="p29">**</ept><ph id="ph24" /> on the node.</source>
          <target state="new"><bpt id="p28">**</bpt>Supervisor<ept id="p28">**</ept>: The supervisor for each worker node is responsible for starting and stopping <bpt id="p29">**</bpt>worker processes<ept id="p29">**</ept><ph id="ph24" /> on the node.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source><bpt id="p30">**</bpt>Worker process<ept id="p30">**</ept>: Runs a subset of a <bpt id="p31">**</bpt>topology<ept id="p31">**</ept>.</source>
          <target state="new"><bpt id="p30">**</bpt>Worker process<ept id="p30">**</ept>: Runs a subset of a <bpt id="p31">**</bpt>topology<ept id="p31">**</ept>.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>A running topology is distributed across many worker processes throughout the cluster.</source>
          <target state="new">A running topology is distributed across many worker processes throughout the cluster.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source><bpt id="p32">**</bpt>Topology<ept id="p32">**</ept>: Defines a graph of computation that processes <bpt id="p33">**</bpt>streams<ept id="p33">**</ept><ph id="ph25" /> of data.</source>
          <target state="new"><bpt id="p32">**</bpt>Topology<ept id="p32">**</ept>: Defines a graph of computation that processes <bpt id="p33">**</bpt>streams<ept id="p33">**</ept><ph id="ph25" /> of data.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>Unlike MapReduce jobs, topologies run until you stop them.</source>
          <target state="new">Unlike MapReduce jobs, topologies run until you stop them.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source><bpt id="p34">**</bpt>Stream<ept id="p34">**</ept>: An unbound collection of <bpt id="p35">**</bpt>tuples<ept id="p35">**</ept>.</source>
          <target state="new"><bpt id="p34">**</bpt>Stream<ept id="p34">**</ept>: An unbound collection of <bpt id="p35">**</bpt>tuples<ept id="p35">**</ept>.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>Streams are produced by <bpt id="p36">**</bpt>spouts<ept id="p36">**</ept><ph id="ph26" /> and <bpt id="p37">**</bpt>bolts<ept id="p37">**</ept>, and they are consumed by <bpt id="p38">**</bpt>bolts<ept id="p38">**</ept>.</source>
          <target state="new">Streams are produced by <bpt id="p36">**</bpt>spouts<ept id="p36">**</ept><ph id="ph26" /> and <bpt id="p37">**</bpt>bolts<ept id="p37">**</ept>, and they are consumed by <bpt id="p38">**</bpt>bolts<ept id="p38">**</ept>.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source><bpt id="p39">**</bpt>Tuple<ept id="p39">**</ept>: A named list of dynamically typed values.</source>
          <target state="new"><bpt id="p39">**</bpt>Tuple<ept id="p39">**</ept>: A named list of dynamically typed values.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source><bpt id="p40">**</bpt>Spout<ept id="p40">**</ept>: Consumes data from a data source and emits one or more <bpt id="p41">**</bpt>streams<ept id="p41">**</ept>.</source>
          <target state="new"><bpt id="p40">**</bpt>Spout<ept id="p40">**</ept>: Consumes data from a data source and emits one or more <bpt id="p41">**</bpt>streams<ept id="p41">**</ept>.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source><ph id="ph27">[AZURE.NOTE]</ph><ph id="ph28" /> In many cases, data is read from a queue, such as Kafka, Azure Service Bus queues, or Event hubs.</source>
          <target state="new"><ph id="ph27">[AZURE.NOTE]</ph><ph id="ph28" /> In many cases, data is read from a queue, such as Kafka, Azure Service Bus queues, or Event hubs.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>The queue ensures that data is persisted if there is an outage.</source>
          <target state="new">The queue ensures that data is persisted if there is an outage.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source><bpt id="p42">**</bpt>Bolt<ept id="p42">**</ept>: Consumes <bpt id="p43">**</bpt>streams<ept id="p43">**</ept>, performs processing on <bpt id="p44">**</bpt>tuples<ept id="p44">**</ept>, and may emit <bpt id="p45">**</bpt>streams<ept id="p45">**</ept>.</source>
          <target state="new"><bpt id="p42">**</bpt>Bolt<ept id="p42">**</ept>: Consumes <bpt id="p43">**</bpt>streams<ept id="p43">**</ept>, performs processing on <bpt id="p44">**</bpt>tuples<ept id="p44">**</ept>, and may emit <bpt id="p45">**</bpt>streams<ept id="p45">**</ept>.</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>Bolts are also responsible for writing data to external storage, such as a queue, HDInsight, HBase, a blob, or other data store.</source>
          <target state="new">Bolts are also responsible for writing data to external storage, such as a queue, HDInsight, HBase, a blob, or other data store.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source><bpt id="p46">**</bpt>Apache Thrift<ept id="p46">**</ept>: A software framework for scalable cross-language service development.</source>
          <target state="new"><bpt id="p46">**</bpt>Apache Thrift<ept id="p46">**</ept>: A software framework for scalable cross-language service development.</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>It allows you to build services that work between C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, and other languages.</source>
          <target state="new">It allows you to build services that work between C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, and other languages.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source><bpt id="p47">**</bpt>Nimbus<ept id="p47">**</ept><ph id="ph29" /> is a Thrift service, and a <bpt id="p48">**</bpt>topology<ept id="p48">**</ept><ph id="ph30" /> is a Thrift definition, so it is possible to develop topologies using a variety of programming languages.</source>
          <target state="new"><bpt id="p47">**</bpt>Nimbus<ept id="p47">**</ept><ph id="ph29" /> is a Thrift service, and a <bpt id="p48">**</bpt>topology<ept id="p48">**</ept><ph id="ph30" /> is a Thrift definition, so it is possible to develop topologies using a variety of programming languages.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>For more information about Storm components, see the <bpt id="p49">[</bpt>Storm tutorial<ept id="p49">][apachetutorial]</ept><ph id="ph31" /> at apache.org.</source>
          <target state="new">For more information about Storm components, see the <bpt id="p49">[</bpt>Storm tutorial<ept id="p49">][apachetutorial]</ept><ph id="ph31" /> at apache.org.</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>What programming languages can I use?</source>
          <target state="new">What programming languages can I use?</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>The Storm on HDInsight cluster provides support for C#, Java, and Python.</source>
          <target state="new">The Storm on HDInsight cluster provides support for C#, Java, and Python.</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>C&amp;#35;</source>
          <target state="new">C&amp;#35;</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>The HDInsight Tools for Visual Studio allow .NET developers to design and implement a topology in C#.</source>
          <target state="new">The HDInsight Tools for Visual Studio allow .NET developers to design and implement a topology in C#.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>You can also create hybrid topologies that use Java and C# components.</source>
          <target state="new">You can also create hybrid topologies that use Java and C# components.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p50">[</bpt>Develop C# topologies for Apache Storm on HDInsight using Visual Studio<ept id="p50">](hdinsight-storm-develop-csharp-visual-studio-topology.md)</ept>.</source>
          <target state="new">For more information, see <bpt id="p50">[</bpt>Develop C# topologies for Apache Storm on HDInsight using Visual Studio<ept id="p50">](hdinsight-storm-develop-csharp-visual-studio-topology.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>Java</source>
          <target state="new">Java</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>Most Java examples you encounter will be plain Java or Trident.</source>
          <target state="new">Most Java examples you encounter will be plain Java or Trident.</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>Trident is a high-level abstraction that makes it easier to do things such as joins, aggregations, grouping, and filtering.</source>
          <target state="new">Trident is a high-level abstraction that makes it easier to do things such as joins, aggregations, grouping, and filtering.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>However, Trident acts on batches of tuples, whereas a raw Java solution processes a stream one tuple at a time.</source>
          <target state="new">However, Trident acts on batches of tuples, whereas a raw Java solution processes a stream one tuple at a time.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>For more information about Trident, see the <bpt id="p51">[</bpt>Trident tutorial<ept id="p51">](https://storm.incubator.apache.org/documentation/Trident-tutorial.html)</ept><ph id="ph32" /> at apache.org.</source>
          <target state="new">For more information about Trident, see the <bpt id="p51">[</bpt>Trident tutorial<ept id="p51">](https://storm.incubator.apache.org/documentation/Trident-tutorial.html)</ept><ph id="ph32" /> at apache.org.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>For examples of Java and Trident topologies, see the <bpt id="p52">[</bpt>list of example Storm topologies<ept id="p52">](hdinsight-storm-example-topology.md)</ept><ph id="ph33" /> or the storm-starter examples on your HDInsight cluster.</source>
          <target state="new">For examples of Java and Trident topologies, see the <bpt id="p52">[</bpt>list of example Storm topologies<ept id="p52">](hdinsight-storm-example-topology.md)</ept><ph id="ph33" /> or the storm-starter examples on your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>The storm-starter examples are located in the __ /usr/hdp/current/storm-client/contrib/storm-starter__ directory on Linux-based clusters, and the <bpt id="p53">**</bpt>%storm_home%\contrib\storm-starter<ept id="p53">**</ept><ph id="ph34" /> directory on Windows-based clusters.</source>
          <target state="new">The storm-starter examples are located in the __ /usr/hdp/current/storm-client/contrib/storm-starter__ directory on Linux-based clusters, and the <bpt id="p53">**</bpt>%storm_home%\contrib\storm-starter<ept id="p53">**</ept><ph id="ph34" /> directory on Windows-based clusters.</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>What are some common development patterns?</source>
          <target state="new">What are some common development patterns?</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>Guaranteed message processing</source>
          <target state="new">Guaranteed message processing</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>Storm can provide different levels of guaranteed message processing.</source>
          <target state="new">Storm can provide different levels of guaranteed message processing.</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>For example, a basic Storm application can guarantee at-least-once processing, and Trident can guarantee exactly-once processing.</source>
          <target state="new">For example, a basic Storm application can guarantee at-least-once processing, and Trident can guarantee exactly-once processing.</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p54">[</bpt>Guarantees on data processing<ept id="p54">](https://storm.apache.org/about/guarantees-data-processing.html)</ept><ph id="ph35" /> at apache.org.</source>
          <target state="new">For more information, see <bpt id="p54">[</bpt>Guarantees on data processing<ept id="p54">](https://storm.apache.org/about/guarantees-data-processing.html)</ept><ph id="ph35" /> at apache.org.</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>IBasicBolt</source>
          <target state="new">IBasicBolt</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>The pattern of reading an input tuple, emitting zero or more tuples, and then acking the input tuple immediately at the end of the execute method is very common, and Storm provides the <bpt id="p55">[</bpt>IBasicBolt<ept id="p55">](https://storm.apache.org/apidocs/backtype/storm/topology/IBasicBolt.html)</ept><ph id="ph36" /> interface to automate this pattern.</source>
          <target state="new">The pattern of reading an input tuple, emitting zero or more tuples, and then acking the input tuple immediately at the end of the execute method is very common, and Storm provides the <bpt id="p55">[</bpt>IBasicBolt<ept id="p55">](https://storm.apache.org/apidocs/backtype/storm/topology/IBasicBolt.html)</ept><ph id="ph36" /> interface to automate this pattern.</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>Joins</source>
          <target state="new">Joins</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>Joining two streams of data will vary between applications.</source>
          <target state="new">Joining two streams of data will vary between applications.</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>For example, you could join each tuple from multiple streams into one new stream, or you could join only batches of tuples for a specific window.</source>
          <target state="new">For example, you could join each tuple from multiple streams into one new stream, or you could join only batches of tuples for a specific window.</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>Either way, joining can be accomplished by using <bpt id="p56">[</bpt>fieldsGrouping<ept id="p56">](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29)</ept>, which is a way of defining how tuples are routed to bolts.</source>
          <target state="new">Either way, joining can be accomplished by using <bpt id="p56">[</bpt>fieldsGrouping<ept id="p56">](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29)</ept>, which is a way of defining how tuples are routed to bolts.</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>In the following Java example, fieldsGrouping is used to route tuples that originate from components "1", "2", and "3" to the <bpt id="p57">**</bpt>MyJoiner<ept id="p57">**</ept><ph id="ph37" /> bolt.</source>
          <target state="new">In the following Java example, fieldsGrouping is used to route tuples that originate from components "1", "2", and "3" to the <bpt id="p57">**</bpt>MyJoiner<ept id="p57">**</ept><ph id="ph37" /> bolt.</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>Batching</source>
          <target state="new">Batching</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>Batching can be accomplished several ways.</source>
          <target state="new">Batching can be accomplished several ways.</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>With a basic Storm Java topology, you might use simple counter to batch X number of tuples before emitting them, or use an internal timing mechanism known as a "tick tuple" to emit a batch every X seconds.</source>
          <target state="new">With a basic Storm Java topology, you might use simple counter to batch X number of tuples before emitting them, or use an internal timing mechanism known as a "tick tuple" to emit a batch every X seconds.</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>For an example of using tick tuples, see <bpt id="p58">[</bpt>Analyzing sensor data with Storm and HBase on HDInsight<ept id="p58">](hdinsight-storm-sensor-data-analysis.md)</ept>.</source>
          <target state="new">For an example of using tick tuples, see <bpt id="p58">[</bpt>Analyzing sensor data with Storm and HBase on HDInsight<ept id="p58">](hdinsight-storm-sensor-data-analysis.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>If you are using Trident, it is based on processing batches of tuples.</source>
          <target state="new">If you are using Trident, it is based on processing batches of tuples.</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>Caching</source>
          <target state="new">Caching</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>In-memory caching is often used as a mechanism for speeding up processing because it keeps frequently used assets in memory.</source>
          <target state="new">In-memory caching is often used as a mechanism for speeding up processing because it keeps frequently used assets in memory.</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>Because a topology is distributed across multiple nodes, and multiple processes within each node, you should consider using <bpt id="p59">[</bpt>fieldsGrouping<ept id="p59">](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29)</ept><ph id="ph38" /> to ensure that tuples containing the fields that are used for cache lookup are always routed to the same process.</source>
          <target state="new">Because a topology is distributed across multiple nodes, and multiple processes within each node, you should consider using <bpt id="p59">[</bpt>fieldsGrouping<ept id="p59">](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29)</ept><ph id="ph38" /> to ensure that tuples containing the fields that are used for cache lookup are always routed to the same process.</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>This avoids duplication of cache entries across processes.</source>
          <target state="new">This avoids duplication of cache entries across processes.</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>Streaming top N</source>
          <target state="new">Streaming top N</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>When your topology depends on calculating a "top N" value, such as the top 5 trends on Twitter, you should calculate the top N value in parallel and then merge the output from those calculations into a global value.</source>
          <target state="new">When your topology depends on calculating a "top N" value, such as the top 5 trends on Twitter, you should calculate the top N value in parallel and then merge the output from those calculations into a global value.</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>This can be done by using <bpt id="p60">[</bpt>fieldsGrouping<ept id="p60">](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29)</ept><ph id="ph39" /> to route by field to the parallel bolts (which partitions the data by field value), and then route to a bolt that globally determines the top N value.</source>
          <target state="new">This can be done by using <bpt id="p60">[</bpt>fieldsGrouping<ept id="p60">](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29)</ept><ph id="ph39" /> to route by field to the parallel bolts (which partitions the data by field value), and then route to a bolt that globally determines the top N value.</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>For an example of this, see the <bpt id="p61">[</bpt>RollingTopWords<ept id="p61">](https://github.com/nathanmarz/storm-starter/blob/master/src/jvm/storm/starter/RollingTopWords.java)</ept><ph id="ph40" /> example.</source>
          <target state="new">For an example of this, see the <bpt id="p61">[</bpt>RollingTopWords<ept id="p61">](https://github.com/nathanmarz/storm-starter/blob/master/src/jvm/storm/starter/RollingTopWords.java)</ept><ph id="ph40" /> example.</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source>Learn more about real-time analytics solutions with Apache Storm in HDInsight:</source>
          <target state="new">Learn more about real-time analytics solutions with Apache Storm in HDInsight:</target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source><bpt id="p62">[</bpt>Getting Started with Storm on HDInsight<ept id="p62">][gettingstarted]</ept></source>
          <target state="new"><bpt id="p62">[</bpt>Getting Started with Storm on HDInsight<ept id="p62">][gettingstarted]</ept></target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source><bpt id="p63">[</bpt>Example topologies for Storm on HDInsight<ept id="p63">](hdinsight-storm-example-topology.md)</ept></source>
          <target state="new"><bpt id="p63">[</bpt>Example topologies for Storm on HDInsight<ept id="p63">](hdinsight-storm-example-topology.md)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">c7bb8411fd78e017758ea2e18f2e06964d220784</xliffext:olfilehash>
  </header>
</xliff>