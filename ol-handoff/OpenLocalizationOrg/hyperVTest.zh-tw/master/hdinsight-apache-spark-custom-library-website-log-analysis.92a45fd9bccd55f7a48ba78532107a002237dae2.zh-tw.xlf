<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Use custom libraries with an HDInsight Spark cluster to analyze website logs | Microsoft Azure</source>
          <target state="new">Use custom libraries with an HDInsight Spark cluster to analyze website logs | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Use custom libraries with an HDInsight Spark cluster to analyze website logs</source>
          <target state="new">Use custom libraries with an HDInsight Spark cluster to analyze website logs</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Analyze logs in HDInsight Spark using a custom library (Linux)</source>
          <target state="new">Analyze logs in HDInsight Spark using a custom library (Linux)</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>This notebook demonstrates how to analyze log data using a custom library with Spark on HDInsight.</source>
          <target state="new">This notebook demonstrates how to analyze log data using a custom library with Spark on HDInsight.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>The custom library we use is a Python library called <bpt id="p1">**</bpt>iislogparser.py<ept id="p1">**</ept>.</source>
          <target state="new">The custom library we use is a Python library called <bpt id="p1">**</bpt>iislogparser.py<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source><ph id="ph2">[AZURE.TIP]</ph><ph id="ph3" /> This tutorial is also available as a Jupyter notebook on a Spark (Linux) cluster that you create in HDInsight.</source>
          <target state="new"><ph id="ph2">[AZURE.TIP]</ph><ph id="ph3" /> This tutorial is also available as a Jupyter notebook on a Spark (Linux) cluster that you create in HDInsight.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>The notebook experience lets you run the Python snippets from the notebook itself.</source>
          <target state="new">The notebook experience lets you run the Python snippets from the notebook itself.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>To perform the tutorial from within a notebook, create a Spark cluster, launch a Jupyter notebook (<ph id="ph4">`https://CLUSTERNAME.azurehdinsight.net/jupyter`</ph>), and then run the notebook <bpt id="p2">**</bpt>Analyze logs with Spark using a custom library.ipynb<ept id="p2">**</ept><ph id="ph5" /> under the <bpt id="p3">**</bpt>Python<ept id="p3">**</ept><ph id="ph6" /> folder.</source>
          <target state="new">To perform the tutorial from within a notebook, create a Spark cluster, launch a Jupyter notebook (<ph id="ph4">`https://CLUSTERNAME.azurehdinsight.net/jupyter`</ph>), and then run the notebook <bpt id="p2">**</bpt>Analyze logs with Spark using a custom library.ipynb<ept id="p2">**</ept><ph id="ph5" /> under the <bpt id="p3">**</bpt>Python<ept id="p3">**</ept><ph id="ph6" /> folder.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source><bpt id="p4">**</bpt>Prerequisites:<ept id="p4">**</ept></source>
          <target state="new"><bpt id="p4">**</bpt>Prerequisites:<ept id="p4">**</ept></target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>You must have the following:</source>
          <target state="new">You must have the following:</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>An Azure subscription.</source>
          <target state="new">An Azure subscription.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>See <bpt id="p5">[</bpt>Get Azure free trial<ept id="p5">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.</source>
          <target state="new">See <bpt id="p5">[</bpt>Get Azure free trial<ept id="p5">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>An Apache Spark cluster on HDInsight Linux.</source>
          <target state="new">An Apache Spark cluster on HDInsight Linux.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>For instructions, see <bpt id="p6">[</bpt>Create Apache Spark clusters in Azure HDInsight<ept id="p6">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.</source>
          <target state="new">For instructions, see <bpt id="p6">[</bpt>Create Apache Spark clusters in Azure HDInsight<ept id="p6">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Save raw data as an RDD</source>
          <target state="new">Save raw data as an RDD</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>In this section, we use the <bpt id="p7">[</bpt>Jupyter<ept id="p7">](https://jupyter.org)</ept><ph id="ph7" /> notebook associated with an Apache Spark cluster in HDInsight to run jobs that process your raw sample data and save it as a Hive table.</source>
          <target state="new">In this section, we use the <bpt id="p7">[</bpt>Jupyter<ept id="p7">](https://jupyter.org)</ept><ph id="ph7" /> notebook associated with an Apache Spark cluster in HDInsight to run jobs that process your raw sample data and save it as a Hive table.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>The sample data is a .csv file (hvac.csv) available on all clusters by default.</source>
          <target state="new">The sample data is a .csv file (hvac.csv) available on all clusters by default.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Once your data is saved as a Hive table, in the next section we will connect to the Hive table using BI tools such as Power BI and Tableau.</source>
          <target state="new">Once your data is saved as a Hive table, in the next section we will connect to the Hive table using BI tools such as Power BI and Tableau.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>From the <bpt id="p8">[</bpt>Azure Preview Portal<ept id="p8">](https://portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</source>
          <target state="new">From the <bpt id="p8">[</bpt>Azure Preview Portal<ept id="p8">](https://portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>You can also navigate to your cluster under <bpt id="p9">**</bpt>Browse All<ept id="p9">**</ept><ph id="ph8" /> &gt; <bpt id="p10">**</bpt>HDInsight Clusters<ept id="p10">**</ept>.</source>
          <target state="new">You can also navigate to your cluster under <bpt id="p9">**</bpt>Browse All<ept id="p9">**</ept><ph id="ph8" /> &gt; <bpt id="p10">**</bpt>HDInsight Clusters<ept id="p10">**</ept>.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>From the Spark cluster blade, click <bpt id="p11">**</bpt>Quick Links<ept id="p11">**</ept>, and then from the <bpt id="p12">**</bpt>Cluster Dashboard<ept id="p12">**</ept><ph id="ph9" /> blade, click <bpt id="p13">**</bpt>Jupyter Notebook<ept id="p13">**</ept>.</source>
          <target state="new">From the Spark cluster blade, click <bpt id="p11">**</bpt>Quick Links<ept id="p11">**</ept>, and then from the <bpt id="p12">**</bpt>Cluster Dashboard<ept id="p12">**</ept><ph id="ph9" /> blade, click <bpt id="p13">**</bpt>Jupyter Notebook<ept id="p13">**</ept>.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>If prompted, enter the admin credentials for the cluster.</source>
          <target state="new">If prompted, enter the admin credentials for the cluster.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source><ph id="ph10">[AZURE.NOTE]</ph><ph id="ph11" /> You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser.</source>
          <target state="new"><ph id="ph10">[AZURE.NOTE]</ph><ph id="ph11" /> You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Replace <bpt id="p14">__</bpt>CLUSTERNAME<ept id="p14">__</ept><ph id="ph12" /> with the name of your cluster:</source>
          <target state="new">Replace <bpt id="p14">__</bpt>CLUSTERNAME<ept id="p14">__</ept><ph id="ph12" /> with the name of your cluster:</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Create a new notebook.</source>
          <target state="new">Create a new notebook.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p15">**</bpt>New<ept id="p15">**</ept>, and then click <bpt id="p16">**</bpt>Python 2<ept id="p16">**</ept>.</source>
          <target state="new">Click <bpt id="p15">**</bpt>New<ept id="p15">**</ept>, and then click <bpt id="p16">**</bpt>Python 2<ept id="p16">**</ept>.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source><ph id="ph14">![</ph>Create a new Jupyter notebook<ph id="ph15">](./media/hdinsight-apache-spark-custom-library-website-log-analysis/hdispark.note.jupyter.createnotebook.png "Create a new Jupyter notebook")</ph></source>
          <target state="new"><ph id="ph14">![</ph>Create a new Jupyter notebook<ph id="ph15">](./media/hdinsight-apache-spark-custom-library-website-log-analysis/hdispark.note.jupyter.createnotebook.png "Create a new Jupyter notebook")</ph></target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>A new notebook is created and opened with the name Untitled.pynb.</source>
          <target state="new">A new notebook is created and opened with the name Untitled.pynb.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Click the notebook name at the top, and enter a friendly name.</source>
          <target state="new">Click the notebook name at the top, and enter a friendly name.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source><ph id="ph16">![</ph>Provide a name for the notebook<ph id="ph17">](./media/hdinsight-apache-spark-custom-library-website-log-analysis/hdispark.note.jupyter.notebook.name.png "Provide a name for the notebook")</ph></source>
          <target state="new"><ph id="ph16">![</ph>Provide a name for the notebook<ph id="ph17">](./media/hdinsight-apache-spark-custom-library-website-log-analysis/hdispark.note.jupyter.notebook.name.png "Provide a name for the notebook")</ph></target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>Import the required modules and create the Spark and SQL contexts.</source>
          <target state="new">Import the required modules and create the Spark and SQL contexts.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Paste the following snippet in an empty cell, and then press <bpt id="p17">**</bpt>SHIFT + ENTER<ept id="p17">**</ept>.</source>
          <target state="new">Paste the following snippet in an empty cell, and then press <bpt id="p17">**</bpt>SHIFT + ENTER<ept id="p17">**</ept>.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Create an RDD using the sample log data already available on the cluster.</source>
          <target state="new">Create an RDD using the sample log data already available on the cluster.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>You
can access the data in the default storage account associated with the cluster
at <bpt id="p18">**</bpt>\HdiSamples\HdiSamples\WebsiteLogSampleData\SampleLog\909f2b.log<ept id="p18">**</ept>.</source>
          <target state="new">You
can access the data in the default storage account associated with the cluster
at <bpt id="p18">**</bpt>\HdiSamples\HdiSamples\WebsiteLogSampleData\SampleLog\909f2b.log<ept id="p18">**</ept>.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Retrieve a sample log set to verify that the previous step completed
successfully.</source>
          <target state="new">Retrieve a sample log set to verify that the previous step completed
successfully.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>You should see an output similar to the following:</source>
          <target state="new">You should see an output similar to the following:</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Analyze log data using a custom Python library</source>
          <target state="new">Analyze log data using a custom Python library</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>In the output above, the first couple lines include the header information and
each remaining line matches the schema described in that header.</source>
          <target state="new">In the output above, the first couple lines include the header information and
each remaining line matches the schema described in that header.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Parsing such
logs could be complicated.</source>
          <target state="new">Parsing such
logs could be complicated.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>So, we use a custom Python library
(<bpt id="p19">**</bpt>iislogparser.py<ept id="p19">**</ept>) that makes parsing such logs much easier.</source>
          <target state="new">So, we use a custom Python library
(<bpt id="p19">**</bpt>iislogparser.py<ept id="p19">**</ept>) that makes parsing such logs much easier.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>By default, this library is included with your Spark cluster on HDInsight.</source>
          <target state="new">By default, this library is included with your Spark cluster on HDInsight.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>However, this library is not in the <ph id="ph18">`PYTHONPATH`</ph><ph id="ph19" /> so we cannot use it by using an import statement like <ph id="ph20">`import iislogparser`</ph>.</source>
          <target state="new">However, this library is not in the <ph id="ph18">`PYTHONPATH`</ph><ph id="ph19" /> so we cannot use it by using an import statement like <ph id="ph20">`import iislogparser`</ph>.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>To use this library, we must distribute it to all the worker nodes.</source>
          <target state="new">To use this library, we must distribute it to all the worker nodes.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>You must then run the following snippet to distribute the library to all worker nodes in the Spark cluster.</source>
          <target state="new">You must then run the following snippet to distribute the library to all worker nodes in the Spark cluster.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source><ph id="ph21">`iislogparser`</ph><ph id="ph22" /> provides a function <ph id="ph23">`parse_log_line`</ph><ph id="ph24" /> that returns <ph id="ph25">`None`</ph><ph id="ph26" /> if a log
line is a header row, and returns an instance of the <ph id="ph27">`LogLine`</ph><ph id="ph28" /> class if it
encounters a log line.</source>
          <target state="new"><ph id="ph21">`iislogparser`</ph><ph id="ph22" /> provides a function <ph id="ph23">`parse_log_line`</ph><ph id="ph24" /> that returns <ph id="ph25">`None`</ph><ph id="ph26" /> if a log
line is a header row, and returns an instance of the <ph id="ph27">`LogLine`</ph><ph id="ph28" /> class if it
encounters a log line.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Use the <ph id="ph29">`LogLine`</ph><ph id="ph30" /> class to extract only the log lines
from the RDD:</source>
          <target state="new">Use the <ph id="ph29">`LogLine`</ph><ph id="ph30" /> class to extract only the log lines
from the RDD:</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>Retrieve a couple of extracted log lines to verify that the step completed
successfully.</source>
          <target state="new">Retrieve a couple of extracted log lines to verify that the step completed
successfully.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>The output should be similar to the following:</source>
          <target state="new">The output should be similar to the following:</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>The <ph id="ph31">`LogLine`</ph><ph id="ph32" /> class, in turn, has some useful methods, like <ph id="ph33">`is_error()`</ph>, which
returns whether a log entry has an error code.</source>
          <target state="new">The <ph id="ph31">`LogLine`</ph><ph id="ph32" /> class, in turn, has some useful methods, like <ph id="ph33">`is_error()`</ph>, which
returns whether a log entry has an error code.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Use this to compute the number of
errors in the extracted log lines, and then log all the errors to a different
file.</source>
          <target state="new">Use this to compute the number of
errors in the extracted log lines, and then log all the errors to a different
file.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>You should see an output like the following:</source>
          <target state="new">You should see an output like the following:</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>You can also use <bpt id="p20">**</bpt>Matplotlib<ept id="p20">**</ept><ph id="ph34" /> to construct a visualization of the data.</source>
          <target state="new">You can also use <bpt id="p20">**</bpt>Matplotlib<ept id="p20">**</ept><ph id="ph34" /> to construct a visualization of the data.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>For
example, if you want to isolate the cause of requests that run for a long time,
you might want to find the files that take the most time to serve on average.</source>
          <target state="new">For
example, if you want to isolate the cause of requests that run for a long time,
you might want to find the files that take the most time to serve on average.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>The snippet below retrieves the top 25 resources that took most time to serve a
request.</source>
          <target state="new">The snippet below retrieves the top 25 resources that took most time to serve a
request.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>You should see an output like the following:</source>
          <target state="new">You should see an output like the following:</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>You can also present this information in the form of plot.</source>
          <target state="new">You can also present this information in the form of plot.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>The plot groups the
logs by time to see if there were any unusual latency spikes at any particular
time.</source>
          <target state="new">The plot groups the
logs by time to see if there were any unusual latency spikes at any particular
time.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>You should see an output like the following:</source>
          <target state="new">You should see an output like the following:</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source><ph id="ph35">![</ph>Matplotlib output<ph id="ph36">](./media/hdinsight-apache-spark-custom-library-website-log-analysis/hdi-apache-spark-web-log-analysis-plot.png "Matplotlib output")</ph></source>
          <target state="new"><ph id="ph35">![</ph>Matplotlib output<ph id="ph36">](./media/hdinsight-apache-spark-custom-library-website-log-analysis/hdi-apache-spark-web-log-analysis-plot.png "Matplotlib output")</ph></target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>After you have finished running the application, you should shutdown the notebook to release the resources.</source>
          <target state="new">After you have finished running the application, you should shutdown the notebook to release the resources.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>To do so, from the <bpt id="p21">**</bpt>File<ept id="p21">**</ept><ph id="ph37" /> menu on the notebook, click <bpt id="p22">**</bpt>Close and Halt<ept id="p22">**</ept>.</source>
          <target state="new">To do so, from the <bpt id="p21">**</bpt>File<ept id="p21">**</ept><ph id="ph37" /> menu on the notebook, click <bpt id="p22">**</bpt>Close and Halt<ept id="p22">**</ept>.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>This will shutdown and close the notebook.</source>
          <target state="new">This will shutdown and close the notebook.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>See also</source>
          <target state="new">See also</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source><bpt id="p23">[</bpt>Overview: Apache Spark on Azure HDInsight<ept id="p23">](hdinsight-apache-spark-overview.md)</ept></source>
          <target state="new"><bpt id="p23">[</bpt>Overview: Apache Spark on Azure HDInsight<ept id="p23">](hdinsight-apache-spark-overview.md)</ept></target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Scenarios</source>
          <target state="new">Scenarios</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source><bpt id="p24">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id="p24">](hdinsight-apache-spark-use-bi-tools.md)</ept></source>
          <target state="new"><bpt id="p24">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id="p24">](hdinsight-apache-spark-use-bi-tools.md)</ept></target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source><bpt id="p25">[</bpt>Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data<ept id="p25">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept></source>
          <target state="new"><bpt id="p25">[</bpt>Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data<ept id="p25">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept></target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source><bpt id="p26">[</bpt>Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results<ept id="p26">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept></source>
          <target state="new"><bpt id="p26">[</bpt>Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results<ept id="p26">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept></target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source><bpt id="p27">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id="p27">](hdinsight-apache-spark-eventhub-streaming.md)</ept></source>
          <target state="new"><bpt id="p27">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id="p27">](hdinsight-apache-spark-eventhub-streaming.md)</ept></target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Create and run applications</source>
          <target state="new">Create and run applications</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source><bpt id="p28">[</bpt>Create a standalone application using Scala<ept id="p28">](hdinsight-apache-spark-create-standalone-application.md)</ept></source>
          <target state="new"><bpt id="p28">[</bpt>Create a standalone application using Scala<ept id="p28">](hdinsight-apache-spark-create-standalone-application.md)</ept></target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source><bpt id="p29">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id="p29">](hdinsight-apache-spark-livy-rest-interface.md)</ept></source>
          <target state="new"><bpt id="p29">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id="p29">](hdinsight-apache-spark-livy-rest-interface.md)</ept></target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Tools and extensions</source>
          <target state="new">Tools and extensions</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source><bpt id="p30">[</bpt>Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons<ept id="p30">](hdinsight-apache-spark-intellij-tool-plugin.md)</ept></source>
          <target state="new"><bpt id="p30">[</bpt>Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons<ept id="p30">](hdinsight-apache-spark-intellij-tool-plugin.md)</ept></target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source><bpt id="p31">[</bpt>Use Zeppelin notebooks with a Spark cluster on HDInsight<ept id="p31">](hdinsight-apache-spark-use-zeppelin-notebook.md)</ept></source>
          <target state="new"><bpt id="p31">[</bpt>Use Zeppelin notebooks with a Spark cluster on HDInsight<ept id="p31">](hdinsight-apache-spark-use-zeppelin-notebook.md)</ept></target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source><bpt id="p32">[</bpt>Kernels available for Jupyter notebook in Spark cluster for HDInsight<ept id="p32">](hdinsight-apache-spark-jupyter-notebook-kernels.md)</ept></source>
          <target state="new"><bpt id="p32">[</bpt>Kernels available for Jupyter notebook in Spark cluster for HDInsight<ept id="p32">](hdinsight-apache-spark-jupyter-notebook-kernels.md)</ept></target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>Manage resources</source>
          <target state="new">Manage resources</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source><bpt id="p33">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id="p33">](hdinsight-apache-spark-resource-manager.md)</ept></source>
          <target state="new"><bpt id="p33">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id="p33">](hdinsight-apache-spark-resource-manager.md)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">2ac803c752e1781c0fdab5acf4a141b2a1576b23</xliffext:olfilehash>
  </header>
</xliff>