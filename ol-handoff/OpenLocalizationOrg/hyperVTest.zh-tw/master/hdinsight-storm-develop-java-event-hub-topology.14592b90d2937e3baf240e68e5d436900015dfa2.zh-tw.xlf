<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Process events from Event Hubs with Storm on HDInsight using Java | Azure</source>
          <target state="new">Process events from Event Hubs with Storm on HDInsight using Java | Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to process Event Hubs data with a Java Storm topology created with Maven.</source>
          <target state="new">Learn how to process Event Hubs data with a Java Storm topology created with Maven.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Process events from Azure Event Hubs with Storm on HDInsight (Java)</source>
          <target state="new">Process events from Azure Event Hubs with Storm on HDInsight (Java)</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Azure Event Hubs allows you to process massive amounts of data from websites, apps, and devices.</source>
          <target state="new">Azure Event Hubs allows you to process massive amounts of data from websites, apps, and devices.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>The Event Hubs spout makes it easy to use Apache Storm on HDInsight to analyze this data in real time.</source>
          <target state="new">The Event Hubs spout makes it easy to use Apache Storm on HDInsight to analyze this data in real time.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>You can also write data to Event Hubs from Storm by using the Event Hubs bolt.</source>
          <target state="new">You can also write data to Event Hubs from Storm by using the Event Hubs bolt.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>In this tutorial, you will learn how to use the Event Hubs spout and bolt to read and write data in a Java-based Storm topology.</source>
          <target state="new">In this tutorial, you will learn how to use the Event Hubs spout and bolt to read and write data in a Java-based Storm topology.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Prerequisites</source>
          <target state="new">Prerequisites</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>An Apache Storm on HDInsight cluster.</source>
          <target state="new">An Apache Storm on HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Use one of the following getting started articles to create a cluster:</source>
          <target state="new">Use one of the following getting started articles to create a cluster:</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>A <bpt id="p1">[</bpt>Linux-based cluster<ept id="p1">](hdinsight-apache-storm-tutorial-get-started-linux.md)</ept>: Select this if you want to use SSH to work with the cluster from Linux, Unix, OS X, or Windows clients</source>
          <target state="new">A <bpt id="p1">[</bpt>Linux-based cluster<ept id="p1">](hdinsight-apache-storm-tutorial-get-started-linux.md)</ept>: Select this if you want to use SSH to work with the cluster from Linux, Unix, OS X, or Windows clients</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>A <bpt id="p2">[</bpt>Windows-based cluster<ept id="p2">](hdinsight-apache-storm-tutorial-get-started.md)</ept>: Select this if you want to use PowerShell to work with the cluster from a Windows client</source>
          <target state="new">A <bpt id="p2">[</bpt>Windows-based cluster<ept id="p2">](hdinsight-apache-storm-tutorial-get-started.md)</ept>: Select this if you want to use PowerShell to work with the cluster from a Windows client</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source><ph id="ph2">[AZURE.NOTE]</ph><ph id="ph3" /> The only difference between the two cluster types is whether you use SSH to submit the topology to the cluster or a web form.</source>
          <target state="new"><ph id="ph2">[AZURE.NOTE]</ph><ph id="ph3" /> The only difference between the two cluster types is whether you use SSH to submit the topology to the cluster or a web form.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>An <bpt id="p3">[</bpt>Azure Event Hub<ept id="p3">](../event-hubs/event-hubs-csharp-ephcs-getstarted.md)</ept></source>
          <target state="new">An <bpt id="p3">[</bpt>Azure Event Hub<ept id="p3">](../event-hubs/event-hubs-csharp-ephcs-getstarted.md)</ept></target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source><bpt id="p4">[</bpt>Oracle Java Developer Kit (JDK) version 7<ept id="p4">](https://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html)</ept><ph id="ph4" /> or equivalent, such as <bpt id="p5">[</bpt>OpenJDK<ept id="p5">](http://openjdk.java.net/)</ept></source>
          <target state="new"><bpt id="p4">[</bpt>Oracle Java Developer Kit (JDK) version 7<ept id="p4">](https://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html)</ept><ph id="ph4" /> or equivalent, such as <bpt id="p5">[</bpt>OpenJDK<ept id="p5">](http://openjdk.java.net/)</ept></target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source><bpt id="p6">[</bpt>Maven<ept id="p6">](https://maven.apache.org/download.cgi)</ept>: Maven is a project build system for Java projects</source>
          <target state="new"><bpt id="p6">[</bpt>Maven<ept id="p6">](https://maven.apache.org/download.cgi)</ept>: Maven is a project build system for Java projects</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>A text editor or Java integrated development environment (IDE)</source>
          <target state="new">A text editor or Java integrated development environment (IDE)</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source><ph id="ph5">[AZURE.NOTE]</ph><ph id="ph6" /> Your editor or IDE may have specific functionality for working with Maven that is not addressed in this document.</source>
          <target state="new"><ph id="ph5">[AZURE.NOTE]</ph><ph id="ph6" /> Your editor or IDE may have specific functionality for working with Maven that is not addressed in this document.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>For information about the capabilities of your editing environment, see the documentation for the product you are using.</source>
          <target state="new">For information about the capabilities of your editing environment, see the documentation for the product you are using.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>An SSH client.</source>
          <target state="new">An SSH client.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>See one of the following articles for more information on using SSH with HDInsight:</source>
          <target state="new">See one of the following articles for more information on using SSH with HDInsight:</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source><bpt id="p7">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X<ept id="p7">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept></source>
          <target state="new"><bpt id="p7">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X<ept id="p7">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept></target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source><bpt id="p8">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id="p8">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept></source>
          <target state="new"><bpt id="p8">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id="p8">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept></target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>An SCP client.</source>
          <target state="new">An SCP client.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>This is provided with all Linux, Unix, and OS X systems.</source>
          <target state="new">This is provided with all Linux, Unix, and OS X systems.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>For Windows clients, we recommend PSCP, which is available from the <bpt id="p9">[</bpt>PuTTY download page<ept id="p9">](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html)</ept>.</source>
          <target state="new">For Windows clients, we recommend PSCP, which is available from the <bpt id="p9">[</bpt>PuTTY download page<ept id="p9">](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html)</ept>.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Understanding the example</source>
          <target state="new">Understanding the example</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>The <bpt id="p10">[</bpt>hdinsight-java-storm-eventhub<ept id="p10">](https://github.com/Blackmist/hdinsight-java-storm-eventhub)</ept><ph id="ph7" /> example contains two topologies:</source>
          <target state="new">The <bpt id="p10">[</bpt>hdinsight-java-storm-eventhub<ept id="p10">](https://github.com/Blackmist/hdinsight-java-storm-eventhub)</ept><ph id="ph7" /> example contains two topologies:</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source><bpt id="p11">__</bpt>com.microsoft.example.EventHubWriter<ept id="p11">__</ept><ph id="ph8" /> writes random data to an Azure Event Hub.</source>
          <target state="new"><bpt id="p11">__</bpt>com.microsoft.example.EventHubWriter<ept id="p11">__</ept><ph id="ph8" /> writes random data to an Azure Event Hub.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>The data is generated by a spout, and is a random device ID and device value.</source>
          <target state="new">The data is generated by a spout, and is a random device ID and device value.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>So it's simulating some hardware that emits a string ID and a numeric value.</source>
          <target state="new">So it's simulating some hardware that emits a string ID and a numeric value.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source><bpt id="p12">__</bpt>com.microsoft.example.EventHubReader<ept id="p12">__</ept><ph id="ph9" /> reads data from Event Hub (the data written by EventHubWriter,) and stores it to HDFS (WASB in this case, since this was written and tested with Azure HDInsight) in the /devicedata directory.</source>
          <target state="new"><bpt id="p12">__</bpt>com.microsoft.example.EventHubReader<ept id="p12">__</ept><ph id="ph9" /> reads data from Event Hub (the data written by EventHubWriter,) and stores it to HDFS (WASB in this case, since this was written and tested with Azure HDInsight) in the /devicedata directory.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>The data is formatted as a JSON document before it is written to Event Hub, and when read by the reader it is parsed out of JSON and into tuples.</source>
          <target state="new">The data is formatted as a JSON document before it is written to Event Hub, and when read by the reader it is parsed out of JSON and into tuples.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>The JSON format is as follows:</source>
          <target state="new">The JSON format is as follows:</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>The reason for using a JSON document to store the data into Event Hub is so that we know what the format is, instead of relying on the internal formatting mechanics of the Event Hub Spout and Bolt.</source>
          <target state="new">The reason for using a JSON document to store the data into Event Hub is so that we know what the format is, instead of relying on the internal formatting mechanics of the Event Hub Spout and Bolt.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Project configuration</source>
          <target state="new">Project configuration</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>The <bpt id="p13">**</bpt>POM.xml<ept id="p13">**</ept><ph id="ph10" /> file contains configuration information for this Maven project.</source>
          <target state="new">The <bpt id="p13">**</bpt>POM.xml<ept id="p13">**</ept><ph id="ph10" /> file contains configuration information for this Maven project.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>The interesting pieces are:</source>
          <target state="new">The interesting pieces are:</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>The EventHubs Storm Spout dependency</source>
          <target state="new">The EventHubs Storm Spout dependency</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>This adds a dependency for the eventhubs-storm-spout package, which contains both a spout for reading from Event Hubs, and a bolt for writing to it.</source>
          <target state="new">This adds a dependency for the eventhubs-storm-spout package, which contains both a spout for reading from Event Hubs, and a bolt for writing to it.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source><ph id="ph11">[AZURE.NOTE]</ph><ph id="ph12" /> This package is not available on Maven, and will be manually installed in your local Maven repository in a later step.</source>
          <target state="new"><ph id="ph11">[AZURE.NOTE]</ph><ph id="ph12" /> This package is not available on Maven, and will be manually installed in your local Maven repository in a later step.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>The HdfsBolt and WASB components</source>
          <target state="new">The HdfsBolt and WASB components</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>The HdfsBolt is normally used to store data to the Hadoop Distributed File System HDFS.</source>
          <target state="new">The HdfsBolt is normally used to store data to the Hadoop Distributed File System HDFS.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>However HDInsight clusters use Azure Storage (WASB) as the default data store, so we have to load several components that allow HdfsBolt to understand the WASB file system.</source>
          <target state="new">However HDInsight clusters use Azure Storage (WASB) as the default data store, so we have to load several components that allow HdfsBolt to understand the WASB file system.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source><ph id="ph13">[AZURE.NOTE]</ph><ph id="ph14" /> The packages to enable WASB are not available on the Maven repository, and will be manually installed in a later step.</source>
          <target state="new"><ph id="ph13">[AZURE.NOTE]</ph><ph id="ph14" /> The packages to enable WASB are not available on the Maven repository, and will be manually installed in a later step.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>The maven-compiler-plugin</source>
          <target state="new">The maven-compiler-plugin</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>This tells Maven that the project should be compiled with compatibility for Java 7, which is what is used by HDInsight clusters.</source>
          <target state="new">This tells Maven that the project should be compiled with compatibility for Java 7, which is what is used by HDInsight clusters.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>The maven-shade-plugin</source>
          <target state="new">The maven-shade-plugin</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>This is used to package the solution into an uber jar that contains both the project code and required dependencies.</source>
          <target state="new">This is used to package the solution into an uber jar that contains both the project code and required dependencies.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>It is also used to:</source>
          <target state="new">It is also used to:</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>Rename license files for the dependencies: if this isn't done it can result in an error at runtime on Windows-based HDInsight clusters.</source>
          <target state="new">Rename license files for the dependencies: if this isn't done it can result in an error at runtime on Windows-based HDInsight clusters.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Exclude security/signatures: if this isn't done it can result in an error at runtime on the HDInsight cluster</source>
          <target state="new">Exclude security/signatures: if this isn't done it can result in an error at runtime on the HDInsight cluster</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>The exec-maven-plugin</source>
          <target state="new">The exec-maven-plugin</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>This allows you to run the topology locally on your development environment using the following command:</source>
          <target state="new">This allows you to run the topology locally on your development environment using the following command:</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>For example, <ph id="ph15">`mvn compile exec:java -Dstorm.topology=com.microsoft.example.EventHubWriter`</ph>.</source>
          <target state="new">For example, <ph id="ph15">`mvn compile exec:java -Dstorm.topology=com.microsoft.example.EventHubWriter`</ph>.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>The resources section</source>
          <target state="new">The resources section</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>This defines resources required by the project:</source>
          <target state="new">This defines resources required by the project:</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source><bpt id="p14">**</bpt>EventHubs.properties<ept id="p14">**</ept>: contains information used to connect to an Azure Event Hub</source>
          <target state="new"><bpt id="p14">**</bpt>EventHubs.properties<ept id="p14">**</ept>: contains information used to connect to an Azure Event Hub</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source><bpt id="p15">**</bpt>core-site.xml<ept id="p15">**</ept>: contains information about the Azure Storage used by the HDInsight cluster.</source>
          <target state="new"><bpt id="p15">**</bpt>core-site.xml<ept id="p15">**</ept>: contains information about the Azure Storage used by the HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>You must populate both of these with information about your Event Hub and HDInsight cluster.</source>
          <target state="new">You must populate both of these with information about your Event Hub and HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Configure environment variables</source>
          <target state="new">Configure environment variables</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>The following environment variables may be set when you install Java and the JDK on your development workstation.</source>
          <target state="new">The following environment variables may be set when you install Java and the JDK on your development workstation.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>However, you should check that they exist and that they contain the correct values for your system.</source>
          <target state="new">However, you should check that they exist and that they contain the correct values for your system.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source><bpt id="p16">**</bpt>JAVA_HOME<ept id="p16">**</ept><ph id="ph16" /> - should point to the directory where the Java runtime environment (JRE) is installed.</source>
          <target state="new"><bpt id="p16">**</bpt>JAVA_HOME<ept id="p16">**</ept><ph id="ph16" /> - should point to the directory where the Java runtime environment (JRE) is installed.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>For example, in a Unix or Linux distribution, it should have a value similar to <ph id="ph17">`/usr/lib/jvm/java-7-oracle`</ph>.</source>
          <target state="new">For example, in a Unix or Linux distribution, it should have a value similar to <ph id="ph17">`/usr/lib/jvm/java-7-oracle`</ph>.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>In Windows, it would have a value similar to <ph id="ph18">`c:\Program Files (x86)\Java\jre1.7`</ph></source>
          <target state="new">In Windows, it would have a value similar to <ph id="ph18">`c:\Program Files (x86)\Java\jre1.7`</ph></target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source><bpt id="p17">**</bpt>PATH<ept id="p17">**</ept><ph id="ph19" /> - should contain the following paths:</source>
          <target state="new"><bpt id="p17">**</bpt>PATH<ept id="p17">**</ept><ph id="ph19" /> - should contain the following paths:</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source><bpt id="p18">**</bpt>JAVA_HOME<ept id="p18">**</ept><ph id="ph20" /> (or the equivalent path)</source>
          <target state="new"><bpt id="p18">**</bpt>JAVA_HOME<ept id="p18">**</ept><ph id="ph20" /> (or the equivalent path)</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source><bpt id="p19">**</bpt>JAVA_HOME\bin<ept id="p19">**</ept><ph id="ph21" /> (or the equivalent path)</source>
          <target state="new"><bpt id="p19">**</bpt>JAVA_HOME\bin<ept id="p19">**</ept><ph id="ph21" /> (or the equivalent path)</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>The directory where Maven is installed</source>
          <target state="new">The directory where Maven is installed</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Configure Event Hub</source>
          <target state="new">Configure Event Hub</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>Event Hubs is the data source for this example.</source>
          <target state="new">Event Hubs is the data source for this example.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Use the following steps to create a new Event Hub.</source>
          <target state="new">Use the following steps to create a new Event Hub.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>From the <bpt id="p20">[</bpt>Azure Classic Portal<ept id="p20">](https://manage.windowsazure.com)</ept>, select <bpt id="p21">**</bpt>NEW<ept id="p21">**</ept><ph id="ph22" /> &gt; <bpt id="p22">**</bpt>Service Bus<ept id="p22">**</ept><ph id="ph23" /> &gt; <bpt id="p23">**</bpt>Event Hub<ept id="p23">**</ept><ph id="ph24" /> &gt; <bpt id="p24">**</bpt>Custom Create<ept id="p24">**</ept>.</source>
          <target state="new">From the <bpt id="p20">[</bpt>Azure Classic Portal<ept id="p20">](https://manage.windowsazure.com)</ept>, select <bpt id="p21">**</bpt>NEW<ept id="p21">**</ept><ph id="ph22" /> &gt; <bpt id="p22">**</bpt>Service Bus<ept id="p22">**</ept><ph id="ph23" /> &gt; <bpt id="p23">**</bpt>Event Hub<ept id="p23">**</ept><ph id="ph24" /> &gt; <bpt id="p24">**</bpt>Custom Create<ept id="p24">**</ept>.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>On the <bpt id="p25">**</bpt>Add a new Event Hub<ept id="p25">**</ept><ph id="ph25" /> screen, enter an <bpt id="p26">**</bpt>Event Hub Name<ept id="p26">**</ept>, select the <bpt id="p27">**</bpt>Region<ept id="p27">**</ept><ph id="ph26" /> to create the hub in, and create a new namespace or select an existing one.</source>
          <target state="new">On the <bpt id="p25">**</bpt>Add a new Event Hub<ept id="p25">**</ept><ph id="ph25" /> screen, enter an <bpt id="p26">**</bpt>Event Hub Name<ept id="p26">**</ept>, select the <bpt id="p27">**</bpt>Region<ept id="p27">**</ept><ph id="ph26" /> to create the hub in, and create a new namespace or select an existing one.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Click the <bpt id="p28">**</bpt>Arrow<ept id="p28">**</ept><ph id="ph27" /> to continue.</source>
          <target state="new">Click the <bpt id="p28">**</bpt>Arrow<ept id="p28">**</ept><ph id="ph27" /> to continue.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source><ph id="ph28">![</ph>wizard page 1<ph id="ph29">](./media/hdinsight-storm-develop-csharp-event-hub-topology/wiz1.png)</ph></source>
          <target state="new"><ph id="ph28">![</ph>wizard page 1<ph id="ph29">](./media/hdinsight-storm-develop-csharp-event-hub-topology/wiz1.png)</ph></target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source><ph id="ph30">[AZURE.NOTE]</ph><ph id="ph31" /> You should select the same <bpt id="p29">**</bpt>Location<ept id="p29">**</ept><ph id="ph32" /> as your Storm on HDInsight server to reduce latency and costs.</source>
          <target state="new"><ph id="ph30">[AZURE.NOTE]</ph><ph id="ph31" /> You should select the same <bpt id="p29">**</bpt>Location<ept id="p29">**</ept><ph id="ph32" /> as your Storm on HDInsight server to reduce latency and costs.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>On the <bpt id="p30">**</bpt>Configure Event Hub<ept id="p30">**</ept><ph id="ph33" /> screen, enter the <bpt id="p31">**</bpt>Partition count<ept id="p31">**</ept><ph id="ph34" /> and <bpt id="p32">**</bpt>Message Retention<ept id="p32">**</ept><ph id="ph35" /> values.</source>
          <target state="new">On the <bpt id="p30">**</bpt>Configure Event Hub<ept id="p30">**</ept><ph id="ph33" /> screen, enter the <bpt id="p31">**</bpt>Partition count<ept id="p31">**</ept><ph id="ph34" /> and <bpt id="p32">**</bpt>Message Retention<ept id="p32">**</ept><ph id="ph35" /> values.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>For this example, use a partition count of 10 and a message retention of 1.</source>
          <target state="new">For this example, use a partition count of 10 and a message retention of 1.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>Note the partition count because you will need this value later.</source>
          <target state="new">Note the partition count because you will need this value later.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source><ph id="ph36">![</ph>wizard page 2<ph id="ph37">](./media/hdinsight-storm-develop-csharp-event-hub-topology/wiz2.png)</ph></source>
          <target state="new"><ph id="ph36">![</ph>wizard page 2<ph id="ph37">](./media/hdinsight-storm-develop-csharp-event-hub-topology/wiz2.png)</ph></target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>After the event hub has been created, select the namespace, select <bpt id="p33">**</bpt>Event Hubs<ept id="p33">**</ept>, and then select the event hub that you created earlier.</source>
          <target state="new">After the event hub has been created, select the namespace, select <bpt id="p33">**</bpt>Event Hubs<ept id="p33">**</ept>, and then select the event hub that you created earlier.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p34">**</bpt>Configure<ept id="p34">**</ept>, then create two new access policies by using the following information.</source>
          <target state="new">Select <bpt id="p34">**</bpt>Configure<ept id="p34">**</ept>, then create two new access policies by using the following information.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source><ph id="ph38">&lt;table&gt;</ph><ph id="ph39">
 &lt;tr&gt;</ph><ph id="ph40">&lt;th&gt;</ph>Name<ph id="ph41">&lt;/th&gt;</ph><ph id="ph42">&lt;th&gt;</ph>Permissions<ph id="ph43">&lt;/th&gt;</ph><ph id="ph44">&lt;/tr&gt;</ph><ph id="ph45">
 &lt;tr&gt;</ph><ph id="ph46">&lt;td&gt;</ph>Writer<ph id="ph47">&lt;/td&gt;</ph><ph id="ph48">&lt;td&gt;</ph>Send<ph id="ph49">&lt;/td&gt;</ph><ph id="ph50">&lt;/tr&gt;</ph><ph id="ph51">
 &lt;tr&gt;</ph><ph id="ph52">&lt;td&gt;</ph>Reader<ph id="ph53">&lt;/td&gt;</ph><ph id="ph54">&lt;td&gt;</ph>Listen<ph id="ph55">&lt;/td&gt;</ph><ph id="ph56">&lt;/tr&gt;</ph><ph id="ph57">
 &lt;/table&gt;</ph></source>
          <target state="new"><ph id="ph38">&lt;table&gt;</ph><ph id="ph39">
 &lt;tr&gt;</ph><ph id="ph40">&lt;th&gt;</ph>Name<ph id="ph41">&lt;/th&gt;</ph><ph id="ph42">&lt;th&gt;</ph>Permissions<ph id="ph43">&lt;/th&gt;</ph><ph id="ph44">&lt;/tr&gt;</ph><ph id="ph45">
 &lt;tr&gt;</ph><ph id="ph46">&lt;td&gt;</ph>Writer<ph id="ph47">&lt;/td&gt;</ph><ph id="ph48">&lt;td&gt;</ph>Send<ph id="ph49">&lt;/td&gt;</ph><ph id="ph50">&lt;/tr&gt;</ph><ph id="ph51">
 &lt;tr&gt;</ph><ph id="ph52">&lt;td&gt;</ph>Reader<ph id="ph53">&lt;/td&gt;</ph><ph id="ph54">&lt;td&gt;</ph>Listen<ph id="ph55">&lt;/td&gt;</ph><ph id="ph56">&lt;/tr&gt;</ph><ph id="ph57">
 &lt;/table&gt;</ph></target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>After You create the permissions, select the <bpt id="p35">**</bpt>Save<ept id="p35">**</ept><ph id="ph58" /> icon at the bottom of the page.</source>
          <target state="new">After You create the permissions, select the <bpt id="p35">**</bpt>Save<ept id="p35">**</ept><ph id="ph58" /> icon at the bottom of the page.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>This creates the shared access policies that will be used to send (writer) and listen (reader) to this Event Hub.</source>
          <target state="new">This creates the shared access policies that will be used to send (writer) and listen (reader) to this Event Hub.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source><ph id="ph59">![</ph>policies<ph id="ph60">](./media/hdinsight-storm-develop-csharp-event-hub-topology/policy.png)</ph></source>
          <target state="new"><ph id="ph59">![</ph>policies<ph id="ph60">](./media/hdinsight-storm-develop-csharp-event-hub-topology/policy.png)</ph></target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>After you save the policies, use the <bpt id="p36">**</bpt>Shared access key generator<ept id="p36">**</ept><ph id="ph61" /> at the bottom of the page to retrieve the key for the <bpt id="p37">**</bpt>writer<ept id="p37">**</ept><ph id="ph62" /> and <bpt id="p38">**</bpt>reader<ept id="p38">**</ept><ph id="ph63" /> policies.</source>
          <target state="new">After you save the policies, use the <bpt id="p36">**</bpt>Shared access key generator<ept id="p36">**</ept><ph id="ph61" /> at the bottom of the page to retrieve the key for the <bpt id="p37">**</bpt>writer<ept id="p37">**</ept><ph id="ph62" /> and <bpt id="p38">**</bpt>reader<ept id="p38">**</ept><ph id="ph63" /> policies.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>Save these because they will be used later.</source>
          <target state="new">Save these because they will be used later.</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>Download and build the project</source>
          <target state="new">Download and build the project</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>Download the project from GitHub: <bpt id="p39">[</bpt>hdinsight-java-storm-eventhub<ept id="p39">](https://github.com/Blackmist/hdinsight-java-storm-eventhub)</ept>.</source>
          <target state="new">Download the project from GitHub: <bpt id="p39">[</bpt>hdinsight-java-storm-eventhub<ept id="p39">](https://github.com/Blackmist/hdinsight-java-storm-eventhub)</ept>.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>You can either download the package as a zip archive, or use <bpt id="p40">[</bpt>git<ept id="p40">](https://git-scm.com/)</ept><ph id="ph64" /> to clone the project locally.</source>
          <target state="new">You can either download the package as a zip archive, or use <bpt id="p40">[</bpt>git<ept id="p40">](https://git-scm.com/)</ept><ph id="ph64" /> to clone the project locally.</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>Use the following commands to install packages included in the project into your local Maven repository.</source>
          <target state="new">Use the following commands to install packages included in the project into your local Maven repository.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>These enable the Event Hub spout and bolt, as well as the ability to use the HdfsBolt to write to Azure Storage (WASB).</source>
          <target state="new">These enable the Event Hub spout and bolt, as well as the ability to use the HdfsBolt to write to Azure Storage (WASB).</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source><ph id="ph65">[AZURE.NOTE]</ph><ph id="ph66" /> If you're using Powershell, you mau have to put the <ph id="ph67">`-D`</ph><ph id="ph68" /> parameters in quotes.</source>
          <target state="new"><ph id="ph65">[AZURE.NOTE]</ph><ph id="ph66" /> If you're using Powershell, you mau have to put the <ph id="ph67">`-D`</ph><ph id="ph68" /> parameters in quotes.</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>For example, <ph id="ph69">`"-Dfile=lib/hadoop/hadoop-main-3.0.0-SNAPSHOT.pom"`</ph>.</source>
          <target state="new">For example, <ph id="ph69">`"-Dfile=lib/hadoop/hadoop-main-3.0.0-SNAPSHOT.pom"`</ph>.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>Also these files are originally from https://github.com/hdinsight/hdinsight-storm-examples, so can find the latest versions there.</source>
          <target state="new">Also these files are originally from https://github.com/hdinsight/hdinsight-storm-examples, so can find the latest versions there.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>Use the following to build and package the project:</source>
          <target state="new">Use the following to build and package the project:</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>This will download required dependencies, build, and then package the project.</source>
          <target state="new">This will download required dependencies, build, and then package the project.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>The output will be stored in the <bpt id="p41">__</bpt>/target<ept id="p41">__</ept><ph id="ph70" /> directory as <bpt id="p42">__</bpt>EventHubExample-1.0-SNAPSHOT.jar<ept id="p42">__</ept>.</source>
          <target state="new">The output will be stored in the <bpt id="p41">__</bpt>/target<ept id="p41">__</ept><ph id="ph70" /> directory as <bpt id="p42">__</bpt>EventHubExample-1.0-SNAPSHOT.jar<ept id="p42">__</ept>.</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>Deploy the topologies</source>
          <target state="new">Deploy the topologies</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>The jar created by this project contains two topologies; <bpt id="p43">__</bpt>com.microsoft.example.EventHubWriter<ept id="p43">__</ept><ph id="ph71" /> and <bpt id="p44">__</bpt>com.microsoft.example.EventHubReader<ept id="p44">__</ept>.</source>
          <target state="new">The jar created by this project contains two topologies; <bpt id="p43">__</bpt>com.microsoft.example.EventHubWriter<ept id="p43">__</ept><ph id="ph71" /> and <bpt id="p44">__</bpt>com.microsoft.example.EventHubReader<ept id="p44">__</ept>.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>The EventHubWriter topology should be started first, as it writes events in to Event Hub that are then read by the EventHubReader.</source>
          <target state="new">The EventHubWriter topology should be started first, as it writes events in to Event Hub that are then read by the EventHubReader.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>If using a Linux-based cluster</source>
          <target state="new">If using a Linux-based cluster</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>Use SCP to copy the jar package to your HDInsight cluster.</source>
          <target state="new">Use SCP to copy the jar package to your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>Replace USERNAME with the SSH user for your cluster.</source>
          <target state="new">Replace USERNAME with the SSH user for your cluster.</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>Replace CLUSTERNAME with the name of your HDInsight cluster:</source>
          <target state="new">Replace CLUSTERNAME with the name of your HDInsight cluster:</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>If you used a password for your SSH account, you will be prompted to enter the password.</source>
          <target state="new">If you used a password for your SSH account, you will be prompted to enter the password.</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>If you used an SSH key with the account, you may need to use the <ph id="ph72">`-i`</ph><ph id="ph73" /> parameter to specify the path to the key file.</source>
          <target state="new">If you used an SSH key with the account, you may need to use the <ph id="ph72">`-i`</ph><ph id="ph73" /> parameter to specify the path to the key file.</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>For example, <ph id="ph74">`scp -i ~/.ssh/id_rsa ./target/EventHubExample-1.0-SNAPSHOT.jar USERNAME@CLUSTERNAME-ssh.azurehdinsight.net:.`</ph>.</source>
          <target state="new">For example, <ph id="ph74">`scp -i ~/.ssh/id_rsa ./target/EventHubExample-1.0-SNAPSHOT.jar USERNAME@CLUSTERNAME-ssh.azurehdinsight.net:.`</ph>.</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source><ph id="ph75">[AZURE.NOTE]</ph><ph id="ph76" /> If your client is a Windows workstation, you may not have an SCP command installed.</source>
          <target state="new"><ph id="ph75">[AZURE.NOTE]</ph><ph id="ph76" /> If your client is a Windows workstation, you may not have an SCP command installed.</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>We recommend PSCP, which can be downloaded from the <bpt id="p45">[</bpt>PuTTY download page<ept id="p45">](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html)</ept>.</source>
          <target state="new">We recommend PSCP, which can be downloaded from the <bpt id="p45">[</bpt>PuTTY download page<ept id="p45">](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html)</ept>.</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>This command will copy the file to the home directory of your SSH user on the cluster.</source>
          <target state="new">This command will copy the file to the home directory of your SSH user on the cluster.</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>Once the file has finished uploading, use SSH to connect to the HDInsight cluster.</source>
          <target state="new">Once the file has finished uploading, use SSH to connect to the HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>Replace <bpt id="p46">**</bpt>USERNAME<ept id="p46">**</ept><ph id="ph77" /> the the name of your SSH login.</source>
          <target state="new">Replace <bpt id="p46">**</bpt>USERNAME<ept id="p46">**</ept><ph id="ph77" /> the the name of your SSH login.</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>Replace <bpt id="p47">**</bpt>CLUSTERNAME<ept id="p47">**</ept><ph id="ph78" /> with your HDInsight cluster name:</source>
          <target state="new">Replace <bpt id="p47">**</bpt>CLUSTERNAME<ept id="p47">**</ept><ph id="ph78" /> with your HDInsight cluster name:</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source><ph id="ph79">[AZURE.NOTE]</ph><ph id="ph80" /> If you used a password for your SSH account, you will be prompted to enter the password.</source>
          <target state="new"><ph id="ph79">[AZURE.NOTE]</ph><ph id="ph80" /> If you used a password for your SSH account, you will be prompted to enter the password.</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>If you used an SSH key with the account, you may need to use the <ph id="ph81">`-i`</ph><ph id="ph82" /> parameter to specify the path to the key file.</source>
          <target state="new">If you used an SSH key with the account, you may need to use the <ph id="ph81">`-i`</ph><ph id="ph82" /> parameter to specify the path to the key file.</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>The following example will load the private key from <ph id="ph83">`~/.ssh/id_rsa`</ph>:</source>
          <target state="new">The following example will load the private key from <ph id="ph83">`~/.ssh/id_rsa`</ph>:</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>If you are using PuTTY, enter <ph id="ph85">`CLUSTERNAME-ssh.azurehdinsight.net`</ph><ph id="ph86" /> in the <bpt id="p48">__</bpt>Host Name (or IP address)<ept id="p48">__</ept><ph id="ph87" /> field, and then click <bpt id="p49">__</bpt>Open<ept id="p49">__</ept><ph id="ph88" /> to connect.</source>
          <target state="new">If you are using PuTTY, enter <ph id="ph85">`CLUSTERNAME-ssh.azurehdinsight.net`</ph><ph id="ph86" /> in the <bpt id="p48">__</bpt>Host Name (or IP address)<ept id="p48">__</ept><ph id="ph87" /> field, and then click <bpt id="p49">__</bpt>Open<ept id="p49">__</ept><ph id="ph88" /> to connect.</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>You will be prompted to enter your SSH account name.</source>
          <target state="new">You will be prompted to enter your SSH account name.</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source><ph id="ph89">[AZURE.NOTE]</ph><ph id="ph90" /> If you used a password for your SSH account, you will be prompted to enter the password.</source>
          <target state="new"><ph id="ph89">[AZURE.NOTE]</ph><ph id="ph90" /> If you used a password for your SSH account, you will be prompted to enter the password.</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>If you used an SSH key with the account, you may need to use the following steps to select the key:</source>
          <target state="new">If you used an SSH key with the account, you may need to use the following steps to select the key:</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>In <bpt id="p50">**</bpt>Category<ept id="p50">**</ept>, expand <bpt id="p51">**</bpt>Connection<ept id="p51">**</ept>, expand <bpt id="p52">**</bpt>SSH<ept id="p52">**</ept>, and select <bpt id="p53">**</bpt>Auth<ept id="p53">**</ept>.</source>
          <target state="new">In <bpt id="p50">**</bpt>Category<ept id="p50">**</ept>, expand <bpt id="p51">**</bpt>Connection<ept id="p51">**</ept>, expand <bpt id="p52">**</bpt>SSH<ept id="p52">**</ept>, and select <bpt id="p53">**</bpt>Auth<ept id="p53">**</ept>.</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p54">**</bpt>Browse<ept id="p54">**</ept><ph id="ph91" /> and select the .ppk file that contains your private key.</source>
          <target state="new">Click <bpt id="p54">**</bpt>Browse<ept id="p54">**</ept><ph id="ph91" /> and select the .ppk file that contains your private key.</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p55">__</bpt>Open<ept id="p55">__</ept><ph id="ph92" /> to connect.</source>
          <target state="new">Click <bpt id="p55">__</bpt>Open<ept id="p55">__</ept><ph id="ph92" /> to connect.</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>Use the following command to start the topologies:</source>
          <target state="new">Use the following command to start the topologies:</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>This will start the topologies and give them a friendly name of "reader" and "writer".</source>
          <target state="new">This will start the topologies and give them a friendly name of "reader" and "writer".</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>Wait a minute or two to allow the topologies to write and read events from event hub, then use the following command to verify that the EventHubReader is storing data to your HDInsight storage:</source>
          <target state="new">Wait a minute or two to allow the topologies to write and read events from event hub, then use the following command to verify that the EventHubReader is storing data to your HDInsight storage:</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>This should return a list of files similar to the following:</source>
          <target state="new">This should return a list of files similar to the following:</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source><ph id="ph93">[AZURE.NOTE]</ph><ph id="ph94" /> Some files may show a size of 0, as they have been created by the EventHubReader, but data has not been stored to them yet.</source>
          <target state="new"><ph id="ph93">[AZURE.NOTE]</ph><ph id="ph94" /> Some files may show a size of 0, as they have been created by the EventHubReader, but data has not been stored to them yet.</target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source>You can view the contents of these files by using the following command:</source>
          <target state="new">You can view the contents of these files by using the following command:</target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source>This will return data similar to the following:</source>
          <target state="new">This will return data similar to the following:</target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>The first column contains the device ID value and the second column is the device value.</source>
          <target state="new">The first column contains the device ID value and the second column is the device value.</target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>Use the following commands to stop the topologies:</source>
          <target state="new">Use the following commands to stop the topologies:</target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>If using a Windows-based cluster</source>
          <target state="new">If using a Windows-based cluster</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>Open your browser to https://CLUSTERNAME.azurehdinsight.net.</source>
          <target state="new">Open your browser to https://CLUSTERNAME.azurehdinsight.net.</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source>When prompted, enter the administrator credentials for your HDInsight cluster.</source>
          <target state="new">When prompted, enter the administrator credentials for your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>You will arrive at the Storm Dashboard.</source>
          <target state="new">You will arrive at the Storm Dashboard.</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>Use the <bpt id="p56">__</bpt>Jar File<ept id="p56">__</ept><ph id="ph95" /> dropdown to browse and select the EventHubExample-1.0-SNAPSHOT.jar file from your build environment.</source>
          <target state="new">Use the <bpt id="p56">__</bpt>Jar File<ept id="p56">__</ept><ph id="ph95" /> dropdown to browse and select the EventHubExample-1.0-SNAPSHOT.jar file from your build environment.</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>For <bpt id="p57">__</bpt>Class Name<ept id="p57">__</ept>, enter <ph id="ph96">`com.mirosoft.example.EventHubWriter`</ph>.</source>
          <target state="new">For <bpt id="p57">__</bpt>Class Name<ept id="p57">__</ept>, enter <ph id="ph96">`com.mirosoft.example.EventHubWriter`</ph>.</target>
        </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>For <bpt id="p58">__</bpt>Additional Parameters<ept id="p58">__</ept>, enter <ph id="ph97">`writer`</ph>.</source>
          <target state="new">For <bpt id="p58">__</bpt>Additional Parameters<ept id="p58">__</ept>, enter <ph id="ph97">`writer`</ph>.</target>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>Finally, click <bpt id="p59">__</bpt>Submit<ept id="p59">__</ept><ph id="ph98" /> to upload the jar and start the EventHubWriter topology.</source>
          <target state="new">Finally, click <bpt id="p59">__</bpt>Submit<ept id="p59">__</ept><ph id="ph98" /> to upload the jar and start the EventHubWriter topology.</target>
        </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>Once the topology has started, use the form to start the EventHubReader:</source>
          <target state="new">Once the topology has started, use the form to start the EventHubReader:</target>
        </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source><bpt id="p60">__</bpt>Jar File<ept id="p60">__</ept>: select the EventHubExample-1.0-SNAPSHOT.jar that was previously uploaded</source>
          <target state="new"><bpt id="p60">__</bpt>Jar File<ept id="p60">__</ept>: select the EventHubExample-1.0-SNAPSHOT.jar that was previously uploaded</target>
        </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source><bpt id="p61">__</bpt>Class Name<ept id="p61">__</ept>: enter <ph id="ph99">`com.microsoft.example.EventHubReader`</ph></source>
          <target state="new"><bpt id="p61">__</bpt>Class Name<ept id="p61">__</ept>: enter <ph id="ph99">`com.microsoft.example.EventHubReader`</ph></target>
        </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source><bpt id="p62">__</bpt>Additional Parameters<ept id="p62">__</ept>: enter <ph id="ph100">`reader`</ph></source>
          <target state="new"><bpt id="p62">__</bpt>Additional Parameters<ept id="p62">__</ept>: enter <ph id="ph100">`reader`</ph></target>
        </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>Click submit to start the EventHubReader topology.</source>
          <target state="new">Click submit to start the EventHubReader topology.</target>
        </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>Wait a few minutes to allow the topologies to generate events and store then to Azure Storage, then select the <bpt id="p63">__</bpt>Query Console<ept id="p63">__</ept><ph id="ph101" /> tab at the top of the <bpt id="p64">__</bpt>Storm Dashboard<ept id="p64">__</ept><ph id="ph102" /> page.</source>
          <target state="new">Wait a few minutes to allow the topologies to generate events and store then to Azure Storage, then select the <bpt id="p63">__</bpt>Query Console<ept id="p63">__</ept><ph id="ph101" /> tab at the top of the <bpt id="p64">__</bpt>Storm Dashboard<ept id="p64">__</ept><ph id="ph102" /> page.</target>
        </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve">
          <source>On the <bpt id="p65">__</bpt>Query Console<ept id="p65">__</ept>, select <bpt id="p66">__</bpt>Hive Editor<ept id="p66">__</ept><ph id="ph103" /> and replace the default <ph id="ph104">`select * from hivesampletable`</ph><ph id="ph105" /> with the following:</source>
          <target state="new">On the <bpt id="p65">__</bpt>Query Console<ept id="p65">__</ept>, select <bpt id="p66">__</bpt>Hive Editor<ept id="p66">__</ept><ph id="ph103" /> and replace the default <ph id="ph104">`select * from hivesampletable`</ph><ph id="ph105" /> with the following:</target>
        </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p67">__</bpt>Select<ept id="p67">__</ept><ph id="ph106" /> to run the query.</source>
          <target state="new">Click <bpt id="p67">__</bpt>Select<ept id="p67">__</ept><ph id="ph106" /> to run the query.</target>
        </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve">
          <source>This will return 10 rows from the data written to Azure Storage (WASB) by the EventHubReader.</source>
          <target state="new">This will return 10 rows from the data written to Azure Storage (WASB) by the EventHubReader.</target>
        </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve">
          <source>Once the query completes, you should see data similar to the following:</source>
          <target state="new">Once the query completes, you should see data similar to the following:</target>
        </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve">
          <source>Select the <bpt id="p68">__</bpt>Storm Dashboard<ept id="p68">__</ept><ph id="ph107" /> at the top of the page, then select <bpt id="p69">__</bpt>Storm UI<ept id="p69">__</ept>.</source>
          <target state="new">Select the <bpt id="p68">__</bpt>Storm Dashboard<ept id="p68">__</ept><ph id="ph107" /> at the top of the page, then select <bpt id="p69">__</bpt>Storm UI<ept id="p69">__</ept>.</target>
        </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source>From the <bpt id="p70">__</bpt>Storm UI<ept id="p70">__</ept>, select the link for the <bpt id="p71">__</bpt>reader<ept id="p71">__</ept><ph id="ph108" /> topology and then use the <bpt id="p72">__</bpt>Kill<ept id="p72">__</ept><ph id="ph109" /> button to stop the topology.</source>
          <target state="new">From the <bpt id="p70">__</bpt>Storm UI<ept id="p70">__</ept>, select the link for the <bpt id="p71">__</bpt>reader<ept id="p71">__</ept><ph id="ph108" /> topology and then use the <bpt id="p72">__</bpt>Kill<ept id="p72">__</ept><ph id="ph109" /> button to stop the topology.</target>
        </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>Repeat the process for the <bpt id="p73">__</bpt>writer<ept id="p73">__</ept><ph id="ph110" /> topology.</source>
          <target state="new">Repeat the process for the <bpt id="p73">__</bpt>writer<ept id="p73">__</ept><ph id="ph110" /> topology.</target>
        </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve">
          <source>Checkpointing</source>
          <target state="new">Checkpointing</target>
        </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve">
          <source>The EventHubSpout periodically checkpoints its state to the Zookeeper node, which saves the current offset for messages read from the queue.</source>
          <target state="new">The EventHubSpout periodically checkpoints its state to the Zookeeper node, which saves the current offset for messages read from the queue.</target>
        </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve">
          <source>This allows the component to start receiving messages at the saved offset in the following scenarios:</source>
          <target state="new">This allows the component to start receiving messages at the saved offset in the following scenarios:</target>
        </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve">
          <source>The component instance fails and is restarted.</source>
          <target state="new">The component instance fails and is restarted.</target>
        </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve">
          <source>You grow or shrink the cluster by adding or removing nodes.</source>
          <target state="new">You grow or shrink the cluster by adding or removing nodes.</target>
        </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve">
          <source>The topology is killed and restarted <bpt id="p74">**</bpt>with the same name<ept id="p74">**</ept>.</source>
          <target state="new">The topology is killed and restarted <bpt id="p74">**</bpt>with the same name<ept id="p74">**</ept>.</target>
        </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve">
          <source>On Windows-based HDInsight clusters</source>
          <target state="new">On Windows-based HDInsight clusters</target>
        </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve">
          <source>You can export and import the persisted checkpoints to WASB (the Azure Storage used by your HDInsight cluster.) The scripts to do this are located on the Storm on HDInsight cluster, at <bpt id="p75">**</bpt>c:\apps\dist\storm-0.9.3.2.2.1.0-2340\zkdatatool-1.0\bin<ept id="p75">**</ept>.</source>
          <target state="new">You can export and import the persisted checkpoints to WASB (the Azure Storage used by your HDInsight cluster.) The scripts to do this are located on the Storm on HDInsight cluster, at <bpt id="p75">**</bpt>c:\apps\dist\storm-0.9.3.2.2.1.0-2340\zkdatatool-1.0\bin<ept id="p75">**</ept>.</target>
        </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve">
          <source><ph id="ph111">[AZURE.NOTE]</ph><ph id="ph112" /> The version number in the path may be different, as the version of Storm installed on the cluster may change in the future.</source>
          <target state="new"><ph id="ph111">[AZURE.NOTE]</ph><ph id="ph112" /> The version number in the path may be different, as the version of Storm installed on the cluster may change in the future.</target>
        </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve">
          <source>The scripts in this directory are:</source>
          <target state="new">The scripts in this directory are:</target>
        </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve">
          <source><bpt id="p76">**</bpt>stormmeta_import.cmd<ept id="p76">**</ept>: Import all Storm metadata from the cluster default storage container into Zookeeper.</source>
          <target state="new"><bpt id="p76">**</bpt>stormmeta_import.cmd<ept id="p76">**</ept>: Import all Storm metadata from the cluster default storage container into Zookeeper.</target>
        </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve">
          <source><bpt id="p77">**</bpt>stormmeta_export.cmd<ept id="p77">**</ept>: Export all Storm metadata from Zookeeper to the cluster default storage container.</source>
          <target state="new"><bpt id="p77">**</bpt>stormmeta_export.cmd<ept id="p77">**</ept>: Export all Storm metadata from Zookeeper to the cluster default storage container.</target>
        </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve">
          <source><bpt id="p78">**</bpt>stormmeta_delete.cmd<ept id="p78">**</ept>: Delete all Storm metadata from Zookeeper.</source>
          <target state="new"><bpt id="p78">**</bpt>stormmeta_delete.cmd<ept id="p78">**</ept>: Delete all Storm metadata from Zookeeper.</target>
        </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve">
          <source>Export an import allows you to persist checkpoint data when you need to delete the cluster, but want to resume processing from the current offset in the hub when you bring a new cluster back online.</source>
          <target state="new">Export an import allows you to persist checkpoint data when you need to delete the cluster, but want to resume processing from the current offset in the hub when you bring a new cluster back online.</target>
        </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve">
          <source><ph id="ph113">[AZURE.NOTE]</ph><ph id="ph114" /> Since the data is persisted to the default storage container, the new cluster <bpt id="p79">**</bpt>must<ept id="p79">**</ept><ph id="ph115" /> use the same storage account and container as the previous cluster.</source>
          <target state="new"><ph id="ph113">[AZURE.NOTE]</ph><ph id="ph114" /> Since the data is persisted to the default storage container, the new cluster <bpt id="p79">**</bpt>must<ept id="p79">**</ept><ph id="ph115" /> use the same storage account and container as the previous cluster.</target>
        </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve">
          <source>Troubleshooting</source>
          <target state="new">Troubleshooting</target>
        </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve">
          <source>If you do not see files being stored to the the /devicedata location (either using the <ph id="ph116">`hadoop fs -ls /devicedata`</ph><ph id="ph117" /> command or the Hive commandd in the Query Console,) use the Storm UI to look for any errors returned by the topologies.</source>
          <target state="new">If you do not see files being stored to the the /devicedata location (either using the <ph id="ph116">`hadoop fs -ls /devicedata`</ph><ph id="ph117" /> command or the Hive commandd in the Query Console,) use the Storm UI to look for any errors returned by the topologies.</target>
        </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve">
          <source>For more information on using the Storm UI, see the following topics:</source>
          <target state="new">For more information on using the Storm UI, see the following topics:</target>
        </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve">
          <source>If you are using a <bpt id="p80">__</bpt>Linux-based<ept id="p80">__</ept><ph id="ph118" /> Storm on HDInsight cluster, see <bpt id="p81">[</bpt>Deploy and manage Apache Storm topologies on Linux-based HDInsight<ept id="p81">](hdinsight-storm-deploy-monitor-topology-linux.md)</ept></source>
          <target state="new">If you are using a <bpt id="p80">__</bpt>Linux-based<ept id="p80">__</ept><ph id="ph118" /> Storm on HDInsight cluster, see <bpt id="p81">[</bpt>Deploy and manage Apache Storm topologies on Linux-based HDInsight<ept id="p81">](hdinsight-storm-deploy-monitor-topology-linux.md)</ept></target>
        </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve">
          <source>If you are using a <bpt id="p82">__</bpt>Windows-based<ept id="p82">__</ept><ph id="ph119" /> Storm on HDInsight cluster, see <bpt id="p83">[</bpt>Deploy and manage Apache Storm topologies on Windows-based HDInsight<ept id="p83">](hdinsight-storm-deploy-monitor-topology-linux.md)</ept></source>
          <target state="new">If you are using a <bpt id="p82">__</bpt>Windows-based<ept id="p82">__</ept><ph id="ph119" /> Storm on HDInsight cluster, see <bpt id="p83">[</bpt>Deploy and manage Apache Storm topologies on Windows-based HDInsight<ept id="p83">](hdinsight-storm-deploy-monitor-topology-linux.md)</ept></target>
        </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve">
          <source><bpt id="p84">[</bpt>Example topologies for Storm on HDInsight<ept id="p84">](hdinsight-storm-example-topology.md)</ept></source>
          <target state="new"><bpt id="p84">[</bpt>Example topologies for Storm on HDInsight<ept id="p84">](hdinsight-storm-example-topology.md)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">24b07aa1693531aeb6c6fd2efcb64143e98e652a</xliffext:olfilehash>
  </header>
</xliff>