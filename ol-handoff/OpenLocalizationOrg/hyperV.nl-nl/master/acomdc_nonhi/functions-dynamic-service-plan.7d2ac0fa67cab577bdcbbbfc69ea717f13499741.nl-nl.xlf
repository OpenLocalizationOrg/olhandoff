<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="nl-nl">
    <header>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">acomdc_nonhi</xliffext:oltranslationpriority>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">73c9af0d54739194ab9a2b96c4c01b752345d7a9</xliffext:olfilehash>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1457980" tool-company="Microsoft" />
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Dynamic Service Plan</source>
          <target state="new">Dynamic Service Plan</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>In the Dynamic Service Plan, your function apps will be assigned to a function app instance.</source>
          <target state="new">In the Dynamic Service Plan, your function apps will be assigned to a function app instance.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>If needed more instances will be added dynamically.</source>
          <target state="new">If needed more instances will be added dynamically.</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Those instances can span across multiple computing resources, making the most out of the available Azure infrastructure.</source>
          <target state="new">Those instances can span across multiple computing resources, making the most out of the available Azure infrastructure.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Moreover, your functions will run in parallel minimizing the total time needed to process requests.</source>
          <target state="new">Moreover, your functions will run in parallel minimizing the total time needed to process requests.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Execution time for each function is added up, in seconds, and aggregated by the containing function app.</source>
          <target state="new">Execution time for each function is added up, in seconds, and aggregated by the containing function app.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>With cost driven by the number of instances, their memory size, and total execution time as measured in Gigabyte seconds.</source>
          <target state="new">With cost driven by the number of instances, their memory size, and total execution time as measured in Gigabyte seconds.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>This is an excellent option if your compute needs are intermittent or your job times tend to be very short as it allows you to only pay for compute resources when they are actually in use.</source>
          <target state="new">This is an excellent option if your compute needs are intermittent or your job times tend to be very short as it allows you to only pay for compute resources when they are actually in use.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Memory tier</source>
          <target state="new">Memory tier</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Depending on your function needs you can select the amount of memory required to run them in the Function App (container of functions).</source>
          <target state="new">Depending on your function needs you can select the amount of memory required to run them in the Function App (container of functions).</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>The memory size options vary from <bpt id="p1">**</bpt>128MB to 1536MB<ept id="p1">**</ept>.</source>
          <target state="new">The memory size options vary from <bpt id="p1">**</bpt>128MB to 1536MB<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>The selected memory size corresponds to the Working Set needed by all the functions that are part of your function app.</source>
          <target state="new">The selected memory size corresponds to the Working Set needed by all the functions that are part of your function app.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>If your code requires more memory than the selected size, the function app instance will be shut down due to lack of available memory.</source>
          <target state="new">If your code requires more memory than the selected size, the function app instance will be shut down due to lack of available memory.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Scaling</source>
          <target state="new">Scaling</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>The Azure Functions platform will evaluate the traffic needs, based on the configured triggers, to decide when to scale up or down.</source>
          <target state="new">The Azure Functions platform will evaluate the traffic needs, based on the configured triggers, to decide when to scale up or down.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>The granularity of scaling is the function app.</source>
          <target state="new">The granularity of scaling is the function app.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Scaling up in this case means adding more instances of a function app.</source>
          <target state="new">Scaling up in this case means adding more instances of a function app.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Inversely as traffic goes down, function app instances are disabled- eventually scaling down to zero when none are running.</source>
          <target state="new">Inversely as traffic goes down, function app instances are disabled- eventually scaling down to zero when none are running.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Resource consumption and billing</source>
          <target state="new">Resource consumption and billing</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>In the Dynamic mode resource allocation is done differently than the standard App Service plan, therefore the consumption model is also different, allowing for a "pay-per-use" model.</source>
          <target state="new">In the Dynamic mode resource allocation is done differently than the standard App Service plan, therefore the consumption model is also different, allowing for a "pay-per-use" model.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Consumption will be reported per function app, only for time when code is being executed.</source>
          <target state="new">Consumption will be reported per function app, only for time when code is being executed.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>It is computed by multiplying the memory size (in GB) by the total amount of execution time (in seconds) for all functions running inside that function app.</source>
          <target state="new">It is computed by multiplying the memory size (in GB) by the total amount of execution time (in seconds) for all functions running inside that function app.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>The unit of consumption will be <bpt id="p1">**</bpt>GB-s (Gigabyte Seconds)<ept id="p1">**</ept>.</source>
          <target state="new">The unit of consumption will be <bpt id="p1">**</bpt>GB-s (Gigabyte Seconds)<ept id="p1">**</ept>.</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>