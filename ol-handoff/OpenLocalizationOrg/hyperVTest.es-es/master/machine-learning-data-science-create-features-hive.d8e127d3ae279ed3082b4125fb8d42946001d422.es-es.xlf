<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="es-es">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Create features for data in an Hadoop cluster using Hive queries | Microsoft Azure</source>
          <target state="new">Create features for data in an Hadoop cluster using Hive queries | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Examples of Hive queries that generate features in data stored in an Azure HDInsight Hadoop cluster.</source>
          <target state="new">Examples of Hive queries that generate features in data stored in an Azure HDInsight Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Create features for data in an Hadoop cluster using Hive queries</source>
          <target state="new">Create features for data in an Hadoop cluster using Hive queries</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Introduction</source>
          <target state="new">Introduction</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Examples of Hive queries that generate features in data stored in an Azure HDInsight Hadoop cluster are presented.</source>
          <target state="new">Examples of Hive queries that generate features in data stored in an Azure HDInsight Hadoop cluster are presented.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>These Hive queries use embedded Hive User Defined Functions (UDFs), the scripts for which are provided.</source>
          <target state="new">These Hive queries use embedded Hive User Defined Functions (UDFs), the scripts for which are provided.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Examples of queries that are specific to <bpt id="p1">[</bpt>NYC Taxi Trip Data<ept id="p1">](http://chriswhong.com/open-data/foil_nyc_taxi/)</ept><ph id="ph2" /> scenarios are also provided in <bpt id="p2">[</bpt>Github repository<ept id="p2">](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/DataScienceProcess/DataScienceScripts)</ept>.</source>
          <target state="new">Examples of queries that are specific to <bpt id="p1">[</bpt>NYC Taxi Trip Data<ept id="p1">](http://chriswhong.com/open-data/foil_nyc_taxi/)</ept><ph id="ph2" /> scenarios are also provided in <bpt id="p2">[</bpt>Github repository<ept id="p2">](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/DataScienceProcess/DataScienceScripts)</ept>.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>These queries already have data schema specified and are ready to be submitted to run.</source>
          <target state="new">These queries already have data schema specified and are ready to be submitted to run.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>In the final section, parameters that users can tune so that the performance of Hive queries can be improved are discussed.</source>
          <target state="new">In the final section, parameters that users can tune so that the performance of Hive queries can be improved are discussed.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source><ph id="ph3">[AZURE.INCLUDE [cap-create-features-data-selector](../../includes/cap-create-features-selector.md)]</ph>
This <bpt id="p3">**</bpt>menu<ept id="p3">**</ept><ph id="ph4" /> links to topics that describe how to create features for data in various environments.</source>
          <target state="new"><ph id="ph3">[AZURE.INCLUDE [cap-create-features-data-selector](../../includes/cap-create-features-selector.md)]</ph>
This <bpt id="p3">**</bpt>menu<ept id="p3">**</ept><ph id="ph4" /> links to topics that describe how to create features for data in various environments.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>This task is a step in the <bpt id="p4">[</bpt>Cortana Analytics Process (CAP)<ept id="p4">](https://azure.microsoft.com/documentation/learning-paths/cortana-analytics-process/)</ept>.</source>
          <target state="new">This task is a step in the <bpt id="p4">[</bpt>Cortana Analytics Process (CAP)<ept id="p4">](https://azure.microsoft.com/documentation/learning-paths/cortana-analytics-process/)</ept>.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Prerequisites</source>
          <target state="new">Prerequisites</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>This article assumes that you have:</source>
          <target state="new">This article assumes that you have:</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Created an Azure storage account.</source>
          <target state="new">Created an Azure storage account.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>If you need instructions, see <bpt id="p5">[</bpt>Create an Azure Storage account<ept id="p5">](../hdinsight-get-started.md#storage)</ept></source>
          <target state="new">If you need instructions, see <bpt id="p5">[</bpt>Create an Azure Storage account<ept id="p5">](../hdinsight-get-started.md#storage)</ept></target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Provisioned a customized Hadoop cluster with the HDInsight service.</source>
          <target state="new">Provisioned a customized Hadoop cluster with the HDInsight service.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>If you need instructions, see <bpt id="p6">[</bpt>Customize Azure HDInsight Hadoop Clusters for Advanced Analytics<ept id="p6">](machine-learning-data-science-customize-hadoop-cluster.md)</ept>.</source>
          <target state="new">If you need instructions, see <bpt id="p6">[</bpt>Customize Azure HDInsight Hadoop Clusters for Advanced Analytics<ept id="p6">](machine-learning-data-science-customize-hadoop-cluster.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>The data has been uploaded to Hive tables in Azure HDInsight Hadoop clusters.</source>
          <target state="new">The data has been uploaded to Hive tables in Azure HDInsight Hadoop clusters.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>If it has not, please follow <bpt id="p7">[</bpt>Create and load data to Hive tables<ept id="p7">](machine-learning-data-science-move-hive-tables.md)</ept><ph id="ph5" /> to upload data to Hive tables first.</source>
          <target state="new">If it has not, please follow <bpt id="p7">[</bpt>Create and load data to Hive tables<ept id="p7">](machine-learning-data-science-move-hive-tables.md)</ept><ph id="ph5" /> to upload data to Hive tables first.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Enabled remote access to the cluster.</source>
          <target state="new">Enabled remote access to the cluster.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>If you need instructions, see <bpt id="p8">[</bpt>Access the Head Node of Hadoop Cluster<ept id="p8">](machine-learning-data-science-customize-hadoop-cluster.md#headnode)</ept>.</source>
          <target state="new">If you need instructions, see <bpt id="p8">[</bpt>Access the Head Node of Hadoop Cluster<ept id="p8">](machine-learning-data-science-customize-hadoop-cluster.md#headnode)</ept>.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Feature Generation</source>
          <target state="new">Feature Generation</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>In this section, several examples of the ways in which features can be generating using Hive queries are described.</source>
          <target state="new">In this section, several examples of the ways in which features can be generating using Hive queries are described.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Once you have generated additional features, you can either add them as columns to the existing table or create a new table with the additional features and primary key, which can then be joined with the original table.</source>
          <target state="new">Once you have generated additional features, you can either add them as columns to the existing table or create a new table with the additional features and primary key, which can then be joined with the original table.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Here are the examples presented:</source>
          <target state="new">Here are the examples presented:</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source><bpt id="p9">[</bpt>Frequency based Feature Generation<ept id="p9">](#hive-frequencyfeature)</ept></source>
          <target state="new"><bpt id="p9">[</bpt>Frequency based Feature Generation<ept id="p9">](#hive-frequencyfeature)</ept></target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source><bpt id="p10">[</bpt>Risks of Categorical Variables in Binary Classification<ept id="p10">](#hive-riskfeature)</ept></source>
          <target state="new"><bpt id="p10">[</bpt>Risks of Categorical Variables in Binary Classification<ept id="p10">](#hive-riskfeature)</ept></target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source><bpt id="p11">[</bpt>Extract features from Datetime Field<ept id="p11">](#hive-datefeatures)</ept></source>
          <target state="new"><bpt id="p11">[</bpt>Extract features from Datetime Field<ept id="p11">](#hive-datefeatures)</ept></target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source><bpt id="p12">[</bpt>Extract features from Text Field<ept id="p12">](#hive-textfeatures)</ept></source>
          <target state="new"><bpt id="p12">[</bpt>Extract features from Text Field<ept id="p12">](#hive-textfeatures)</ept></target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><bpt id="p13">[</bpt>Calculate distance between GPS coordinates<ept id="p13">](#hive-gpsdistance)</ept></source>
          <target state="new"><bpt id="p13">[</bpt>Calculate distance between GPS coordinates<ept id="p13">](#hive-gpsdistance)</ept></target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Frequency based Feature Generation</source>
          <target state="new">Frequency based Feature Generation</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>It is often useful to calculate the frequencies of the levels of a categorical variable, or the frequencies of certain combinations of levels from multiple categorical variables.</source>
          <target state="new">It is often useful to calculate the frequencies of the levels of a categorical variable, or the frequencies of certain combinations of levels from multiple categorical variables.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Users can use the following script to calculate these frequencies:</source>
          <target state="new">Users can use the following script to calculate these frequencies:</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Risks of Categorical Variables in Binary Classification</source>
          <target state="new">Risks of Categorical Variables in Binary Classification</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>In binary classification, we need to convert non-numeric categorical variables into numeric features when the models being used only take numeric features.</source>
          <target state="new">In binary classification, we need to convert non-numeric categorical variables into numeric features when the models being used only take numeric features.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>This is done by replacing each non-numeric level with a numeric risk.</source>
          <target state="new">This is done by replacing each non-numeric level with a numeric risk.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>In this section, we show some generic Hive queries that calculate the risk values (log odds) of a categorical variable.</source>
          <target state="new">In this section, we show some generic Hive queries that calculate the risk values (log odds) of a categorical variable.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>In this example, variables <ph id="ph6">`smooth_param1`</ph><ph id="ph7" /> and <ph id="ph8">`smooth_param2`</ph><ph id="ph9" /> are set to smooth the risk values calculated from the data. Ri</source>
          <target state="new">In this example, variables <ph id="ph6">`smooth_param1`</ph><ph id="ph7" /> and <ph id="ph8">`smooth_param2`</ph><ph id="ph9" /> are set to smooth the risk values calculated from the data. Ri</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>sks have a range between -Inf and Inf. A</source>
          <target state="new">sks have a range between -Inf and Inf. A</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>risks &gt; 0 indicates that the probability that the target is equal to 1 is greater than 0.5.</source>
          <target state="new">risks &gt; 0 indicates that the probability that the target is equal to 1 is greater than 0.5.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>After the risk table is calculated, users can assign risk values to a table by joining it with the risk table.</source>
          <target state="new">After the risk table is calculated, users can assign risk values to a table by joining it with the risk table.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>The Hive joining query was provided in previous section.</source>
          <target state="new">The Hive joining query was provided in previous section.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>Extract features from Datetime Fields</source>
          <target state="new">Extract features from Datetime Fields</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Hive comes with a set of UDFs for processing datetime fields.</source>
          <target state="new">Hive comes with a set of UDFs for processing datetime fields.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>In Hive, the default datetime format is 'yyyy-MM-dd 00:00:00' ('1970-01-01 12:21:32' for example).</source>
          <target state="new">In Hive, the default datetime format is 'yyyy-MM-dd 00:00:00' ('1970-01-01 12:21:32' for example).</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>In this section, we show examples that extract the day of a month, the month from a datetime field, and other examples that convert a datetime string in a format other than the default format to a datetime string in default format.</source>
          <target state="new">In this section, we show examples that extract the day of a month, the month from a datetime field, and other examples that convert a datetime string in a format other than the default format to a datetime string in default format.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>This Hive query assumes that the <bpt id="p14">*</bpt>&amp;#60;datetime field&gt;<ept id="p14">*</ept><ph id="ph10" /> is in the default datetime format.</source>
          <target state="new">This Hive query assumes that the <bpt id="p14">*</bpt>&amp;#60;datetime field&gt;<ept id="p14">*</ept><ph id="ph10" /> is in the default datetime format.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>If a datetime field is not in the default format, you need to convert the datetime field into Unix time stamp first, and then convert the Unix time stamp to a datetime string that is in the default format.</source>
          <target state="new">If a datetime field is not in the default format, you need to convert the datetime field into Unix time stamp first, and then convert the Unix time stamp to a datetime string that is in the default format.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>When the datetime is in default format, users can apply the embedded datetime UDFs to extract features.</source>
          <target state="new">When the datetime is in default format, users can apply the embedded datetime UDFs to extract features.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>In this query, if the <bpt id="p15">*</bpt>&amp;#60;datetime field&gt;<ept id="p15">*</ept><ph id="ph11" /> has the pattern like <bpt id="p16">*</bpt>03/26/2015 12:04:39<ept id="p16">*</ept>, the <bpt id="p17">*</bpt>'&amp;#60;pattern of the datetime field&gt;'<ept id="p17">*</ept><ph id="ph12" /> should be <ph id="ph13">`'MM/dd/yyyy HH:mm:ss'`</ph>.</source>
          <target state="new">In this query, if the <bpt id="p15">*</bpt>&amp;#60;datetime field&gt;<ept id="p15">*</ept><ph id="ph11" /> has the pattern like <bpt id="p16">*</bpt>03/26/2015 12:04:39<ept id="p16">*</ept>, the <bpt id="p17">*</bpt>'&amp;#60;pattern of the datetime field&gt;'<ept id="p17">*</ept><ph id="ph12" /> should be <ph id="ph13">`'MM/dd/yyyy HH:mm:ss'`</ph>.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>To test it, users can run</source>
          <target state="new">To test it, users can run</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>The <bpt id="p18">*</bpt>hivesampletable<ept id="p18">*</ept><ph id="ph14" /> in this query comes preinstalled on all Azure HDInsight Hadoop clusters by default when the clusters are provisioned.</source>
          <target state="new">The <bpt id="p18">*</bpt>hivesampletable<ept id="p18">*</ept><ph id="ph14" /> in this query comes preinstalled on all Azure HDInsight Hadoop clusters by default when the clusters are provisioned.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>Extract features from Text Fields</source>
          <target state="new">Extract features from Text Fields</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>When the Hive table has a text field that contains a string of words that are delimited by spaces, the following query extracts the length of the string, and the number of words in the string.</source>
          <target state="new">When the Hive table has a text field that contains a string of words that are delimited by spaces, the following query extracts the length of the string, and the number of words in the string.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Calculate distances between sets of GPS coordinates</source>
          <target state="new">Calculate distances between sets of GPS coordinates</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>The query given in this section can be directly applied to the NYC Taxi Trip Data.</source>
          <target state="new">The query given in this section can be directly applied to the NYC Taxi Trip Data.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>The purpose of this query is to show how to apply an embedded mathematical functions in Hive to generate features.</source>
          <target state="new">The purpose of this query is to show how to apply an embedded mathematical functions in Hive to generate features.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>The fields that are used in this query are the GPS coordinates of pickup and dropoff locations, named <bpt id="p19">*</bpt>pickup\_longitude<ept id="p19">*</ept>, <bpt id="p20">*</bpt>pickup\_latitude<ept id="p20">*</ept>, <bpt id="p21">*</bpt>dropoff\_longitude<ept id="p21">*</ept>, and <bpt id="p22">*</bpt>dropoff\_latitude<ept id="p22">*</ept>.</source>
          <target state="new">The fields that are used in this query are the GPS coordinates of pickup and dropoff locations, named <bpt id="p19">*</bpt>pickup\_longitude<ept id="p19">*</ept>, <bpt id="p20">*</bpt>pickup\_latitude<ept id="p20">*</ept>, <bpt id="p21">*</bpt>dropoff\_longitude<ept id="p21">*</ept>, and <bpt id="p22">*</bpt>dropoff\_latitude<ept id="p22">*</ept>.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>The queries that calculate the direct distance between the pickup and dropoff coordinates are:</source>
          <target state="new">The queries that calculate the direct distance between the pickup and dropoff coordinates are:</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>The mathematical equations that calculate the distance between two GPS coordinates can be found on the <ph id="ph15">&lt;a href="http://www.movable-type.co.uk/scripts/latlong.html" target="_blank"&gt;</ph>Movable Type Scripts<ph id="ph16">&lt;/a&gt;</ph><ph id="ph17" /> site, authored by Peter Lapisu.</source>
          <target state="new">The mathematical equations that calculate the distance between two GPS coordinates can be found on the <ph id="ph15">&lt;a href="http://www.movable-type.co.uk/scripts/latlong.html" target="_blank"&gt;</ph>Movable Type Scripts<ph id="ph16">&lt;/a&gt;</ph><ph id="ph17" /> site, authored by Peter Lapisu.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>In his Javascript, the function <ph id="ph18">`toRad()`</ph><ph id="ph19" /> is just <bpt id="p23">*</bpt>lat_or_lon<ept id="p23">*</ept>pi/180*, which converts degrees to radians.</source>
          <target state="new">In his Javascript, the function <ph id="ph18">`toRad()`</ph><ph id="ph19" /> is just <bpt id="p23">*</bpt>lat_or_lon<ept id="p23">*</ept>pi/180*, which converts degrees to radians.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Here, <bpt id="p24">*</bpt>lat_or_lon<ept id="p24">*</ept><ph id="ph20" /> is the latitude or longitude.</source>
          <target state="new">Here, <bpt id="p24">*</bpt>lat_or_lon<ept id="p24">*</ept><ph id="ph20" /> is the latitude or longitude.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Since Hive does not provide the function <ph id="ph21">`atan2`</ph>, but provides the function <ph id="ph22">`atan`</ph>, the <ph id="ph23">`atan2`</ph><ph id="ph24" /> function is implemented by <ph id="ph25">`atan`</ph><ph id="ph26" /> function in the above Hive query using the definition provided in <ph id="ph27">&lt;a href="http://en.wikipedia.org/wiki/Atan2" target="_blank"&gt;</ph>Wikipedia<ph id="ph28">&lt;/a&gt;</ph>.</source>
          <target state="new">Since Hive does not provide the function <ph id="ph21">`atan2`</ph>, but provides the function <ph id="ph22">`atan`</ph>, the <ph id="ph23">`atan2`</ph><ph id="ph24" /> function is implemented by <ph id="ph25">`atan`</ph><ph id="ph26" /> function in the above Hive query using the definition provided in <ph id="ph27">&lt;a href="http://en.wikipedia.org/wiki/Atan2" target="_blank"&gt;</ph>Wikipedia<ph id="ph28">&lt;/a&gt;</ph>.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source><ph id="ph29">![</ph>Create workspace<ph id="ph30">][1]</ph></source>
          <target state="new"><ph id="ph29">![</ph>Create workspace<ph id="ph30">][1]</ph></target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>A full list of Hive embedded UDFs can be found in the <bpt id="p25">**</bpt>Built-in Functions<ept id="p25">**</ept><ph id="ph31" /> section on the <ph id="ph32">&lt;a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-MathematicalFunctions" target="_blank"&gt;</ph>Apache Hive wiki<ph id="ph33">&lt;/a&gt;</ph>).</source>
          <target state="new">A full list of Hive embedded UDFs can be found in the <bpt id="p25">**</bpt>Built-in Functions<ept id="p25">**</ept><ph id="ph31" /> section on the <ph id="ph32">&lt;a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-MathematicalFunctions" target="_blank"&gt;</ph>Apache Hive wiki<ph id="ph33">&lt;/a&gt;</ph>).</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>Advanced topics: Tune Hive Parameters to Improve Query Speed</source>
          <target state="new">Advanced topics: Tune Hive Parameters to Improve Query Speed</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>The default parameter settings of Hive cluster might not be suitable for the Hive queries and the data that the queries are processing.</source>
          <target state="new">The default parameter settings of Hive cluster might not be suitable for the Hive queries and the data that the queries are processing.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>In this section, we discuss some parameters that users can tune that improve the performance of Hive queries.</source>
          <target state="new">In this section, we discuss some parameters that users can tune that improve the performance of Hive queries.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>Users need to add the parameter tuning queries before the queries of processing data.</source>
          <target state="new">Users need to add the parameter tuning queries before the queries of processing data.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source><bpt id="p26">**</bpt>Java heap space<ept id="p26">**</ept>: For queries involving joining large datasets, or processing long records, <bpt id="p27">**</bpt>running out of heap space<ept id="p27">**</ept><ph id="ph34" /> is one of the common error.</source>
          <target state="new"><bpt id="p26">**</bpt>Java heap space<ept id="p26">**</ept>: For queries involving joining large datasets, or processing long records, <bpt id="p27">**</bpt>running out of heap space<ept id="p27">**</ept><ph id="ph34" /> is one of the common error.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>This can be tuned by setting parameters <bpt id="p28">*</bpt>mapreduce.map.java.opts<ept id="p28">*</ept><ph id="ph35" /> and <bpt id="p29">*</bpt>mapreduce.task.io.sort.mb<ept id="p29">*</ept><ph id="ph36" /> to desired values.</source>
          <target state="new">This can be tuned by setting parameters <bpt id="p28">*</bpt>mapreduce.map.java.opts<ept id="p28">*</ept><ph id="ph35" /> and <bpt id="p29">*</bpt>mapreduce.task.io.sort.mb<ept id="p29">*</ept><ph id="ph36" /> to desired values.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>Here is an example:</source>
          <target state="new">Here is an example:</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>This parameter allocates 4GB memory to Java heap space and also makes sorting more efficient by allocating more memory for it.</source>
          <target state="new">This parameter allocates 4GB memory to Java heap space and also makes sorting more efficient by allocating more memory for it.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>It is a good idea to play with these allocations if there are any job failure errors related to heap space.</source>
          <target state="new">It is a good idea to play with these allocations if there are any job failure errors related to heap space.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source><bpt id="p30">**</bpt>DFS block size<ept id="p30">**</ept><ph id="ph37" /> : This parameter sets the smallest unit of data that the file system stores.</source>
          <target state="new"><bpt id="p30">**</bpt>DFS block size<ept id="p30">**</ept><ph id="ph37" /> : This parameter sets the smallest unit of data that the file system stores.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>As an example, if the DFS block size is 128MB, then any data of size less than and up to 128MB is stored in a single block, while data that is larger than 128MB is allotted extra blocks.</source>
          <target state="new">As an example, if the DFS block size is 128MB, then any data of size less than and up to 128MB is stored in a single block, while data that is larger than 128MB is allotted extra blocks.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>Choosing a very small block size causes large overheads in Hadoop since the name node has to process many more requests to find the relevant block pertaining to the file.</source>
          <target state="new">Choosing a very small block size causes large overheads in Hadoop since the name node has to process many more requests to find the relevant block pertaining to the file.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>A recommended setting when dealing with gigabytes (or larger) data is :</source>
          <target state="new">A recommended setting when dealing with gigabytes (or larger) data is :</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source><bpt id="p31">**</bpt>Optimizing join operation in Hive<ept id="p31">**</ept><ph id="ph38" /> : While join operations in the map/reduce framework typically take place in the reduce phase, sometimes, enormous gains can be achieved by scheduling joins in the map phase (also called "mapjoins").</source>
          <target state="new"><bpt id="p31">**</bpt>Optimizing join operation in Hive<ept id="p31">**</ept><ph id="ph38" /> : While join operations in the map/reduce framework typically take place in the reduce phase, sometimes, enormous gains can be achieved by scheduling joins in the map phase (also called "mapjoins").</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>To direct Hive to do this whenever possible, we can set :</source>
          <target state="new">To direct Hive to do this whenever possible, we can set :</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source><bpt id="p32">**</bpt>Specifying the number of mappers to Hive<ept id="p32">**</ept><ph id="ph39" /> : While Hadoop allows the user to set the number of reducers, the number of mappers is typically not be set by the user.</source>
          <target state="new"><bpt id="p32">**</bpt>Specifying the number of mappers to Hive<ept id="p32">**</ept><ph id="ph39" /> : While Hadoop allows the user to set the number of reducers, the number of mappers is typically not be set by the user.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>A trick that allows some degree of control on this number is to choose the Hadoop variables, <bpt id="p33">*</bpt>mapred.min.split.size<ept id="p33">*</ept><ph id="ph40" /> and <bpt id="p34">*</bpt>mapred.max.split.size<ept id="p34">*</ept><ph id="ph41" /> as the size of each map task is determined by :</source>
          <target state="new">A trick that allows some degree of control on this number is to choose the Hadoop variables, <bpt id="p33">*</bpt>mapred.min.split.size<ept id="p33">*</ept><ph id="ph40" /> and <bpt id="p34">*</bpt>mapred.max.split.size<ept id="p34">*</ept><ph id="ph41" /> as the size of each map task is determined by :</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>Typically, the default value of <bpt id="p35">*</bpt>mapred.min.split.size<ept id="p35">*</ept><ph id="ph42" /> is 0, that of <bpt id="p36">*</bpt>mapred.max.split.size<ept id="p36">*</ept><ph id="ph43" /> is <bpt id="p37">**</bpt>Long.MAX<ept id="p37">**</ept><ph id="ph44" /> and that of <bpt id="p38">*</bpt>dfs.block.size<ept id="p38">*</ept><ph id="ph45" /> is 64MB.</source>
          <target state="new">Typically, the default value of <bpt id="p35">*</bpt>mapred.min.split.size<ept id="p35">*</ept><ph id="ph42" /> is 0, that of <bpt id="p36">*</bpt>mapred.max.split.size<ept id="p36">*</ept><ph id="ph43" /> is <bpt id="p37">**</bpt>Long.MAX<ept id="p37">**</ept><ph id="ph44" /> and that of <bpt id="p38">*</bpt>dfs.block.size<ept id="p38">*</ept><ph id="ph45" /> is 64MB.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>As we can see, given the data size, tuning these parameters by "setting" them allows us to tune the number of mappers used.</source>
          <target state="new">As we can see, given the data size, tuning these parameters by "setting" them allows us to tune the number of mappers used.</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>A few other more <bpt id="p39">**</bpt>advanced options<ept id="p39">**</ept><ph id="ph46" /> for optimizing Hive performance are mentioned below.</source>
          <target state="new">A few other more <bpt id="p39">**</bpt>advanced options<ept id="p39">**</ept><ph id="ph46" /> for optimizing Hive performance are mentioned below.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>These allow you to set the memory allocated to map and reduce tasks, and can be useful in tweaking performance.</source>
          <target state="new">These allow you to set the memory allocated to map and reduce tasks, and can be useful in tweaking performance.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>Please keep in mind that the <bpt id="p40">*</bpt>mapreduce.reduce.memory.mb<ept id="p40">*</ept><ph id="ph47" /> cannot be greater than the physical memory size of each worker node in the Hadoop cluster.</source>
          <target state="new">Please keep in mind that the <bpt id="p40">*</bpt>mapreduce.reduce.memory.mb<ept id="p40">*</ept><ph id="ph47" /> cannot be greater than the physical memory size of each worker node in the Hadoop cluster.</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">66c4ad755418027728a2a3eb0110afc3c541bad2</xliffext:olfilehash>
  </header>
</xliff>