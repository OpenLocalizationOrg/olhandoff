<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="ja-jp">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;properties
 pageTitle="</ph>Develop Scalding MapReduce jobs with Maven | Microsoft Azure<ph id="ph2">"
 description="</ph>Learn how to use Maven to create a Scalding MapReduce job, then deploy and run the job on a Hadoop on HDInsight cluster.<ph id="ph3">"
 services="hdinsight"
 documentationCenter=""
 authors="Blackmist"
 manager="paulettm"
 editor="cgronlun"
    tags="azure-portal"/&gt;</ph><ph id="ph4">
&lt;tags
 ms.service="hdinsight"
 ms.devlang="na"
 ms.topic="article"
 ms.tgt_pltfrm="na"
 ms.workload="big-data"
 ms.date="02/05/2016"
 ms.author="larryfr"/&gt;</ph></source>
          <target state="new"><ph id="ph1">&lt;properties
 pageTitle="</ph>Develop Scalding MapReduce jobs with Maven | Microsoft Azure<ph id="ph2">"
 description="</ph>Learn how to use Maven to create a Scalding MapReduce job, then deploy and run the job on a Hadoop on HDInsight cluster.<ph id="ph3">"
 services="hdinsight"
 documentationCenter=""
 authors="Blackmist"
 manager="paulettm"
 editor="cgronlun"
    tags="azure-portal"/&gt;</ph><ph id="ph4">
&lt;tags
 ms.service="hdinsight"
 ms.devlang="na"
 ms.topic="article"
 ms.tgt_pltfrm="na"
 ms.workload="big-data"
 ms.date="02/05/2016"
 ms.author="larryfr"/&gt;</ph></target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Develop Scalding MapReduce jobs with Apache Hadoop on HDInsight</source>
          <target state="new">Develop Scalding MapReduce jobs with Apache Hadoop on HDInsight</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Scalding is a Scala library that makes it easy to create Hadoop MapReduce jobs.</source>
          <target state="new">Scalding is a Scala library that makes it easy to create Hadoop MapReduce jobs.</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>It offers a concise syntax, as well as tight integration with Scala.</source>
          <target state="new">It offers a concise syntax, as well as tight integration with Scala.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>In this document, learn how to use Maven to create a basic word count MapReduce job written in Scalding.</source>
          <target state="new">In this document, learn how to use Maven to create a basic word count MapReduce job written in Scalding.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>You will then learn how to deploy and run this job on an HDInsight cluster.</source>
          <target state="new">You will then learn how to deploy and run this job on an HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Prerequisites</source>
          <target state="new">Prerequisites</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>An Azure subscription<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>An Azure subscription<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>See <bpt id="p2">[</bpt>Get Azure free trial<ept id="p2">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.</source>
          <target state="new">See <bpt id="p2">[</bpt>Get Azure free trial<ept id="p2">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source><bpt id="p3">**</bpt>A Windows or Linux based Hadoop on HDInsight cluster<ept id="p3">**</ept>.</source>
          <target state="new"><bpt id="p3">**</bpt>A Windows or Linux based Hadoop on HDInsight cluster<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>See <bpt id="p4">[</bpt>Provision Linux-based Hadoop on HDInsight<ept id="p4">](hdinsight-hadoop-provision-linux-clusters.md)</ept><ph id="ph5" /> or <bpt id="p5">[</bpt>Provision Windows-based Hadoop on HDInsight<ept id="p5">](hdinsight-provision-clusters.md)</ept><ph id="ph6" /> for more information.</source>
          <target state="new">See <bpt id="p4">[</bpt>Provision Linux-based Hadoop on HDInsight<ept id="p4">](hdinsight-hadoop-provision-linux-clusters.md)</ept><ph id="ph5" /> or <bpt id="p5">[</bpt>Provision Windows-based Hadoop on HDInsight<ept id="p5">](hdinsight-provision-clusters.md)</ept><ph id="ph6" /> for more information.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source><bpt id="p6">**</bpt><bpt id="p7">[</bpt>Maven<ept id="p7">](http://maven.apache.org/)</ept><ept id="p6">**</ept></source>
          <target state="new"><bpt id="p6">**</bpt><bpt id="p7">[</bpt>Maven<ept id="p7">](http://maven.apache.org/)</ept><ept id="p6">**</ept></target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source><bpt id="p8">**</bpt><bpt id="p9">[</bpt>Java platform JDK<ept id="p9">](http://www.oracle.com/technetwork/java/javase/downloads/index.html)</ept><ph id="ph7" /> 7 or later<ept id="p8">**</ept></source>
          <target state="new"><bpt id="p8">**</bpt><bpt id="p9">[</bpt>Java platform JDK<ept id="p9">](http://www.oracle.com/technetwork/java/javase/downloads/index.html)</ept><ph id="ph7" /> 7 or later<ept id="p8">**</ept></target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Create and build the project</source>
          <target state="new">Create and build the project</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Use the following command to create a new Maven project:</source>
          <target state="new">Use the following command to create a new Maven project:</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>This command will create a new directory named <bpt id="p10">**</bpt>scaldingwordcount<ept id="p10">**</ept>, and create the scaffolding for an Scala application.</source>
          <target state="new">This command will create a new directory named <bpt id="p10">**</bpt>scaldingwordcount<ept id="p10">**</ept>, and create the scaffolding for an Scala application.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p11">**</bpt>scaldingwordcount<ept id="p11">**</ept><ph id="ph8" /> directory, open the <bpt id="p12">**</bpt>pom.xml<ept id="p12">**</ept><ph id="ph9" /> file and replace the contents with the following:</source>
          <target state="new">In the <bpt id="p11">**</bpt>scaldingwordcount<ept id="p11">**</ept><ph id="ph8" /> directory, open the <bpt id="p12">**</bpt>pom.xml<ept id="p12">**</ept><ph id="ph9" /> file and replace the contents with the following:</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>This file describes the project, dependencies, and plugins.</source>
          <target state="new">This file describes the project, dependencies, and plugins.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Here are the important entries:</source>
          <target state="new">Here are the important entries:</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p13">**</bpt>maven.compiler.source<ept id="p13">**</ept><ph id="ph10" /> and <bpt id="p14">**</bpt>maven.compiler.target<ept id="p14">**</ept>: sets the Java version for this project</source>
          <target state="new"><bpt id="p13">**</bpt>maven.compiler.source<ept id="p13">**</ept><ph id="ph10" /> and <bpt id="p14">**</bpt>maven.compiler.target<ept id="p14">**</ept>: sets the Java version for this project</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source><bpt id="p15">**</bpt>repositories<ept id="p15">**</ept>: the repositories that contain the dependency files used by this project</source>
          <target state="new"><bpt id="p15">**</bpt>repositories<ept id="p15">**</ept>: the repositories that contain the dependency files used by this project</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source><bpt id="p16">**</bpt>scalding-core_2.11<ept id="p16">**</ept><ph id="ph11" /> and <bpt id="p17">**</bpt>hadoop-core<ept id="p17">**</ept>: this project depends on both Scalding and Hadoop core packages</source>
          <target state="new"><bpt id="p16">**</bpt>scalding-core_2.11<ept id="p16">**</ept><ph id="ph11" /> and <bpt id="p17">**</bpt>hadoop-core<ept id="p17">**</ept>: this project depends on both Scalding and Hadoop core packages</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source><bpt id="p18">**</bpt>maven-scala-plugin<ept id="p18">**</ept>: plugin to compile scala applications</source>
          <target state="new"><bpt id="p18">**</bpt>maven-scala-plugin<ept id="p18">**</ept>: plugin to compile scala applications</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source><bpt id="p19">**</bpt>maven-shade-plugin<ept id="p19">**</ept>: plugin to create shaded (fat) jars.</source>
          <target state="new"><bpt id="p19">**</bpt>maven-shade-plugin<ept id="p19">**</ept>: plugin to create shaded (fat) jars.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>This plugin applies filters and transformations; specificially:</source>
          <target state="new">This plugin applies filters and transformations; specificially:</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source><bpt id="p20">**</bpt>filters<ept id="p20">**</ept>: The filters applied modify the meta information included with in the jar file.</source>
          <target state="new"><bpt id="p20">**</bpt>filters<ept id="p20">**</ept>: The filters applied modify the meta information included with in the jar file.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>To prevent signing exceptions at runtime, this excludes various signature files that may be included with dependencies.</source>
          <target state="new">To prevent signing exceptions at runtime, this excludes various signature files that may be included with dependencies.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source><bpt id="p21">**</bpt>executions<ept id="p21">**</ept>: The package phase execution configuration specifies the <bpt id="p22">**</bpt>com.twitter.scalding.Tool<ept id="p22">**</ept><ph id="ph12" /> class as the main class for the package.</source>
          <target state="new"><bpt id="p21">**</bpt>executions<ept id="p21">**</ept>: The package phase execution configuration specifies the <bpt id="p22">**</bpt>com.twitter.scalding.Tool<ept id="p22">**</ept><ph id="ph12" /> class as the main class for the package.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Without this, you would need to specify com.twitter.scalding.Tool, as well as the class that contains the application logic, when running the job with the hadoop command.</source>
          <target state="new">Without this, you would need to specify com.twitter.scalding.Tool, as well as the class that contains the application logic, when running the job with the hadoop command.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Delete the <bpt id="p23">**</bpt>src/test<ept id="p23">**</ept><ph id="ph13" /> directory, as you will not be creating tests with this example.</source>
          <target state="new">Delete the <bpt id="p23">**</bpt>src/test<ept id="p23">**</ept><ph id="ph13" /> directory, as you will not be creating tests with this example.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>Open the <bpt id="p24">**</bpt>src/main/scala/com/microsoft/example/app.scala<ept id="p24">**</ept><ph id="ph14" /> file and replace the contents with the following:</source>
          <target state="new">Open the <bpt id="p24">**</bpt>src/main/scala/com/microsoft/example/app.scala<ept id="p24">**</ept><ph id="ph14" /> file and replace the contents with the following:</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>This implements a basic word count job.</source>
          <target state="new">This implements a basic word count job.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Save and close the files.</source>
          <target state="new">Save and close the files.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Use the following command from the <bpt id="p25">**</bpt>scaldingwordcount<ept id="p25">**</ept><ph id="ph15" /> directory to build and package the application:</source>
          <target state="new">Use the following command from the <bpt id="p25">**</bpt>scaldingwordcount<ept id="p25">**</ept><ph id="ph15" /> directory to build and package the application:</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Once this job completes, the package containing the WordCount application can be found at <bpt id="p26">**</bpt>target/scaldingwordcount-1.0-SNAPSHOT.jar<ept id="p26">**</ept>.</source>
          <target state="new">Once this job completes, the package containing the WordCount application can be found at <bpt id="p26">**</bpt>target/scaldingwordcount-1.0-SNAPSHOT.jar<ept id="p26">**</ept>.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Run the job on a Linux-based cluster</source>
          <target state="new">Run the job on a Linux-based cluster</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source><ph id="ph16">[AZURE.NOTE]</ph><ph id="ph17" /> The following steps use SSH and the Hadoop command.</source>
          <target state="new"><ph id="ph16">[AZURE.NOTE]</ph><ph id="ph17" /> The following steps use SSH and the Hadoop command.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>For other methods of running MapReduce jobs, see <bpt id="p27">[</bpt>Use MapReduce in Hadoop on HDInsight<ept id="p27">](hdinsight-use-mapreduce.md)</ept>.</source>
          <target state="new">For other methods of running MapReduce jobs, see <bpt id="p27">[</bpt>Use MapReduce in Hadoop on HDInsight<ept id="p27">](hdinsight-use-mapreduce.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Use the following command to upload the package to your HDInsight cluster:</source>
          <target state="new">Use the following command to upload the package to your HDInsight cluster:</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>This copies the files from the local system to the head node.</source>
          <target state="new">This copies the files from the local system to the head node.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source><ph id="ph18">[AZURE.NOTE]</ph><ph id="ph19" /> If you used a password to secure your SSH account, you will be prompted for the password.</source>
          <target state="new"><ph id="ph18">[AZURE.NOTE]</ph><ph id="ph19" /> If you used a password to secure your SSH account, you will be prompted for the password.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>If you used an SSH key, you may have to use the <ph id="ph20">`-i`</ph><ph id="ph21" /> parameter and the path to the private key.</source>
          <target state="new">If you used an SSH key, you may have to use the <ph id="ph20">`-i`</ph><ph id="ph21" /> parameter and the path to the private key.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>For example, <ph id="ph22">`scp -i /path/to/private/key target/scaldingwordcount-1.0-SNAPSHOT.jar username@clustername-ssh.azurehdinsight.net:.`</ph></source>
          <target state="new">For example, <ph id="ph22">`scp -i /path/to/private/key target/scaldingwordcount-1.0-SNAPSHOT.jar username@clustername-ssh.azurehdinsight.net:.`</ph></target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Use the following command to connect to the cluster head node:</source>
          <target state="new">Use the following command to connect to the cluster head node:</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source><ph id="ph23">[AZURE.NOTE]</ph><ph id="ph24" /> If you used a password to secure your SSH account, you will be prompted for the password.</source>
          <target state="new"><ph id="ph23">[AZURE.NOTE]</ph><ph id="ph24" /> If you used a password to secure your SSH account, you will be prompted for the password.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>If you used an SSH key, you may have to use the <ph id="ph25">`-i`</ph><ph id="ph26" /> parameter and the path to the private key.</source>
          <target state="new">If you used an SSH key, you may have to use the <ph id="ph25">`-i`</ph><ph id="ph26" /> parameter and the path to the private key.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>For example, <ph id="ph27">`ssh -i /path/to/private/key username@clustername-ssh.azurehdinsight.net`</ph></source>
          <target state="new">For example, <ph id="ph27">`ssh -i /path/to/private/key username@clustername-ssh.azurehdinsight.net`</ph></target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Once connected to the head node, use the following command to run the word cound job</source>
          <target state="new">Once connected to the head node, use the following command to run the word cound job</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>This runs the WordCount class you implemented earlier.</source>
          <target state="new">This runs the WordCount class you implemented earlier.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source><ph id="ph28">`--hdfs`</ph><ph id="ph29" /> instructs the job to use HDFS.</source>
          <target state="new"><ph id="ph28">`--hdfs`</ph><ph id="ph29" /> instructs the job to use HDFS.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source><ph id="ph30">`--input`</ph><ph id="ph31" /> specifies the input text file, while <ph id="ph32">`--output`</ph><ph id="ph33" /> specifies the output location.</source>
          <target state="new"><ph id="ph30">`--input`</ph><ph id="ph31" /> specifies the input text file, while <ph id="ph32">`--output`</ph><ph id="ph33" /> specifies the output location.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>After the job completes, use the following to view the output.</source>
          <target state="new">After the job completes, use the following to view the output.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>This will display information similar to the following:</source>
          <target state="new">This will display information similar to the following:</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>Run the job on a Windows-based cluster</source>
          <target state="new">Run the job on a Windows-based cluster</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source><ph id="ph34">[AZURE.NOTE]</ph><ph id="ph35" /> The following steps use Windows PowerShell.</source>
          <target state="new"><ph id="ph34">[AZURE.NOTE]</ph><ph id="ph35" /> The following steps use Windows PowerShell.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>For other methods of running MapReduce jobs, see <bpt id="p28">[</bpt>Use MapReduce in Hadoop on HDInsight<ept id="p28">](hdinsight-use-mapreduce.md)</ept>.</source>
          <target state="new">For other methods of running MapReduce jobs, see <bpt id="p28">[</bpt>Use MapReduce in Hadoop on HDInsight<ept id="p28">](hdinsight-use-mapreduce.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source><bpt id="p29">[</bpt>Install and configure Azure PowerShell<ept id="p29">](../powershell-install-configure.md)</ept>.</source>
          <target state="new"><bpt id="p29">[</bpt>Install and configure Azure PowerShell<ept id="p29">](../powershell-install-configure.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>Start Azure PowerShell and Log in to your Azure account.</source>
          <target state="new">Start Azure PowerShell and Log in to your Azure account.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>After providing your credentials, the command returns information about your account.</source>
          <target state="new">After providing your credentials, the command returns information about your account.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>If you have multiple subscriptions, provide the subscription id you wish to use for deployment.</source>
          <target state="new">If you have multiple subscriptions, provide the subscription id you wish to use for deployment.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source><ph id="ph36">[AZURE.NOTE]</ph><ph id="ph37" /> You can use <ph id="ph38">`Get-AzureRMSubscription`</ph><ph id="ph39" /> to get a list of all subscriptions associated with your account, which includes the subscription Id for each one.</source>
          <target state="new"><ph id="ph36">[AZURE.NOTE]</ph><ph id="ph37" /> You can use <ph id="ph38">`Get-AzureRMSubscription`</ph><ph id="ph39" /> to get a list of all subscriptions associated with your account, which includes the subscription Id for each one.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>use the following script to upload and run the WordCount job.</source>
          <target state="new">use the following script to upload and run the WordCount job.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Replace <ph id="ph40">`CLUSTERNAME`</ph><ph id="ph41" /> with the name of your HDInsight cluster, and make sure that <ph id="ph42">`$fileToUpload`</ph><ph id="ph43" /> is the correct path to the <bpt id="p30">__</bpt>scaldingwordcount-1.0-SNAPSHOT.jar<ept id="p30">__</ept><ph id="ph44" /> file.</source>
          <target state="new">Replace <ph id="ph40">`CLUSTERNAME`</ph><ph id="ph41" /> with the name of your HDInsight cluster, and make sure that <ph id="ph42">`$fileToUpload`</ph><ph id="ph43" /> is the correct path to the <bpt id="p30">__</bpt>scaldingwordcount-1.0-SNAPSHOT.jar<ept id="p30">__</ept><ph id="ph44" /> file.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>When you run the script, you will be prompted to enter the admin username and password for your HDInsight cluster.</source>
          <target state="new">When you run the script, you will be prompted to enter the admin username and password for your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Any errors that occur while the job is running will be logged to the console.</source>
          <target state="new">Any errors that occur while the job is running will be logged to the console.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Once the job completes, the output will be downloaded to the file <bpt id="p31">__</bpt>output.txt<ept id="p31">__</ept><ph id="ph45" /> in the current directory.</source>
          <target state="new">Once the job completes, the output will be downloaded to the file <bpt id="p31">__</bpt>output.txt<ept id="p31">__</ept><ph id="ph45" /> in the current directory.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Use the following command to display the results.</source>
          <target state="new">Use the following command to display the results.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>The file should contain values similar to the following:</source>
          <target state="new">The file should contain values similar to the following:</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Now that you have learned how to use Scalding to create MapReduce jobs for HDInsight, use the following links to explore other ways to work with Azure HDInsight.</source>
          <target state="new">Now that you have learned how to use Scalding to create MapReduce jobs for HDInsight, use the following links to explore other ways to work with Azure HDInsight.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source><bpt id="p32">[</bpt>Use Hive with HDInsight<ept id="p32">](hdinsight-use-hive.md)</ept></source>
          <target state="new"><bpt id="p32">[</bpt>Use Hive with HDInsight<ept id="p32">](hdinsight-use-hive.md)</ept></target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source><bpt id="p33">[</bpt>Use Pig with HDInsight<ept id="p33">](hdinsight-use-pig.md)</ept></source>
          <target state="new"><bpt id="p33">[</bpt>Use Pig with HDInsight<ept id="p33">](hdinsight-use-pig.md)</ept></target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source><bpt id="p34">[</bpt>Use MapReduce jobs with HDInsight<ept id="p34">](hdinsight-use-mapreduce.md)</ept></source>
          <target state="new"><bpt id="p34">[</bpt>Use MapReduce jobs with HDInsight<ept id="p34">](hdinsight-use-mapreduce.md)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">c8b6e3bba523112774b71718ab9e1324307d099e</xliffext:olfilehash>
  </header>
</xliff>