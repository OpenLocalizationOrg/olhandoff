{
  "nodes": [
    {
      "content": "Data factory is a multi-tenant service that has the following default limits in place to make sure customer subscriptions are protected from each others workloads.",
      "pos": [
        0,
        163
      ]
    },
    {
      "content": "Many of the limits can be easily raised for your subscription up to the maximum limit by contacting support.",
      "pos": [
        164,
        272
      ]
    },
    {
      "content": "Resource",
      "pos": [
        277,
        285
      ]
    },
    {
      "content": "Default Limit",
      "pos": [
        292,
        305
      ]
    },
    {
      "content": "Maximum Limit",
      "pos": [
        312,
        325
      ]
    },
    {
      "content": "pipelines within a data factory",
      "pos": [
        369,
        400
      ]
    },
    {
      "content": "100",
      "pos": [
        403,
        406
      ]
    },
    {
      "content": "2500",
      "pos": [
        409,
        413
      ]
    },
    {
      "content": "datasets within a data factory",
      "pos": [
        414,
        444
      ]
    },
    {
      "content": "500",
      "pos": [
        447,
        450
      ]
    },
    {
      "content": "5000",
      "pos": [
        453,
        457
      ]
    },
    {
      "content": "concurrent slices per dataset",
      "pos": [
        458,
        487
      ]
    },
    {
      "content": "10",
      "pos": [
        490,
        492
      ]
    },
    {
      "content": "10",
      "pos": [
        495,
        497
      ]
    },
    {
      "pos": [
        498,
        548
      ],
      "content": "bytes per object for pipeline objects <ph id=\"ph1\">&lt;sup&gt;</ph>1<ph id=\"ph2\">&lt;/sup&gt;</ph>"
    },
    {
      "content": "200 KB",
      "pos": [
        551,
        557
      ]
    },
    {
      "content": "2000 KB",
      "pos": [
        560,
        567
      ]
    },
    {
      "pos": [
        568,
        635
      ],
      "content": "bytes per object for dataset and linkedservice objects <ph id=\"ph1\">&lt;sup&gt;</ph>1<ph id=\"ph2\">&lt;/sup&gt;</ph>"
    },
    {
      "content": "30 KB",
      "pos": [
        638,
        643
      ]
    },
    {
      "content": "2000 KB",
      "pos": [
        646,
        653
      ]
    },
    {
      "content": "fields per object",
      "pos": [
        654,
        671
      ]
    },
    {
      "content": "100",
      "pos": [
        674,
        677
      ]
    },
    {
      "content": "Contact support",
      "pos": [
        681,
        696
      ]
    },
    {
      "content": "bytes per field name or identifier",
      "pos": [
        782,
        816
      ]
    },
    {
      "content": "2 KB",
      "pos": [
        819,
        823
      ]
    },
    {
      "content": "Contact support",
      "pos": [
        827,
        842
      ]
    },
    {
      "content": "bytes per field",
      "pos": [
        928,
        943
      ]
    },
    {
      "content": "30 KB",
      "pos": [
        946,
        951
      ]
    },
    {
      "content": "Contact support",
      "pos": [
        955,
        970
      ]
    },
    {
      "pos": [
        1056,
        1124
      ],
      "content": "HDInsight on-demand cluster cores within a subscription <ph id=\"ph1\">&lt;sup&gt;</ph>2<ph id=\"ph2\">&lt;/sup&gt;</ph>"
    },
    {
      "content": "48",
      "pos": [
        1127,
        1129
      ]
    },
    {
      "content": "Contact support",
      "pos": [
        1133,
        1148
      ]
    },
    {
      "content": "Retry count for pipeline activity runs",
      "pos": [
        1234,
        1272
      ]
    },
    {
      "content": "1000",
      "pos": [
        1275,
        1279
      ]
    },
    {
      "content": "MaxInt (32 bit)",
      "pos": [
        1282,
        1297
      ]
    },
    {
      "content": "<ph id=\"ph1\">&lt;sup&gt;</ph>1<ph id=\"ph2\">&lt;/sup&gt;</ph> Pipeline, dataset, and linked service objects represent a logical grouping of your workload.",
      "pos": [
        1299,
        1404
      ]
    },
    {
      "content": "Limits for these objects do not relate to amount of data you can move and process with the Azure Data Factory service.",
      "pos": [
        1405,
        1523
      ]
    },
    {
      "content": "Data factory is designed to scale to handle petabytes of data.",
      "pos": [
        1524,
        1586
      ]
    },
    {
      "content": "<ph id=\"ph1\">&lt;sup&gt;</ph>2<ph id=\"ph2\">&lt;/sup&gt;</ph>On-demand HDInsight cores are allocated out of the subscription that contains the data factory.",
      "pos": [
        1588,
        1695
      ]
    },
    {
      "content": "As a result, the above limit is the Data Factory enforced core limit for on-demand HDInsight cores and is different from the core limit associated with your Azure subscription.",
      "pos": [
        1696,
        1872
      ]
    },
    {
      "content": "Resource",
      "pos": [
        1877,
        1885
      ]
    },
    {
      "content": "Default lower limit",
      "pos": [
        1892,
        1911
      ]
    },
    {
      "content": "Minimum limit",
      "pos": [
        1918,
        1931
      ]
    },
    {
      "content": "Scheduling interval",
      "pos": [
        1981,
        2000
      ]
    },
    {
      "content": "15 minutes",
      "pos": [
        2003,
        2013
      ]
    },
    {
      "content": "15 minutes",
      "pos": [
        2016,
        2026
      ]
    },
    {
      "content": "Interval between retry attempts",
      "pos": [
        2027,
        2058
      ]
    },
    {
      "content": "1 second",
      "pos": [
        2061,
        2069
      ]
    },
    {
      "content": "1 second",
      "pos": [
        2072,
        2080
      ]
    },
    {
      "content": "Retry timeout value",
      "pos": [
        2081,
        2100
      ]
    },
    {
      "content": "1 second",
      "pos": [
        2103,
        2111
      ]
    },
    {
      "content": "1 second",
      "pos": [
        2114,
        2122
      ]
    },
    {
      "content": "Web service call limits",
      "pos": [
        2129,
        2152
      ]
    },
    {
      "content": "Azure resource manager has limits for API calls.",
      "pos": [
        2154,
        2202
      ]
    },
    {
      "content": "You can make API calls at a rate within the <bpt id=\"p1\">[</bpt>Azure Resource Manager API limits<ept id=\"p1\">](../azure-subscription-service-limits/#resource-group-limits)</ept>.",
      "pos": [
        2203,
        2344
      ]
    }
  ],
  "content": "Data factory is a multi-tenant service that has the following default limits in place to make sure customer subscriptions are protected from each others workloads. Many of the limits can be easily raised for your subscription up to the maximum limit by contacting support. \n\n**Resource** | **Default Limit** | **Maximum Limit**\n-------- | ------------- | -------------\npipelines within a data factory | 100 | 2500\ndatasets within a data factory | 500 | 5000\nconcurrent slices per dataset | 10 | 10\nbytes per object for pipeline objects <sup>1</sup> | 200 KB | 2000 KB\nbytes per object for dataset and linkedservice objects <sup>1</sup> | 30 KB | 2000 KB\nfields per object | 100 | [Contact support](https://azure.microsoft.com/blog/2014/06/04/azure-limits-quotas-increase-requests/)\nbytes per field name or identifier | 2 KB | [Contact support](https://azure.microsoft.com/blog/2014/06/04/azure-limits-quotas-increase-requests/)\nbytes per field | 30 KB | [Contact support](https://azure.microsoft.com/blog/2014/06/04/azure-limits-quotas-increase-requests/)\nHDInsight on-demand cluster cores within a subscription <sup>2</sup> | 48 | [Contact support](https://azure.microsoft.com/blog/2014/06/04/azure-limits-quotas-increase-requests/)\nRetry count for pipeline activity runs | 1000 | MaxInt (32 bit)\n\n<sup>1</sup> Pipeline, dataset, and linked service objects represent a logical grouping of your workload. Limits for these objects do not relate to amount of data you can move and process with the Azure Data Factory service. Data factory is designed to scale to handle petabytes of data.\n\n<sup>2</sup>On-demand HDInsight cores are allocated out of the subscription that contains the data factory. As a result, the above limit is the Data Factory enforced core limit for on-demand HDInsight cores and is different from the core limit associated with your Azure subscription.\n\n\n**Resource** | **Default lower limit** | **Minimum limit**\n-------- | ------------------- | -------------\nScheduling interval | 15 minutes | 15 minutes\nInterval between retry attempts | 1 second | 1 second\nRetry timeout value | 1 second | 1 second\n\n\n### Web service call limits\n\nAzure resource manager has limits for API calls. You can make API calls at a rate within the [Azure Resource Manager API limits](../azure-subscription-service-limits/#resource-group-limits). \n\n\n"
}