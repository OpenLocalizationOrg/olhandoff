{
  "nodes": [
    {
      "content": "Automatically scale compute nodes in an Azure Batch pool | Microsoft Azure",
      "pos": [
        27,
        101
      ]
    },
    {
      "content": "Enable automatic scaling on a cloud pool to dynamically adjust the number of compute nodes in the pool.",
      "pos": [
        120,
        223
      ]
    },
    {
      "content": "Automatically scale compute nodes in an Azure Batch pool",
      "pos": [
        519,
        575
      ]
    },
    {
      "content": "By using automatic scaling in Azure Batch, you can dynamically add or remove compute nodes in a Batch pool during job execution to automatically adjust the processing power that is used by your application.",
      "pos": [
        577,
        783
      ]
    },
    {
      "content": "This automatic adjustment can save you both time and money.",
      "pos": [
        784,
        843
      ]
    },
    {
      "content": "You can enable automatic scaling on a pool of compute nodes by associating an <bpt id=\"p1\">*</bpt>autoscale formula<ept id=\"p1\">*</ept> with the pool, such as with the <bpt id=\"p2\">[</bpt>PoolOperations.EnableAutoScale<ph id=\"ph1\">][</ph>net_enableautoscale<ept id=\"p2\">]</ept> method in the <bpt id=\"p3\">[</bpt>Batch .NET<ept id=\"p3\">](batch-dotnet-get-started.md)</ept> library.",
      "pos": [
        845,
        1093
      ]
    },
    {
      "content": "The Batch service then uses this formula to determine the number of compute nodes that are needed to execute your workload.",
      "pos": [
        1094,
        1217
      ]
    },
    {
      "content": "The number of compute nodes in the pool, which responds to service metrics data samples that are collected periodically, is adjusted at a configurable interval based on the associated formula.",
      "pos": [
        1218,
        1410
      ]
    },
    {
      "content": "You can enable automatic scaling when a pool is created, or on an existing pool.",
      "pos": [
        1412,
        1492
      ]
    },
    {
      "content": "You can also change an existing formula on a pool that is \"autoscale\" enabled.",
      "pos": [
        1493,
        1571
      ]
    },
    {
      "content": "Batch provides the ability to evaluate your formulas before assigning them to pools, as well as for monitoring the status of automatic scaling runs.",
      "pos": [
        1572,
        1720
      ]
    },
    {
      "content": "Automatic scaling formulas",
      "pos": [
        1725,
        1751
      ]
    },
    {
      "content": "An automatic scaling formula is a string value that contains one or more statements that are assigned to a pool's <bpt id=\"p1\">[</bpt>autoScaleFormula<ph id=\"ph1\">][</ph>rest_autoscaleformula<ept id=\"p1\">]</ept> element (Batch REST API), or the <bpt id=\"p2\">[</bpt>CloudPool.AutoScaleFormula<ph id=\"ph2\">][</ph>net_cloudpool_autoscaleformula<ept id=\"p2\">]</ept> property (Batch .NET API).",
      "pos": [
        1753,
        2029
      ]
    },
    {
      "content": "You define these formulas.",
      "pos": [
        2030,
        2056
      ]
    },
    {
      "content": "When they are assigned to a pool, they determine the number of available compute nodes in a pool for the next interval of processing (see more on intervals later).",
      "pos": [
        2057,
        2220
      ]
    },
    {
      "content": "The formula string cannot exceed 8 KB in size, can include up to 100 statements that are separated by semicolons, and can include line breaks and comments.",
      "pos": [
        2221,
        2376
      ]
    },
    {
      "content": "You can think of automatic scaling formulas as using a Batch autoscale \"language.\"",
      "pos": [
        2378,
        2460
      ]
    },
    {
      "content": "Formula statements are free-formed expressions that can include system-defined and user-defined variables, as well as constants.",
      "pos": [
        2461,
        2589
      ]
    },
    {
      "content": "They can perform various operations on these values by using built-in types, operators, and functions.",
      "pos": [
        2590,
        2692
      ]
    },
    {
      "content": "For example, a statement might take the following form:",
      "pos": [
        2693,
        2748
      ]
    },
    {
      "content": "Formulas generally contain multiple statements that perform operations on values that are obtained in previous statements:",
      "pos": [
        2821,
        2943
      ]
    },
    {
      "content": "By using the statements in your formula, your goal is to arrive at a number of compute nodes that the pool should be scaled to--the <bpt id=\"p1\">**</bpt>target<ept id=\"p1\">**</ept> number of <bpt id=\"p2\">**</bpt>dedicated nodes<ept id=\"p2\">**</ept>.",
      "pos": [
        3052,
        3225
      ]
    },
    {
      "content": "This number may be higher, lower, or the same as the current number of nodes in the pool.",
      "pos": [
        3226,
        3315
      ]
    },
    {
      "content": "Batch evaluates a pool's autoscale formula at a specific interval (<bpt id=\"p1\">[</bpt>automatic scaling intervals<ept id=\"p1\">](#interval)</ept> are discussed below).",
      "pos": [
        3316,
        3445
      ]
    },
    {
      "content": "Then it will adjust the target number of nodes in the pool to the number that your autoscale formula specifies at the time of evaluation.",
      "pos": [
        3446,
        3583
      ]
    },
    {
      "content": "As a quick example, this two-line autoscale formula specifies that the number of nodes should be adjusted according to the number of active tasks, up to a maximum of 10 compute nodes:",
      "pos": [
        3585,
        3768
      ]
    },
    {
      "content": "The next few sections of this article discuss the various entities that will make up your autoscale formulas, including variables, operators, operations, and functions.",
      "pos": [
        3913,
        4081
      ]
    },
    {
      "content": "You'll find out how to obtain various compute resource and task metrics within Batch.",
      "pos": [
        4082,
        4167
      ]
    },
    {
      "content": "You can use these metrics to intelligently adjust your pool's node count based on resource usage and task status.",
      "pos": [
        4168,
        4281
      ]
    },
    {
      "content": "You'll then learn how to construct a formula and enable automatic scaling on a pool by using both the Batch REST and .NET APIs.",
      "pos": [
        4282,
        4409
      ]
    },
    {
      "content": "We'll finish up with a few example formulas.",
      "pos": [
        4410,
        4454
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Each Azure Batch account is limited to a maximum number of compute nodes that can be used for processing.",
      "pos": [
        4458,
        4576
      ]
    },
    {
      "content": "The Batch service will create nodes only up to that limit.",
      "pos": [
        4577,
        4635
      ]
    },
    {
      "content": "Therefore, it may not reach the target number that is specified by a formula.",
      "pos": [
        4636,
        4713
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Quotas and limits for the Azure Batch service<ept id=\"p1\">](batch-quota-limit.md)</ept> for information on viewing and increasing your account quotas.",
      "pos": [
        4714,
        4850
      ]
    },
    {
      "pos": [
        4855,
        4888
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"variables\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Variables"
    },
    {
      "content": "You can use both system-defined and user-defined variables in autoscale formulas.",
      "pos": [
        4890,
        4971
      ]
    },
    {
      "content": "In the two-line example formula above, <ph id=\"ph1\">`$TargetDedicated`</ph> is a system-defined variable, while <ph id=\"ph2\">`$averageActiveTaskCount`</ph> is user-defined.",
      "pos": [
        4972,
        5108
      ]
    },
    {
      "content": "The tables below show both read-write and read-only variables that are defined by the Batch service.",
      "pos": [
        5109,
        5209
      ]
    },
    {
      "pos": [
        5211,
        5324
      ],
      "content": "<bpt id=\"p1\">*</bpt>Get<ept id=\"p1\">*</ept> and <bpt id=\"p2\">*</bpt>set<ept id=\"p2\">*</ept> the values of these <bpt id=\"p3\">**</bpt>system-defined variables<ept id=\"p3\">**</ept> to manage the number of compute nodes in a pool:"
    },
    {
      "content": "Variables (read-write)",
      "pos": [
        5349,
        5371
      ]
    },
    {
      "content": "Description",
      "pos": [
        5385,
        5396
      ]
    },
    {
      "content": "$TargetDedicated",
      "pos": [
        5425,
        5441
      ]
    },
    {
      "content": "The <ph id=\"ph1\">&lt;b&gt;</ph>target<ph id=\"ph2\">&lt;/b&gt;</ph> number of <ph id=\"ph3\">&lt;b&gt;</ph>dedicated compute nodes<ph id=\"ph4\">&lt;/b&gt;</ph> for the pool.",
      "pos": [
        5455,
        5527
      ]
    },
    {
      "content": "This is the number of compute nodes that the pool should be scaled to.",
      "pos": [
        5528,
        5598
      ]
    },
    {
      "content": "It is a \"target\" number since it's possible for a pool not to reach the target number of nodes.",
      "pos": [
        5599,
        5694
      ]
    },
    {
      "content": "This can occur if the target number of nodes is modified again by a subsequent autoscale evaluation before the pool has reached the initial target.",
      "pos": [
        5695,
        5842
      ]
    },
    {
      "content": "It can also happen if a Batch account node or core quota is reached before the target number of nodes is reached.",
      "pos": [
        5843,
        5956
      ]
    },
    {
      "content": "$NodeDeallocationOption",
      "pos": [
        5985,
        6008
      ]
    },
    {
      "content": "The action that occurs when compute nodes are removed from a pool.",
      "pos": [
        6022,
        6088
      ]
    },
    {
      "content": "Possible values are:",
      "pos": [
        6089,
        6109
      ]
    },
    {
      "content": "requeue<ph id=\"ph1\">&lt;/b&gt;</ph>--Terminates tasks immediately and puts them back on the job queue so that they are rescheduled.",
      "pos": [
        6151,
        6258
      ]
    },
    {
      "content": "terminate<ph id=\"ph1\">&lt;/b&gt;</ph>--Terminates tasks immediately and removes them from the job queue.",
      "pos": [
        6286,
        6366
      ]
    },
    {
      "content": "taskcompletion<ph id=\"ph1\">&lt;/b&gt;</ph>--Waits for currently running tasks to finish and then removes the node from the pool.",
      "pos": [
        6394,
        6498
      ]
    },
    {
      "content": "retaineddata<ph id=\"ph1\">&lt;/b&gt;</ph>--Waits for all the local task-retained data on the node to be cleaned up before removing the node from the pool.",
      "pos": [
        6526,
        6655
      ]
    },
    {
      "pos": [
        6701,
        6824
      ],
      "content": "<bpt id=\"p1\">*</bpt>Get<ept id=\"p1\">*</ept> the value of these <bpt id=\"p2\">**</bpt>system-defined variables<ept id=\"p2\">**</ept> to make adjustments that are based on metrics from the Batch service:"
    },
    {
      "content": "Variables (read-only)",
      "pos": [
        6849,
        6870
      ]
    },
    {
      "content": "Description",
      "pos": [
        6884,
        6895
      ]
    },
    {
      "content": "$CPUPercent",
      "pos": [
        6924,
        6935
      ]
    },
    {
      "content": "The average percentage of CPU usage.",
      "pos": [
        6949,
        6985
      ]
    },
    {
      "content": "$WallClockSeconds",
      "pos": [
        7014,
        7031
      ]
    },
    {
      "content": "The number of seconds consumed.",
      "pos": [
        7045,
        7076
      ]
    },
    {
      "content": "$MemoryBytes",
      "pos": [
        7105,
        7117
      ]
    },
    {
      "content": "The average number of megabytes used.",
      "pos": [
        7131,
        7168
      ]
    },
    {
      "content": "$DiskBytes",
      "pos": [
        7189,
        7199
      ]
    },
    {
      "content": "The average number of gigabytes used on the local disks.",
      "pos": [
        7213,
        7269
      ]
    },
    {
      "content": "$DiskReadBytes",
      "pos": [
        7298,
        7312
      ]
    },
    {
      "content": "The number of bytes read.",
      "pos": [
        7326,
        7351
      ]
    },
    {
      "content": "$DiskWriteBytes",
      "pos": [
        7380,
        7395
      ]
    },
    {
      "content": "The number of bytes written.",
      "pos": [
        7409,
        7437
      ]
    },
    {
      "content": "$DiskReadOps",
      "pos": [
        7466,
        7478
      ]
    },
    {
      "content": "The count of read disk operations performed.",
      "pos": [
        7492,
        7536
      ]
    },
    {
      "content": "$DiskWriteOps",
      "pos": [
        7565,
        7578
      ]
    },
    {
      "content": "The count of write disk operations performed.",
      "pos": [
        7592,
        7637
      ]
    },
    {
      "content": "$NetworkInBytes",
      "pos": [
        7666,
        7681
      ]
    },
    {
      "content": "The number of inbound bytes.",
      "pos": [
        7695,
        7723
      ]
    },
    {
      "content": "$NetworkOutBytes",
      "pos": [
        7752,
        7768
      ]
    },
    {
      "content": "The number of outbound bytes.",
      "pos": [
        7782,
        7811
      ]
    },
    {
      "content": "$SampleNodeCount",
      "pos": [
        7840,
        7856
      ]
    },
    {
      "content": "The count of compute nodes.",
      "pos": [
        7870,
        7897
      ]
    },
    {
      "content": "$ActiveTasks",
      "pos": [
        7926,
        7938
      ]
    },
    {
      "content": "The number of tasks in an active state.",
      "pos": [
        7952,
        7991
      ]
    },
    {
      "content": "$RunningTasks",
      "pos": [
        8020,
        8033
      ]
    },
    {
      "content": "The number of tasks in a running state.",
      "pos": [
        8047,
        8086
      ]
    },
    {
      "content": "$SucceededTasks",
      "pos": [
        8115,
        8130
      ]
    },
    {
      "content": "The number of tasks that finished successfully.",
      "pos": [
        8144,
        8191
      ]
    },
    {
      "content": "$FailedTasks",
      "pos": [
        8220,
        8232
      ]
    },
    {
      "content": "The number of tasks that failed.",
      "pos": [
        8246,
        8278
      ]
    },
    {
      "content": "$CurrentDedicated",
      "pos": [
        8307,
        8324
      ]
    },
    {
      "content": "The current number of dedicated compute nodes.",
      "pos": [
        8338,
        8384
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.TIP]</ph> The read-only, system-defined variables that are shown above are <bpt id=\"p1\">*</bpt>objects<ept id=\"p1\">*</ept> that provide various methods to access data associated with each.",
      "pos": [
        8410,
        8562
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Obtain sample data<ept id=\"p1\">](#getsampledata)</ept> below for more information.",
      "pos": [
        8563,
        8631
      ]
    },
    {
      "content": "Types",
      "pos": [
        8636,
        8641
      ]
    },
    {
      "pos": [
        8643,
        8686
      ],
      "content": "These <bpt id=\"p1\">**</bpt>types<ept id=\"p1\">**</ept> are supported in a formula."
    },
    {
      "content": "double",
      "pos": [
        8690,
        8696
      ]
    },
    {
      "content": "doubleVec",
      "pos": [
        8699,
        8708
      ]
    },
    {
      "content": "doubleVecList",
      "pos": [
        8711,
        8724
      ]
    },
    {
      "content": "string",
      "pos": [
        8727,
        8733
      ]
    },
    {
      "content": "timestamp--timestamp is a compound structure that contains the following members:",
      "pos": [
        8736,
        8817
      ]
    },
    {
      "content": "year",
      "pos": [
        8824,
        8828
      ]
    },
    {
      "content": "month (1-12)",
      "pos": [
        8835,
        8847
      ]
    },
    {
      "content": "day (1-31)",
      "pos": [
        8854,
        8864
      ]
    },
    {
      "content": "weekday (in the format of number, e.g. 1 for Monday)",
      "pos": [
        8871,
        8923
      ]
    },
    {
      "content": "hour (in 24-hour number format, e.g. 13 means 1 PM)",
      "pos": [
        8930,
        8981
      ]
    },
    {
      "content": "minute (00-59)",
      "pos": [
        8988,
        9002
      ]
    },
    {
      "content": "second (00-59)",
      "pos": [
        9009,
        9023
      ]
    },
    {
      "content": "timeinterval",
      "pos": [
        9026,
        9038
      ]
    },
    {
      "content": "TimeInterval_Zero",
      "pos": [
        9045,
        9062
      ]
    },
    {
      "content": "TimeInterval_100ns",
      "pos": [
        9069,
        9087
      ]
    },
    {
      "content": "TimeInterval_Microsecond",
      "pos": [
        9094,
        9118
      ]
    },
    {
      "content": "TimeInterval_Millisecond",
      "pos": [
        9125,
        9149
      ]
    },
    {
      "content": "TimeInterval_Second",
      "pos": [
        9156,
        9175
      ]
    },
    {
      "content": "TimeInterval_Minute",
      "pos": [
        9182,
        9201
      ]
    },
    {
      "content": "TimeInterval_Hour",
      "pos": [
        9208,
        9225
      ]
    },
    {
      "content": "TimeInterval_Day",
      "pos": [
        9232,
        9248
      ]
    },
    {
      "content": "TimeInterval_Week",
      "pos": [
        9255,
        9272
      ]
    },
    {
      "content": "TimeInterval_Year",
      "pos": [
        9279,
        9296
      ]
    },
    {
      "content": "Operations",
      "pos": [
        9301,
        9311
      ]
    },
    {
      "pos": [
        9313,
        9381
      ],
      "content": "These <bpt id=\"p1\">**</bpt>operations<ept id=\"p1\">**</ept> are allowed on the types that are listed above."
    },
    {
      "content": "Operation",
      "pos": [
        9406,
        9415
      ]
    },
    {
      "content": "Allowed operators",
      "pos": [
        9429,
        9446
      ]
    },
    {
      "content": "double &amp;lt;operator&amp;gt; double =&amp;gt; double",
      "pos": [
        9475,
        9518
      ]
    },
    {
      "content": "+, -, *, /",
      "pos": [
        9532,
        9542
      ]
    },
    {
      "content": "double &amp;lt;operator&amp;gt; timeinterval =&amp;gt; timeinterval",
      "pos": [
        9571,
        9626
      ]
    },
    {
      "content": "doubleVec &amp;lt;operator&amp;gt; double =&amp;gt; doubleVec",
      "pos": [
        9670,
        9719
      ]
    },
    {
      "content": "+, -, *, /",
      "pos": [
        9733,
        9743
      ]
    },
    {
      "content": "doubleVec &amp;lt;operator&amp;gt; doubleVec =&amp;gt; doubleVec",
      "pos": [
        9772,
        9824
      ]
    },
    {
      "content": "+, -, *, /",
      "pos": [
        9838,
        9848
      ]
    },
    {
      "content": "timeinterval &amp;lt;operator&amp;gt; double =&amp;gt; timeinterval",
      "pos": [
        9877,
        9932
      ]
    },
    {
      "content": "*, /",
      "pos": [
        9946,
        9950
      ]
    },
    {
      "content": "timeinterval &amp;lt;operator&amp;gt; timeinterval =&amp;gt; timeinterval",
      "pos": [
        9979,
        10040
      ]
    },
    {
      "content": "+, -",
      "pos": [
        10054,
        10058
      ]
    },
    {
      "content": "timeinterval &amp;lt;operator&amp;gt; timestamp =&amp;gt; timestamp",
      "pos": [
        10087,
        10142
      ]
    },
    {
      "content": "timestamp &amp;lt;operator&amp;gt; timeinterval =&amp;gt; timestamp",
      "pos": [
        10186,
        10241
      ]
    },
    {
      "content": "timestamp &amp;lt;operator&amp;gt; timestamp =&amp;gt; timeinterval",
      "pos": [
        10285,
        10340
      ]
    },
    {
      "content": "&amp;lt;operator&amp;gt;double =&amp;gt; double",
      "pos": [
        10384,
        10419
      ]
    },
    {
      "content": "-, !",
      "pos": [
        10433,
        10437
      ]
    },
    {
      "content": "&amp;lt;operator&amp;gt;timeinterval =&amp;gt; timeinterval",
      "pos": [
        10466,
        10513
      ]
    },
    {
      "content": "double &amp;lt;operator&amp;gt; double =&amp;gt; double",
      "pos": [
        10557,
        10600
      ]
    },
    {
      "content": "&amp;lt;, &amp;lt;=, ==, &amp;gt;=, &amp;gt;, !=",
      "pos": [
        10614,
        10646
      ]
    },
    {
      "content": "string &amp;lt;operator&amp;gt; string =&amp;gt; double",
      "pos": [
        10675,
        10718
      ]
    },
    {
      "content": "&amp;lt;, &amp;lt;=, ==, &amp;gt;=, &amp;gt;, !=",
      "pos": [
        10732,
        10764
      ]
    },
    {
      "content": "timestamp &amp;lt;operator&amp;gt; timestamp =&amp;gt; double",
      "pos": [
        10793,
        10842
      ]
    },
    {
      "content": "&amp;lt;, &amp;lt;=, ==, &amp;gt;=, &amp;gt, !=",
      "pos": [
        10856,
        10887
      ]
    },
    {
      "content": "timeinterval &amp;lt;operator&amp;gt; timeinterval =&amp;gt; double",
      "pos": [
        10916,
        10971
      ]
    },
    {
      "content": "&amp;lt;, &amp;lt;=, ==, &amp;gt;=, &amp;gt;, !=",
      "pos": [
        10985,
        11017
      ]
    },
    {
      "content": "double &amp;lt;operator&amp;gt; double =&amp;gt; double",
      "pos": [
        11046,
        11089
      ]
    },
    {
      "content": "&amp;&amp;, ||",
      "pos": [
        11103,
        11109
      ]
    },
    {
      "content": "test double only (nonzero is true, zero is false)",
      "pos": [
        11138,
        11187
      ]
    },
    {
      "content": "?",
      "pos": [
        11201,
        11202
      ]
    },
    {
      "content": ":",
      "pos": [
        11203,
        11204
      ]
    },
    {
      "content": "Functions",
      "pos": [
        11231,
        11240
      ]
    },
    {
      "pos": [
        11242,
        11343
      ],
      "content": "These predefined <bpt id=\"p1\">**</bpt>functions<ept id=\"p1\">**</ept> are available for you to use in defining an automatic scaling formula."
    },
    {
      "content": "Function",
      "pos": [
        11368,
        11376
      ]
    },
    {
      "content": "Description",
      "pos": [
        11390,
        11401
      ]
    },
    {
      "content": "double <ph id=\"ph1\">&lt;b&gt;</ph>avg<ph id=\"ph2\">&lt;/b&gt;</ph>(doubleVecList)",
      "pos": [
        11430,
        11462
      ]
    },
    {
      "content": "Returns the average value for all values in the doubleVecList.",
      "pos": [
        11476,
        11538
      ]
    },
    {
      "content": "double <ph id=\"ph1\">&lt;b&gt;</ph>len<ph id=\"ph2\">&lt;/b&gt;</ph>(doubleVecList)",
      "pos": [
        11567,
        11599
      ]
    },
    {
      "content": "Returns the length of the vector that is created from the doubleVecList.",
      "pos": [
        11613,
        11685
      ]
    },
    {
      "content": "double <ph id=\"ph1\">&lt;b&gt;</ph>lg<ph id=\"ph2\">&lt;/b&gt;</ph>(double)",
      "pos": [
        11706,
        11730
      ]
    },
    {
      "content": "Returns the log base 2 of the double.",
      "pos": [
        11744,
        11781
      ]
    },
    {
      "content": "doubleVec <ph id=\"ph1\">&lt;b&gt;</ph>lg<ph id=\"ph2\">&lt;/b&gt;</ph>(doubleVecList)",
      "pos": [
        11810,
        11844
      ]
    },
    {
      "content": "Returns the componentwise log base 2 of the doubleVecList.",
      "pos": [
        11858,
        11916
      ]
    },
    {
      "content": "A vec(double) must explicitly be passed for the single double parameter.",
      "pos": [
        11917,
        11989
      ]
    },
    {
      "content": "Otherwise, the double lg(double) version is assumed.",
      "pos": [
        11990,
        12042
      ]
    },
    {
      "content": "double <ph id=\"ph1\">&lt;b&gt;</ph>ln<ph id=\"ph2\">&lt;/b&gt;</ph>(double)",
      "pos": [
        12071,
        12095
      ]
    },
    {
      "content": "Returns the natural log of the double.",
      "pos": [
        12109,
        12147
      ]
    },
    {
      "content": "doubleVec <ph id=\"ph1\">&lt;b&gt;</ph>ln<ph id=\"ph2\">&lt;/b&gt;</ph>(doubleVecList)",
      "pos": [
        12176,
        12210
      ]
    },
    {
      "content": "Returns the componentwise log base 2 of the doubleVecList.",
      "pos": [
        12224,
        12282
      ]
    },
    {
      "content": "A vec(double) must explicitly be passed for the single double parameter.",
      "pos": [
        12284,
        12356
      ]
    },
    {
      "content": "Otherwise, the double lg(double) version is assumed.",
      "pos": [
        12357,
        12409
      ]
    },
    {
      "content": "double <ph id=\"ph1\">&lt;b&gt;</ph>log<ph id=\"ph2\">&lt;/b&gt;</ph>(double)",
      "pos": [
        12438,
        12463
      ]
    },
    {
      "content": "Returns the log base 10 of the double.",
      "pos": [
        12477,
        12515
      ]
    },
    {
      "content": "doubleVec <ph id=\"ph1\">&lt;b&gt;</ph>log<ph id=\"ph2\">&lt;/b&gt;</ph>(doubleVecList)",
      "pos": [
        12544,
        12579
      ]
    },
    {
      "content": "Returns the componentwise log base 10 of the doubleVecList.",
      "pos": [
        12593,
        12652
      ]
    },
    {
      "content": "A vec(double) must explicitly be passed for the single double parameter.",
      "pos": [
        12653,
        12725
      ]
    },
    {
      "content": "Otherwise, the double log(double) version is assumed.",
      "pos": [
        12726,
        12779
      ]
    },
    {
      "content": "double <ph id=\"ph1\">&lt;b&gt;</ph>max<ph id=\"ph2\">&lt;/b&gt;</ph>(doubleVecList)",
      "pos": [
        12808,
        12840
      ]
    },
    {
      "content": "Returns the maximum value in the doubleVecList.",
      "pos": [
        12854,
        12901
      ]
    },
    {
      "content": "double <ph id=\"ph1\">&lt;b&gt;</ph>min<ph id=\"ph2\">&lt;/b&gt;</ph>(doubleVecList)",
      "pos": [
        12930,
        12962
      ]
    },
    {
      "content": "Returns the minimum value in the doubleVecList.",
      "pos": [
        12976,
        13023
      ]
    },
    {
      "content": "double <ph id=\"ph1\">&lt;b&gt;</ph>norm<ph id=\"ph2\">&lt;/b&gt;</ph>(doubleVecList)",
      "pos": [
        13052,
        13085
      ]
    },
    {
      "content": "Returns the two-norm of the vector that is created from the doubleVecList.",
      "pos": [
        13099,
        13173
      ]
    },
    {
      "content": "double <ph id=\"ph1\">&lt;b&gt;</ph>percentile<ph id=\"ph2\">&lt;/b&gt;</ph>(doubleVec v, double p)",
      "pos": [
        13197,
        13244
      ]
    },
    {
      "content": "Returns the percentile element of the vector v.",
      "pos": [
        13258,
        13305
      ]
    },
    {
      "content": "double <ph id=\"ph1\">&lt;b&gt;</ph>rand<ph id=\"ph2\">&lt;/b&gt;</ph>()",
      "pos": [
        13334,
        13354
      ]
    },
    {
      "content": "Returns a random value between 0.0 and 1.0.",
      "pos": [
        13368,
        13411
      ]
    },
    {
      "content": "double <ph id=\"ph1\">&lt;b&gt;</ph>range<ph id=\"ph2\">&lt;/b&gt;</ph>(doubleVecList)",
      "pos": [
        13440,
        13474
      ]
    },
    {
      "content": "Returns the difference between the min and max values in the doubleVecList.",
      "pos": [
        13488,
        13563
      ]
    },
    {
      "content": "double <ph id=\"ph1\">&lt;b&gt;</ph>std<ph id=\"ph2\">&lt;/b&gt;</ph>(doubleVecList)",
      "pos": [
        13592,
        13624
      ]
    },
    {
      "content": "Returns the sample standard deviation of the values in the doubleVecList.",
      "pos": [
        13638,
        13711
      ]
    },
    {
      "content": "stop<ph id=\"ph1\">&lt;/b&gt;</ph>()",
      "pos": [
        13743,
        13753
      ]
    },
    {
      "content": "Stops evaluation of the autoscaling expression.",
      "pos": [
        13767,
        13814
      ]
    },
    {
      "content": "double <ph id=\"ph1\">&lt;b&gt;</ph>sum<ph id=\"ph2\">&lt;/b&gt;</ph>(doubleVecList)",
      "pos": [
        13843,
        13875
      ]
    },
    {
      "content": "Returns the sum of all the components of the doubleVecList.",
      "pos": [
        13889,
        13948
      ]
    },
    {
      "content": "timestamp <ph id=\"ph1\">&lt;b&gt;</ph>time<ph id=\"ph2\">&lt;/b&gt;</ph>(string dateTime=\"\")",
      "pos": [
        13977,
        14018
      ]
    },
    {
      "content": "Returns the time stamp of the current time if no parameters are passed, or the time stamp of the dateTime string if it is passed.",
      "pos": [
        14032,
        14161
      ]
    },
    {
      "content": "Supported dateTime formats are W3C-DTF and RFC 1123.",
      "pos": [
        14162,
        14214
      ]
    },
    {
      "content": "double <ph id=\"ph1\">&lt;b&gt;</ph>val<ph id=\"ph2\">&lt;/b&gt;</ph>(doubleVec v, double i)",
      "pos": [
        14243,
        14283
      ]
    },
    {
      "content": "Returns the value of the element that is at location i in vector v, with a starting index of zero.",
      "pos": [
        14297,
        14395
      ]
    },
    {
      "content": "Some of the functions that are described in the table above can accept a list as an argument.",
      "pos": [
        14419,
        14512
      ]
    },
    {
      "content": "The comma-separated list is any combination of <bpt id=\"p1\">*</bpt>double<ept id=\"p1\">*</ept> and <bpt id=\"p2\">*</bpt>doubleVec<ept id=\"p2\">*</ept>.",
      "pos": [
        14513,
        14585
      ]
    },
    {
      "content": "For example:",
      "pos": [
        14586,
        14598
      ]
    },
    {
      "content": "The <bpt id=\"p1\">*</bpt>doubleVecList<ept id=\"p1\">*</ept> value is converted to a single <bpt id=\"p2\">*</bpt>doubleVec<ept id=\"p2\">*</ept> prior to evaluation.",
      "pos": [
        14673,
        14756
      ]
    },
    {
      "content": "For example, if <ph id=\"ph1\">`v = [1,2,3]`</ph>, then calling <ph id=\"ph2\">`avg(v)`</ph> is equivalent to calling <ph id=\"ph3\">`avg(1,2,3)`</ph>.",
      "pos": [
        14757,
        14848
      ]
    },
    {
      "content": "Calling <ph id=\"ph1\">`avg(v, 7)`</ph> is equivalent to calling <ph id=\"ph2\">`avg(1,2,3,7)`</ph>.",
      "pos": [
        14849,
        14909
      ]
    },
    {
      "pos": [
        14914,
        14960
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"getsampledata\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Obtain sample data"
    },
    {
      "content": "Autoscale formulas act on metrics data (samples) that is provided by the Batch service.",
      "pos": [
        14962,
        15049
      ]
    },
    {
      "content": "A formula grows or shrinks pool size based on the values that it obtains from the service.",
      "pos": [
        15050,
        15140
      ]
    },
    {
      "content": "The system-defined variables that are described above are objects that provide various methods to access data that is associated with that object.",
      "pos": [
        15141,
        15287
      ]
    },
    {
      "content": "For example, the following expression shows a request to get the last five minutes of CPU usage:",
      "pos": [
        15288,
        15384
      ]
    },
    {
      "content": "Method",
      "pos": [
        15459,
        15465
      ]
    },
    {
      "content": "Description",
      "pos": [
        15479,
        15490
      ]
    },
    {
      "content": "GetSample()",
      "pos": [
        15519,
        15530
      ]
    },
    {
      "content": "The <ph id=\"ph1\">&lt;b&gt;</ph>GetSample()<ph id=\"ph2\">&lt;/b&gt;</ph> method returns a vector of data samples.",
      "pos": [
        15547,
        15610
      ]
    },
    {
      "content": "A sample is 30 seconds worth of metrics data.",
      "pos": [
        15618,
        15663
      ]
    },
    {
      "content": "In other words, samples are obtained every 30 seconds.",
      "pos": [
        15664,
        15718
      ]
    },
    {
      "content": "But as noted below, there is a delay between when a sample is collected and when it is available to a formula.",
      "pos": [
        15719,
        15829
      ]
    },
    {
      "content": "As such, not all samples for a given time period may be available for evaluation by a formula.",
      "pos": [
        15830,
        15924
      ]
    },
    {
      "content": "doubleVec GetSample(double count)<ph id=\"ph1\">&lt;/b&gt;</ph>--Specifies the number of samples to obtain from the most recent samples that were collected.",
      "pos": [
        15958,
        16088
      ]
    },
    {
      "content": "GetSample(1) returns the last available sample.",
      "pos": [
        16114,
        16161
      ]
    },
    {
      "content": "For metrics like $CPUPercent, however, this should not be used because it is impossible to know <ph id=\"ph1\">&lt;em&gt;</ph>when<ph id=\"ph2\">&lt;/em&gt;</ph> the sample was collected.",
      "pos": [
        16162,
        16297
      ]
    },
    {
      "content": "It might be recent, or, because of system issues, it might be much older.",
      "pos": [
        16298,
        16371
      ]
    },
    {
      "content": "It is better in such cases to use a time interval as shown below.",
      "pos": [
        16372,
        16437
      ]
    },
    {
      "content": "doubleVec GetSample((timestamp | timeinterval) startTime [, double samplePercent])<ph id=\"ph1\">&lt;/b&gt;</ph>--Specifies a time frame for gathering sample data.",
      "pos": [
        16467,
        16604
      ]
    },
    {
      "content": "Optionally, it also specifies the percentage of samples that must be available in the requested time frame.",
      "pos": [
        16605,
        16712
      ]
    },
    {
      "content": "$CPUPercent.GetSample(TimeInterval_Minute * 10)<ph id=\"ph1\">&lt;/em&gt;</ph> would return 20 samples if all samples for the last ten minutes are present in the CPUPercent history.",
      "pos": [
        16734,
        16889
      ]
    },
    {
      "content": "If the last minute of history was not available, however, only 18 samples would be returned.",
      "pos": [
        16890,
        16982
      ]
    },
    {
      "content": "In this case:",
      "pos": [
        16983,
        16996
      ]
    },
    {
      "content": "<ph id=\"ph1\">\n          &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;em&gt;</ph>$CPUPercent.GetSample(TimeInterval_Minute * 10, 95)<ph id=\"ph2\">&lt;/em&gt;</ph> would fail because only 90 percent of the samples are available.",
      "pos": [
        17001,
        17161
      ]
    },
    {
      "content": "<ph id=\"ph1\">\n          &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;em&gt;</ph>$CPUPercent.GetSample(TimeInterval_Minute * 10, 80)<ph id=\"ph2\">&lt;/em&gt;</ph> would succeed.",
      "pos": [
        17166,
        17276
      ]
    },
    {
      "content": "doubleVec GetSample((timestamp | timeinterval) startTime, (timestamp | timeinterval) endTime [, double samplePercent])<ph id=\"ph1\">&lt;/b&gt;</ph>--Specifies a time frame for gathering data, with both a start time and an end time.",
      "pos": [
        17306,
        17512
      ]
    },
    {
      "content": "As mentioned above, there is a delay between when a sample is collected and when it is available to a formula.",
      "pos": [
        17540,
        17650
      ]
    },
    {
      "content": "This must be considered when you use the <ph id=\"ph1\">&lt;em&gt;</ph>GetSample<ph id=\"ph2\">&lt;/em&gt;</ph> method.",
      "pos": [
        17651,
        17718
      ]
    },
    {
      "content": "See <ph id=\"ph1\">&lt;em&gt;</ph>GetSamplePercent<ph id=\"ph2\">&lt;/em&gt;</ph> below.",
      "pos": [
        17719,
        17755
      ]
    },
    {
      "content": "GetSamplePeriod()",
      "pos": [
        17784,
        17801
      ]
    },
    {
      "content": "Returns the period of samples that were taken in a historical sample data set.",
      "pos": [
        17815,
        17893
      ]
    },
    {
      "content": "Count()",
      "pos": [
        17928,
        17935
      ]
    },
    {
      "content": "Returns the total number of samples in the metric history.",
      "pos": [
        17953,
        18011
      ]
    },
    {
      "content": "HistoryBeginTime()",
      "pos": [
        18042,
        18060
      ]
    },
    {
      "content": "Returns the time stamp of the oldest available data sample for the metric.",
      "pos": [
        18074,
        18148
      ]
    },
    {
      "content": "GetSamplePercent()",
      "pos": [
        18177,
        18195
      ]
    },
    {
      "content": "Returns the percentage of samples that are available for a given time interval.",
      "pos": [
        18212,
        18291
      ]
    },
    {
      "content": "For example:",
      "pos": [
        18292,
        18304
      ]
    },
    {
      "content": "doubleVec GetSamplePercent( (timestamp | timeinterval) startTime [, (timestamp | timeinterval) endTime] )<ph id=\"ph1\">&lt;/b&gt;</ph><ph id=\"ph2\">\n    </ph>",
      "pos": [
        18319,
        18433
      ]
    },
    {
      "content": "Because the GetSample method fails if the percentage of samples returned is less than the samplePercent specified, you can use the GetSamplePercent method to check first.",
      "pos": [
        18436,
        18606
      ]
    },
    {
      "content": "Then you can perform an alternate action if insufficient samples are present, without halting the automatic scaling evaluation.",
      "pos": [
        18607,
        18734
      ]
    },
    {
      "pos": [
        18766,
        18822
      ],
      "content": "Samples, sample percentage, and the <bpt id=\"p1\">*</bpt>GetSample()<ept id=\"p1\">*</ept> method"
    },
    {
      "content": "The core operation of an autoscale formula is to obtain task and resource metric data and then adjust pool size based on that data.",
      "pos": [
        18824,
        18955
      ]
    },
    {
      "content": "As such, it is important to have a clear understanding of how autoscale formulas interact with metrics data, or \"samples.\"",
      "pos": [
        18956,
        19078
      ]
    },
    {
      "content": "Samples",
      "pos": [
        19082,
        19089
      ]
    },
    {
      "content": "The Batch service periodically takes <bpt id=\"p1\">*</bpt>samples<ept id=\"p1\">*</ept> of task and resource metrics and makes them available to your autoscale formulas.",
      "pos": [
        19093,
        19221
      ]
    },
    {
      "content": "These samples are recorded every 30 seconds by the Batch service.",
      "pos": [
        19222,
        19287
      ]
    },
    {
      "content": "However, there is typically some latency that causes a delay between when those samples were recorded and when they are made available to (and can be read by) your autoscale formulas.",
      "pos": [
        19288,
        19471
      ]
    },
    {
      "content": "Additionally, due to various factors such as network or other infrastructure issues, samples may not have been recorded for a particular interval.",
      "pos": [
        19472,
        19618
      ]
    },
    {
      "content": "This results in \"missing\" samples.",
      "pos": [
        19619,
        19653
      ]
    },
    {
      "content": "Sample percentage",
      "pos": [
        19657,
        19674
      ]
    },
    {
      "pos": [
        19678,
        19984
      ],
      "content": "When <ph id=\"ph1\">`samplePercent`</ph> is passed to the <ph id=\"ph2\">`GetSample()`</ph> method or the <ph id=\"ph3\">`GetSamplePercent()`</ph> method is called, \"percent\" refers to a comparison between the total <bpt id=\"p1\">*</bpt>possible<ept id=\"p1\">*</ept> number of samples that are recorded by the Batch service and the number of samples that are actually <bpt id=\"p2\">*</bpt>available<ept id=\"p2\">*</ept> to your autoscale formula."
    },
    {
      "content": "Let's look at a 10-minute timespan as an example.",
      "pos": [
        19986,
        20035
      ]
    },
    {
      "content": "Because samples are recorded every 30 seconds, within a 10 minute timespan, the maximum total number of samples that are recorded by Batch would be 20 samples (2 per minute).",
      "pos": [
        20036,
        20210
      ]
    },
    {
      "content": "However, due to the inherent latency of the reporting mechanism or some other issue within the Azure infrastructure, there may be only 15 samples that are available to your autoscale formula for reading.",
      "pos": [
        20211,
        20414
      ]
    },
    {
      "content": "This means that, for that 10-minute period, only <bpt id=\"p1\">**</bpt>75 percent<ept id=\"p1\">**</ept> of the total number of samples recorded are actually available to your formula.",
      "pos": [
        20415,
        20558
      ]
    },
    {
      "content": "GetSample() and sample ranges",
      "pos": [
        20562,
        20591
      ]
    },
    {
      "content": "Your autoscale formulas are going to be growing and shrinking your pools--adding nodes or removing nodes.",
      "pos": [
        20595,
        20700
      ]
    },
    {
      "content": "Because nodes cost you money, you want to ensure that your formulas use an intelligent method of analysis that is based on sufficient data.",
      "pos": [
        20701,
        20840
      ]
    },
    {
      "content": "Therefore, we recommend that you use a trending-type analysis in your formulas.",
      "pos": [
        20841,
        20920
      ]
    },
    {
      "content": "This type will grow and shrink your pools based on a <bpt id=\"p1\">*</bpt>range<ept id=\"p1\">*</ept> of collected samples.",
      "pos": [
        20921,
        21003
      ]
    },
    {
      "pos": [
        21005,
        21115
      ],
      "content": "To do so, use <ph id=\"ph1\">`GetSample(interval look-back start, interval look-back end)`</ph> to return a <bpt id=\"p1\">**</bpt>vector<ept id=\"p1\">**</ept> of samples:"
    },
    {
      "content": "When the above line is evaluated by Batch, it will return a range of samples as a vector of values.",
      "pos": [
        21216,
        21315
      ]
    },
    {
      "content": "For example:",
      "pos": [
        21316,
        21328
      ]
    },
    {
      "pos": [
        21375,
        21535
      ],
      "content": "Once you've collected the vector of samples, you can then use functions like <ph id=\"ph1\">`min()`</ph>, <ph id=\"ph2\">`max()`</ph>, and <ph id=\"ph3\">`avg()`</ph> to derive meaningful values from the collected range."
    },
    {
      "content": "For additional security, you can force a formula evaluation to <bpt id=\"p1\">*</bpt>fail<ept id=\"p1\">*</ept> if less than a certain sample percentage is available for a particular time period.",
      "pos": [
        21537,
        21690
      ]
    },
    {
      "content": "When you force a formula evaluation to fail, you instruct Batch to cease further evaluation of the formula if the specified percentage of samples is not available--and no change to pool size will be made.",
      "pos": [
        21691,
        21895
      ]
    },
    {
      "content": "To specify a required percentage of samples for the evaluation to succeed, specify it as the third parameter to <ph id=\"ph1\">`GetSample()`</ph>.",
      "pos": [
        21896,
        22022
      ]
    },
    {
      "content": "Here, a requirement of 75 percent of samples is specified:",
      "pos": [
        22023,
        22081
      ]
    },
    {
      "content": "It is also important, due to the previously mentioned delay in sample availability, to always specify a time range with a look-back start time that is older than one minute.",
      "pos": [
        22189,
        22362
      ]
    },
    {
      "content": "This is because it takes approximately one minute for samples to propagate through the system, so samples in the range <ph id=\"ph1\">`(0 * TimeInterval_Second, 60 * TimeInterval_Second)`</ph> will often not be available.",
      "pos": [
        22363,
        22564
      ]
    },
    {
      "content": "Again, you can use the percentage parameter of <ph id=\"ph1\">`GetSample()`</ph> to force a particular sample percentage requirement.",
      "pos": [
        22565,
        22678
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.IMPORTANT]</ph> We <bpt id=\"p1\">**</bpt>strongly recommend<ept id=\"p1\">**</ept> that you <bpt id=\"p2\">**</bpt>avoid relying <bpt id=\"p3\">*</bpt>only<ept id=\"p3\">*</ept> on <ph id=\"ph2\">`GetSample(1)`</ph> in your autoscale formulas<ept id=\"p2\">**</ept>.",
      "pos": [
        22682,
        22805
      ]
    },
    {
      "content": "This is because <ph id=\"ph1\">`GetSample(1)`</ph> essentially says to the Batch service, \"Give me the last sample you have, no matter how long ago you got it.\"",
      "pos": [
        22806,
        22946
      ]
    },
    {
      "content": "Since it is only a single sample, and it may be an older sample, it may not be representative of the larger picture of recent task or resource state.",
      "pos": [
        22947,
        23096
      ]
    },
    {
      "content": "If you do use <ph id=\"ph1\">`GetSample(1)`</ph>, make sure that it's part of a larger statement and not the only data point that your formula relies on.",
      "pos": [
        23097,
        23230
      ]
    },
    {
      "content": "Metrics",
      "pos": [
        23235,
        23242
      ]
    },
    {
      "content": "You can use both <bpt id=\"p1\">**</bpt>resource<ept id=\"p1\">**</ept> and <bpt id=\"p2\">**</bpt>task<ept id=\"p2\">**</ept> metrics when you're defining a formula.",
      "pos": [
        23244,
        23326
      ]
    },
    {
      "content": "You adjust the target number of dedicated nodes in the pool based on the metrics data that you obtain and evaluate.",
      "pos": [
        23327,
        23442
      ]
    },
    {
      "content": "See the <bpt id=\"p1\">[</bpt>Variables<ept id=\"p1\">](#variables)</ept> section above for more information on each metric.",
      "pos": [
        23443,
        23525
      ]
    },
    {
      "content": "Metric",
      "pos": [
        23550,
        23556
      ]
    },
    {
      "content": "Description",
      "pos": [
        23570,
        23581
      ]
    },
    {
      "content": "Resource",
      "pos": [
        23613,
        23621
      ]
    },
    {
      "content": "Resource metrics<ph id=\"ph1\">&lt;/b&gt;</ph> are based on the CPU, bandwidth, and memory usage of compute nodes, as well as the number of nodes.",
      "pos": [
        23645,
        23765
      ]
    },
    {
      "content": "These system-defined variables are useful for making adjustments based on node count:",
      "pos": [
        23782,
        23867
      ]
    },
    {
      "content": "$TargetDedicated",
      "pos": [
        23894,
        23910
      ]
    },
    {
      "content": "$CurrentDedicated",
      "pos": [
        23932,
        23949
      ]
    },
    {
      "content": "$SampleNodeCount",
      "pos": [
        23971,
        23987
      ]
    },
    {
      "content": "These system-defined variables are useful for making adjustments based on node resource usage:",
      "pos": [
        24014,
        24108
      ]
    },
    {
      "content": "$CPUPercent",
      "pos": [
        24135,
        24146
      ]
    },
    {
      "content": "$WallClockSeconds",
      "pos": [
        24162,
        24179
      ]
    },
    {
      "content": "$MemoryBytes",
      "pos": [
        24195,
        24207
      ]
    },
    {
      "content": "$DiskBytes",
      "pos": [
        24223,
        24233
      ]
    },
    {
      "content": "$DiskReadBytes",
      "pos": [
        24249,
        24263
      ]
    },
    {
      "content": "$DiskWriteBytes",
      "pos": [
        24279,
        24294
      ]
    },
    {
      "content": "$DiskReadOps",
      "pos": [
        24310,
        24322
      ]
    },
    {
      "content": "$DiskWriteOps",
      "pos": [
        24338,
        24351
      ]
    },
    {
      "content": "$NetworkInBytes",
      "pos": [
        24367,
        24382
      ]
    },
    {
      "content": "$NetworkOutBytes",
      "pos": [
        24398,
        24414
      ]
    },
    {
      "content": "Task",
      "pos": [
        24455,
        24459
      ]
    },
    {
      "content": "Task metrics<ph id=\"ph1\">&lt;/b&gt;</ph> are based on the status of tasks, such as Active, Pending, and Completed.",
      "pos": [
        24483,
        24573
      ]
    },
    {
      "content": "The following system-defined variables are useful for making pool-size adjustments based on task metrics:",
      "pos": [
        24574,
        24679
      ]
    },
    {
      "content": "$ActiveTasks",
      "pos": [
        24706,
        24718
      ]
    },
    {
      "content": "$RunningTasks",
      "pos": [
        24734,
        24747
      ]
    },
    {
      "content": "$SucceededTasks",
      "pos": [
        24763,
        24778
      ]
    },
    {
      "content": "$FailedTasks",
      "pos": [
        24800,
        24812
      ]
    },
    {
      "content": "Build an autoscale formula",
      "pos": [
        24862,
        24888
      ]
    },
    {
      "content": "You construct an autoscale formula by forming statements that use the above components and then combining those statements into a complete formula.",
      "pos": [
        24890,
        25037
      ]
    },
    {
      "content": "For example, here we construct a formula by first defining the requirements for a formula that will:",
      "pos": [
        25038,
        25138
      ]
    },
    {
      "content": "Increase the target number of compute nodes in a pool if CPU usage is high.",
      "pos": [
        25143,
        25218
      ]
    },
    {
      "content": "Decrease the target number of compute nodes in a pool when CPU usage is low.",
      "pos": [
        25222,
        25298
      ]
    },
    {
      "content": "Always restrict the maximum number of nodes to 400.",
      "pos": [
        25302,
        25353
      ]
    },
    {
      "pos": [
        25355,
        25636
      ],
      "content": "For the <bpt id=\"p1\">*</bpt>increase<ept id=\"p1\">*</ept> of nodes during high CPU usage, we define the statement that populates a user-defined variable ($TotalNodes) with a value that is 110 percent of the current target number of nodes, if the minimum average CPU usage during the last 10 minutes was above 70 percent:"
    },
    {
      "content": "The next statement sets the same variable to 90 percent of the current target number of nodes if the average CPU usage of the past 60 minutes was <bpt id=\"p1\">*</bpt>under<ept id=\"p1\">*</ept> 20 percent.",
      "pos": [
        25763,
        25928
      ]
    },
    {
      "content": "This lowers the target number during low CPU usage.",
      "pos": [
        25929,
        25980
      ]
    },
    {
      "content": "Note that this statement also references the user-defined variable <bpt id=\"p1\">*</bpt>$TotalNodes<ept id=\"p1\">*</ept> from the statement above.",
      "pos": [
        25981,
        26087
      ]
    },
    {
      "pos": [
        26210,
        26289
      ],
      "content": "Now limit the target number of dedicated compute nodes to a <bpt id=\"p1\">**</bpt>maximum<ept id=\"p1\">**</ept> of 400:"
    },
    {
      "content": "Here's the complete formula:",
      "pos": [
        26335,
        26363
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> An automatic scaling formula is comprised of <bpt id=\"p1\">[</bpt>Batch REST<ph id=\"ph2\">][</ph>rest_api<ept id=\"p1\">]</ept> API variables, types, operations, and functions.",
      "pos": [
        26655,
        26784
      ]
    },
    {
      "content": "You use these in formula strings even while you're working with the <bpt id=\"p1\">[</bpt>Batch .NET<ph id=\"ph1\">][</ph>net_api<ept id=\"p1\">]</ept> library.",
      "pos": [
        26785,
        26883
      ]
    },
    {
      "content": "Create a pool with automatic scaling enabled",
      "pos": [
        26888,
        26932
      ]
    },
    {
      "content": "To enable automatic scaling when you're creating a pool, use one of the following techniques:",
      "pos": [
        26934,
        27027
      ]
    },
    {
      "pos": [
        27031,
        27215
      ],
      "content": "<bpt id=\"p1\">[</bpt>New-AzureBatchPool<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/mt125936.aspx)</ept>--This Azure PowerShell cmdlet uses the AutoScaleFormula parameter to specify the automatic scaling formula."
    },
    {
      "pos": [
        27218,
        27732
      ],
      "content": "<bpt id=\"p1\">[</bpt>BatchClient.PoolOperations.CreatePool<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.createpool.aspx)</ept>--After this .NET method is called to create a pool, you'll then set the pool's <bpt id=\"p2\">[</bpt>CloudPool.AutoScaleEnabled<ept id=\"p2\">](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.autoscaleenabled.aspx)</ept> property and <bpt id=\"p3\">[</bpt>CloudPool.AutoScaleFormula<ept id=\"p3\">](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.autoscaleformula.aspx)</ept> property to enable automatic scaling."
    },
    {
      "pos": [
        27735,
        27963
      ],
      "content": "<bpt id=\"p1\">[</bpt>Add a pool to an account<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/dn820174.aspx)</ept>--The enableAutoScale and autoScaleFormula elements are used in this REST API request to set up automatic scaling for the pool when it is created."
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.IMPORTANT]</ph> If you create an autoscale-enabled pool by using one of the above techniques, the <bpt id=\"p1\">*</bpt>targetDedicated<ept id=\"p1\">*</ept> parameter for the pool must <bpt id=\"p2\">**</bpt>not<ept id=\"p2\">**</ept> be specified.",
      "pos": [
        27967,
        28134
      ]
    },
    {
      "content": "Also note that if you wish to manually resize an autoscale-enabled pool (for example, with <bpt id=\"p1\">[</bpt>BatchClient.PoolOperations.ResizePool<ph id=\"ph1\">][</ph>net_poolops_resizepool<ept id=\"p1\">]</ept>), then you must first <bpt id=\"p2\">**</bpt>disable<ept id=\"p2\">**</ept> automatic scaling on the pool, then resize it.",
      "pos": [
        28135,
        28370
      ]
    },
    {
      "content": "The following code snippet shows the creation of an autoscale-enabled pool (<bpt id=\"p1\">[</bpt>CloudPool<ph id=\"ph1\">][</ph>net_cloudpool<ept id=\"p1\">]</ept>) by using the <bpt id=\"p2\">[</bpt>Batch .NET<ph id=\"ph2\">][</ph>net_api<ept id=\"p2\">]</ept> library.",
      "pos": [
        28372,
        28519
      ]
    },
    {
      "content": "The pool's autoscale formula sets the target number of nodes to five on Mondays, and one on every other day of the week.",
      "pos": [
        28520,
        28640
      ]
    },
    {
      "content": "In addition, the automatic scaling interval is set to 30 minutes (see <bpt id=\"p1\">[</bpt>Automatic scaling interval<ept id=\"p1\">](#interval)</ept> below).",
      "pos": [
        28641,
        28758
      ]
    },
    {
      "content": "In this and the other C# snippets in this article, \"myBatchClient\" is a properly initialized instance of <bpt id=\"p1\">[</bpt>BatchClient<ph id=\"ph1\">][</ph>net_batchclient<ept id=\"p1\">]</ept>.",
      "pos": [
        28759,
        28895
      ]
    },
    {
      "pos": [
        29169,
        29218
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"interval\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Automatic scaling interval"
    },
    {
      "content": "By default, the Batch service adjusts a pool's size according to its autoscale formula every <bpt id=\"p1\">**</bpt>15 minutes<ept id=\"p1\">**</ept>.",
      "pos": [
        29220,
        29328
      ]
    },
    {
      "content": "This interval is configurable, however, by using the following pool properties:",
      "pos": [
        29329,
        29408
      ]
    },
    {
      "pos": [
        29412,
        29475
      ],
      "content": "REST API--<bpt id=\"p1\">[</bpt>autoScaleEvaluationInterval<ph id=\"ph1\">][</ph>rest_autoscaleinterval<ept id=\"p1\">]</ept>"
    },
    {
      "pos": [
        29478,
        29564
      ],
      "content": ".NET API--<bpt id=\"p1\">[</bpt>CloudPool.AutoScaleEvaluationInterval<ph id=\"ph1\">][</ph>net_cloudpool_autoscaleevalinterval<ept id=\"p1\">]</ept>"
    },
    {
      "content": "The minimum interval is five minutes, and the maximum is 168 hours.",
      "pos": [
        29566,
        29633
      ]
    },
    {
      "content": "If an interval outside this range is specified, the Batch service will return a Bad Request (400) error.",
      "pos": [
        29634,
        29738
      ]
    },
    {
      "pos": [
        29742,
        29925
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Autoscaling is not currently intended to respond to changes in less than a minute, but rather is intended to adjust the size of your pool gradually as you run a workload."
    },
    {
      "content": "Enable automatic scaling after a pool is created",
      "pos": [
        29930,
        29978
      ]
    },
    {
      "content": "If you've already set up a pool with a specified number of compute nodes by using the <bpt id=\"p1\">*</bpt>targetDedicated<ept id=\"p1\">*</ept> parameter, you can update the existing pool at a later time to automatically scale.",
      "pos": [
        29980,
        30167
      ]
    },
    {
      "content": "You can do this in one of these ways:",
      "pos": [
        30168,
        30205
      ]
    },
    {
      "pos": [
        30209,
        30384
      ],
      "content": "<bpt id=\"p1\">[</bpt>BatchClient.PoolOperations.EnableAutoScale<ph id=\"ph1\">][</ph>net_enableautoscale<ept id=\"p1\">]</ept>--This .NET method requires the ID of an existing pool and the automatic scaling formula to apply to the pool."
    },
    {
      "pos": [
        30387,
        30571
      ],
      "content": "<bpt id=\"p1\">[</bpt>Enable automatic scaling on a pool<ph id=\"ph1\">][</ph>rest_enableautoscale<ept id=\"p1\">]</ept>--This REST API request requires the ID of the existing pool in the URI and the automatic scaling formula in the request body."
    },
    {
      "pos": [
        30575,
        30738
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> If a value was specified for the <bpt id=\"p1\">*</bpt>targetDedicated<ept id=\"p1\">*</ept> parameter when the pool was created, it is ignored when the automatic scaling formula is evaluated."
    },
    {
      "content": "This code snippet demonstrates enabling autoscaling on an existing pool by using the <bpt id=\"p1\">[</bpt>Batch .NET<ph id=\"ph1\">][</ph>net_api<ept id=\"p1\">]</ept> library.",
      "pos": [
        30740,
        30855
      ]
    },
    {
      "content": "Note that both enabling and updating the formula on an existing pool use the same method.",
      "pos": [
        30856,
        30945
      ]
    },
    {
      "content": "As such, this technique would <bpt id=\"p1\">*</bpt>update<ept id=\"p1\">*</ept> the formula on the specified pool if autoscaling had already been enabled.",
      "pos": [
        30946,
        31059
      ]
    },
    {
      "content": "The snippet assumes that \"mypool\" is the ID of an existing pool (<bpt id=\"p1\">[</bpt>CloudPool<ph id=\"ph1\">][</ph>net_cloudpool<ept id=\"p1\">]</ept>).",
      "pos": [
        31060,
        31153
      ]
    },
    {
      "content": "Evaluate the automatic scaling formula",
      "pos": [
        31689,
        31727
      ]
    },
    {
      "content": "It’s always a good practice to evaluate a formula before you use it in your application.",
      "pos": [
        31729,
        31817
      ]
    },
    {
      "content": "A formula is evaluated by performing a \"test run\" of the formula on an existing pool.",
      "pos": [
        31818,
        31903
      ]
    },
    {
      "content": "Do this by using:",
      "pos": [
        31904,
        31921
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>BatchClient.PoolOperations.EvaluateAutoScale<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.evaluateautoscale.aspx)</ept> or <bpt id=\"p2\">[</bpt>BatchClient.PoolOperations.EvaluateAutoScaleAsync<ept id=\"p2\">](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.evaluateautoscaleasync.aspx)</ept>--These .NET methods require the ID of an existing pool and the string that contains the automatic scaling formula.",
      "pos": [
        31925,
        32350
      ]
    },
    {
      "content": "The results of the call are contained in an instance of the <bpt id=\"p1\">[</bpt>AutoScaleEvaluation<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.autoscaleevaluation.aspx)</ept> class.",
      "pos": [
        32351,
        32528
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Evaluate an automatic scaling formula<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/dn820183.aspx)</ept>--In this REST API request, the pool ID is specified in the URI.",
      "pos": [
        32531,
        32690
      ]
    },
    {
      "content": "The automatic scaling formula is specified in the <bpt id=\"p1\">*</bpt>autoScaleFormula<ept id=\"p1\">*</ept> element of the request body.",
      "pos": [
        32691,
        32788
      ]
    },
    {
      "content": "The response of the operation contains any error information that might be related to the formula.",
      "pos": [
        32789,
        32887
      ]
    },
    {
      "pos": [
        32891,
        33015
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> To evaluate an autoscale formula, you must first have enabled autoscaling on the pool by using a valid formula."
    },
    {
      "pos": [
        33017,
        33167
      ],
      "content": "In this code snippet that uses the <bpt id=\"p1\">[</bpt>Batch .NET<ph id=\"ph1\">][</ph>net_api<ept id=\"p1\">]</ept> library, we evaluate a formula prior to applying it to the pool (<bpt id=\"p2\">[</bpt>CloudPool<ph id=\"ph2\">][</ph>net_cloudpool<ept id=\"p2\">]</ept>)."
    },
    {
      "content": "Successful evaluation of the formula in this snippet will result in output similar to the following:",
      "pos": [
        34686,
        34786
      ]
    },
    {
      "content": "Obtain information about automatic scaling runs",
      "pos": [
        34969,
        35016
      ]
    },
    {
      "content": "Periodically check the results of automatic scaling runs to ensure that a formula is performing as expected.",
      "pos": [
        35018,
        35126
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>CloudPool.AutoScaleRun<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.autoscalerun.aspx)</ept>--When you use the .NET library, this property of a pool provides an instance of the <bpt id=\"p2\">[</bpt>AutoScaleRun<ept id=\"p2\">](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.autoscalerun.aspx)</ept> class.",
      "pos": [
        35130,
        35434
      ]
    },
    {
      "content": "This class provides the following properties of the latest automatic scaling run:",
      "pos": [
        35435,
        35516
      ]
    },
    {
      "content": "AutoScaleRun.Error",
      "pos": [
        35522,
        35540
      ]
    },
    {
      "content": "AutoScaleRun.Results",
      "pos": [
        35635,
        35655
      ]
    },
    {
      "content": "AutoScaleRun.Timestamp",
      "pos": [
        35752,
        35774
      ]
    },
    {
      "pos": [
        35870,
        36058
      ],
      "content": "<bpt id=\"p1\">[</bpt>Get information about a pool<ept id=\"p1\">](https://msdn.microsoft.com/library/dn820165.aspx)</ept>--This REST API request returns information about the pool, which includes the latest automatic scaling run."
    },
    {
      "pos": [
        36063,
        36102
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"examples\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Example formulas"
    },
    {
      "content": "Let's take a look at some examples that show just a few ways that formulas can be used to automatically scale compute resources in a pool.",
      "pos": [
        36104,
        36242
      ]
    },
    {
      "content": "Example 1: Time-based adjustment",
      "pos": [
        36248,
        36280
      ]
    },
    {
      "content": "Perhaps you want to adjust the pool size based on the day of the week and time of day, to increase or decrease the number of nodes in the pool accordingly:",
      "pos": [
        36282,
        36437
      ]
    },
    {
      "content": "This formula first obtains the current time.",
      "pos": [
        36663,
        36707
      ]
    },
    {
      "content": "If it's a weekday (1-5) and within working hours (8 AM to 6 PM), the target pool size is set to 20 nodes.",
      "pos": [
        36708,
        36813
      ]
    },
    {
      "content": "Otherwise, the pool size is targeted at 10 nodes.",
      "pos": [
        36814,
        36863
      ]
    },
    {
      "content": "Example 2: Task-based adjustment",
      "pos": [
        36869,
        36901
      ]
    },
    {
      "content": "In this example, the pool size is adjusted based on the number of tasks in the queue.",
      "pos": [
        36903,
        36988
      ]
    },
    {
      "content": "Note that both comments and line breaks are acceptable in formula strings.",
      "pos": [
        36989,
        37063
      ]
    },
    {
      "content": "Example 3: Accounting for parallel tasks",
      "pos": [
        37974,
        38014
      ]
    },
    {
      "content": "This is another example that adjusts the pool size based on the number of tasks.",
      "pos": [
        38016,
        38096
      ]
    },
    {
      "content": "This formula also takes into account the <bpt id=\"p1\">[</bpt>MaxTasksPerComputeNode<ph id=\"ph1\">][</ph>net_maxtasks<ept id=\"p1\">]</ept> value that has been set for the pool.",
      "pos": [
        38097,
        38214
      ]
    },
    {
      "content": "This is particularly useful in situations where <bpt id=\"p1\">[</bpt>parallel task execution<ept id=\"p1\">](batch-parallel-node-tasks.md)</ept> has been enabled on your pool.",
      "pos": [
        38215,
        38349
      ]
    },
    {
      "content": "Example 4: Setting an initial pool size",
      "pos": [
        39226,
        39265
      ]
    },
    {
      "content": "This example shows a C# code snippet with an autoscale formula that sets the pool size to a certain number of nodes for an initial time period.",
      "pos": [
        39267,
        39410
      ]
    },
    {
      "content": "Then it adjusts the pool size based on the number of running and active tasks after the initial time period has elapsed.",
      "pos": [
        39411,
        39531
      ]
    },
    {
      "content": "The formula in the above code snippet:",
      "pos": [
        40000,
        40038
      ]
    },
    {
      "content": "Sets the initial pool size to four nodes.",
      "pos": [
        40042,
        40083
      ]
    },
    {
      "content": "Does not adjust the pool size within the first 10 minutes of the pool's lifecycle.",
      "pos": [
        40086,
        40168
      ]
    },
    {
      "content": "After 10 minutes, obtains the max value of the number of running and active tasks within the past 60 minutes.",
      "pos": [
        40171,
        40280
      ]
    },
    {
      "content": "If both values are 0 (indicating that no tasks were running or active in the last 60 minutes), the pool size is set to 0.",
      "pos": [
        40285,
        40406
      ]
    },
    {
      "content": "If either value is greater than zero, no change is made.",
      "pos": [
        40411,
        40467
      ]
    },
    {
      "content": "Next steps",
      "pos": [
        40472,
        40482
      ]
    },
    {
      "content": "To fully assess the efficiency of your application, you might need to access a compute node.",
      "pos": [
        40487,
        40579
      ]
    },
    {
      "content": "To take advantage of remote access, a user account must be added to the node that you want to access, and a Remote Desktop Protocol (RDP) file must be retrieved for that node.",
      "pos": [
        40580,
        40755
      ]
    },
    {
      "content": "Add the user account in one of these ways:",
      "pos": [
        40762,
        40804
      ]
    },
    {
      "pos": [
        40815,
        40993
      ],
      "content": "<bpt id=\"p1\">[</bpt>New-AzureBatchVMUser<ept id=\"p1\">](https://msdn.microsoft.com/library/mt149846.aspx)</ept>--This PowerShell cmdlet takes the pool name, compute node name, account name, and password as parameters."
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>BatchClient.PoolOperations.CreateComputeNodeUser<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.createcomputenodeuser.aspx)</ept>--This .NET method creates an instance of the <bpt id=\"p2\">[</bpt>ComputeNodeUser<ept id=\"p2\">](https://msdn.microsoft.com/library/microsoft.azure.batch.computenodeuser.aspx)</ept> class, on which the account name and password can be set for the compute node.",
      "pos": [
        41004,
        41381
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>ComputeNodeUser.Commit<ept id=\"p1\">](https://msdn.microsoft.com/library/microsoft.azure.batch.computenodeuser.commit.aspx)</ept> is then called on the instance to create the user on that node.",
      "pos": [
        41382,
        41556
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Add a user account to a node<ept id=\"p1\">](https://msdn.microsoft.com/library/dn820137.aspx)</ept>--The name of the pool and the compute node are specified in the URI.",
      "pos": [
        41567,
        41716
      ]
    },
    {
      "content": "The account name and password are sent to the node in the request body of this REST API request.",
      "pos": [
        41717,
        41813
      ]
    },
    {
      "content": "Get the RDP file:",
      "pos": [
        41820,
        41837
      ]
    },
    {
      "pos": [
        41848,
        42082
      ],
      "content": "<bpt id=\"p1\">[</bpt>BatchClient.PoolOperations.GetRDPFile<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.getrdpfile.aspx)</ept>--This .NET method requires the ID of the pool, the node ID, and the name of the RDP file to create."
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Get a remote desktop protocol file from a node<ept id=\"p1\">](https://msdn.microsoft.com/library/dn820120.aspx)</ept>--This REST API request requires the name of the pool and the name of the compute node.",
      "pos": [
        42093,
        42278
      ]
    },
    {
      "content": "The response contains the contents of the RDP file.",
      "pos": [
        42279,
        42330
      ]
    },
    {
      "pos": [
        42341,
        42548
      ],
      "content": "<bpt id=\"p1\">[</bpt>Get-AzureBatchRDPFile<ept id=\"p1\">](https://msdn.microsoft.com/library/mt149851.aspx)</ept>--This PowerShell cmdlet gets the RDP file from the specified compute node and saves it to the specified file location or to a stream."
    },
    {
      "content": "Some applications produce large amounts of data that can be difficult to process.",
      "pos": [
        42553,
        42634
      ]
    },
    {
      "content": "One way to solve this is through <bpt id=\"p1\">[</bpt>efficient list querying<ept id=\"p1\">](batch-efficient-list-queries.md)</ept>.",
      "pos": [
        42635,
        42727
      ]
    },
    {
      "pos": [
        42729,
        42794
      ],
      "content": "<ph id=\"ph1\">[</ph>net_api<ph id=\"ph2\">]: https://msdn.microsoft.com/library/azure/mt348682.aspx</ph>"
    },
    {
      "pos": [
        42795,
        42892
      ],
      "content": "<ph id=\"ph1\">[</ph>net_batchclient<ph id=\"ph2\">]: http://msdn.microsoft.com/library/azure/microsoft.azure.batch.batchclient.aspx</ph>"
    },
    {
      "pos": [
        42893,
        42987
      ],
      "content": "<ph id=\"ph1\">[</ph>net_cloudpool<ph id=\"ph2\">]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.aspx</ph>"
    },
    {
      "pos": [
        42988,
        43116
      ],
      "content": "<ph id=\"ph1\">[</ph>net_cloudpool_autoscaleformula<ph id=\"ph2\">]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.autoscaleformula.aspx</ph>"
    },
    {
      "pos": [
        43117,
        43261
      ],
      "content": "<ph id=\"ph1\">[</ph>net_cloudpool_autoscaleevalinterval<ph id=\"ph2\">]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.autoscaleevaluationinterval.aspx</ph>"
    },
    {
      "pos": [
        43262,
        43383
      ],
      "content": "<ph id=\"ph1\">[</ph>net_enableautoscale<ph id=\"ph2\">]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.enableautoscale.aspx</ph>"
    },
    {
      "pos": [
        43384,
        43500
      ],
      "content": "<ph id=\"ph1\">[</ph>net_maxtasks<ph id=\"ph2\">]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.maxtaskspercomputenode.aspx</ph>"
    },
    {
      "pos": [
        43501,
        43620
      ],
      "content": "<ph id=\"ph1\">[</ph>net_poolops_resizepool<ph id=\"ph2\">]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.resizepool.aspx</ph>"
    },
    {
      "pos": [
        43622,
        43688
      ],
      "content": "<ph id=\"ph1\">[</ph>rest_api<ph id=\"ph2\">]: https://msdn.microsoft.com/library/azure/dn820158.aspx</ph>"
    },
    {
      "pos": [
        43689,
        43768
      ],
      "content": "<ph id=\"ph1\">[</ph>rest_autoscaleformula<ph id=\"ph2\">]: https://msdn.microsoft.com/library/azure/dn820173.aspx</ph>"
    },
    {
      "pos": [
        43769,
        43855
      ],
      "content": "<ph id=\"ph1\">[</ph>rest_autoscaleinterval<ph id=\"ph2\">]: https://msdn.microsoft.com/en-us/library/azure/dn820173.aspx</ph>"
    },
    {
      "pos": [
        43856,
        43934
      ],
      "content": "<ph id=\"ph1\">[</ph>rest_enableautoscale<ph id=\"ph2\">]: https://msdn.microsoft.com/library/azure/dn820173.aspx</ph>"
    }
  ],
  "content": "<properties\n    pageTitle=\"Automatically scale compute nodes in an Azure Batch pool | Microsoft Azure\"\n    description=\"Enable automatic scaling on a cloud pool to dynamically adjust the number of compute nodes in the pool.\"\n    services=\"batch\"\n    documentationCenter=\"\"\n    authors=\"mmacy\"\n    manager=\"timlt\"\n    editor=\"tysonn\"/>\n\n<tags\n    ms.service=\"batch\"\n    ms.devlang=\"na\"\n    ms.topic=\"article\"\n    ms.tgt_pltfrm=\"vm-windows\"\n    ms.workload=\"multiple\"\n    ms.date=\"01/08/2016\"\n    ms.author=\"marsma\"/>\n\n# Automatically scale compute nodes in an Azure Batch pool\n\nBy using automatic scaling in Azure Batch, you can dynamically add or remove compute nodes in a Batch pool during job execution to automatically adjust the processing power that is used by your application. This automatic adjustment can save you both time and money.\n\nYou can enable automatic scaling on a pool of compute nodes by associating an *autoscale formula* with the pool, such as with the [PoolOperations.EnableAutoScale][net_enableautoscale] method in the [Batch .NET](batch-dotnet-get-started.md) library. The Batch service then uses this formula to determine the number of compute nodes that are needed to execute your workload. The number of compute nodes in the pool, which responds to service metrics data samples that are collected periodically, is adjusted at a configurable interval based on the associated formula.\n\nYou can enable automatic scaling when a pool is created, or on an existing pool. You can also change an existing formula on a pool that is \"autoscale\" enabled. Batch provides the ability to evaluate your formulas before assigning them to pools, as well as for monitoring the status of automatic scaling runs.\n\n## Automatic scaling formulas\n\nAn automatic scaling formula is a string value that contains one or more statements that are assigned to a pool's [autoScaleFormula][rest_autoscaleformula] element (Batch REST API), or the [CloudPool.AutoScaleFormula][net_cloudpool_autoscaleformula] property (Batch .NET API). You define these formulas. When they are assigned to a pool, they determine the number of available compute nodes in a pool for the next interval of processing (see more on intervals later). The formula string cannot exceed 8 KB in size, can include up to 100 statements that are separated by semicolons, and can include line breaks and comments.\n\nYou can think of automatic scaling formulas as using a Batch autoscale \"language.\" Formula statements are free-formed expressions that can include system-defined and user-defined variables, as well as constants. They can perform various operations on these values by using built-in types, operators, and functions. For example, a statement might take the following form:\n\n`VAR = Expression(system-defined variables, user-defined variables);`\n\nFormulas generally contain multiple statements that perform operations on values that are obtained in previous statements:\n\n```\nVAR₀ = Expression₀(system-defined variables);\nVAR₁ = Expression₁(system-defined variables, VAR₀);\n```\n\nBy using the statements in your formula, your goal is to arrive at a number of compute nodes that the pool should be scaled to--the **target** number of **dedicated nodes**. This number may be higher, lower, or the same as the current number of nodes in the pool. Batch evaluates a pool's autoscale formula at a specific interval ([automatic scaling intervals](#interval) are discussed below). Then it will adjust the target number of nodes in the pool to the number that your autoscale formula specifies at the time of evaluation.\n\nAs a quick example, this two-line autoscale formula specifies that the number of nodes should be adjusted according to the number of active tasks, up to a maximum of 10 compute nodes:\n\n```\n$averageActiveTaskCount = avg($ActiveTasks.GetSample(TimeInterval_Minute * 15));\n$TargetDedicated = min(10, $averageActiveTaskCount);\n```\n\nThe next few sections of this article discuss the various entities that will make up your autoscale formulas, including variables, operators, operations, and functions. You'll find out how to obtain various compute resource and task metrics within Batch. You can use these metrics to intelligently adjust your pool's node count based on resource usage and task status. You'll then learn how to construct a formula and enable automatic scaling on a pool by using both the Batch REST and .NET APIs. We'll finish up with a few example formulas.\n\n> [AZURE.NOTE] Each Azure Batch account is limited to a maximum number of compute nodes that can be used for processing. The Batch service will create nodes only up to that limit. Therefore, it may not reach the target number that is specified by a formula. See [Quotas and limits for the Azure Batch service](batch-quota-limit.md) for information on viewing and increasing your account quotas.\n\n## <a name=\"variables\"></a>Variables\n\nYou can use both system-defined and user-defined variables in autoscale formulas. In the two-line example formula above, `$TargetDedicated` is a system-defined variable, while `$averageActiveTaskCount` is user-defined. The tables below show both read-write and read-only variables that are defined by the Batch service.\n\n*Get* and *set* the values of these **system-defined variables** to manage the number of compute nodes in a pool:\n\n<table>\n  <tr>\n    <th>Variables (read-write)</th>\n    <th>Description</th>\n  </tr>\n  <tr>\n    <td>$TargetDedicated</td>\n    <td>The <b>target</b> number of <b>dedicated compute nodes</b> for the pool. This is the number of compute nodes that the pool should be scaled to. It is a \"target\" number since it's possible for a pool not to reach the target number of nodes. This can occur if the target number of nodes is modified again by a subsequent autoscale evaluation before the pool has reached the initial target. It can also happen if a Batch account node or core quota is reached before the target number of nodes is reached.</td>\n  </tr>\n  <tr>\n    <td>$NodeDeallocationOption</td>\n    <td>The action that occurs when compute nodes are removed from a pool. Possible values are:\n      <br/>\n      <ul>\n        <li><p><b>requeue</b>--Terminates tasks immediately and puts them back on the job queue so that they are rescheduled.</p></li>\n        <li><p><b>terminate</b>--Terminates tasks immediately and removes them from the job queue.</p></li>\n        <li><p><b>taskcompletion</b>--Waits for currently running tasks to finish and then removes the node from the pool.</p></li>\n        <li><p><b>retaineddata</b>--Waits for all the local task-retained data on the node to be cleaned up before removing the node from the pool.</p></li>\n      </ul></td>\n   </tr>\n</table>\n\n*Get* the value of these **system-defined variables** to make adjustments that are based on metrics from the Batch service:\n\n<table>\n  <tr>\n    <th>Variables (read-only)</th>\n    <th>Description</th>\n  </tr>\n  <tr>\n    <td>$CPUPercent</td>\n    <td>The average percentage of CPU usage.</td>\n  </tr>\n  <tr>\n    <td>$WallClockSeconds</td>\n    <td>The number of seconds consumed.</td>\n  </tr>\n  <tr>\n    <td>$MemoryBytes</td>\n    <td>The average number of megabytes used.</td>\n  <tr>\n    <td>$DiskBytes</td>\n    <td>The average number of gigabytes used on the local disks.</td>\n  </tr>\n  <tr>\n    <td>$DiskReadBytes</td>\n    <td>The number of bytes read.</td>\n  </tr>\n  <tr>\n    <td>$DiskWriteBytes</td>\n    <td>The number of bytes written.</td>\n  </tr>\n  <tr>\n    <td>$DiskReadOps</td>\n    <td>The count of read disk operations performed.</td>\n  </tr>\n  <tr>\n    <td>$DiskWriteOps</td>\n    <td>The count of write disk operations performed.</td>\n  </tr>\n  <tr>\n    <td>$NetworkInBytes</td>\n    <td>The number of inbound bytes.</td>\n  </tr>\n  <tr>\n    <td>$NetworkOutBytes</td>\n    <td>The number of outbound bytes.</td>\n  </tr>\n  <tr>\n    <td>$SampleNodeCount</td>\n    <td>The count of compute nodes.</td>\n  </tr>\n  <tr>\n    <td>$ActiveTasks</td>\n    <td>The number of tasks in an active state.</td>\n  </tr>\n  <tr>\n    <td>$RunningTasks</td>\n    <td>The number of tasks in a running state.</td>\n  </tr>\n  <tr>\n    <td>$SucceededTasks</td>\n    <td>The number of tasks that finished successfully.</td>\n  </tr>\n  <tr>\n    <td>$FailedTasks</td>\n    <td>The number of tasks that failed.</td>\n  </tr>\n  <tr>\n    <td>$CurrentDedicated</td>\n    <td>The current number of dedicated compute nodes.</td>\n  </tr>\n</table>\n\n> [AZURE.TIP] The read-only, system-defined variables that are shown above are *objects* that provide various methods to access data associated with each. See [Obtain sample data](#getsampledata) below for more information.\n\n## Types\n\nThese **types** are supported in a formula.\n\n- double\n- doubleVec\n- doubleVecList\n- string\n- timestamp--timestamp is a compound structure that contains the following members:\n    - year\n    - month (1-12)\n    - day (1-31)\n    - weekday (in the format of number, e.g. 1 for Monday)\n    - hour (in 24-hour number format, e.g. 13 means 1 PM)\n    - minute (00-59)\n    - second (00-59)\n- timeinterval\n    - TimeInterval_Zero\n    - TimeInterval_100ns\n    - TimeInterval_Microsecond\n    - TimeInterval_Millisecond\n    - TimeInterval_Second\n    - TimeInterval_Minute\n    - TimeInterval_Hour\n    - TimeInterval_Day\n    - TimeInterval_Week\n    - TimeInterval_Year\n\n## Operations\n\nThese **operations** are allowed on the types that are listed above.\n\n<table>\n  <tr>\n    <th>Operation</th>\n    <th>Allowed operators</th>\n  </tr>\n  <tr>\n    <td>double &lt;operator&gt; double =&gt; double</td>\n    <td>+, -, *, /</td>\n  </tr>\n  <tr>\n    <td>double &lt;operator&gt; timeinterval =&gt; timeinterval</td>\n    <td>*</td>\n  </tr>\n  <tr>\n    <td>doubleVec &lt;operator&gt; double =&gt; doubleVec</td>\n    <td>+, -, *, /</td>\n  </tr>\n  <tr>\n    <td>doubleVec &lt;operator&gt; doubleVec =&gt; doubleVec</td>\n    <td>+, -, *, /</td>\n  </tr>\n  <tr>\n    <td>timeinterval &lt;operator&gt; double =&gt; timeinterval</td>\n    <td>*, /</td>\n  </tr>\n  <tr>\n    <td>timeinterval &lt;operator&gt; timeinterval =&gt; timeinterval</td>\n    <td>+, -</td>\n  </tr>\n  <tr>\n    <td>timeinterval &lt;operator&gt; timestamp =&gt; timestamp</td>\n    <td>+</td>\n  </tr>\n  <tr>\n    <td>timestamp &lt;operator&gt; timeinterval =&gt; timestamp</td>\n    <td>+</td>\n  </tr>\n  <tr>\n    <td>timestamp &lt;operator&gt; timestamp =&gt; timeinterval</td>\n    <td>-</td>\n  </tr>\n  <tr>\n    <td>&lt;operator&gt;double =&gt; double</td>\n    <td>-, !</td>\n  </tr>\n  <tr>\n    <td>&lt;operator&gt;timeinterval =&gt; timeinterval</td>\n    <td>-</td>\n  </tr>\n  <tr>\n    <td>double &lt;operator&gt; double =&gt; double</td>\n    <td>&lt;, &lt;=, ==, &gt;=, &gt;, !=</td>\n  </tr>\n  <tr>\n    <td>string &lt;operator&gt; string =&gt; double</td>\n    <td>&lt;, &lt;=, ==, &gt;=, &gt;, !=</td>\n  </tr>\n  <tr>\n    <td>timestamp &lt;operator&gt; timestamp =&gt; double</td>\n    <td>&lt;, &lt;=, ==, &gt;=, &gt, !=</td>\n  </tr>\n  <tr>\n    <td>timeinterval &lt;operator&gt; timeinterval =&gt; double</td>\n    <td>&lt;, &lt;=, ==, &gt;=, &gt;, !=</td>\n  </tr>\n  <tr>\n    <td>double &lt;operator&gt; double =&gt; double</td>\n    <td>&&, ||</td>\n  </tr>\n  <tr>\n    <td>test double only (nonzero is true, zero is false)</td>\n    <td>? :</td>\n  </tr>\n</table>\n\n## Functions\n\nThese predefined **functions** are available for you to use in defining an automatic scaling formula.\n\n<table>\n  <tr>\n    <th>Function</th>\n    <th>Description</th>\n  </tr>\n  <tr>\n    <td>double <b>avg</b>(doubleVecList)</td>\n    <td>Returns the average value for all values in the doubleVecList.</td>\n  </tr>\n  <tr>\n    <td>double <b>len</b>(doubleVecList)</td>\n    <td>Returns the length of the vector that is created from the doubleVecList.</td>\n  <tr>\n    <td>double <b>lg</b>(double)</td>\n    <td>Returns the log base 2 of the double.</td>\n  </tr>\n  <tr>\n    <td>doubleVec <b>lg</b>(doubleVecList)</td>\n    <td>Returns the componentwise log base 2 of the doubleVecList. A vec(double) must explicitly be passed for the single double parameter. Otherwise, the double lg(double) version is assumed.</td>\n  </tr>\n  <tr>\n    <td>double <b>ln</b>(double)</td>\n    <td>Returns the natural log of the double.</td>\n  </tr>\n  <tr>\n    <td>doubleVec <b>ln</b>(doubleVecList)</td>\n    <td>Returns the componentwise log base 2 of the doubleVecList.  A vec(double) must explicitly be passed for the single double parameter. Otherwise, the double lg(double) version is assumed.</td>\n  </tr>\n  <tr>\n    <td>double <b>log</b>(double)</td>\n    <td>Returns the log base 10 of the double.</td>\n  </tr>\n  <tr>\n    <td>doubleVec <b>log</b>(doubleVecList)</td>\n    <td>Returns the componentwise log base 10 of the doubleVecList. A vec(double) must explicitly be passed for the single double parameter. Otherwise, the double log(double) version is assumed.</td>\n  </tr>\n  <tr>\n    <td>double <b>max</b>(doubleVecList)</td>\n    <td>Returns the maximum value in the doubleVecList.</td>\n  </tr>\n  <tr>\n    <td>double <b>min</b>(doubleVecList)</td>\n    <td>Returns the minimum value in the doubleVecList.</td>\n  </tr>\n  <tr>\n    <td>double <b>norm</b>(doubleVecList)</td>\n    <td>Returns the two-norm of the vector that is created from the doubleVecList.\n  </tr>\n  <tr>\n    <td>double <b>percentile</b>(doubleVec v, double p)</td>\n    <td>Returns the percentile element of the vector v.</td>\n  </tr>\n  <tr>\n    <td>double <b>rand</b>()</td>\n    <td>Returns a random value between 0.0 and 1.0.</td>\n  </tr>\n  <tr>\n    <td>double <b>range</b>(doubleVecList)</td>\n    <td>Returns the difference between the min and max values in the doubleVecList.</td>\n  </tr>\n  <tr>\n    <td>double <b>std</b>(doubleVecList)</td>\n    <td>Returns the sample standard deviation of the values in the doubleVecList.</td>\n  </tr>\n  <tr>\n    <td><b>stop</b>()</td>\n    <td>Stops evaluation of the autoscaling expression.</td>\n  </tr>\n  <tr>\n    <td>double <b>sum</b>(doubleVecList)</td>\n    <td>Returns the sum of all the components of the doubleVecList.</td>\n  </tr>\n  <tr>\n    <td>timestamp <b>time</b>(string dateTime=\"\")</td>\n    <td>Returns the time stamp of the current time if no parameters are passed, or the time stamp of the dateTime string if it is passed. Supported dateTime formats are W3C-DTF and RFC 1123.</td>\n  </tr>\n  <tr>\n    <td>double <b>val</b>(doubleVec v, double i)</td>\n    <td>Returns the value of the element that is at location i in vector v, with a starting index of zero.</td>\n  </tr>\n</table>\n\nSome of the functions that are described in the table above can accept a list as an argument. The comma-separated list is any combination of *double* and *doubleVec*. For example:\n\n`doubleVecList := ( (double | doubleVec)+(, (double | doubleVec) )* )?`\n\nThe *doubleVecList* value is converted to a single *doubleVec* prior to evaluation. For example, if `v = [1,2,3]`, then calling `avg(v)` is equivalent to calling `avg(1,2,3)`. Calling `avg(v, 7)` is equivalent to calling `avg(1,2,3,7)`.\n\n## <a name=\"getsampledata\"></a>Obtain sample data\n\nAutoscale formulas act on metrics data (samples) that is provided by the Batch service. A formula grows or shrinks pool size based on the values that it obtains from the service. The system-defined variables that are described above are objects that provide various methods to access data that is associated with that object. For example, the following expression shows a request to get the last five minutes of CPU usage:\n\n`$CPUPercent.GetSample(TimeInterval_Minute * 5)`\n\n<table>\n  <tr>\n    <th>Method</th>\n    <th>Description</th>\n  </tr>\n  <tr>\n    <td>GetSample()</td>\n    <td><p>The <b>GetSample()</b> method returns a vector of data samples.\n    <p>A sample is 30 seconds worth of metrics data. In other words, samples are obtained every 30 seconds. But as noted below, there is a delay between when a sample is collected and when it is available to a formula. As such, not all samples for a given time period may be available for evaluation by a formula.\n        <ul>\n          <li><p><b>doubleVec GetSample(double count)</b>--Specifies the number of samples to obtain from the most recent samples that were collected.</p>\n                  <p>GetSample(1) returns the last available sample. For metrics like $CPUPercent, however, this should not be used because it is impossible to know <em>when</em> the sample was collected. It might be recent, or, because of system issues, it might be much older. It is better in such cases to use a time interval as shown below.</p></li>\n          <li><p><b>doubleVec GetSample((timestamp | timeinterval) startTime [, double samplePercent])</b>--Specifies a time frame for gathering sample data. Optionally, it also specifies the percentage of samples that must be available in the requested time frame.</p>\n          <p><em>$CPUPercent.GetSample(TimeInterval_Minute * 10)</em> would return 20 samples if all samples for the last ten minutes are present in the CPUPercent history. If the last minute of history was not available, however, only 18 samples would be returned. In this case:<br/>\n          &nbsp;&nbsp;&nbsp;&nbsp;<em>$CPUPercent.GetSample(TimeInterval_Minute * 10, 95)</em> would fail because only 90 percent of the samples are available.<br/>\n          &nbsp;&nbsp;&nbsp;&nbsp;<em>$CPUPercent.GetSample(TimeInterval_Minute * 10, 80)</em> would succeed.</p></li>\n          <li><p><b>doubleVec GetSample((timestamp | timeinterval) startTime, (timestamp | timeinterval) endTime [, double samplePercent])</b>--Specifies a time frame for gathering data, with both a start time and an end time.</p></li></ul>\n          <p>As mentioned above, there is a delay between when a sample is collected and when it is available to a formula. This must be considered when you use the <em>GetSample</em> method. See <em>GetSamplePercent</em> below.</td>\n  </tr>\n  <tr>\n    <td>GetSamplePeriod()</td>\n    <td>Returns the period of samples that were taken in a historical sample data set.</td>\n  </tr>\n    <tr>\n        <td>Count()</td>\n        <td>Returns the total number of samples in the metric history.</td>\n    </tr>\n  <tr>\n    <td>HistoryBeginTime()</td>\n    <td>Returns the time stamp of the oldest available data sample for the metric.</td>\n  </tr>\n  <tr>\n    <td>GetSamplePercent()</td>\n    <td><p>Returns the percentage of samples that are available for a given time interval. For example:</p>\n    <p><b>doubleVec GetSamplePercent( (timestamp | timeinterval) startTime [, (timestamp | timeinterval) endTime] )</b>\n    <p>Because the GetSample method fails if the percentage of samples returned is less than the samplePercent specified, you can use the GetSamplePercent method to check first. Then you can perform an alternate action if insufficient samples are present, without halting the automatic scaling evaluation.</p></td>\n  </tr>\n</table>\n\n### Samples, sample percentage, and the *GetSample()* method\n\nThe core operation of an autoscale formula is to obtain task and resource metric data and then adjust pool size based on that data. As such, it is important to have a clear understanding of how autoscale formulas interact with metrics data, or \"samples.\"\n\n**Samples**\n\nThe Batch service periodically takes *samples* of task and resource metrics and makes them available to your autoscale formulas. These samples are recorded every 30 seconds by the Batch service. However, there is typically some latency that causes a delay between when those samples were recorded and when they are made available to (and can be read by) your autoscale formulas. Additionally, due to various factors such as network or other infrastructure issues, samples may not have been recorded for a particular interval. This results in \"missing\" samples.\n\n**Sample percentage**\n\nWhen `samplePercent` is passed to the `GetSample()` method or the `GetSamplePercent()` method is called, \"percent\" refers to a comparison between the total *possible* number of samples that are recorded by the Batch service and the number of samples that are actually *available* to your autoscale formula.\n\nLet's look at a 10-minute timespan as an example. Because samples are recorded every 30 seconds, within a 10 minute timespan, the maximum total number of samples that are recorded by Batch would be 20 samples (2 per minute). However, due to the inherent latency of the reporting mechanism or some other issue within the Azure infrastructure, there may be only 15 samples that are available to your autoscale formula for reading. This means that, for that 10-minute period, only **75 percent** of the total number of samples recorded are actually available to your formula.\n\n**GetSample() and sample ranges**\n\nYour autoscale formulas are going to be growing and shrinking your pools--adding nodes or removing nodes. Because nodes cost you money, you want to ensure that your formulas use an intelligent method of analysis that is based on sufficient data. Therefore, we recommend that you use a trending-type analysis in your formulas. This type will grow and shrink your pools based on a *range* of collected samples.\n\nTo do so, use `GetSample(interval look-back start, interval look-back end)` to return a **vector** of samples:\n\n`runningTasksSample = $RunningTasks.GetSample(1 * TimeInterval_Minute, 6 * TimeInterval_Minute);`\n\nWhen the above line is evaluated by Batch, it will return a range of samples as a vector of values. For example:\n\n`runningTasksSample=[1,1,1,1,1,1,1,1,1,1];`\n\nOnce you've collected the vector of samples, you can then use functions like `min()`, `max()`, and `avg()` to derive meaningful values from the collected range.\n\nFor additional security, you can force a formula evaluation to *fail* if less than a certain sample percentage is available for a particular time period. When you force a formula evaluation to fail, you instruct Batch to cease further evaluation of the formula if the specified percentage of samples is not available--and no change to pool size will be made. To specify a required percentage of samples for the evaluation to succeed, specify it as the third parameter to `GetSample()`. Here, a requirement of 75 percent of samples is specified:\n\n`runningTasksSample = $RunningTasks.GetSample(60 * TimeInterval_Second, 120 * TimeInterval_Second, 75);`\n\nIt is also important, due to the previously mentioned delay in sample availability, to always specify a time range with a look-back start time that is older than one minute. This is because it takes approximately one minute for samples to propagate through the system, so samples in the range `(0 * TimeInterval_Second, 60 * TimeInterval_Second)` will often not be available. Again, you can use the percentage parameter of `GetSample()` to force a particular sample percentage requirement.\n\n> [AZURE.IMPORTANT] We **strongly recommend** that you **avoid relying *only* on `GetSample(1)` in your autoscale formulas**. This is because `GetSample(1)` essentially says to the Batch service, \"Give me the last sample you have, no matter how long ago you got it.\" Since it is only a single sample, and it may be an older sample, it may not be representative of the larger picture of recent task or resource state. If you do use `GetSample(1)`, make sure that it's part of a larger statement and not the only data point that your formula relies on.\n\n## Metrics\n\nYou can use both **resource** and **task** metrics when you're defining a formula. You adjust the target number of dedicated nodes in the pool based on the metrics data that you obtain and evaluate. See the [Variables](#variables) section above for more information on each metric.\n\n<table>\n  <tr>\n    <th>Metric</th>\n    <th>Description</th>\n  </tr>\n  <tr>\n    <td><b>Resource</b></td>\n    <td><p><b>Resource metrics</b> are based on the CPU, bandwidth, and memory usage of compute nodes, as well as the number of nodes.</p>\n        <p> These system-defined variables are useful for making adjustments based on node count:</p>\n    <p><ul>\n      <li>$TargetDedicated</li>\n            <li>$CurrentDedicated</li>\n            <li>$SampleNodeCount</li>\n    </ul></p>\n    <p>These system-defined variables are useful for making adjustments based on node resource usage:</p>\n    <p><ul>\n      <li>$CPUPercent</li>\n      <li>$WallClockSeconds</li>\n      <li>$MemoryBytes</li>\n      <li>$DiskBytes</li>\n      <li>$DiskReadBytes</li>\n      <li>$DiskWriteBytes</li>\n      <li>$DiskReadOps</li>\n      <li>$DiskWriteOps</li>\n      <li>$NetworkInBytes</li>\n      <li>$NetworkOutBytes</li></ul></p>\n  </tr>\n  <tr>\n    <td><b>Task</b></td>\n    <td><p><b>Task metrics</b> are based on the status of tasks, such as Active, Pending, and Completed. The following system-defined variables are useful for making pool-size adjustments based on task metrics:</p>\n    <p><ul>\n      <li>$ActiveTasks</li>\n      <li>$RunningTasks</li>\n      <li>$SucceededTasks</li>\n            <li>$FailedTasks</li></ul></p>\n        </td>\n  </tr>\n</table>\n\n## Build an autoscale formula\n\nYou construct an autoscale formula by forming statements that use the above components and then combining those statements into a complete formula. For example, here we construct a formula by first defining the requirements for a formula that will:\n\n1. Increase the target number of compute nodes in a pool if CPU usage is high.\n2. Decrease the target number of compute nodes in a pool when CPU usage is low.\n3. Always restrict the maximum number of nodes to 400.\n\nFor the *increase* of nodes during high CPU usage, we define the statement that populates a user-defined variable ($TotalNodes) with a value that is 110 percent of the current target number of nodes, if the minimum average CPU usage during the last 10 minutes was above 70 percent:\n\n`$TotalNodes = (min($CPUPercent.GetSample(TimeInterval_Minute*10)) > 0.7) ? ($CurrentDedicated * 1.1) : $CurrentDedicated;`\n\nThe next statement sets the same variable to 90 percent of the current target number of nodes if the average CPU usage of the past 60 minutes was *under* 20 percent. This lowers the target number during low CPU usage. Note that this statement also references the user-defined variable *$TotalNodes* from the statement above.\n\n`$TotalNodes = (avg($CPUPercent.GetSample(TimeInterval_Minute * 60)) < 0.2) ? ($CurrentDedicated * 0.9) : $TotalNodes;`\n\nNow limit the target number of dedicated compute nodes to a **maximum** of 400:\n\n`$TargetDedicated = min(400, $TotalNodes)`\n\nHere's the complete formula:\n\n```\n$TotalNodes = (min($CPUPercent.GetSample(TimeInterval_Minute*10)) > 0.7) ? ($CurrentDedicated * 1.1) : $CurrentDedicated;\n$TotalNodes = (avg($CPUPercent.GetSample(TimeInterval_Minute*60)) < 0.2) ? ($CurrentDedicated * 0.9) : $TotalNodes;\n$TargetDedicated = min(400, $TotalNodes)\n```\n\n> [AZURE.NOTE] An automatic scaling formula is comprised of [Batch REST][rest_api] API variables, types, operations, and functions. You use these in formula strings even while you're working with the [Batch .NET][net_api] library.\n\n## Create a pool with automatic scaling enabled\n\nTo enable automatic scaling when you're creating a pool, use one of the following techniques:\n\n- [New-AzureBatchPool](https://msdn.microsoft.com/library/azure/mt125936.aspx)--This Azure PowerShell cmdlet uses the AutoScaleFormula parameter to specify the automatic scaling formula.\n- [BatchClient.PoolOperations.CreatePool](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.createpool.aspx)--After this .NET method is called to create a pool, you'll then set the pool's [CloudPool.AutoScaleEnabled](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.autoscaleenabled.aspx) property and [CloudPool.AutoScaleFormula](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.autoscaleformula.aspx) property to enable automatic scaling.\n- [Add a pool to an account](https://msdn.microsoft.com/library/azure/dn820174.aspx)--The enableAutoScale and autoScaleFormula elements are used in this REST API request to set up automatic scaling for the pool when it is created.\n\n> [AZURE.IMPORTANT] If you create an autoscale-enabled pool by using one of the above techniques, the *targetDedicated* parameter for the pool must **not** be specified. Also note that if you wish to manually resize an autoscale-enabled pool (for example, with [BatchClient.PoolOperations.ResizePool][net_poolops_resizepool]), then you must first **disable** automatic scaling on the pool, then resize it.\n\nThe following code snippet shows the creation of an autoscale-enabled pool ([CloudPool][net_cloudpool]) by using the [Batch .NET][net_api] library. The pool's autoscale formula sets the target number of nodes to five on Mondays, and one on every other day of the week. In addition, the automatic scaling interval is set to 30 minutes (see [Automatic scaling interval](#interval) below). In this and the other C# snippets in this article, \"myBatchClient\" is a properly initialized instance of [BatchClient][net_batchclient].\n\n```\nCloudPool pool = myBatchClient.PoolOperations.CreatePool(\"mypool\", \"3\", \"small\");\npool.AutoScaleEnabled = true;\npool.AutoScaleFormula = \"$TargetDedicated = (time().weekday==1?5:1);\";\npool.AutoScaleEvaluationInterval = TimeSpan.FromMinutes(30);\npool.Commit();\n```\n\n### <a name=\"interval\"></a>Automatic scaling interval\n\nBy default, the Batch service adjusts a pool's size according to its autoscale formula every **15 minutes**. This interval is configurable, however, by using the following pool properties:\n\n- REST API--[autoScaleEvaluationInterval][rest_autoscaleinterval]\n- .NET API--[CloudPool.AutoScaleEvaluationInterval][net_cloudpool_autoscaleevalinterval]\n\nThe minimum interval is five minutes, and the maximum is 168 hours. If an interval outside this range is specified, the Batch service will return a Bad Request (400) error.\n\n> [AZURE.NOTE] Autoscaling is not currently intended to respond to changes in less than a minute, but rather is intended to adjust the size of your pool gradually as you run a workload.\n\n## Enable automatic scaling after a pool is created\n\nIf you've already set up a pool with a specified number of compute nodes by using the *targetDedicated* parameter, you can update the existing pool at a later time to automatically scale. You can do this in one of these ways:\n\n- [BatchClient.PoolOperations.EnableAutoScale][net_enableautoscale]--This .NET method requires the ID of an existing pool and the automatic scaling formula to apply to the pool.\n- [Enable automatic scaling on a pool][rest_enableautoscale]--This REST API request requires the ID of the existing pool in the URI and the automatic scaling formula in the request body.\n\n> [AZURE.NOTE] If a value was specified for the *targetDedicated* parameter when the pool was created, it is ignored when the automatic scaling formula is evaluated.\n\nThis code snippet demonstrates enabling autoscaling on an existing pool by using the [Batch .NET][net_api] library. Note that both enabling and updating the formula on an existing pool use the same method. As such, this technique would *update* the formula on the specified pool if autoscaling had already been enabled. The snippet assumes that \"mypool\" is the ID of an existing pool ([CloudPool][net_cloudpool]).\n\n         // Define the autoscaling formula. In this snippet, the  formula sets the target number of nodes to 5 on\n         // Mondays, and 1 on every other day of the week\n         string myAutoScaleFormula = \"$TargetDedicated = (time().weekday==1?5:1);\";\n\n         // Update the existing pool's autoscaling formula by calling the BatchClient.PoolOperations.EnableAutoScale\n         // method, passing in both the pool's ID and the new formula.\n         myBatchClient.PoolOperations.EnableAutoScale(\"mypool\", myAutoScaleFormula);\n\n## Evaluate the automatic scaling formula\n\nIt’s always a good practice to evaluate a formula before you use it in your application. A formula is evaluated by performing a \"test run\" of the formula on an existing pool. Do this by using:\n\n- [BatchClient.PoolOperations.EvaluateAutoScale](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.evaluateautoscale.aspx) or [BatchClient.PoolOperations.EvaluateAutoScaleAsync](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.evaluateautoscaleasync.aspx)--These .NET methods require the ID of an existing pool and the string that contains the automatic scaling formula. The results of the call are contained in an instance of the [AutoScaleEvaluation](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.autoscaleevaluation.aspx) class.\n- [Evaluate an automatic scaling formula](https://msdn.microsoft.com/library/azure/dn820183.aspx)--In this REST API request, the pool ID is specified in the URI. The automatic scaling formula is specified in the *autoScaleFormula* element of the request body. The response of the operation contains any error information that might be related to the formula.\n\n> [AZURE.NOTE] To evaluate an autoscale formula, you must first have enabled autoscaling on the pool by using a valid formula.\n\nIn this code snippet that uses the [Batch .NET][net_api] library, we evaluate a formula prior to applying it to the pool ([CloudPool][net_cloudpool]).\n\n```\n// First obtain a reference to the existing pool\nCloudPool pool = myBatchClient.PoolOperations.GetPool(\"mypool\");\n\n// We must ensure that autoscaling is enabled on the pool prior to evaluating a formula\nif (pool.AutoScaleEnabled.HasValue && pool.AutoScaleEnabled.Value)\n{\n    // The formula to evaluate - adjusts target number of nodes based on day of week and time of day\n    string myFormula = @\"\n        $CurTime=time();\n        $WorkHours=$CurTime.hour>=8 && $CurTime.hour<18;\n        $IsWeekday=$CurTime.weekday>=1 && $CurTime.weekday<=5;\n        $IsWorkingWeekdayHour=$WorkHours && $IsWeekday;\n        $TargetDedicated=$IsWorkingWeekdayHour?20:10;\n    \";\n\n    // Perform the autoscale formula evaluation. Note that this does not actually apply the formula to\n    // the pool.\n    AutoScaleEvaluation eval = client.PoolOperations.EvaluateAutoScale(pool.Id, myFormula);\n\n    if (eval.AutoScaleRun.Error == null)\n    {\n        // Evaluation success - print the results of the AutoScaleRun. This will display the values of each\n        // variable as evaluated by the autoscale formula.\n        Console.WriteLine(\"AutoScaleRun.Results: \" + eval.AutoScaleRun.Results);\n\n        // Apply the formula to the pool since it evaluated successfully\n        client.PoolOperations.EnableAutoScale(pool.Id, myFormula);\n    }\n    else\n    {\n        // Evaluation failed, output the message associated with the error\n        Console.WriteLine(\"AutoScaleRun.Error.Message: \" + eval.AutoScaleRun.Error.Message);\n    }\n}\n```\n\nSuccessful evaluation of the formula in this snippet will result in output similar to the following:\n\n`AutoScaleRun.Results: $TargetDedicated = 10;$NodeDeallocationOption = requeue;$CurTime = 2015 - 08 - 25T20: 08:42.271Z;$IsWeekday = 1;$IsWorkingWeekdayHour = 0;$WorkHours = 0`\n\n## Obtain information about automatic scaling runs\n\nPeriodically check the results of automatic scaling runs to ensure that a formula is performing as expected.\n\n- [CloudPool.AutoScaleRun](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.autoscalerun.aspx)--When you use the .NET library, this property of a pool provides an instance of the [AutoScaleRun](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.autoscalerun.aspx) class. This class provides the following properties of the latest automatic scaling run:\n  - [AutoScaleRun.Error](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.autoscalerun.error.aspx)\n  - [AutoScaleRun.Results](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.autoscalerun.results.aspx)\n  - [AutoScaleRun.Timestamp](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.autoscalerun.timestamp.aspx)\n- [Get information about a pool](https://msdn.microsoft.com/library/dn820165.aspx)--This REST API request returns information about the pool, which includes the latest automatic scaling run.\n\n## <a name=\"examples\"></a>Example formulas\n\nLet's take a look at some examples that show just a few ways that formulas can be used to automatically scale compute resources in a pool.\n\n### Example 1: Time-based adjustment\n\nPerhaps you want to adjust the pool size based on the day of the week and time of day, to increase or decrease the number of nodes in the pool accordingly:\n\n```\n$CurTime=time();\n$WorkHours=$CurTime.hour>=8 && $CurTime.hour<18;\n$IsWeekday=$CurTime.weekday>=1 && $CurTime.weekday<=5;\n$IsWorkingWeekdayHour=$WorkHours && $IsWeekday;\n$TargetDedicated=$IsWorkingWeekdayHour?20:10;\n```\n\nThis formula first obtains the current time. If it's a weekday (1-5) and within working hours (8 AM to 6 PM), the target pool size is set to 20 nodes. Otherwise, the pool size is targeted at 10 nodes.\n\n### Example 2: Task-based adjustment\n\nIn this example, the pool size is adjusted based on the number of tasks in the queue. Note that both comments and line breaks are acceptable in formula strings.\n\n```\n// Get pending tasks for the past 15 minutes.\n$Samples = $ActiveTasks.GetSamplePercent(TimeInterval_Minute * 15);\n// If we have fewer than 70 percent data points, we use the last sample point, otherwise we use the maximum of\n// last sample point and the history average.\n$Tasks = $Samples < 70 ? max(0,$ActiveTasks.GetSample(1)) : max( $ActiveTasks.GetSample(1), avg($ActiveTasks.GetSample(TimeInterval_Minute * 15)));\n// If number of pending tasks is not 0, set targetVM to pending tasks, otherwise half of current dedicated.\n$TargetVMs = $Tasks > 0? $Tasks:max(0, $TargetDedicated/2);\n// The pool size is capped at 20, if target VM value is more than that, set it to 20. This value\n// should be adjusted according to your use case.\n$TargetDedicated = max(0,min($TargetVMs,20));\n// Set node deallocation mode - keep nodes active only until tasks finish\n$NodeDeallocationOption = taskcompletion;\n```\n\n### Example 3: Accounting for parallel tasks\n\nThis is another example that adjusts the pool size based on the number of tasks. This formula also takes into account the [MaxTasksPerComputeNode][net_maxtasks] value that has been set for the pool. This is particularly useful in situations where [parallel task execution](batch-parallel-node-tasks.md) has been enabled on your pool.\n\n```\n// Determine whether 70 percent of the samples have been recorded in the past 15 minutes; if not, use last sample\n$Samples = $ActiveTasks.GetSamplePercent(TimeInterval_Minute * 15);\n$Tasks = $Samples < 70 ? max(0,$ActiveTasks.GetSample(1)) : max( $ActiveTasks.GetSample(1),avg($ActiveTasks.GetSample(TimeInterval_Minute * 15)));\n// Set the number of nodes to add to one-fourth the number of active tasks (the MaxTasksPerComputeNode\n// property on this pool is set to 4, adjust this number for your use case)\n$Cores = $TargetDedicated * 4;\n$ExtraVMs = (($Tasks - $Cores) + 3) / 4;\n$TargetVMs = ($TargetDedicated+$ExtraVMs);\n// Attempt to grow the number of compute nodes to match the number of active tasks, with a maximum of 3\n$TargetDedicated = max(0,min($TargetVMs,3));\n// Keep the nodes active until the tasks finish\n$NodeDeallocationOption = taskcompletion;\n```\n\n### Example 4: Setting an initial pool size\n\nThis example shows a C# code snippet with an autoscale formula that sets the pool size to a certain number of nodes for an initial time period. Then it adjusts the pool size based on the number of running and active tasks after the initial time period has elapsed.\n\n```\nstring now = DateTime.UtcNow.ToString(\"r\");\nstring formula = string.Format(@\"\n\n    $TargetDedicated = {1};\n    lifespan         = time() - time(\"\"{0}\"\");\n    span             = TimeInterval_Minute * 60;\n    startup          = TimeInterval_Minute * 10;\n    ratio            = 50;\n\n    $TargetDedicated = (lifespan > startup ? (max($RunningTasks.GetSample(span, ratio), $ActiveTasks.GetSample(span, ratio)) == 0 ? 0 : $TargetDedicated) : {1});\n    \", now, 4);\n```\n\nThe formula in the above code snippet:\n\n- Sets the initial pool size to four nodes.\n- Does not adjust the pool size within the first 10 minutes of the pool's lifecycle.\n- After 10 minutes, obtains the max value of the number of running and active tasks within the past 60 minutes.\n  - If both values are 0 (indicating that no tasks were running or active in the last 60 minutes), the pool size is set to 0.\n  - If either value is greater than zero, no change is made.\n\n## Next steps\n\n1. To fully assess the efficiency of your application, you might need to access a compute node. To take advantage of remote access, a user account must be added to the node that you want to access, and a Remote Desktop Protocol (RDP) file must be retrieved for that node.\n    - Add the user account in one of these ways:\n        * [New-AzureBatchVMUser](https://msdn.microsoft.com/library/mt149846.aspx)--This PowerShell cmdlet takes the pool name, compute node name, account name, and password as parameters.\n        * [BatchClient.PoolOperations.CreateComputeNodeUser](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.createcomputenodeuser.aspx)--This .NET method creates an instance of the [ComputeNodeUser](https://msdn.microsoft.com/library/microsoft.azure.batch.computenodeuser.aspx) class, on which the account name and password can be set for the compute node. [ComputeNodeUser.Commit](https://msdn.microsoft.com/library/microsoft.azure.batch.computenodeuser.commit.aspx) is then called on the instance to create the user on that node.\n        * [Add a user account to a node](https://msdn.microsoft.com/library/dn820137.aspx)--The name of the pool and the compute node are specified in the URI. The account name and password are sent to the node in the request body of this REST API request.\n    - Get the RDP file:\n        * [BatchClient.PoolOperations.GetRDPFile](https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.getrdpfile.aspx)--This .NET method requires the ID of the pool, the node ID, and the name of the RDP file to create.\n        * [Get a remote desktop protocol file from a node](https://msdn.microsoft.com/library/dn820120.aspx)--This REST API request requires the name of the pool and the name of the compute node. The response contains the contents of the RDP file.\n        * [Get-AzureBatchRDPFile](https://msdn.microsoft.com/library/mt149851.aspx)--This PowerShell cmdlet gets the RDP file from the specified compute node and saves it to the specified file location or to a stream.\n2.  Some applications produce large amounts of data that can be difficult to process. One way to solve this is through [efficient list querying](batch-efficient-list-queries.md).\n\n[net_api]: https://msdn.microsoft.com/library/azure/mt348682.aspx\n[net_batchclient]: http://msdn.microsoft.com/library/azure/microsoft.azure.batch.batchclient.aspx\n[net_cloudpool]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.aspx\n[net_cloudpool_autoscaleformula]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.autoscaleformula.aspx\n[net_cloudpool_autoscaleevalinterval]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.autoscaleevaluationinterval.aspx\n[net_enableautoscale]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.enableautoscale.aspx\n[net_maxtasks]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.maxtaskspercomputenode.aspx\n[net_poolops_resizepool]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.resizepool.aspx\n\n[rest_api]: https://msdn.microsoft.com/library/azure/dn820158.aspx\n[rest_autoscaleformula]: https://msdn.microsoft.com/library/azure/dn820173.aspx\n[rest_autoscaleinterval]: https://msdn.microsoft.com/en-us/library/azure/dn820173.aspx\n[rest_enableautoscale]: https://msdn.microsoft.com/library/azure/dn820173.aspx\n"
}