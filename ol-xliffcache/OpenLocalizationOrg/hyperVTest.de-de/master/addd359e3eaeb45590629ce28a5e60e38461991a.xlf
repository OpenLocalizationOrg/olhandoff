<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="de-de">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Access Hadoop YARN application logs on Linux-based HDInsight | Microsoft Azure</source>
          <target state="new">Access Hadoop YARN application logs on Linux-based HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to access YARN application logs on a Linux-based HDInsight (Hadoop) cluster using both the command-line and a web browser.</source>
          <target state="new">Learn how to access YARN application logs on a Linux-based HDInsight (Hadoop) cluster using both the command-line and a web browser.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Access YARN application logs on Linux-based HDInsight</source>
          <target state="new">Access YARN application logs on Linux-based HDInsight</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>This document explains how to access the logs for YARN (Yet Another Resource Negotiator) applications that have finished on a Hadoop cluster in Azure HDInsight.</source>
          <target state="new">This document explains how to access the logs for YARN (Yet Another Resource Negotiator) applications that have finished on a Hadoop cluster in Azure HDInsight.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source><ph id="ph2">[AZURE.NOTE]</ph><ph id="ph3" /> The information in this document is specific to Linux-based HDInsight clusters.</source>
          <target state="new"><ph id="ph2">[AZURE.NOTE]</ph><ph id="ph3" /> The information in this document is specific to Linux-based HDInsight clusters.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>For information on Windows-based clusters, see <bpt id="p1">[</bpt>Access YARN application logs on Windows-based HDInsight<ept id="p1">](hdinsight-hadoop-access-yarn-app-logs.md)</ept></source>
          <target state="new">For information on Windows-based clusters, see <bpt id="p1">[</bpt>Access YARN application logs on Windows-based HDInsight<ept id="p1">](hdinsight-hadoop-access-yarn-app-logs.md)</ept></target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Prerequisites</source>
          <target state="new">Prerequisites</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>A Linux-based HDInsight cluster.</source>
          <target state="new">A Linux-based HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>You must <bpt id="p2">[</bpt>create an SSH tunnel<ept id="p2">](hdinsight-linux-ambari-ssh-tunnel.md)</ept><ph id="ph4" /> before you can access the ResourceManager Logs web UI.</source>
          <target state="new">You must <bpt id="p2">[</bpt>create an SSH tunnel<ept id="p2">](hdinsight-linux-ambari-ssh-tunnel.md)</ept><ph id="ph4" /> before you can access the ResourceManager Logs web UI.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>YARN Timeline Server</source>
          <target state="new">YARN Timeline Server</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>The <bpt id="p3">[</bpt>YARN Timeline Server<ept id="p3">](http://hadoop.apache.org/docs/r2.4.0/hadoop-yarn/hadoop-yarn-site/TimelineServer.html)</ept><ph id="ph5" /> provides generic information on completed applications as well as framework-specific application information through two different interfaces.</source>
          <target state="new">The <bpt id="p3">[</bpt>YARN Timeline Server<ept id="p3">](http://hadoop.apache.org/docs/r2.4.0/hadoop-yarn/hadoop-yarn-site/TimelineServer.html)</ept><ph id="ph5" /> provides generic information on completed applications as well as framework-specific application information through two different interfaces.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Specifically:</source>
          <target state="new">Specifically:</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Storage and retrieval of generic application information on HDInsight clusters has been enabled with version 3.1.1.374 or higher.</source>
          <target state="new">Storage and retrieval of generic application information on HDInsight clusters has been enabled with version 3.1.1.374 or higher.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>The framework-specific application information component of the Timeline Server is not currently available on HDInsight clusters.</source>
          <target state="new">The framework-specific application information component of the Timeline Server is not currently available on HDInsight clusters.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Generic information on applications includes the following sorts of data:</source>
          <target state="new">Generic information on applications includes the following sorts of data:</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>The application ID, a unique identifier of an application</source>
          <target state="new">The application ID, a unique identifier of an application</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>The user who started the application</source>
          <target state="new">The user who started the application</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Information on attempts made to complete the application</source>
          <target state="new">Information on attempts made to complete the application</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>The containers used by any given application attempt</source>
          <target state="new">The containers used by any given application attempt</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>YARN applications and logs</source>
          <target state="new">YARN applications and logs</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>YARN supports multiple programming models (MapReduce being one of them) by decoupling resource management from application scheduling/monitoring.</source>
          <target state="new">YARN supports multiple programming models (MapReduce being one of them) by decoupling resource management from application scheduling/monitoring.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>This is done through a global <bpt id="p4">*</bpt>ResourceManager<ept id="p4">*</ept><ph id="ph6" /> (RM), per-worker-node <bpt id="p5">*</bpt>NodeManagers<ept id="p5">*</ept><ph id="ph7" /> (NMs), and per-application <bpt id="p6">*</bpt>ApplicationMasters<ept id="p6">*</ept><ph id="ph8" /> (AMs).</source>
          <target state="new">This is done through a global <bpt id="p4">*</bpt>ResourceManager<ept id="p4">*</ept><ph id="ph6" /> (RM), per-worker-node <bpt id="p5">*</bpt>NodeManagers<ept id="p5">*</ept><ph id="ph7" /> (NMs), and per-application <bpt id="p6">*</bpt>ApplicationMasters<ept id="p6">*</ept><ph id="ph8" /> (AMs).</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>The per-application AM negotiates resources (CPU, memory, disk, network) for running your application with the RM.</source>
          <target state="new">The per-application AM negotiates resources (CPU, memory, disk, network) for running your application with the RM.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>The RM works with NMs to grant these resources, which are granted as <bpt id="p7">*</bpt>containers<ept id="p7">*</ept>.</source>
          <target state="new">The RM works with NMs to grant these resources, which are granted as <bpt id="p7">*</bpt>containers<ept id="p7">*</ept>.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>The AM is responsible for tracking the progress of the containers assigned to it by the RM.</source>
          <target state="new">The AM is responsible for tracking the progress of the containers assigned to it by the RM.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>An application may require many containers depending on the nature of the application.</source>
          <target state="new">An application may require many containers depending on the nature of the application.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Furthermore, each application may consist of multiple <bpt id="p8">*</bpt>application attempts<ept id="p8">*</ept><ph id="ph9" /> in order to finish in the presence of crashes or due to the loss of communication between an AM and an RM.</source>
          <target state="new">Furthermore, each application may consist of multiple <bpt id="p8">*</bpt>application attempts<ept id="p8">*</ept><ph id="ph9" /> in order to finish in the presence of crashes or due to the loss of communication between an AM and an RM.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Hence, containers are granted to a specific attempt of an application.</source>
          <target state="new">Hence, containers are granted to a specific attempt of an application.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>In a sense, a container provides the context for basic unit of work performed by a YARN application, and all work that is done within the context of a container is performed on the single worker node on which the container was allocated.</source>
          <target state="new">In a sense, a container provides the context for basic unit of work performed by a YARN application, and all work that is done within the context of a container is performed on the single worker node on which the container was allocated.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>See <bpt id="p9">[</bpt>YARN Concepts<ept id="p9">][YARN-concepts]</ept><ph id="ph10" /> for further reference.</source>
          <target state="new">See <bpt id="p9">[</bpt>YARN Concepts<ept id="p9">][YARN-concepts]</ept><ph id="ph10" /> for further reference.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>Application logs (and the associated container logs) are critical in debugging problematic Hadoop applications.</source>
          <target state="new">Application logs (and the associated container logs) are critical in debugging problematic Hadoop applications.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>YARN provides a nice framework for collecting, aggregating, and storing application logs with the <bpt id="p10">[</bpt>Log Aggregation<ept id="p10">][log-aggregation]</ept><ph id="ph11" /> feature.</source>
          <target state="new">YARN provides a nice framework for collecting, aggregating, and storing application logs with the <bpt id="p10">[</bpt>Log Aggregation<ept id="p10">][log-aggregation]</ept><ph id="ph11" /> feature.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>The Log Aggregation feature makes accessing application logs more deterministic, as it aggregates logs across all containers on a worker node and stores them as one aggregated log file per worker node on the default file system after an application finishes.</source>
          <target state="new">The Log Aggregation feature makes accessing application logs more deterministic, as it aggregates logs across all containers on a worker node and stores them as one aggregated log file per worker node on the default file system after an application finishes.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Your application may use hundreds or thousands of containers, but logs for all containers run on a single worker node will always be aggregated to a single file, resulting in one log file per worker node used by your application.</source>
          <target state="new">Your application may use hundreds or thousands of containers, but logs for all containers run on a single worker node will always be aggregated to a single file, resulting in one log file per worker node used by your application.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Log Aggregation is enabled by default on HDInsight clusters (version 3.0 and above), and aggregated logs can be found in the default container of your cluster at the following location:</source>
          <target state="new">Log Aggregation is enabled by default on HDInsight clusters (version 3.0 and above), and aggregated logs can be found in the default container of your cluster at the following location:</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>In that location, <bpt id="p11">*</bpt>user<ept id="p11">*</ept><ph id="ph12" /> is the name of the user who started the application, and <bpt id="p12">*</bpt>applicationId<ept id="p12">*</ept><ph id="ph13" /> is the unique identifier of an application as assigned by the YARN RM.</source>
          <target state="new">In that location, <bpt id="p11">*</bpt>user<ept id="p11">*</ept><ph id="ph12" /> is the name of the user who started the application, and <bpt id="p12">*</bpt>applicationId<ept id="p12">*</ept><ph id="ph13" /> is the unique identifier of an application as assigned by the YARN RM.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>The aggregated logs are not directly readable, as they are written in a <bpt id="p13">[</bpt>TFile<ept id="p13">][T-file]</ept>, <bpt id="p14">[</bpt>binary format<ept id="p14">][binary-format]</ept><ph id="ph14" /> indexed by container.</source>
          <target state="new">The aggregated logs are not directly readable, as they are written in a <bpt id="p13">[</bpt>TFile<ept id="p13">][T-file]</ept>, <bpt id="p14">[</bpt>binary format<ept id="p14">][binary-format]</ept><ph id="ph14" /> indexed by container.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>You must use the YARN ResourceManager logs or CLI tools to view these logs as plain text for applications or containers of interest.</source>
          <target state="new">You must use the YARN ResourceManager logs or CLI tools to view these logs as plain text for applications or containers of interest.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>YARN CLI tools</source>
          <target state="new">YARN CLI tools</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>In order to use the YARN CLI tools, you must first connect to the HDInsight cluster using SSH.</source>
          <target state="new">In order to use the YARN CLI tools, you must first connect to the HDInsight cluster using SSH.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Use one of the following documents for information on using SSH with HDInsight:</source>
          <target state="new">Use one of the following documents for information on using SSH with HDInsight:</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source><bpt id="p15">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X<ept id="p15">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept></source>
          <target state="new"><bpt id="p15">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X<ept id="p15">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept></target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source><bpt id="p16">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id="p16">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept></source>
          <target state="new"><bpt id="p16">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id="p16">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept></target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>You can view these logs as plain text by running one of the following commands:</source>
          <target state="new">You can view these logs as plain text by running one of the following commands:</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>You must specify the &amp;lt;applicationId&gt;, &amp;lt;user-who-started-the-application&gt;, &amp;lt;containerId&gt;, and &amp;ltworker-node-address&gt; information when running these commands.</source>
          <target state="new">You must specify the &amp;lt;applicationId&gt;, &amp;lt;user-who-started-the-application&gt;, &amp;lt;containerId&gt;, and &amp;ltworker-node-address&gt; information when running these commands.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>YARN ResourceManager UI</source>
          <target state="new">YARN ResourceManager UI</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>The YARN ResourceManager UI runs on the cluster headnode, and can be accessed through the Ambari web UI; however, you must first <bpt id="p17">[</bpt>create an SSH tunnel<ept id="p17">](hdinsight-linux-ambari-ssh-tunnel.md)</ept><ph id="ph15" /> before you can access the ResourceManager UI.</source>
          <target state="new">The YARN ResourceManager UI runs on the cluster headnode, and can be accessed through the Ambari web UI; however, you must first <bpt id="p17">[</bpt>create an SSH tunnel<ept id="p17">](hdinsight-linux-ambari-ssh-tunnel.md)</ept><ph id="ph15" /> before you can access the ResourceManager UI.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Once you have created an SSH tunnel, use the following steps to view the YARN logs:</source>
          <target state="new">Once you have created an SSH tunnel, use the following steps to view the YARN logs:</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>In your web browser, navigate to https://CLUSTERNAME.azurehdinsight.net.</source>
          <target state="new">In your web browser, navigate to https://CLUSTERNAME.azurehdinsight.net.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Replace CLUSTERNAME with the name of your HDInsight cluster.</source>
          <target state="new">Replace CLUSTERNAME with the name of your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>From the list of services on the left, select <bpt id="p18">__</bpt>YARN<ept id="p18">__</ept>.</source>
          <target state="new">From the list of services on the left, select <bpt id="p18">__</bpt>YARN<ept id="p18">__</ept>.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source><ph id="ph16">![</ph>Yarn service selected<ph id="ph17">](./media/hdinsight-hadoop-access-yarn-app-logs-linux/yarnservice.png)</ph></source>
          <target state="new"><ph id="ph16">![</ph>Yarn service selected<ph id="ph17">](./media/hdinsight-hadoop-access-yarn-app-logs-linux/yarnservice.png)</ph></target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>From the <bpt id="p19">__</bpt>Quick Links<ept id="p19">__</ept><ph id="ph18" /> dropdown, select one of the cluster head nodes and then select <bpt id="p20">__</bpt>ResourceManager Log<ept id="p20">__</ept>.</source>
          <target state="new">From the <bpt id="p19">__</bpt>Quick Links<ept id="p19">__</ept><ph id="ph18" /> dropdown, select one of the cluster head nodes and then select <bpt id="p20">__</bpt>ResourceManager Log<ept id="p20">__</ept>.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source><ph id="ph19">![</ph>Yarn quick linnks<ph id="ph20">](./media/hdinsight-hadoop-access-yarn-app-logs-linux/yarnquicklinks.png)</ph></source>
          <target state="new"><ph id="ph19">![</ph>Yarn quick linnks<ph id="ph20">](./media/hdinsight-hadoop-access-yarn-app-logs-linux/yarnquicklinks.png)</ph></target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>You will be presented with a list of links to YARN logs.</source>
          <target state="new">You will be presented with a list of links to YARN logs.</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">addd359e3eaeb45590629ce28a5e60e38461991a</xliffext:olfilehash>
  </header>
</xliff>