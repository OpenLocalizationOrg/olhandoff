{
  "nodes": [
    {
      "pos": [
        26,
        90
      ],
      "content": "Hive query with Hadoop tools for Visual Studio | Microsoft Azure"
    },
    {
      "pos": [
        108,
        188
      ],
      "content": "Learn how to use Hive with Hadoop in HDInsight using Visual Studio Hadoop tools."
    },
    {
      "pos": [
        505,
        565
      ],
      "content": "Run Hive queries using the HDInsight tools for Visual Studio"
    },
    {
      "pos": [
        647,
        774
      ],
      "content": "In this article, you will learn how to submit Hive queries to an HDInsight cluster using the HDInsight tools for Visual Studio."
    },
    {
      "pos": [
        778,
        1026
      ],
      "content": "<ph id=\"ph3\">[AZURE.NOTE]</ph><ph id=\"ph4\"/> This document does not provide a detailed description of what the HiveQL statements used in the examples do. For information about the HiveQL that is used in this example, see <bpt id=\"p1\">[</bpt>Use Hive with Hadoop on HDInsight<ept id=\"p1\">](hdinsight-use-hive.md)</ept>.",
      "nodes": [
        {
          "content": "<ph id=\"ph3\">[AZURE.NOTE]</ph><ph id=\"ph4\"/> This document does not provide a detailed description of what the HiveQL statements used in the examples do.",
          "pos": [
            0,
            153
          ]
        },
        {
          "content": "For information about the HiveQL that is used in this example, see <bpt id=\"p1\">[</bpt>Use Hive with Hadoop on HDInsight<ept id=\"p1\">](hdinsight-use-hive.md)</ept>.",
          "pos": [
            154,
            318
          ]
        }
      ]
    },
    {
      "pos": [
        1028,
        1030
      ],
      "content": "##"
    },
    {
      "pos": [
        1049,
        1062
      ],
      "content": "Prerequisites"
    },
    {
      "pos": [
        1064,
        1131
      ],
      "content": "To complete the steps in this article, you will need the following."
    },
    {
      "pos": [
        1135,
        1208
      ],
      "content": "An Azure HDInsight (Hadoop on HDInsight) cluster (Linux or Windows-based)"
    },
    {
      "pos": [
        1212,
        1466
      ],
      "content": "Visual Studio 2012 <bpt id=\"p2\">[</bpt>Update 4<ept id=\"p2\">](http://www.microsoft.com/download/details.aspx?id=39305)</ept>, Visual Studio 2013 <bpt id=\"p3\">[</bpt>Update 3<ept id=\"p3\">](http://go.microsoft.com/fwlink/?LinkId=390465)</ept>, or <bpt id=\"p4\">[</bpt>Visual Studio Express 2013<ept id=\"p4\">](http://www.microsoft.com/download/details.aspx?id=40769)</ept>"
    },
    {
      "pos": [
        1468,
        1470
      ],
      "content": "##"
    },
    {
      "pos": [
        1487,
        1547
      ],
      "content": "Run Hive queries using the HDInsight tools for Visual Studio"
    },
    {
      "pos": [
        1552,
        1680
      ],
      "content": "Open <bpt id=\"p5\">**</bpt>Visual Studio<ept id=\"p5\">**</ept><ph id=\"ph5\"/> and select <bpt id=\"p6\">**</bpt>New<ept id=\"p6\">**</ept><ph id=\"ph6\"/> &gt; <bpt id=\"p7\">**</bpt>Project<ept id=\"p7\">**</ept><ph id=\"ph7\"/> &gt; <bpt id=\"p8\">**</bpt>HDInsight<ept id=\"p8\">**</ept><ph id=\"ph8\"/> &gt; <bpt id=\"p9\">**</bpt>Hive Application<ept id=\"p9\">**</ept>. Provide a name for this project.",
      "nodes": [
        {
          "content": "Open <bpt id=\"p5\">**</bpt>Visual Studio<ept id=\"p5\">**</ept><ph id=\"ph5\"/> and select <bpt id=\"p6\">**</bpt>New<ept id=\"p6\">**</ept><ph id=\"ph6\"/> &gt; <bpt id=\"p7\">**</bpt>Project<ept id=\"p7\">**</ept><ph id=\"ph7\"/> &gt; <bpt id=\"p8\">**</bpt>HDInsight<ept id=\"p8\">**</ept><ph id=\"ph8\"/> &gt; <bpt id=\"p9\">**</bpt>Hive Application<ept id=\"p9\">**</ept>.",
          "pos": [
            0,
            350
          ]
        },
        {
          "content": "Provide a name for this project.",
          "pos": [
            351,
            383
          ]
        }
      ]
    },
    {
      "pos": [
        1685,
        1794
      ],
      "content": "Open the <bpt id=\"p10\">**</bpt>Script.hql<ept id=\"p10\">**</ept><ph id=\"ph9\"/> file that is created with this project, and paste in the following HiveQL statements:"
    },
    {
      "pos": [
        2192,
        2239
      ],
      "content": "These statements perform the following actions:"
    },
    {
      "pos": [
        2247,
        2327
      ],
      "content": "<bpt id=\"p11\">**</bpt>DROP TABLE<ept id=\"p11\">**</ept>: Deletes the table and the data file if the table already exists."
    },
    {
      "pos": [
        2334,
        2501
      ],
      "content": "<bpt id=\"p12\">**</bpt>CREATE EXTERNAL TABLE<ept id=\"p12\">**</ept>: Creates a new 'external' table in Hive. External tables only store the table definition in Hive (the data is left in the original location).",
      "nodes": [
        {
          "content": "<bpt id=\"p12\">**</bpt>CREATE EXTERNAL TABLE<ept id=\"p12\">**</ept>: Creates a new 'external' table in Hive.",
          "pos": [
            0,
            106
          ]
        },
        {
          "content": "External tables only store the table definition in Hive (the data is left in the original location).",
          "pos": [
            107,
            207
          ]
        }
      ]
    },
    {
      "pos": [
        2513,
        2763
      ],
      "content": "<ph id=\"ph10\">[AZURE.NOTE]</ph><ph id=\"ph11\"/> External tables should be used when you expect the underlying data to be updated by an external source (such as an automated data upload process) or by another MapReduce operation, but you always want Hive queries to use the latest data."
    },
    {
      "pos": [
        2784,
        2867
      ],
      "content": "Dropping an external table does <bpt id=\"p13\">**</bpt>not<ept id=\"p13\">**</ept><ph id=\"ph12\"/> delete the data, only the table definition."
    },
    {
      "pos": [
        2875,
        2991
      ],
      "content": "<bpt id=\"p14\">**</bpt>ROW FORMAT<ept id=\"p14\">**</ept>: Tells Hive how the data is formatted. In this case, the fields in each log are separated by a space.",
      "nodes": [
        {
          "content": "<bpt id=\"p14\">**</bpt>ROW FORMAT<ept id=\"p14\">**</ept>: Tells Hive how the data is formatted.",
          "pos": [
            0,
            93
          ]
        },
        {
          "content": "In this case, the fields in each log are separated by a space.",
          "pos": [
            94,
            156
          ]
        }
      ]
    },
    {
      "pos": [
        2998,
        3126
      ],
      "content": "<bpt id=\"p15\">**</bpt>STORED AS TEXTFILE LOCATION<ept id=\"p15\">**</ept>: Tells Hive where the data is stored (the example/data directory) and that it is stored as text."
    },
    {
      "pos": [
        3133,
        3312
      ],
      "content": "<bpt id=\"p16\">**</bpt>SELECT<ept id=\"p16\">**</ept>: Select a count of all rows where column <bpt id=\"p17\">**</bpt>t4<ept id=\"p17\">**</ept><ph id=\"ph13\"/> contain the value <bpt id=\"p18\">**</bpt>[ERROR]<ept id=\"p18\">**</ept>. This should return a value of <bpt id=\"p19\">**</bpt>3<ept id=\"p19\">**</ept><ph id=\"ph14\"/> because there are three rows that contain this value.",
      "nodes": [
        {
          "content": "<bpt id=\"p16\">**</bpt>SELECT<ept id=\"p16\">**</ept>: Select a count of all rows where column <bpt id=\"p17\">**</bpt>t4<ept id=\"p17\">**</ept><ph id=\"ph13\"/> contain the value <bpt id=\"p18\">**</bpt>[ERROR]<ept id=\"p18\">**</ept>.",
          "pos": [
            0,
            224
          ]
        },
        {
          "content": "This should return a value of <bpt id=\"p19\">**</bpt>3<ept id=\"p19\">**</ept><ph id=\"ph14\"/> because there are three rows that contain this value.",
          "pos": [
            225,
            369
          ]
        }
      ]
    },
    {
      "pos": [
        3319,
        3602
      ],
      "content": "<bpt id=\"p20\">**</bpt>INPUT__FILE__NAME LIKE '%.log'<ept id=\"p20\">**</ept><ph id=\"ph15\"/> - Tells Hive that we should only return data from files ending in .log. This restricts the search to the sample.log file that contains the data, and keeps it from returning data from other example data files that do not match the schema we defined.",
      "nodes": [
        {
          "content": "<bpt id=\"p20\">**</bpt>INPUT__FILE__NAME LIKE '%.log'<ept id=\"p20\">**</ept><ph id=\"ph15\"/> - Tells Hive that we should only return data from files ending in .log.",
          "pos": [
            0,
            161
          ]
        },
        {
          "content": "This restricts the search to the sample.log file that contains the data, and keeps it from returning data from other example data files that do not match the schema we defined.",
          "pos": [
            162,
            338
          ]
        }
      ]
    },
    {
      "pos": [
        3607,
        3947
      ],
      "content": "From the toolbar, select the <bpt id=\"p21\">**</bpt>HDInsight Cluster<ept id=\"p21\">**</ept><ph id=\"ph16\"/> that you want to use for this query, and then select <bpt id=\"p22\">**</bpt>Submit<ept id=\"p22\">**</ept><ph id=\"ph17\"/> to run the statements as a Hive job. The <bpt id=\"p23\">**</bpt>Hive Job Summary<ept id=\"p23\">**</ept><ph id=\"ph18\"/> appears and displays information about the running job. Use the <bpt id=\"p24\">**</bpt>Refresh<ept id=\"p24\">**</ept><ph id=\"ph19\"/> link to refresh the job information, until the <bpt id=\"p25\">**</bpt>Job Status<ept id=\"p25\">**</ept><ph id=\"ph20\"/> changes to <bpt id=\"p26\">**</bpt>Completed<ept id=\"p26\">**</ept>.",
      "nodes": [
        {
          "content": "From the toolbar, select the <bpt id=\"p21\">**</bpt>HDInsight Cluster<ept id=\"p21\">**</ept><ph id=\"ph16\"/> that you want to use for this query, and then select <bpt id=\"p22\">**</bpt>Submit<ept id=\"p22\">**</ept><ph id=\"ph17\"/> to run the statements as a Hive job.",
          "pos": [
            0,
            261
          ]
        },
        {
          "content": "The <bpt id=\"p23\">**</bpt>Hive Job Summary<ept id=\"p23\">**</ept><ph id=\"ph18\"/> appears and displays information about the running job.",
          "pos": [
            262,
            397
          ]
        },
        {
          "content": "Use the <bpt id=\"p24\">**</bpt>Refresh<ept id=\"p24\">**</ept><ph id=\"ph19\"/> link to refresh the job information, until the <bpt id=\"p25\">**</bpt>Job Status<ept id=\"p25\">**</ept><ph id=\"ph20\"/> changes to <bpt id=\"p26\">**</bpt>Completed<ept id=\"p26\">**</ept>.",
          "pos": [
            398,
            655
          ]
        }
      ]
    },
    {
      "pos": [
        3952,
        4095
      ],
      "content": "Use the <bpt id=\"p27\">**</bpt>Job Output<ept id=\"p27\">**</ept><ph id=\"ph21\"/> link to view the output of this job. It should display <ph id=\"ph22\">`[ERROR] 3`</ph>, which is the value returned by the SELECT statement.",
      "nodes": [
        {
          "content": "Use the <bpt id=\"p27\">**</bpt>Job Output<ept id=\"p27\">**</ept><ph id=\"ph21\"/> link to view the output of this job.",
          "pos": [
            0,
            114
          ]
        },
        {
          "content": "It should display <ph id=\"ph22\">`[ERROR] 3`</ph>, which is the value returned by the SELECT statement.",
          "pos": [
            115,
            217
          ]
        }
      ]
    },
    {
      "pos": [
        4100,
        4293
      ],
      "content": "You can also run Hive queries without creating a project. Using <bpt id=\"p28\">**</bpt>Server Explorer<ept id=\"p28\">**</ept>, expand <bpt id=\"p29\">**</bpt>Azure<ept id=\"p29\">**</ept><ph id=\"ph23\"/> &gt; <bpt id=\"p30\">**</bpt>HDInsight<ept id=\"p30\">**</ept>, right-click your HDInsight server, and then select <bpt id=\"p31\">**</bpt>Write a Hive Query<ept id=\"p31\">**</ept>.",
      "nodes": [
        {
          "content": "You can also run Hive queries without creating a project.",
          "pos": [
            0,
            57
          ]
        },
        {
          "content": "Using <bpt id=\"p28\">**</bpt>Server Explorer<ept id=\"p28\">**</ept>, expand <bpt id=\"p29\">**</bpt>Azure<ept id=\"p29\">**</ept><ph id=\"ph23\"/> &gt; <bpt id=\"p30\">**</bpt>HDInsight<ept id=\"p30\">**</ept>, right-click your HDInsight server, and then select <bpt id=\"p31\">**</bpt>Write a Hive Query<ept id=\"p31\">**</ept>.",
          "pos": [
            58,
            371
          ]
        }
      ]
    },
    {
      "pos": [
        4298,
        4377
      ],
      "content": "In the <bpt id=\"p32\">**</bpt>temp.hql<ept id=\"p32\">**</ept><ph id=\"ph24\"/> document that appears, add the following HiveQL statements:"
    },
    {
      "pos": [
        4669,
        4716
      ],
      "content": "These statements perform the following actions:"
    },
    {
      "pos": [
        4724,
        4952
      ],
      "content": "<bpt id=\"p33\">**</bpt>CREATE TABLE IF NOT EXISTS<ept id=\"p33\">**</ept>: Creates a table if it does not already exist. Because the <bpt id=\"p34\">**</bpt>EXTERNAL<ept id=\"p34\">**</ept><ph id=\"ph25\"/> keyword is not used, this is an internal table, which is stored in the Hive data warehouse and is managed completely by Hive.",
      "nodes": [
        {
          "content": "<bpt id=\"p33\">**</bpt>CREATE TABLE IF NOT EXISTS<ept id=\"p33\">**</ept>: Creates a table if it does not already exist.",
          "pos": [
            0,
            117
          ]
        },
        {
          "content": "Because the <bpt id=\"p34\">**</bpt>EXTERNAL<ept id=\"p34\">**</ept><ph id=\"ph25\"/> keyword is not used, this is an internal table, which is stored in the Hive data warehouse and is managed completely by Hive.",
          "pos": [
            118,
            323
          ]
        }
      ]
    },
    {
      "pos": [
        4964,
        5065
      ],
      "content": "<ph id=\"ph26\">[AZURE.NOTE]</ph><ph id=\"ph27\"/> Unlike <bpt id=\"p35\">**</bpt>EXTERNAL<ept id=\"p35\">**</ept><ph id=\"ph28\"/> tables, dropping an internal table also deletes the underlying data."
    },
    {
      "pos": [
        5073,
        5218
      ],
      "content": "<bpt id=\"p36\">**</bpt>STORED AS ORC<ept id=\"p36\">**</ept>: Stores the data in optimized row columnar (ORC) format. This is a highly optimized and efficient format for storing Hive data.",
      "nodes": [
        {
          "content": "<bpt id=\"p36\">**</bpt>STORED AS ORC<ept id=\"p36\">**</ept>: Stores the data in optimized row columnar (ORC) format.",
          "pos": [
            0,
            114
          ]
        },
        {
          "content": "This is a highly optimized and efficient format for storing Hive data.",
          "pos": [
            115,
            185
          ]
        }
      ]
    },
    {
      "pos": [
        5225,
        5377
      ],
      "content": "<bpt id=\"p37\">**</bpt>INSERT OVERWRITE ... SELECT<ept id=\"p37\">**</ept>: Selects rows from the <bpt id=\"p38\">**</bpt>log4jLogs<ept id=\"p38\">**</ept><ph id=\"ph29\"/> table that contain <bpt id=\"p39\">**</bpt>[ERROR]<ept id=\"p39\">**</ept>, then inserts the data into the <bpt id=\"p40\">**</bpt>errorLogs<ept id=\"p40\">**</ept><ph id=\"ph30\"/> table."
    },
    {
      "pos": [
        5382,
        5510
      ],
      "content": "From the toolbar, select <bpt id=\"p41\">**</bpt>Submit<ept id=\"p41\">**</ept><ph id=\"ph31\"/> to run the job. Use the <bpt id=\"p42\">**</bpt>Job Status<ept id=\"p42\">**</ept><ph id=\"ph32\"/> to determine that the job has completed successfully.",
      "nodes": [
        {
          "content": "From the toolbar, select <bpt id=\"p41\">**</bpt>Submit<ept id=\"p41\">**</ept><ph id=\"ph31\"/> to run the job.",
          "pos": [
            0,
            106
          ]
        },
        {
          "content": "Use the <bpt id=\"p42\">**</bpt>Job Status<ept id=\"p42\">**</ept><ph id=\"ph32\"/> to determine that the job has completed successfully.",
          "pos": [
            107,
            238
          ]
        }
      ]
    },
    {
      "pos": [
        5515,
        5766
      ],
      "content": "To verify that the job completed and created a new table, use <bpt id=\"p43\">**</bpt>Server Explorer<ept id=\"p43\">**</ept><ph id=\"ph33\"/> and expand <bpt id=\"p44\">**</bpt>Azure<ept id=\"p44\">**</ept><ph id=\"ph34\"/> &gt; <bpt id=\"p45\">**</bpt>HDInsight<ept id=\"p45\">**</ept><ph id=\"ph35\"/> &gt; your HDInsight cluster &gt; <bpt id=\"p46\">**</bpt>Hive Databases<ept id=\"p46\">**</ept><ph id=\"ph36\"/> &gt; and <bpt id=\"p47\">**</bpt>default<ept id=\"p47\">**</ept>. You should see the <bpt id=\"p48\">**</bpt>errorLogs<ept id=\"p48\">**</ept><ph id=\"ph37\"/> table and the <bpt id=\"p49\">**</bpt>log4jLogs<ept id=\"p49\">**</ept><ph id=\"ph38\"/> table.",
      "nodes": [
        {
          "content": "To verify that the job completed and created a new table, use <bpt id=\"p43\">**</bpt>Server Explorer<ept id=\"p43\">**</ept><ph id=\"ph33\"/> and expand <bpt id=\"p44\">**</bpt>Azure<ept id=\"p44\">**</ept><ph id=\"ph34\"/> &gt; <bpt id=\"p45\">**</bpt>HDInsight<ept id=\"p45\">**</ept><ph id=\"ph35\"/> &gt; your HDInsight cluster &gt; <bpt id=\"p46\">**</bpt>Hive Databases<ept id=\"p46\">**</ept><ph id=\"ph36\"/> &gt; and <bpt id=\"p47\">**</bpt>default<ept id=\"p47\">**</ept>.",
          "pos": [
            0,
            455
          ]
        },
        {
          "content": "You should see the <bpt id=\"p48\">**</bpt>errorLogs<ept id=\"p48\">**</ept><ph id=\"ph37\"/> table and the <bpt id=\"p49\">**</bpt>log4jLogs<ept id=\"p49\">**</ept><ph id=\"ph38\"/> table.",
          "pos": [
            456,
            633
          ]
        }
      ]
    },
    {
      "pos": [
        5768,
        5770
      ],
      "content": "##"
    },
    {
      "pos": [
        5790,
        5797
      ],
      "content": "Summary"
    },
    {
      "pos": [
        5799,
        5970
      ],
      "content": "As you can see, the the HDInsight tools for Visual Studio provide an easy way to run Hive queries on an HDInsight cluster, monitor the job status, and retrieve the output."
    },
    {
      "pos": [
        5972,
        5974
      ],
      "content": "##"
    },
    {
      "pos": [
        5996,
        6006
      ],
      "content": "Next steps"
    },
    {
      "pos": [
        6008,
        6056
      ],
      "content": "For general information about Hive in HDInsight:"
    },
    {
      "pos": [
        6060,
        6118
      ],
      "content": "<bpt id=\"p50\">[</bpt>Use Hive with Hadoop on HDInsight<ept id=\"p50\">](hdinsight-use-hive.md)</ept>"
    },
    {
      "pos": [
        6120,
        6191
      ],
      "content": "For information about other ways you can work with Hadoop on HDInsight:"
    },
    {
      "pos": [
        6195,
        6251
      ],
      "content": "<bpt id=\"p51\">[</bpt>Use Pig with Hadoop on HDInsight<ept id=\"p51\">](hdinsight-use-pig.md)</ept>"
    },
    {
      "pos": [
        6255,
        6323
      ],
      "content": "<bpt id=\"p52\">[</bpt>Use MapReduce with Hadoop on HDInsight<ept id=\"p52\">](hdinsight-use-mapreduce.md)</ept>"
    },
    {
      "pos": [
        6325,
        6390
      ],
      "content": "For more information about the HDInsight tools for Visual Studio:"
    },
    {
      "pos": [
        6394,
        6516
      ],
      "content": "<bpt id=\"p53\">[</bpt>Getting started with HDInsight tools for Visual Studio<ept id=\"p53\">](../HDInsight/hdinsight-hadoop-visual-studio-tools-get-started.md)</ept>"
    }
  ],
  "content": "<properties\n   pageTitle=\"Hive query with Hadoop tools for Visual Studio | Microsoft Azure\"\n   description=\"Learn how to use Hive with Hadoop in HDInsight using Visual Studio Hadoop tools.\"\n   services=\"hdinsight\"\n   documentationCenter=\"\"\n   authors=\"Blackmist\"\n   manager=\"paulettm\"\n   editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags\n   ms.service=\"hdinsight\"\n   ms.devlang=\"na\"\n   ms.topic=\"article\"\n   ms.tgt_pltfrm=\"na\"\n   ms.workload=\"big-data\"\n   ms.date=\"02/05/2016\"\n   ms.author=\"larryfr\"/>\n\n#Run Hive queries using the HDInsight tools for Visual Studio\n\n[AZURE.INCLUDE [hive-selector](../../includes/hdinsight-selector-use-hive.md)]\n\nIn this article, you will learn how to submit Hive queries to an HDInsight cluster using the HDInsight tools for Visual Studio.\n\n> [AZURE.NOTE] This document does not provide a detailed description of what the HiveQL statements used in the examples do. For information about the HiveQL that is used in this example, see [Use Hive with Hadoop on HDInsight](hdinsight-use-hive.md).\n\n##<a id=\"prereq\"></a>Prerequisites\n\nTo complete the steps in this article, you will need the following.\n\n* An Azure HDInsight (Hadoop on HDInsight) cluster (Linux or Windows-based)\n\n* Visual Studio 2012 [Update 4](http://www.microsoft.com/download/details.aspx?id=39305), Visual Studio 2013 [Update 3](http://go.microsoft.com/fwlink/?LinkId=390465), or [Visual Studio Express 2013](http://www.microsoft.com/download/details.aspx?id=40769)\n\n##<a id=\"run\"></a> Run Hive queries using the HDInsight tools for Visual Studio\n\n1. Open **Visual Studio** and select **New** > **Project** > **HDInsight** > **Hive Application**. Provide a name for this project.\n\n2. Open the **Script.hql** file that is created with this project, and paste in the following HiveQL statements:\n\n        DROP TABLE log4jLogs;\n        CREATE EXTERNAL TABLE log4jLogs (t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string)\n        ROW FORMAT DELIMITED FIELDS TERMINATED BY ' '\n        STORED AS TEXTFILE LOCATION 'wasb:///example/data/';\n        SELECT t4 AS sev, COUNT(*) AS count FROM log4jLogs WHERE t4 = '[ERROR]' AND INPUT__FILE__NAME LIKE '%.log' GROUP BY t4;\n\n    These statements perform the following actions:\n\n    * **DROP TABLE**: Deletes the table and the data file if the table already exists.\n    * **CREATE EXTERNAL TABLE**: Creates a new 'external' table in Hive. External tables only store the table definition in Hive (the data is left in the original location).\n\n        > [AZURE.NOTE] External tables should be used when you expect the underlying data to be updated by an external source (such as an automated data upload process) or by another MapReduce operation, but you always want Hive queries to use the latest data.\n        >\n        > Dropping an external table does **not** delete the data, only the table definition.\n\n    * **ROW FORMAT**: Tells Hive how the data is formatted. In this case, the fields in each log are separated by a space.\n    * **STORED AS TEXTFILE LOCATION**: Tells Hive where the data is stored (the example/data directory) and that it is stored as text.\n    * **SELECT**: Select a count of all rows where column **t4** contain the value **[ERROR]**. This should return a value of **3** because there are three rows that contain this value.\n    * **INPUT__FILE__NAME LIKE '%.log'** - Tells Hive that we should only return data from files ending in .log. This restricts the search to the sample.log file that contains the data, and keeps it from returning data from other example data files that do not match the schema we defined.\n\n3. From the toolbar, select the **HDInsight Cluster** that you want to use for this query, and then select **Submit** to run the statements as a Hive job. The **Hive Job Summary** appears and displays information about the running job. Use the **Refresh** link to refresh the job information, until the **Job Status** changes to **Completed**.\n\n4. Use the **Job Output** link to view the output of this job. It should display `[ERROR] 3`, which is the value returned by the SELECT statement.\n\n5. You can also run Hive queries without creating a project. Using **Server Explorer**, expand **Azure** > **HDInsight**, right-click your HDInsight server, and then select **Write a Hive Query**.\n\n6. In the **temp.hql** document that appears, add the following HiveQL statements:\n\n        CREATE TABLE IF NOT EXISTS errorLogs (t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string) STORED AS ORC;\n        INSERT OVERWRITE TABLE errorLogs SELECT t1, t2, t3, t4, t5, t6, t7 FROM log4jLogs WHERE t4 = '[ERROR]' AND INPUT__FILE__NAME LIKE '%.log';\n\n    These statements perform the following actions:\n\n    * **CREATE TABLE IF NOT EXISTS**: Creates a table if it does not already exist. Because the **EXTERNAL** keyword is not used, this is an internal table, which is stored in the Hive data warehouse and is managed completely by Hive.\n\n        > [AZURE.NOTE] Unlike **EXTERNAL** tables, dropping an internal table also deletes the underlying data.\n\n    * **STORED AS ORC**: Stores the data in optimized row columnar (ORC) format. This is a highly optimized and efficient format for storing Hive data.\n    * **INSERT OVERWRITE ... SELECT**: Selects rows from the **log4jLogs** table that contain **[ERROR]**, then inserts the data into the **errorLogs** table.\n\n7. From the toolbar, select **Submit** to run the job. Use the **Job Status** to determine that the job has completed successfully.\n\n8. To verify that the job completed and created a new table, use **Server Explorer** and expand **Azure** > **HDInsight** > your HDInsight cluster > **Hive Databases** > and **default**. You should see the **errorLogs** table and the **log4jLogs** table.\n\n##<a id=\"summary\"></a>Summary\n\nAs you can see, the the HDInsight tools for Visual Studio provide an easy way to run Hive queries on an HDInsight cluster, monitor the job status, and retrieve the output.\n\n##<a id=\"nextsteps\"></a>Next steps\n\nFor general information about Hive in HDInsight:\n\n* [Use Hive with Hadoop on HDInsight](hdinsight-use-hive.md)\n\nFor information about other ways you can work with Hadoop on HDInsight:\n\n* [Use Pig with Hadoop on HDInsight](hdinsight-use-pig.md)\n\n* [Use MapReduce with Hadoop on HDInsight](hdinsight-use-mapreduce.md)\n\nFor more information about the HDInsight tools for Visual Studio:\n\n* [Getting started with HDInsight tools for Visual Studio](../HDInsight/hdinsight-hadoop-visual-studio-tools-get-started.md)\n\n\n[hdinsight-sdk-documentation]: http://msdnstage.redmond.corp.microsoft.com/library/dn479185.aspx\n\n[azure-purchase-options]: http://azure.microsoft.com/pricing/purchase-options/\n[azure-member-offers]: http://azure.microsoft.com/pricing/member-offers/\n[azure-free-trial]: http://azure.microsoft.com/pricing/free-trial/\n\n[apache-tez]: http://tez.apache.org\n[apache-hive]: http://hive.apache.org/\n[apache-log4j]: http://en.wikipedia.org/wiki/Log4j\n[hive-on-tez-wiki]: https://cwiki.apache.org/confluence/display/Hive/Hive+on+Tez\n[import-to-excel]: http://azure.microsoft.com/documentation/articles/hdinsight-connect-excel-power-query/\n\n\n[hdinsight-use-oozie]: hdinsight-use-oozie.md\n[hdinsight-analyze-flight-data]: hdinsight-analyze-flight-delay-data.md\n\n\n\n[hdinsight-storage]: hdinsight-hadoop-use-blob-storage.md\n\n[hdinsight-provision]: hdinsight-provision-clusters.md\n[hdinsight-submit-jobs]: hdinsight-submit-hadoop-jobs-programmatically.md\n[hdinsight-upload-data]: hdinsight-upload-data.md\n[hdinsight-get-started]: hdinsight-hadoop-linux-tutorial-get-started.md\n\n[powershell-here-strings]: http://technet.microsoft.com/library/ee692792.aspx\n\n[image-hdi-hive-powershell]: ./media/hdinsight-use-hive/HDI.HIVE.PowerShell.png\n[img-hdi-hive-powershell-output]: ./media/hdinsight-use-hive/HDI.Hive.PowerShell.Output.png\n[image-hdi-hive-architecture]: ./media/hdinsight-use-hive/HDI.Hive.Architecture.png\n"
}