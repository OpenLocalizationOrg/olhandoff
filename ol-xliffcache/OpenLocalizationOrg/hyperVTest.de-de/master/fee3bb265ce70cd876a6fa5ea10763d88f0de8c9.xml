{
  "nodes": [
    {
      "pos": [
        28,
        128
      ],
      "content": "Use Resource Manager to allocate resources to the Apache Spark cluster in HDInsight| Microsoft Azure"
    },
    {
      "pos": [
        148,
        241
      ],
      "content": "Learn how to use the Resource Manager for Spark clusters on HDInsight for better performance."
    },
    {
      "pos": [
        582,
        654
      ],
      "content": "Manage resources for the Apache Spark cluster in Azure HDInsight (Linux)"
    },
    {
      "pos": [
        656,
        1113
      ],
      "content": "Spark on Azure HDInsight (Linux) provides the Ambari Web UI to manage the cluster resources and monitor the health of the cluster. You can also use the Spark History Server to track applications that have finished running on the cluster. You can use the YARN UI to monitor that are currently running on the cluster. This article provides instructions on how to access these UIs and how to perform some basic resource management tasks using these interfaces.",
      "nodes": [
        {
          "content": "Spark on Azure HDInsight (Linux) provides the Ambari Web UI to manage the cluster resources and monitor the health of the cluster.",
          "pos": [
            0,
            130
          ]
        },
        {
          "content": "You can also use the Spark History Server to track applications that have finished running on the cluster.",
          "pos": [
            131,
            237
          ]
        },
        {
          "content": "You can use the YARN UI to monitor that are currently running on the cluster.",
          "pos": [
            238,
            315
          ]
        },
        {
          "content": "This article provides instructions on how to access these UIs and how to perform some basic resource management tasks using these interfaces.",
          "pos": [
            316,
            457
          ]
        }
      ]
    },
    {
      "pos": [
        1115,
        1133
      ],
      "content": "<bpt id=\"p1\">**</bpt>Prerequisites:<ept id=\"p1\">**</ept>"
    },
    {
      "pos": [
        1135,
        1163
      ],
      "content": "You must have the following:"
    },
    {
      "pos": [
        1167,
        1321
      ],
      "content": "An Azure subscription. See <bpt id=\"p2\">[</bpt>Get Azure free trial<ept id=\"p2\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
      "nodes": [
        {
          "content": "An Azure subscription.",
          "pos": [
            0,
            22
          ]
        },
        {
          "content": "See <bpt id=\"p2\">[</bpt>Get Azure free trial<ept id=\"p2\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
          "pos": [
            23,
            192
          ]
        }
      ]
    },
    {
      "pos": [
        1324,
        1485
      ],
      "content": "An Apache Spark cluster on HDInsight Linux. For instructions, see <bpt id=\"p3\">[</bpt>Create Apache Spark clusters in Azure HDInsight<ept id=\"p3\">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.",
      "nodes": [
        {
          "content": "An Apache Spark cluster on HDInsight Linux.",
          "pos": [
            0,
            43
          ]
        },
        {
          "content": "For instructions, see <bpt id=\"p3\">[</bpt>Create Apache Spark clusters in Azure HDInsight<ept id=\"p3\">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.",
          "pos": [
            44,
            199
          ]
        }
      ]
    },
    {
      "pos": [
        1490,
        1524
      ],
      "content": "How do I launch the Ambari Web UI?"
    },
    {
      "pos": [
        1529,
        1773
      ],
      "content": "From the <bpt id=\"p4\">[</bpt>Azure Preview Portal<ept id=\"p4\">](https://ms.portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard). You can also navigate to your cluster under <bpt id=\"p5\">**</bpt>Browse All<ept id=\"p5\">**</ept><ph id=\"ph2\"/> &gt; <bpt id=\"p6\">**</bpt>HDInsight Clusters<ept id=\"p6\">**</ept>.",
      "nodes": [
        {
          "content": "From the <bpt id=\"p4\">[</bpt>Azure Preview Portal<ept id=\"p4\">](https://ms.portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).",
          "pos": [
            0,
            197
          ]
        },
        {
          "content": "You can also navigate to your cluster under <bpt id=\"p5\">**</bpt>Browse All<ept id=\"p5\">**</ept><ph id=\"ph2\"/> &gt; <bpt id=\"p6\">**</bpt>HDInsight Clusters<ept id=\"p6\">**</ept>.",
          "pos": [
            198,
            375
          ]
        }
      ]
    },
    {
      "pos": [
        1780,
        1896
      ],
      "content": "From the Spark cluster blade, click <bpt id=\"p7\">**</bpt>Dashboard<ept id=\"p7\">**</ept>. When prompted, enter the admin credentials for the Spark cluster.",
      "nodes": [
        {
          "content": "From the Spark cluster blade, click <bpt id=\"p7\">**</bpt>Dashboard<ept id=\"p7\">**</ept>.",
          "pos": [
            0,
            88
          ]
        },
        {
          "content": "When prompted, enter the admin credentials for the Spark cluster.",
          "pos": [
            89,
            154
          ]
        }
      ]
    },
    {
      "pos": [
        1902,
        2030
      ],
      "content": "<ph id=\"ph3\">![</ph>Launch Ambari<ph id=\"ph4\">](./media/hdinsight-apache-spark-resource-manager/hdispark.cluster.launch.dashboard.png \"Start Resource Manager\")</ph>"
    },
    {
      "pos": [
        2035,
        2088
      ],
      "content": "This should launch the Ambari Web UI, as shown below."
    },
    {
      "pos": [
        2094,
        2193
      ],
      "content": "<ph id=\"ph5\">![</ph>Ambari Web UI<ph id=\"ph6\">](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png \"Ambari Web UI\")</ph>"
    },
    {
      "pos": [
        2201,
        2242
      ],
      "content": "How do I launch the Spark History Server?"
    },
    {
      "pos": [
        2247,
        2406
      ],
      "content": "From the <bpt id=\"p8\">[</bpt>Azure Preview Portal<ept id=\"p8\">](https://ms.portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard)."
    },
    {
      "pos": [
        2411,
        2554
      ],
      "content": "From the cluster blade, under <bpt id=\"p9\">**</bpt>Quick Links<ept id=\"p9\">**</ept>, click <bpt id=\"p10\">**</bpt>Cluster Dashboard<ept id=\"p10\">**</ept>. In the <bpt id=\"p11\">**</bpt>Cluster Dashboard<ept id=\"p11\">**</ept><ph id=\"ph7\"/> blade, click <bpt id=\"p12\">**</bpt>Spark History Server<ept id=\"p12\">**</ept>.",
      "nodes": [
        {
          "content": "From the cluster blade, under <bpt id=\"p9\">**</bpt>Quick Links<ept id=\"p9\">**</ept>, click <bpt id=\"p10\">**</bpt>Cluster Dashboard<ept id=\"p10\">**</ept>.",
          "pos": [
            0,
            153
          ]
        },
        {
          "content": "In the <bpt id=\"p11\">**</bpt>Cluster Dashboard<ept id=\"p11\">**</ept><ph id=\"ph7\"/> blade, click <bpt id=\"p12\">**</bpt>Spark History Server<ept id=\"p12\">**</ept>.",
          "pos": [
            154,
            315
          ]
        }
      ]
    },
    {
      "pos": [
        2560,
        2681
      ],
      "content": "<ph id=\"ph8\">![</ph>Spark History Server<ph id=\"ph9\">](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png \"Spark History Server\")</ph>"
    },
    {
      "pos": [
        2687,
        2752
      ],
      "content": "When prompted, enter the admin credentials for the Spark cluster."
    },
    {
      "pos": [
        2758,
        2786
      ],
      "content": "How do I launch the Yarn UI?"
    },
    {
      "pos": [
        2788,
        3072
      ],
      "content": "You can use the YARN UI to monitor applications that are currently running on the Spark cluster. Before accessing the YARN UI, you should have enabled SSH tunneling to the cluster. For instructions, see <bpt id=\"p13\">[</bpt>Use SSH Tunneling to access Ambari web UI<ept id=\"p13\">](hdinsight-linux-ambari-ssh-tunnel.md)</ept>",
      "nodes": [
        {
          "content": "You can use the YARN UI to monitor applications that are currently running on the Spark cluster.",
          "pos": [
            0,
            96
          ]
        },
        {
          "content": "Before accessing the YARN UI, you should have enabled SSH tunneling to the cluster.",
          "pos": [
            97,
            180
          ]
        },
        {
          "content": "For instructions, see <bpt id=\"p13\">[</bpt>Use SSH Tunneling to access Ambari web UI<ept id=\"p13\">](hdinsight-linux-ambari-ssh-tunnel.md)</ept>",
          "pos": [
            181,
            324
          ]
        }
      ]
    },
    {
      "pos": [
        3077,
        3132
      ],
      "content": "Launch the Ambari Web UI as shown in the section above."
    },
    {
      "pos": [
        3137,
        3211
      ],
      "content": "From the Ambari Web UI, select YARN from the list on the left of the page."
    },
    {
      "pos": [
        3216,
        3405
      ],
      "content": "3.When the YARN service information is displayed, select <bpt id=\"p14\">**</bpt>Quick Links<ept id=\"p14\">**</ept>. A list of the cluster head nodes will appear. Select one of the head nodes, and then select <bpt id=\"p15\">**</bpt>ResourceManager UI<ept id=\"p15\">**</ept>.",
      "nodes": [
        {
          "content": "3.When the YARN service information is displayed, select <bpt id=\"p14\">**</bpt>Quick Links<ept id=\"p14\">**</ept>.",
          "pos": [
            0,
            113
          ]
        },
        {
          "content": "A list of the cluster head nodes will appear.",
          "pos": [
            114,
            159
          ]
        },
        {
          "content": "Select one of the head nodes, and then select <bpt id=\"p15\">**</bpt>ResourceManager UI<ept id=\"p15\">**</ept>.",
          "pos": [
            160,
            269
          ]
        }
      ]
    },
    {
      "pos": [
        3411,
        3513
      ],
      "content": "<ph id=\"ph10\">![</ph>Launch YARN UI<ph id=\"ph11\">](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png \"Launch YARN UI\")</ph>"
    },
    {
      "pos": [
        3518,
        3600
      ],
      "content": "This should launch the YARN UI and you should see a page similar to the following:"
    },
    {
      "pos": [
        3606,
        3687
      ],
      "content": "<ph id=\"ph12\">![</ph>YARN UI<ph id=\"ph13\">](./media/hdinsight-apache-spark-resource-manager/yarn-ui.png \"YARN UI\")</ph>"
    },
    {
      "pos": [
        3689,
        3691
      ],
      "content": "##"
    },
    {
      "pos": [
        3717,
        3767
      ],
      "content": "How do I manage resources using the Ambari Web UI?"
    },
    {
      "pos": [
        3769,
        3918
      ],
      "content": "Here are some common scenarios that you might run into with your Spark cluster, and the instructions on how to address those using the Ambari Web UI."
    },
    {
      "pos": [
        3924,
        3993
      ],
      "content": "I do not use BI with Spark cluster. How do I take the resources back?",
      "nodes": [
        {
          "content": "I do not use BI with Spark cluster.",
          "pos": [
            0,
            35
          ]
        },
        {
          "content": "How do I take the resources back?",
          "pos": [
            36,
            69
          ]
        }
      ]
    },
    {
      "pos": [
        3998,
        4114
      ],
      "content": "Launch the Ambari Web UI as shown above. From the left navigation pane, click <bpt id=\"p16\">**</bpt>Spark<ept id=\"p16\">**</ept>, and then click <bpt id=\"p17\">**</bpt>Configs<ept id=\"p17\">**</ept>.",
      "nodes": [
        {
          "content": "Launch the Ambari Web UI as shown above.",
          "pos": [
            0,
            40
          ]
        },
        {
          "content": "From the left navigation pane, click <bpt id=\"p16\">**</bpt>Spark<ept id=\"p16\">**</ept>, and then click <bpt id=\"p17\">**</bpt>Configs<ept id=\"p17\">**</ept>.",
          "pos": [
            41,
            196
          ]
        }
      ]
    },
    {
      "pos": [
        4119,
        4291
      ],
      "content": "In the list of configurations available, look for <bpt id=\"p18\">**</bpt>Custom spark-thrift-sparkconf<ept id=\"p18\">**</ept><ph id=\"ph14\"/> and change the values for <bpt id=\"p19\">**</bpt>spark.executor.memory<ept id=\"p19\">**</ept><ph id=\"ph15\"/> and <bpt id=\"p20\">**</bpt>spark.drivers.core<ept id=\"p20\">**</ept><ph id=\"ph16\"/> to <bpt id=\"p21\">**</bpt>0<ept id=\"p21\">**</ept>."
    },
    {
      "pos": [
        4297,
        4407
      ],
      "content": "<ph id=\"ph17\">![</ph>Resources for BI<ph id=\"ph18\">](./media/hdinsight-apache-spark-resource-manager/spark-bi-resources.png \"Resources for BI\")</ph>"
    },
    {
      "pos": [
        4412,
        4503
      ],
      "content": "Click <bpt id=\"p22\">**</bpt>Save<ept id=\"p22\">**</ept>. Enter a description for the changes you made and then click <bpt id=\"p23\">**</bpt>Save<ept id=\"p23\">**</ept><ph id=\"ph19\"/> again.",
      "nodes": [
        {
          "content": "Click <bpt id=\"p22\">**</bpt>Save<ept id=\"p22\">**</ept>.",
          "pos": [
            0,
            55
          ]
        },
        {
          "content": "Enter a description for the changes you made and then click <bpt id=\"p23\">**</bpt>Save<ept id=\"p23\">**</ept><ph id=\"ph19\"/> again.",
          "pos": [
            56,
            186
          ]
        }
      ]
    },
    {
      "pos": [
        4508,
        4635
      ],
      "content": "At the top of the page, you should see a prompt to restart the Spark service. Click <bpt id=\"p24\">**</bpt>Restart<ept id=\"p24\">**</ept><ph id=\"ph20\"/> for the changes to take affect.",
      "nodes": [
        {
          "content": "At the top of the page, you should see a prompt to restart the Spark service.",
          "pos": [
            0,
            77
          ]
        },
        {
          "content": "Click <bpt id=\"p24\">**</bpt>Restart<ept id=\"p24\">**</ept><ph id=\"ph20\"/> for the changes to take affect.",
          "pos": [
            78,
            182
          ]
        }
      ]
    },
    {
      "pos": [
        4642,
        4722
      ],
      "content": "My Jupyter notebooks are not running as expected. How can I restart the service?",
      "nodes": [
        {
          "content": "My Jupyter notebooks are not running as expected.",
          "pos": [
            0,
            49
          ]
        },
        {
          "content": "How can I restart the service?",
          "pos": [
            50,
            80
          ]
        }
      ]
    },
    {
      "pos": [
        4727,
        4934
      ],
      "content": "Launch the Ambari Web UI as shown above. From the left navigation pane, click <bpt id=\"p25\">**</bpt>Jupyter<ept id=\"p25\">**</ept>, click <bpt id=\"p26\">**</bpt>Service Actions<ept id=\"p26\">**</ept>, and then click <bpt id=\"p27\">**</bpt>Restart All<ept id=\"p27\">**</ept>. This will start the Jupyter service on all the headnodes.",
      "nodes": [
        {
          "content": "Launch the Ambari Web UI as shown above.",
          "pos": [
            0,
            40
          ]
        },
        {
          "content": "From the left navigation pane, click <bpt id=\"p25\">**</bpt>Jupyter<ept id=\"p25\">**</ept>, click <bpt id=\"p26\">**</bpt>Service Actions<ept id=\"p26\">**</ept>, and then click <bpt id=\"p27\">**</bpt>Restart All<ept id=\"p27\">**</ept>.",
          "pos": [
            41,
            269
          ]
        },
        {
          "content": "This will start the Jupyter service on all the headnodes.",
          "pos": [
            270,
            327
          ]
        }
      ]
    },
    {
      "pos": [
        4940,
        5045
      ],
      "content": "<ph id=\"ph21\">![</ph>Restart Jupyter<ph id=\"ph22\">](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png \"Restart Jupyter\")</ph>"
    },
    {
      "pos": [
        5079,
        5087
      ],
      "content": "See also"
    },
    {
      "pos": [
        5092,
        5171
      ],
      "content": "<bpt id=\"p28\">[</bpt>Overview: Apache Spark on Azure HDInsight<ept id=\"p28\">](hdinsight-apache-spark-overview.md)</ept>"
    },
    {
      "pos": [
        5177,
        5186
      ],
      "content": "Scenarios"
    },
    {
      "pos": [
        5190,
        5319
      ],
      "content": "<bpt id=\"p29\">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id=\"p29\">](hdinsight-apache-spark-use-bi-tools.md)</ept>"
    },
    {
      "pos": [
        5323,
        5488
      ],
      "content": "<bpt id=\"p30\">[</bpt>Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data<ept id=\"p30\">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept>"
    },
    {
      "pos": [
        5492,
        5638
      ],
      "content": "<bpt id=\"p31\">[</bpt>Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results<ept id=\"p31\">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept>"
    },
    {
      "pos": [
        5642,
        5775
      ],
      "content": "<bpt id=\"p32\">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id=\"p32\">](hdinsight-apache-spark-eventhub-streaming.md)</ept>"
    },
    {
      "pos": [
        5779,
        5889
      ],
      "content": "<bpt id=\"p33\">[</bpt>Website log analysis using Spark in HDInsight<ept id=\"p33\">](hdinsight-apache-spark-custom-library-website-log-analysis.md)</ept>"
    },
    {
      "pos": [
        5895,
        5922
      ],
      "content": "Create and run applications"
    },
    {
      "pos": [
        5926,
        6028
      ],
      "content": "<bpt id=\"p34\">[</bpt>Create a standalone application using Scala<ept id=\"p34\">](hdinsight-apache-spark-create-standalone-application.md)</ept>"
    },
    {
      "pos": [
        6032,
        6128
      ],
      "content": "<bpt id=\"p35\">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id=\"p35\">](hdinsight-apache-spark-livy-rest-interface.md)</ept>"
    },
    {
      "pos": [
        6134,
        6154
      ],
      "content": "Tools and extensions"
    },
    {
      "pos": [
        6158,
        6297
      ],
      "content": "<bpt id=\"p36\">[</bpt>Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons<ept id=\"p36\">](hdinsight-apache-spark-intellij-tool-plugin.md)</ept>"
    },
    {
      "pos": [
        6301,
        6408
      ],
      "content": "<bpt id=\"p37\">[</bpt>Use Zeppelin notebooks with a Spark cluster on HDInsight<ept id=\"p37\">](hdinsight-apache-spark-use-zeppelin-notebook.md)</ept>"
    },
    {
      "pos": [
        6412,
        6535
      ],
      "content": "<bpt id=\"p38\">[</bpt>Kernels available for Jupyter notebook in Spark cluster for HDInsight<ept id=\"p38\">](hdinsight-apache-spark-jupyter-notebook-kernels.md)</ept>"
    }
  ],
  "content": "<properties \n    pageTitle=\"Use Resource Manager to allocate resources to the Apache Spark cluster in HDInsight| Microsoft Azure\" \n    description=\"Learn how to use the Resource Manager for Spark clusters on HDInsight for better performance.\" \n    services=\"hdinsight\" \n    documentationCenter=\"\" \n    authors=\"nitinme\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags \n    ms.service=\"hdinsight\" \n    ms.workload=\"big-data\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"02/05/2016\" \n    ms.author=\"nitinme\"/>\n\n\n# Manage resources for the Apache Spark cluster in Azure HDInsight (Linux)\n\nSpark on Azure HDInsight (Linux) provides the Ambari Web UI to manage the cluster resources and monitor the health of the cluster. You can also use the Spark History Server to track applications that have finished running on the cluster. You can use the YARN UI to monitor that are currently running on the cluster. This article provides instructions on how to access these UIs and how to perform some basic resource management tasks using these interfaces.\n\n**Prerequisites:**\n\nYou must have the following:\n\n- An Azure subscription. See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).\n- An Apache Spark cluster on HDInsight Linux. For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).\n\n## How do I launch the Ambari Web UI?\n\n1. From the [Azure Preview Portal](https://ms.portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard). You can also navigate to your cluster under **Browse All** > **HDInsight Clusters**. \n \n2. From the Spark cluster blade, click **Dashboard**. When prompted, enter the admin credentials for the Spark cluster.\n\n    ![Launch Ambari](./media/hdinsight-apache-spark-resource-manager/hdispark.cluster.launch.dashboard.png \"Start Resource Manager\")\n\n3. This should launch the Ambari Web UI, as shown below.\n\n    ![Ambari Web UI](./media/hdinsight-apache-spark-resource-manager/ambari-web-ui.png \"Ambari Web UI\")   \n\n## How do I launch the Spark History Server?\n\n1. From the [Azure Preview Portal](https://ms.portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).\n\n2. From the cluster blade, under **Quick Links**, click **Cluster Dashboard**. In the **Cluster Dashboard** blade, click **Spark History Server**.\n\n    ![Spark History Server](./media/hdinsight-apache-spark-resource-manager/launch-history-server.png \"Spark History Server\")\n\n    When prompted, enter the admin credentials for the Spark cluster.\n\n\n## How do I launch the Yarn UI?\n\nYou can use the YARN UI to monitor applications that are currently running on the Spark cluster. Before accessing the YARN UI, you should have enabled SSH tunneling to the cluster. For instructions, see [Use SSH Tunneling to access Ambari web UI](hdinsight-linux-ambari-ssh-tunnel.md)\n\n1. Launch the Ambari Web UI as shown in the section above.\n\n2. From the Ambari Web UI, select YARN from the list on the left of the page.\n\n3. 3.When the YARN service information is displayed, select **Quick Links**. A list of the cluster head nodes will appear. Select one of the head nodes, and then select **ResourceManager UI**.\n\n    ![Launch YARN UI](./media/hdinsight-apache-spark-resource-manager/launch-yarn-ui.png \"Launch YARN UI\")\n\n4. This should launch the YARN UI and you should see a page similar to the following:\n\n    ![YARN UI](./media/hdinsight-apache-spark-resource-manager/yarn-ui.png \"YARN UI\")\n\n##<a name=\"scenariosrm\"></a>How do I manage resources using the Ambari Web UI?\n\nHere are some common scenarios that you might run into with your Spark cluster, and the instructions on how to address those using the Ambari Web UI.\n\n### I do not use BI with Spark cluster. How do I take the resources back?\n\n1. Launch the Ambari Web UI as shown above. From the left navigation pane, click **Spark**, and then click **Configs**.\n\n2. In the list of configurations available, look for **Custom spark-thrift-sparkconf** and change the values for **spark.executor.memory** and **spark.drivers.core** to **0**.\n\n    ![Resources for BI](./media/hdinsight-apache-spark-resource-manager/spark-bi-resources.png \"Resources for BI\")\n\n3. Click **Save**. Enter a description for the changes you made and then click **Save** again.\n\n4. At the top of the page, you should see a prompt to restart the Spark service. Click **Restart** for the changes to take affect.\n\n\n### My Jupyter notebooks are not running as expected. How can I restart the service?\n\n1. Launch the Ambari Web UI as shown above. From the left navigation pane, click **Jupyter**, click **Service Actions**, and then click **Restart All**. This will start the Jupyter service on all the headnodes.\n\n    ![Restart Jupyter](./media/hdinsight-apache-spark-resource-manager/restart-jupyter.png \"Restart Jupyter\")\n\n    \n\n\n## <a name=\"seealso\"></a>See also\n\n\n* [Overview: Apache Spark on Azure HDInsight](hdinsight-apache-spark-overview.md)\n\n### Scenarios\n\n* [Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools](hdinsight-apache-spark-use-bi-tools.md)\n\n* [Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data](hdinsight-apache-spark-ipython-notebook-machine-learning.md)\n\n* [Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results](hdinsight-apache-spark-machine-learning-mllib-ipython.md)\n\n* [Spark Streaming: Use Spark in HDInsight for building real-time streaming applications](hdinsight-apache-spark-eventhub-streaming.md)\n\n* [Website log analysis using Spark in HDInsight](hdinsight-apache-spark-custom-library-website-log-analysis.md)\n\n### Create and run applications\n\n* [Create a standalone application using Scala](hdinsight-apache-spark-create-standalone-application.md)\n\n* [Run jobs remotely on a Spark cluster using Livy](hdinsight-apache-spark-livy-rest-interface.md)\n\n### Tools and extensions\n\n* [Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons](hdinsight-apache-spark-intellij-tool-plugin.md)\n\n* [Use Zeppelin notebooks with a Spark cluster on HDInsight](hdinsight-apache-spark-use-zeppelin-notebook.md)\n\n* [Kernels available for Jupyter notebook in Spark cluster for HDInsight](hdinsight-apache-spark-jupyter-notebook-kernels.md)\n\n\n\n[hdinsight-versions]: hdinsight-component-versioning.md\n[hdinsight-upload-data]: hdinsight-upload-data.md\n[hdinsight-storage]: hdinsight-hadoop-use-blob-storage.md\n\n\n[azure-purchase-options]: http://azure.microsoft.com/pricing/purchase-options/\n[azure-member-offers]: http://azure.microsoft.com/pricing/member-offers/\n[azure-free-trial]: http://azure.microsoft.com/pricing/free-trial/\n[azure-management-portal]: https://manage.windowsazure.com/\n[azure-create-storageaccount]: storage-create-storage-account.md \n"
}