{
  "nodes": [
    {
      "pos": [
        27,
        96
      ],
      "content": "What's new in Hadoop cluster versions of HDInsight? | Microsoft Azure",
      "nodes": [
        {
          "content": "What's new in Hadoop cluster versions of HDInsight?",
          "pos": [
            0,
            51
          ]
        },
        {
          "content": "| Microsoft Azure",
          "pos": [
            52,
            69
          ]
        }
      ]
    },
    {
      "pos": [
        115,
        262
      ],
      "content": "HDInsight supports multiple deployable Hadoop cluster versions. See the Hadoop and HortonWorks Data Platform (HDP) distribution versions supported.",
      "nodes": [
        {
          "content": "HDInsight supports multiple deployable Hadoop cluster versions.",
          "pos": [
            0,
            63
          ]
        },
        {
          "content": "See the Hadoop and HortonWorks Data Platform (HDP) distribution versions supported.",
          "pos": [
            64,
            147
          ]
        }
      ]
    },
    {
      "pos": [
        562,
        626
      ],
      "content": "What's new in the Hadoop cluster versions provided by HDInsight?"
    },
    {
      "pos": [
        630,
        670
      ],
      "content": "HDInsight versions and Hadoop components"
    },
    {
      "pos": [
        671,
        1158
      ],
      "content": "Azure HDInsight supports multiple Hadoop cluster versions that can be deployed at any time. Each version choice provisions a specific version of the Hortonworks Data Platform (HDP) distribution and a set of components that are contained within that distribution. The component versions associated with HDInsight cluster versions are itemized in the following table. Note that the default cluster version used by Azure HDInsight is currently 3.1, and, as of 11/7/2014, based on HDP 2.1.7.",
      "nodes": [
        {
          "content": "Azure HDInsight supports multiple Hadoop cluster versions that can be deployed at any time.",
          "pos": [
            0,
            91
          ]
        },
        {
          "content": "Each version choice provisions a specific version of the Hortonworks Data Platform (HDP) distribution and a set of components that are contained within that distribution.",
          "pos": [
            92,
            262
          ]
        },
        {
          "content": "The component versions associated with HDInsight cluster versions are itemized in the following table.",
          "pos": [
            263,
            365
          ]
        },
        {
          "content": "Note that the default cluster version used by Azure HDInsight is currently 3.1, and, as of 11/7/2014, based on HDP 2.1.7.",
          "pos": [
            366,
            487
          ]
        }
      ]
    },
    {
      "pos": [
        1179,
        1180
      ],
      "content": "\n"
    },
    {
      "pos": [
        1188,
        1197
      ],
      "content": "Component"
    },
    {
      "pos": [
        1206,
        1227
      ],
      "content": "HDInsight Version 3.2"
    },
    {
      "pos": [
        1236,
        1267
      ],
      "content": "HDInsight Version 3.1 (Default)"
    },
    {
      "pos": [
        1276,
        1297
      ],
      "content": "HDInsight Version 3.0"
    },
    {
      "pos": [
        1306,
        1327
      ],
      "content": "HDInsight Version 2.1"
    },
    {
      "pos": [
        1337,
        1338
      ],
      "content": "\n"
    },
    {
      "pos": [
        1346,
        1371
      ],
      "content": "Hortonworks Data Platform"
    },
    {
      "pos": [
        1380,
        1383
      ],
      "content": "2.2"
    },
    {
      "pos": [
        1392,
        1397
      ],
      "content": "2.1.7"
    },
    {
      "pos": [
        1406,
        1409
      ],
      "content": "2.0"
    },
    {
      "pos": [
        1418,
        1421
      ],
      "content": "1.3"
    },
    {
      "pos": [
        1431,
        1432
      ],
      "content": "\n"
    },
    {
      "pos": [
        1440,
        1460
      ],
      "content": "Apache Hadoop &amp; YARN"
    },
    {
      "pos": [
        1469,
        1474
      ],
      "content": "2.6.0"
    },
    {
      "pos": [
        1483,
        1488
      ],
      "content": "2.4.0"
    },
    {
      "pos": [
        1497,
        1502
      ],
      "content": "2.2.0"
    },
    {
      "pos": [
        1511,
        1516
      ],
      "content": "1.2.0"
    },
    {
      "pos": [
        1526,
        1527
      ],
      "content": "\n"
    },
    {
      "pos": [
        1535,
        1545
      ],
      "content": "Apache Tez"
    },
    {
      "pos": [
        1554,
        1559
      ],
      "content": "0.5.2"
    },
    {
      "pos": [
        1568,
        1573
      ],
      "content": "0.4.0"
    },
    {
      "pos": [
        1601,
        1602
      ],
      "content": "\n"
    },
    {
      "pos": [
        1610,
        1620
      ],
      "content": "Apache Pig"
    },
    {
      "pos": [
        1629,
        1635
      ],
      "content": "0.14.0"
    },
    {
      "pos": [
        1644,
        1650
      ],
      "content": "0.12.1"
    },
    {
      "pos": [
        1659,
        1665
      ],
      "content": "0.12.0"
    },
    {
      "pos": [
        1674,
        1680
      ],
      "content": "0.11.0"
    },
    {
      "pos": [
        1690,
        1691
      ],
      "content": "\n"
    },
    {
      "pos": [
        1699,
        1721
      ],
      "content": "Apache Hive &amp; HCatalog"
    },
    {
      "pos": [
        1730,
        1736
      ],
      "content": "0.14.0"
    },
    {
      "pos": [
        1745,
        1751
      ],
      "content": "0.13.1"
    },
    {
      "pos": [
        1760,
        1766
      ],
      "content": "0.12.0"
    },
    {
      "pos": [
        1775,
        1781
      ],
      "content": "0.11.0"
    },
    {
      "pos": [
        1791,
        1792
      ],
      "content": "\n"
    },
    {
      "pos": [
        1800,
        1812
      ],
      "content": "Apazhe HBase"
    },
    {
      "pos": [
        1822,
        1828
      ],
      "content": "0.98.4"
    },
    {
      "pos": [
        1837,
        1843
      ],
      "content": "0.98.0"
    },
    {
      "pos": [
        1871,
        1872
      ],
      "content": "\n"
    },
    {
      "pos": [
        1880,
        1892
      ],
      "content": "Apache Sqoop"
    },
    {
      "pos": [
        1901,
        1906
      ],
      "content": "1.4.5"
    },
    {
      "pos": [
        1915,
        1920
      ],
      "content": "1.4.4"
    },
    {
      "pos": [
        1929,
        1934
      ],
      "content": "1.4.4"
    },
    {
      "pos": [
        1943,
        1948
      ],
      "content": "1.4.3"
    },
    {
      "pos": [
        1958,
        1959
      ],
      "content": "\n"
    },
    {
      "pos": [
        1967,
        1979
      ],
      "content": "Apache Oozie"
    },
    {
      "pos": [
        1988,
        1993
      ],
      "content": "4.1.0"
    },
    {
      "pos": [
        2002,
        2007
      ],
      "content": "4.0.0"
    },
    {
      "pos": [
        2016,
        2021
      ],
      "content": "4.0.0"
    },
    {
      "pos": [
        2030,
        2035
      ],
      "content": "3.3.2"
    },
    {
      "pos": [
        2045,
        2046
      ],
      "content": "\n"
    },
    {
      "pos": [
        2054,
        2070
      ],
      "content": "Apache Zookeeper"
    },
    {
      "pos": [
        2079,
        2084
      ],
      "content": "3.4.6"
    },
    {
      "pos": [
        2093,
        2098
      ],
      "content": "3.4.5"
    },
    {
      "pos": [
        2107,
        2112
      ],
      "content": "3.4.5"
    },
    {
      "pos": [
        2131,
        2132
      ],
      "content": "\n"
    },
    {
      "pos": [
        2140,
        2152
      ],
      "content": "Apache Storm"
    },
    {
      "pos": [
        2161,
        2166
      ],
      "content": "0.9.3"
    },
    {
      "pos": [
        2175,
        2180
      ],
      "content": "0.9.1"
    },
    {
      "pos": [
        2208,
        2209
      ],
      "content": "\n"
    },
    {
      "pos": [
        2217,
        2230
      ],
      "content": "Apache Mahout"
    },
    {
      "pos": [
        2239,
        2244
      ],
      "content": "0.9.0"
    },
    {
      "pos": [
        2253,
        2258
      ],
      "content": "0.9.0"
    },
    {
      "pos": [
        2286,
        2287
      ],
      "content": "\n"
    },
    {
      "pos": [
        2295,
        2309
      ],
      "content": "Apache Phoenix"
    },
    {
      "pos": [
        2318,
        2323
      ],
      "content": "4.2.0"
    },
    {
      "pos": [
        2332,
        2350
      ],
      "content": "4.0.0.2.1.7.0-2162"
    },
    {
      "pos": [
        2378,
        2379
      ],
      "content": "\n"
    },
    {
      "pos": [
        2387,
        2399
      ],
      "content": "Apache Spark"
    },
    {
      "pos": [
        2408,
        2413
      ],
      "content": "1.3.1"
    },
    {
      "pos": [
        2450,
        2451
      ],
      "content": "\n"
    },
    {
      "pos": [
        2462,
        2507
      ],
      "content": "<bpt id=\"p1\">**</bpt>Get current component version information<ept id=\"p1\">**</ept>"
    },
    {
      "pos": [
        2509,
        3070
      ],
      "content": "The component versions associated with HDInsight cluster versions may change in future updates to HDInsight. One way to determine the available components and to verify which versions are being used for a cluster is to use the Ambari REST API. The <bpt id=\"p2\">**</bpt>GetComponentInformation<ept id=\"p2\">**</ept><ph id=\"ph2\"/> command can be used to retrieve information about a service component. For details, see the <bpt id=\"p3\">[</bpt>Ambari documentation<ept id=\"p3\">][ambari-docs]</ept>. Another way to obtain this information is to log in to a cluster by using Remote Desktop and examine the contents of the \"C:\\apps\\dist\\\" directory directly.",
      "nodes": [
        {
          "content": "The component versions associated with HDInsight cluster versions may change in future updates to HDInsight.",
          "pos": [
            0,
            108
          ]
        },
        {
          "content": "One way to determine the available components and to verify which versions are being used for a cluster is to use the Ambari REST API.",
          "pos": [
            109,
            243
          ]
        },
        {
          "content": "The <bpt id=\"p2\">**</bpt>GetComponentInformation<ept id=\"p2\">**</ept><ph id=\"ph2\"/> command can be used to retrieve information about a service component.",
          "pos": [
            244,
            398
          ]
        },
        {
          "content": "For details, see the <bpt id=\"p3\">[</bpt>Ambari documentation<ept id=\"p3\">][ambari-docs]</ept>.",
          "pos": [
            399,
            494
          ]
        },
        {
          "content": "Another way to obtain this information is to log in to a cluster by using Remote Desktop and examine the contents of the \"C:\\apps\\dist\\\" directory directly.",
          "pos": [
            495,
            651
          ]
        }
      ]
    },
    {
      "pos": [
        3073,
        3090
      ],
      "content": "<bpt id=\"p4\">**</bpt>Release notes<ept id=\"p4\">**</ept>"
    },
    {
      "pos": [
        3092,
        3215
      ],
      "content": "See <bpt id=\"p5\">[</bpt>HDInsight release notes<ept id=\"p5\">](hdinsight-release-notes.md)</ept><ph id=\"ph3\"/> for additional release notes on the latest versions of HDInsight."
    },
    {
      "pos": [
        3221,
        3276
      ],
      "content": "Select a version when provisioning an HDInsight cluster"
    },
    {
      "pos": [
        3278,
        3471
      ],
      "content": "When creating a cluster through the HDInsight Windows PowerShell cmdlets or the HDInsight .NET SDK, you can choose the version for the HDInsight Hadoop cluster by using the \"Version\" parameter."
    },
    {
      "pos": [
        3473,
        3797
      ],
      "content": "If you use the <bpt id=\"p6\">**</bpt>Quick Create<ept id=\"p6\">**</ept><ph id=\"ph4\"/> option, you will get version 3.1 of HDInsight, which creates a Hadoop cluster by default. If you use the <bpt id=\"p7\">**</bpt>Custom Create<ept id=\"p7\">**</ept><ph id=\"ph5\"/> option from the Azure Classic Portal, you can choose the version of the cluster you will deploy from the <bpt id=\"p8\">**</bpt>HDInsight Version<ept id=\"p8\">**</ept><ph id=\"ph6\"/> drop-down on the <bpt id=\"p9\">**</bpt>Cluster Details<ept id=\"p9\">**</ept><ph id=\"ph7\"/> page.",
      "nodes": [
        {
          "content": "If you use the <bpt id=\"p6\">**</bpt>Quick Create<ept id=\"p6\">**</ept><ph id=\"ph4\"/> option, you will get version 3.1 of HDInsight, which creates a Hadoop cluster by default.",
          "pos": [
            0,
            173
          ]
        },
        {
          "content": "If you use the <bpt id=\"p7\">**</bpt>Custom Create<ept id=\"p7\">**</ept><ph id=\"ph5\"/> option from the Azure Classic Portal, you can choose the version of the cluster you will deploy from the <bpt id=\"p8\">**</bpt>HDInsight Version<ept id=\"p8\">**</ept><ph id=\"ph6\"/> drop-down on the <bpt id=\"p9\">**</bpt>Cluster Details<ept id=\"p9\">**</ept><ph id=\"ph7\"/> page.",
          "pos": [
            174,
            532
          ]
        }
      ]
    },
    {
      "pos": [
        3801,
        3819
      ],
      "content": "Feature highlights"
    },
    {
      "pos": [
        3820,
        3883
      ],
      "content": "Some of the salient features of the HDInsight platform include:"
    },
    {
      "pos": [
        3887,
        4188
      ],
      "content": "<bpt id=\"p10\">**</bpt>Spark<ept id=\"p10\">**</ept><ph id=\"ph8\"/> - Apache Spark is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications. Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations.",
      "nodes": [
        {
          "content": "<bpt id=\"p10\">**</bpt>Spark<ept id=\"p10\">**</ept><ph id=\"ph8\"/> - Apache Spark is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.",
          "pos": [
            0,
            221
          ]
        },
        {
          "content": "Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations.",
          "pos": [
            222,
            355
          ]
        }
      ]
    },
    {
      "pos": [
        4194,
        4526
      ],
      "content": "Spark can also be used to perform conventional disk-based data processing. Spark improves the traditional MapReduce framework by avoiding writes to disk in the intermediate stages. Also, Spark is compatible with the Hadoop Distributed File System (HDFS) and Azure Blob storage so the existing data can easily be processed via Spark.",
      "nodes": [
        {
          "content": "Spark can also be used to perform conventional disk-based data processing.",
          "pos": [
            0,
            74
          ]
        },
        {
          "content": "Spark improves the traditional MapReduce framework by avoiding writes to disk in the intermediate stages.",
          "pos": [
            75,
            180
          ]
        },
        {
          "content": "Also, Spark is compatible with the Hadoop Distributed File System (HDFS) and Azure Blob storage so the existing data can easily be processed via Spark.",
          "pos": [
            181,
            332
          ]
        }
      ]
    },
    {
      "pos": [
        4532,
        4796
      ],
      "content": "Spark can also be added using Script Action.  Script action adds either Spark 1.2.0 to HDInsight 3.2 cluster or Spark 1.0.2 to HDInsight 3.1 cluster. For more information, see <bpt id=\"p11\">[</bpt>Install and use Spark on HDInsight Hadoop clusters<ept id=\"p11\">](hdinsight-hadoop-spark-install.md)</ept>.",
      "nodes": [
        {
          "content": "Spark can also be added using Script Action.",
          "pos": [
            0,
            44
          ]
        },
        {
          "content": "Script action adds either Spark 1.2.0 to HDInsight 3.2 cluster or Spark 1.0.2 to HDInsight 3.1 cluster.",
          "pos": [
            46,
            149
          ]
        },
        {
          "content": "For more information, see <bpt id=\"p11\">[</bpt>Install and use Spark on HDInsight Hadoop clusters<ept id=\"p11\">](hdinsight-hadoop-spark-install.md)</ept>.",
          "pos": [
            150,
            304
          ]
        }
      ]
    },
    {
      "pos": [
        4801,
        5438
      ],
      "content": "<bpt id=\"p12\">**</bpt>Storm<ept id=\"p12\">**</ept><ph id=\"ph9\"/> - Storm on Azure HDInsight is now generally available, giving a fast and easy way to deploy real-time analytics in just a few clicks and within minutes. Apache Storm on Azure HDInsight is an open-source project in the Apache Hadoop ecosystem that provides access to an analytics platform capable of reliably processing millions of events. Now Hadoop users can gain insights as events happen, along with insights from past events. Microsoft is also providing built-in integration with Visual Studio, making developer interaction with Storm easy. You can now develop, deploy, and debug Storm topologies from within Visual Studio.",
      "nodes": [
        {
          "content": "<bpt id=\"p12\">**</bpt>Storm<ept id=\"p12\">**</ept><ph id=\"ph9\"/> - Storm on Azure HDInsight is now generally available, giving a fast and easy way to deploy real-time analytics in just a few clicks and within minutes.",
          "pos": [
            0,
            216
          ]
        },
        {
          "content": "Apache Storm on Azure HDInsight is an open-source project in the Apache Hadoop ecosystem that provides access to an analytics platform capable of reliably processing millions of events.",
          "pos": [
            217,
            402
          ]
        },
        {
          "content": "Now Hadoop users can gain insights as events happen, along with insights from past events.",
          "pos": [
            403,
            493
          ]
        },
        {
          "content": "Microsoft is also providing built-in integration with Visual Studio, making developer interaction with Storm easy.",
          "pos": [
            494,
            608
          ]
        },
        {
          "content": "You can now develop, deploy, and debug Storm topologies from within Visual Studio.",
          "pos": [
            609,
            691
          ]
        }
      ]
    },
    {
      "pos": [
        5442,
        5972
      ],
      "content": "<bpt id=\"p13\">**</bpt>HDInsight on Linux<ept id=\"p13\">**</ept><ph id=\"ph10\"/> - Azure HDInsight provides the option of provisioning Hadoop clusters that run on Linux (Ubuntu) virtual machines (VMs). You can use this option if you are familiar with Linux or Unix, are migrating from an existing Linux-based Hadoop solution, or want easy integration with Hadoop ecosystem components built for Linux. You can provision an HDInsight cluster on Linux from a client computer running Windows or Linux by using the Azure Classic Portal, the Azure CLI, or the HDInsight .NET SDK (Windows only).",
      "nodes": [
        {
          "content": "<bpt id=\"p13\">**</bpt>HDInsight on Linux<ept id=\"p13\">**</ept><ph id=\"ph10\"/> - Azure HDInsight provides the option of provisioning Hadoop clusters that run on Linux (Ubuntu) virtual machines (VMs).",
          "pos": [
            0,
            198
          ]
        },
        {
          "content": "You can use this option if you are familiar with Linux or Unix, are migrating from an existing Linux-based Hadoop solution, or want easy integration with Hadoop ecosystem components built for Linux.",
          "pos": [
            199,
            397
          ]
        },
        {
          "content": "You can provision an HDInsight cluster on Linux from a client computer running Windows or Linux by using the Azure Classic Portal, the Azure CLI, or the HDInsight .NET SDK (Windows only).",
          "pos": [
            398,
            585
          ]
        }
      ]
    },
    {
      "pos": [
        5976,
        6603
      ],
      "content": "<bpt id=\"p14\">**</bpt>Additional VM sizes<ept id=\"p14\">**</ept><ph id=\"ph11\"/> - HDInsight clusters are now available on more VM types and sizes. HDInsight clusters can now utilize A2 to A7 sizes built for general purposes; D-Series nodes that feature solid-state drives (SSDs) and 60-percent faster processors; and A8 and A9 sizes that have InfiniBand support for fast networking. Apache HBase on Azure HDInsight customers can benefit from the larger memory configurations of the D-Series to increase performance. Apache Storm on Azure HDInsight customers can also benefit from additional memory for loading larger reference data sets, as well as faster CPUs for higher throughput.",
      "nodes": [
        {
          "content": "<bpt id=\"p14\">**</bpt>Additional VM sizes<ept id=\"p14\">**</ept><ph id=\"ph11\"/> - HDInsight clusters are now available on more VM types and sizes.",
          "pos": [
            0,
            145
          ]
        },
        {
          "content": "HDInsight clusters can now utilize A2 to A7 sizes built for general purposes; D-Series nodes that feature solid-state drives (SSDs) and 60-percent faster processors; and A8 and A9 sizes that have InfiniBand support for fast networking.",
          "pos": [
            146,
            381
          ]
        },
        {
          "content": "Apache HBase on Azure HDInsight customers can benefit from the larger memory configurations of the D-Series to increase performance.",
          "pos": [
            382,
            514
          ]
        },
        {
          "content": "Apache Storm on Azure HDInsight customers can also benefit from additional memory for loading larger reference data sets, as well as faster CPUs for higher throughput.",
          "pos": [
            515,
            682
          ]
        }
      ]
    },
    {
      "pos": [
        6607,
        6860
      ],
      "content": "<bpt id=\"p15\">**</bpt>Cluster scaling<ept id=\"p15\">**</ept><ph id=\"ph12\"/> - Cluster scaling enables you to change the number of nodes of a running HDInsight cluster without having to delete or re-create it. Currently, only Hadoop Query and Apache Storm have this ability, but Apache HBase is soon to follow.",
      "nodes": [
        {
          "content": "<bpt id=\"p15\">**</bpt>Cluster scaling<ept id=\"p15\">**</ept><ph id=\"ph12\"/> - Cluster scaling enables you to change the number of nodes of a running HDInsight cluster without having to delete or re-create it.",
          "pos": [
            0,
            207
          ]
        },
        {
          "content": "Currently, only Hadoop Query and Apache Storm have this ability, but Apache HBase is soon to follow.",
          "pos": [
            208,
            308
          ]
        }
      ]
    },
    {
      "pos": [
        6864,
        7257
      ],
      "content": "<bpt id=\"p16\">**</bpt>Script Action<ept id=\"p16\">**</ept><ph id=\"ph13\"/> - This cluster customization feature enables the modification of Hadoop clusters in arbitrary ways by using custom scripts. With this new feature, users can experiment with and deploy projects available from the Apache Hadoop ecosystem to Azure HDInsight clusters. This customization feature is available on all types of HDInsight clusters, including Hadoop, HBase and Storm.",
      "nodes": [
        {
          "content": "<bpt id=\"p16\">**</bpt>Script Action<ept id=\"p16\">**</ept><ph id=\"ph13\"/> - This cluster customization feature enables the modification of Hadoop clusters in arbitrary ways by using custom scripts.",
          "pos": [
            0,
            196
          ]
        },
        {
          "content": "With this new feature, users can experiment with and deploy projects available from the Apache Hadoop ecosystem to Azure HDInsight clusters.",
          "pos": [
            197,
            337
          ]
        },
        {
          "content": "This customization feature is available on all types of HDInsight clusters, including Hadoop, HBase and Storm.",
          "pos": [
            338,
            448
          ]
        }
      ]
    },
    {
      "pos": [
        7261,
        7810
      ],
      "content": "<bpt id=\"p17\">**</bpt>HBase<ept id=\"p17\">**</ept><ph id=\"ph14\"/> - HBase is a low-latency NoSQL database that allows online transactional processing of big data. HBase is offered as a managed cluster integrated into the Azure environment. The clusters are configured to store data directly in Azure Blob storage, which provides low latency and increased elasticity in performance/cost choices. This enables customers to build interactive websites that work with large datasets, to build services that store sensor and telemetry data from millions of end points, and to analyze this data with Hadoop jobs.",
      "nodes": [
        {
          "content": "<bpt id=\"p17\">**</bpt>HBase<ept id=\"p17\">**</ept><ph id=\"ph14\"/> - HBase is a low-latency NoSQL database that allows online transactional processing of big data.",
          "pos": [
            0,
            161
          ]
        },
        {
          "content": "HBase is offered as a managed cluster integrated into the Azure environment.",
          "pos": [
            162,
            238
          ]
        },
        {
          "content": "The clusters are configured to store data directly in Azure Blob storage, which provides low latency and increased elasticity in performance/cost choices.",
          "pos": [
            239,
            393
          ]
        },
        {
          "content": "This enables customers to build interactive websites that work with large datasets, to build services that store sensor and telemetry data from millions of end points, and to analyze this data with Hadoop jobs.",
          "pos": [
            394,
            604
          ]
        }
      ]
    },
    {
      "pos": [
        7814,
        8606
      ],
      "content": "<bpt id=\"p18\">**</bpt>Apache Phoenix<ept id=\"p18\">**</ept><ph id=\"ph15\"/> - Apache Phoenix is a Structured Query Language (SQL) query layer over HBase. It supports a limited subset of the SQL query language specification, including support of secondary indexes. It is delivered as a client-embedded Java Database Connectivity (JDBC) driver that targets low-latency queries over HBase data. Apache Phoenix takes your SQL query, compiles it into a series of HBase scans and coprocessors calls, and produces regular JDBC result sets. Apache Phoenix is a relational database layer over HBase. It is delivered as a client-embedded JDBC driver that targets low-latency queries over HBase data. Apache Phoenix takes your SQL query, compiles it into a series of HBase scans, and orchestrates the running of those scans to produce regular JDBC result sets.",
      "nodes": [
        {
          "content": "<bpt id=\"p18\">**</bpt>Apache Phoenix<ept id=\"p18\">**</ept><ph id=\"ph15\"/> - Apache Phoenix is a Structured Query Language (SQL) query layer over HBase.",
          "pos": [
            0,
            151
          ]
        },
        {
          "content": "It supports a limited subset of the SQL query language specification, including support of secondary indexes.",
          "pos": [
            152,
            261
          ]
        },
        {
          "content": "It is delivered as a client-embedded Java Database Connectivity (JDBC) driver that targets low-latency queries over HBase data.",
          "pos": [
            262,
            389
          ]
        },
        {
          "content": "Apache Phoenix takes your SQL query, compiles it into a series of HBase scans and coprocessors calls, and produces regular JDBC result sets.",
          "pos": [
            390,
            530
          ]
        },
        {
          "content": "Apache Phoenix is a relational database layer over HBase.",
          "pos": [
            531,
            588
          ]
        },
        {
          "content": "It is delivered as a client-embedded JDBC driver that targets low-latency queries over HBase data.",
          "pos": [
            589,
            687
          ]
        },
        {
          "content": "Apache Phoenix takes your SQL query, compiles it into a series of HBase scans, and orchestrates the running of those scans to produce regular JDBC result sets.",
          "pos": [
            688,
            847
          ]
        }
      ]
    },
    {
      "pos": [
        8610,
        8856
      ],
      "content": "<bpt id=\"p19\">**</bpt>Cluster Dashboard<ept id=\"p19\">**</ept><ph id=\"ph16\"/> - A new web application that is deployed to your HDInsight cluster. Use it to run Hive queries, check job logs, and browse Azure Blob storage. The URL used to access the web application is &lt;<bpt id=\"p20\">*</bpt>ClusterName<ept id=\"p20\">*</ept>&gt;.azurehdinsight.net.",
      "nodes": [
        {
          "content": "<bpt id=\"p19\">**</bpt>Cluster Dashboard<ept id=\"p19\">**</ept><ph id=\"ph16\"/> - A new web application that is deployed to your HDInsight cluster. Us",
          "pos": [
            0,
            147
          ]
        },
        {
          "content": "e it to run Hive queries, check job logs, and browse Azure Blob storage. Th",
          "pos": [
            147,
            222
          ]
        },
        {
          "content": "e URL used to access the web application is &lt;<bpt id=\"p20\">*</bpt>ClusterName<ept id=\"p20\">*</ept>&gt;.azurehdinsight.net.",
          "pos": [
            222,
            347
          ]
        }
      ]
    },
    {
      "pos": [
        8860,
        9454
      ],
      "content": "<bpt id=\"p21\">**</bpt>Microsoft Avro Library<ept id=\"p21\">**</ept><ph id=\"ph17\"/> - This library implements the Apache Avro data serialization system for the Microsoft .NET environment. Apache Avro provides a compact binary data interchange format for serialization. It uses JavaScript Object Notation (JSON) to define a language-agnostic schema that underwrites language interoperability. Data serialized in one language can be read in another. Currently C, C++, C#, Java, PHP, Python, and Ruby are supported. The Apache Avro serialization format is widely used in Azure HDInsight to represent complex data structures within a Hadoop MapReduce job.",
      "nodes": [
        {
          "content": "<bpt id=\"p21\">**</bpt>Microsoft Avro Library<ept id=\"p21\">**</ept><ph id=\"ph17\"/> - This library implements the Apache Avro data serialization system for the Microsoft .NET environment.",
          "pos": [
            0,
            185
          ]
        },
        {
          "content": "Apache Avro provides a compact binary data interchange format for serialization.",
          "pos": [
            186,
            266
          ]
        },
        {
          "content": "It uses JavaScript Object Notation (JSON) to define a language-agnostic schema that underwrites language interoperability.",
          "pos": [
            267,
            389
          ]
        },
        {
          "content": "Data serialized in one language can be read in another.",
          "pos": [
            390,
            445
          ]
        },
        {
          "content": "Currently C, C++, C#, Java, PHP, Python, and Ruby are supported.",
          "pos": [
            446,
            510
          ]
        },
        {
          "content": "The Apache Avro serialization format is widely used in Azure HDInsight to represent complex data structures within a Hadoop MapReduce job.",
          "pos": [
            511,
            649
          ]
        }
      ]
    },
    {
      "pos": [
        9458,
        10025
      ],
      "content": "<bpt id=\"p22\">**</bpt>YARN<ept id=\"p22\">**</ept><ph id=\"ph18\"/> - A new, general-purpose, distributed application management framework that has replaced the classic Apache Hadoop MapReduce framework for processing data in Hadoop clusters. It effectively serves as the Hadoop operating system, and takes Hadoop from a single-use data platform for batch processing to a multi-use platform that enables batch, interactive, online and stream processing. This new management framework improves scalability and cluster utilization according to criteria such as capacity guarantees, fairness, and service-level agreements (SLAs).",
      "nodes": [
        {
          "content": "<bpt id=\"p22\">**</bpt>YARN<ept id=\"p22\">**</ept><ph id=\"ph18\"/> - A new, general-purpose, distributed application management framework that has replaced the classic Apache Hadoop MapReduce framework for processing data in Hadoop clusters.",
          "pos": [
            0,
            238
          ]
        },
        {
          "content": "It effectively serves as the Hadoop operating system, and takes Hadoop from a single-use data platform for batch processing to a multi-use platform that enables batch, interactive, online and stream processing.",
          "pos": [
            239,
            449
          ]
        },
        {
          "content": "This new management framework improves scalability and cluster utilization according to criteria such as capacity guarantees, fairness, and service-level agreements (SLAs).",
          "pos": [
            450,
            622
          ]
        }
      ]
    },
    {
      "pos": [
        10029,
        10596
      ],
      "content": "<bpt id=\"p23\">**</bpt>Tez (HDInsight 3.1 and above only)<ept id=\"p23\">**</ept><ph id=\"ph19\"/> - A general-purpose and customizable framework that creates simplified data-processing tasks across both small-scale and large-scale workloads in Hadoop. It provides the ability to execute a complex directed acyclic graph (DAG) of tasks for a single job, so that projects in the Apache Hadoop ecosystem, such as Apache Hive and Apache Pig, can meet requirements for human-interactive response times and extreme throughput at petabyte scale. Note that Hive 0.13 allows Hive queries to run on top of Tez, rather than on MapReduce.",
      "nodes": [
        {
          "content": "<bpt id=\"p23\">**</bpt>Tez (HDInsight 3.1 and above only)<ept id=\"p23\">**</ept><ph id=\"ph19\"/> - A general-purpose and customizable framework that creates simplified data-processing tasks across both small-scale and large-scale workloads in Hadoop.",
          "pos": [
            0,
            247
          ]
        },
        {
          "content": "It provides the ability to execute a complex directed acyclic graph (DAG) of tasks for a single job, so that projects in the Apache Hadoop ecosystem, such as Apache Hive and Apache Pig, can meet requirements for human-interactive response times and extreme throughput at petabyte scale.",
          "pos": [
            248,
            534
          ]
        },
        {
          "content": "Note that Hive 0.13 allows Hive queries to run on top of Tez, rather than on MapReduce.",
          "pos": [
            535,
            622
          ]
        }
      ]
    },
    {
      "pos": [
        10600,
        11114
      ],
      "content": "<bpt id=\"p24\">**</bpt>High Availability (HA)<ept id=\"p24\">**</ept><ph id=\"ph20\"/> - A second head node has been added to the Hadoop clusters deployed by HDInsight to increase the availability of the service. Standard implementations of Hadoop clusters typically have a single head node. HDInsight removes this single point of failure with the addition of a secondary head node. The switch to a new HA cluster configuration doesn't change the price of the cluster, unless customers provision clusters with an extra-large head node instead of the default large-size node.",
      "nodes": [
        {
          "content": "<bpt id=\"p24\">**</bpt>High Availability (HA)<ept id=\"p24\">**</ept><ph id=\"ph20\"/> - A second head node has been added to the Hadoop clusters deployed by HDInsight to increase the availability of the service.",
          "pos": [
            0,
            207
          ]
        },
        {
          "content": "Standard implementations of Hadoop clusters typically have a single head node.",
          "pos": [
            208,
            286
          ]
        },
        {
          "content": "HDInsight removes this single point of failure with the addition of a secondary head node.",
          "pos": [
            287,
            377
          ]
        },
        {
          "content": "The switch to a new HA cluster configuration doesn't change the price of the cluster, unless customers provision clusters with an extra-large head node instead of the default large-size node.",
          "pos": [
            378,
            569
          ]
        }
      ]
    },
    {
      "pos": [
        11118,
        11300
      ],
      "content": "<bpt id=\"p25\">**</bpt>Hive performance<ept id=\"p25\">**</ept><ph id=\"ph21\"/> - Order-of-magnitude improvements to Hive query response times (up to 40x) and to data compression (up to 80%) using the <bpt id=\"p26\">**</bpt>Optimized Row Columnar<ept id=\"p26\">**</ept><ph id=\"ph22\"/> (ORC) format."
    },
    {
      "pos": [
        11304,
        11537
      ],
      "content": "<bpt id=\"p27\">**</bpt>Pig, Sqoop, Oozie, Ambari<ept id=\"p27\">**</ept><ph id=\"ph23\"/> - Component version upgrades for HDInsight cluster version 3.0 (HDP 2.0/Hadoop 2.2) that provide parity with HDInsight cluster version 2.1 (HDP 1.3/Hadoop 1.2). See the version table below for specifics.",
      "nodes": [
        {
          "content": "<bpt id=\"p27\">**</bpt>Pig, Sqoop, Oozie, Ambari<ept id=\"p27\">**</ept><ph id=\"ph23\"/> - Component version upgrades for HDInsight cluster version 3.0 (HDP 2.0/Hadoop 2.2) that provide parity with HDInsight cluster version 2.1 (HDP 1.3/Hadoop 1.2).",
          "pos": [
            0,
            245
          ]
        },
        {
          "content": "See the version table below for specifics.",
          "pos": [
            246,
            288
          ]
        }
      ]
    },
    {
      "pos": [
        11541,
        11755
      ],
      "content": "<bpt id=\"p28\">**</bpt>Mahout<ept id=\"p28\">**</ept><ph id=\"ph24\"/> - This library of scalable machine-learning algorithms is pre-installed on HDInsight 3.1 (and above) Hadoop clusters. So you can run Mahout jobs without the need for any additional cluster configuration.",
      "nodes": [
        {
          "content": "<bpt id=\"p28\">**</bpt>Mahout<ept id=\"p28\">**</ept><ph id=\"ph24\"/> - This library of scalable machine-learning algorithms is pre-installed on HDInsight 3.1 (and above) Hadoop clusters.",
          "pos": [
            0,
            183
          ]
        },
        {
          "content": "So you can run Mahout jobs without the need for any additional cluster configuration.",
          "pos": [
            184,
            269
          ]
        }
      ]
    },
    {
      "pos": [
        11759,
        11963
      ],
      "content": "<bpt id=\"p29\">**</bpt>Virtual Network support<ept id=\"p29\">**</ept><ph id=\"ph25\"/> - HDInsight clusters can be used with Azure Virtual Network to support isolation of cloud resources or hybrid scenarios that link cloud resources with those in your datacenter."
    },
    {
      "pos": [
        11969,
        11987
      ],
      "content": "Supported versions"
    },
    {
      "pos": [
        11988,
        12258
      ],
      "content": "The following table lists the versions of HDInsight currently available, the corresponding Hortonworks Data Platform versions that they use, and their release dates. When known, their support expiration and deprecation dates are also provided. Please note the following:",
      "nodes": [
        {
          "content": "The following table lists the versions of HDInsight currently available, the corresponding Hortonworks Data Platform versions that they use, and their release dates.",
          "pos": [
            0,
            165
          ]
        },
        {
          "content": "When known, their support expiration and deprecation dates are also provided.",
          "pos": [
            166,
            243
          ]
        },
        {
          "content": "Please note the following:",
          "pos": [
            244,
            270
          ]
        }
      ]
    },
    {
      "pos": [
        12262,
        12411
      ],
      "content": "Highly available clusters with two head nodes are deployed by default for HDInsight 2.1 and above. They are not available for HDInsight 1.6 clusters.",
      "nodes": [
        {
          "content": "Highly available clusters with two head nodes are deployed by default for HDInsight 2.1 and above.",
          "pos": [
            0,
            98
          ]
        },
        {
          "content": "They are not available for HDInsight 1.6 clusters.",
          "pos": [
            99,
            149
          ]
        }
      ]
    },
    {
      "pos": [
        12414,
        12850
      ],
      "content": "Once the support has expired for a particular version, it may not be available through the Azure Classic Portal. The following table indicates which versions are available on the Azure Classic Portal. Cluster versions will continue to be available using the <ph id=\"ph26\">`Version`</ph><ph id=\"ph27\"/> parameter in the Windows PowerShell <bpt id=\"p30\">[</bpt>New-AzureRmHDInsightCluster<ept id=\"p30\">](https://msdn.microsoft.com/library/mt619331.aspx)</ept><ph id=\"ph28\"/> command and the .NET SDK until its deprecation date.",
      "nodes": [
        {
          "content": "Once the support has expired for a particular version, it may not be available through the Azure Classic Portal.",
          "pos": [
            0,
            112
          ]
        },
        {
          "content": "The following table indicates which versions are available on the Azure Classic Portal.",
          "pos": [
            113,
            200
          ]
        },
        {
          "content": "Cluster versions will continue to be available using the <ph id=\"ph26\">`Version`</ph><ph id=\"ph27\"/> parameter in the Windows PowerShell <bpt id=\"p30\">[</bpt>New-AzureRmHDInsightCluster<ept id=\"p30\">](https://msdn.microsoft.com/library/mt619331.aspx)</ept><ph id=\"ph28\"/> command and the .NET SDK until its deprecation date.",
          "pos": [
            201,
            525
          ]
        }
      ]
    },
    {
      "pos": [
        12870,
        12871
      ],
      "content": "\n"
    },
    {
      "pos": [
        12879,
        12896
      ],
      "content": "HDInsight Version"
    },
    {
      "pos": [
        12905,
        12916
      ],
      "content": "HDP Version"
    },
    {
      "pos": [
        12924,
        12941
      ],
      "content": "High Availability"
    },
    {
      "pos": [
        12955,
        12967
      ],
      "content": "Release Date"
    },
    {
      "pos": [
        12976,
        13009
      ],
      "content": "Available on Azure Classic Portal"
    },
    {
      "pos": [
        13018,
        13041
      ],
      "content": "Support Expiration Date"
    },
    {
      "pos": [
        13050,
        13066
      ],
      "content": "Deprecation Date"
    },
    {
      "pos": [
        13076,
        13077
      ],
      "content": "\n"
    },
    {
      "pos": [
        13085,
        13092
      ],
      "content": "HDI 3.2"
    },
    {
      "pos": [
        13101,
        13108
      ],
      "content": "HDP 2.2"
    },
    {
      "pos": [
        13117,
        13120
      ],
      "content": "Yes"
    },
    {
      "pos": [
        13129,
        13138
      ],
      "content": "2/18/2015"
    },
    {
      "pos": [
        13147,
        13150
      ],
      "content": "Yes"
    },
    {
      "pos": [
        13178,
        13179
      ],
      "content": "\n"
    },
    {
      "pos": [
        13187,
        13194
      ],
      "content": "HDI 3.1"
    },
    {
      "pos": [
        13203,
        13210
      ],
      "content": "HDP 2.1"
    },
    {
      "pos": [
        13219,
        13222
      ],
      "content": "Yes"
    },
    {
      "pos": [
        13231,
        13240
      ],
      "content": "6/24/2014"
    },
    {
      "pos": [
        13249,
        13252
      ],
      "content": "Yes"
    },
    {
      "pos": [
        13280,
        13281
      ],
      "content": "\n"
    },
    {
      "pos": [
        13289,
        13296
      ],
      "content": "HDI 3.0"
    },
    {
      "pos": [
        13305,
        13312
      ],
      "content": "HDP 2.0"
    },
    {
      "pos": [
        13321,
        13324
      ],
      "content": "Yes"
    },
    {
      "pos": [
        13333,
        13343
      ],
      "content": "02/11/2014"
    },
    {
      "pos": [
        13352,
        13355
      ],
      "content": "Yes"
    },
    {
      "pos": [
        13364,
        13374
      ],
      "content": "09/17/2014"
    },
    {
      "pos": [
        13383,
        13393
      ],
      "content": "06/30/2015"
    },
    {
      "pos": [
        13403,
        13404
      ],
      "content": "\n"
    },
    {
      "pos": [
        13412,
        13419
      ],
      "content": "HDI 2.1"
    },
    {
      "pos": [
        13428,
        13435
      ],
      "content": "HDP 1.3"
    },
    {
      "pos": [
        13444,
        13447
      ],
      "content": "Yes"
    },
    {
      "pos": [
        13456,
        13466
      ],
      "content": "10/28/2013"
    },
    {
      "pos": [
        13475,
        13477
      ],
      "content": "No"
    },
    {
      "pos": [
        13486,
        13496
      ],
      "content": "05/12/2014"
    },
    {
      "pos": [
        13505,
        13515
      ],
      "content": "05/31/2015"
    },
    {
      "pos": [
        13525,
        13526
      ],
      "content": "\n"
    },
    {
      "pos": [
        13534,
        13541
      ],
      "content": "HDI 1.6"
    },
    {
      "pos": [
        13550,
        13557
      ],
      "content": "HDP 1.1"
    },
    {
      "pos": [
        13566,
        13568
      ],
      "content": "No"
    },
    {
      "pos": [
        13577,
        13587
      ],
      "content": "10/28/2013"
    },
    {
      "pos": [
        13596,
        13598
      ],
      "content": "No"
    },
    {
      "pos": [
        13607,
        13617
      ],
      "content": "04/26/2014"
    },
    {
      "pos": [
        13626,
        13636
      ],
      "content": "05/31/2015"
    },
    {
      "pos": [
        13646,
        13647
      ],
      "content": "\n"
    },
    {
      "pos": [
        13661,
        13699
      ],
      "content": "<bpt id=\"p31\">**</bpt>Deployment of non-default clusters<ept id=\"p31\">**</ept>"
    },
    {
      "pos": [
        13701,
        13894
      ],
      "content": "HDInsight 3.1 clusters are created by default on Hadoop 2.4, so users must use the <bpt id=\"p32\">**</bpt>Custom Create<ept id=\"p32\">**</ept><ph id=\"ph29\"/> option in the portal to specify other HDInsight cluster versions if they need to be created."
    },
    {
      "pos": [
        13900,
        13958
      ],
      "content": "The service-level agreement for HDInsight cluster versions"
    },
    {
      "pos": [
        13960,
        14480
      ],
      "content": "The SLA is defined in terms of a \"Support Window\". A Support Window refers to the period of time that an HDInsight cluster version is supported by Microsoft Customer Service and Support. An HDInsight cluster is outside the Support Window if its version has a <bpt id=\"p33\">**</bpt>Support Expiration Date<ept id=\"p33\">**</ept><ph id=\"ph30\"/> past the current date. A list of supported HDInsight cluster versions can be found in the table above. The support expiration date for a given HDInsight version X (once a newer X+1 version is available) is calculated as the later of:",
      "nodes": [
        {
          "content": "The SLA is defined in terms of a \"Support Window\".",
          "pos": [
            0,
            50
          ]
        },
        {
          "content": "A Support Window refers to the period of time that an HDInsight cluster version is supported by Microsoft Customer Service and Support.",
          "pos": [
            51,
            186
          ]
        },
        {
          "content": "An HDInsight cluster is outside the Support Window if its version has a <bpt id=\"p33\">**</bpt>Support Expiration Date<ept id=\"p33\">**</ept><ph id=\"ph30\"/> past the current date.",
          "pos": [
            187,
            364
          ]
        },
        {
          "content": "A list of supported HDInsight cluster versions can be found in the table above.",
          "pos": [
            365,
            444
          ]
        },
        {
          "content": "The support expiration date for a given HDInsight version X (once a newer X+1 version is available) is calculated as the later of:",
          "pos": [
            445,
            575
          ]
        }
      ]
    },
    {
      "pos": [
        14486,
        14563
      ],
      "content": "Formula 1: Add 180 days to the date HDInsight cluster version X was released."
    },
    {
      "pos": [
        14566,
        14710
      ],
      "content": "Formula 2: Add 90 days to the date HDInsight cluster version X+1 (the subsequent version after X) is made available in the Azure Classic Portal."
    },
    {
      "pos": [
        14712,
        14812
      ],
      "content": "The <bpt id=\"p34\">**</bpt>Deprecation Date<ept id=\"p34\">**</ept><ph id=\"ph31\"/> is the date after which the cluster version cannot be created on HDInsight."
    },
    {
      "pos": [
        14816,
        15047
      ],
      "content": "<ph id=\"ph32\">[AZURE.NOTE]</ph><ph id=\"ph33\"/> Both HDInsight 2.1 and 3.0 clusters run on Azure Guest OS <bpt id=\"p35\">[</bpt>Family 4<ept id=\"p35\">](../cloud-services-guestos-update-matrix.md)</ept>, which uses the 64-bit version of Windows Server 2012 R2 and supports .NET Framework 4.0, 4.5. and 4.5.1.",
      "nodes": [
        {
          "content": "<ph id=\"ph32\">[AZURE.NOTE]</ph><ph id=\"ph33\"/> Both HDInsight 2.1 and 3.0 clusters run on Azure Guest OS <bpt id=\"p35\">[</bpt>Family 4<ept id=\"p35\">](../cloud-services-guestos-update-matrix.md)</ept>, which uses the 64-bit version of Windows Server 2012 R2 and supports .NET Framework 4.0, 4.5.",
          "pos": [
            0,
            294
          ]
        },
        {
          "content": "and 4.5.1.",
          "pos": [
            295,
            305
          ]
        }
      ]
    },
    {
      "pos": [
        15052,
        15112
      ],
      "content": "Hortonworks release notes associated with HDInsight versions"
    },
    {
      "pos": [
        15118,
        15233
      ],
      "content": "HDInsight cluster version 3.2 uses a Hadoop distribution that is based on <bpt id=\"p36\">[</bpt>Hortonworks Data Platform 2.2<ept id=\"p36\">][hdp-2-2]</ept>."
    },
    {
      "pos": [
        15241,
        16551
      ],
      "content": "Release notes for specific Apache components - <bpt id=\"p37\">[</bpt>Hive 0.14<ept id=\"p37\">](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310843&amp;version=12326450)</ept>, <bpt id=\"p38\">[</bpt>Pig 0.14<ept id=\"p38\">](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310730&amp;version=12326954)</ept>, <bpt id=\"p39\">[</bpt>HBase 0.98.4<ept id=\"p39\">](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310753&amp;version=12326810)</ept>, <bpt id=\"p40\">[</bpt>Phoenix 4.2.0<ept id=\"p40\">](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12315120&amp;version=12327581)</ept>, <bpt id=\"p41\">[</bpt>M/R 2.6<ept id=\"p41\">](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310941&amp;version=12327180)</ept>, <bpt id=\"p42\">[</bpt>HDFS 2.6<ept id=\"p42\">](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310942&amp;version=12327181)</ept>, <bpt id=\"p43\">[</bpt>YARN 2.6<ept id=\"p43\">](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12313722&amp;version=12327197)</ept>, <bpt id=\"p44\">[</bpt>Common<ept id=\"p44\">](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310240&amp;version=12327179)</ept>, <bpt id=\"p45\">[</bpt>Tez 0.5.2<ept id=\"p45\">](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12314426&amp;version=12328742)</ept>, <bpt id=\"p46\">[</bpt>Ambari 2.0<ept id=\"p46\">](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12312020&amp;version=12327486)</ept>, <bpt id=\"p47\">[</bpt>Storm 0.9.3<ept id=\"p47\">](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12314820&amp;version=12327112)</ept>, <bpt id=\"p48\">[</bpt>Oozie 4.1.0<ept id=\"p48\">](https://issues.apache.org/jira/secure/ReleaseNote.jspa?version=12324960&amp;projectId=12311620)</ept>."
    },
    {
      "pos": [
        16556,
        16889
      ],
      "content": "HDInsight cluster version 3.1 uses a Hadoop distribution that is based on <bpt id=\"p49\">[</bpt>Hortonworks Data Platform 2.1.7<ept id=\"p49\">][hdp-2-1-7]</ept>. This is the <bpt id=\"p50\">**</bpt>default<ept id=\"p50\">**</ept><ph id=\"ph34\"/> Hadoop cluster created when using the Azure HDInsight portal after 11/7/2014. HDInsight 3.1 clusters created before 11/7/2014 were based on the <bpt id=\"p51\">[</bpt>Hortonworks Data Platform 2.1.1<ept id=\"p51\">][hdp-2-1-1]</ept>.",
      "nodes": [
        {
          "content": "HDInsight cluster version 3.1 uses a Hadoop distribution that is based on <bpt id=\"p49\">[</bpt>Hortonworks Data Platform 2.1.7<ept id=\"p49\">][hdp-2-1-7]</ept>.",
          "pos": [
            0,
            159
          ]
        },
        {
          "content": "This is the <bpt id=\"p50\">**</bpt>default<ept id=\"p50\">**</ept><ph id=\"ph34\"/> Hadoop cluster created when using the Azure HDInsight portal after 11/7/2014.",
          "pos": [
            160,
            316
          ]
        },
        {
          "content": "HDInsight 3.1 clusters created before 11/7/2014 were based on the <bpt id=\"p51\">[</bpt>Hortonworks Data Platform 2.1.1<ept id=\"p51\">][hdp-2-1-1]</ept>.",
          "pos": [
            317,
            468
          ]
        }
      ]
    },
    {
      "pos": [
        16893,
        17010
      ],
      "content": "HDInsight cluster version 3.0 uses a Hadoop distribution that is based on <bpt id=\"p52\">[</bpt>Hortonworks Data Platform 2.0<ept id=\"p52\">][hdp-2-0-8]</ept>."
    },
    {
      "pos": [
        17014,
        17131
      ],
      "content": "HDInsight cluster version 2.1 uses a Hadoop distribution that is based on <bpt id=\"p53\">[</bpt>Hortonworks Data Platform 1.3<ept id=\"p53\">][hdp-1-3-0]</ept>."
    },
    {
      "pos": [
        17135,
        17252
      ],
      "content": "HDInsight cluster version 1.6 uses a Hadoop distribution that is based on <bpt id=\"p54\">[</bpt>Hortonworks Data Platform 1.1<ept id=\"p54\">][hdp-1-1-0]</ept>."
    }
  ],
  "content": "<properties\n    pageTitle=\"What's new in Hadoop cluster versions of HDInsight? | Microsoft Azure\"\n    description=\"HDInsight supports multiple deployable Hadoop cluster versions. See the Hadoop and HortonWorks Data Platform (HDP) distribution versions supported.\"\n    services=\"hdinsight\"\n    editor=\"cgronlun\"\n    manager=\"paulettm\"\n    authors=\"mumian\"\n    documentationCenter=\"\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.workload=\"big-data\"\n    ms.tgt_pltfrm=\"na\"\n    ms.devlang=\"na\"\n    ms.topic=\"article\"\n    ms.date=\"02/04/2016\"\n    ms.author=\"jgao\"/>\n\n\n#What's new in the Hadoop cluster versions provided by HDInsight?\n\n##HDInsight versions and Hadoop components\nAzure HDInsight supports multiple Hadoop cluster versions that can be deployed at any time. Each version choice provisions a specific version of the Hortonworks Data Platform (HDP) distribution and a set of components that are contained within that distribution. The component versions associated with HDInsight cluster versions are itemized in the following table. Note that the default cluster version used by Azure HDInsight is currently 3.1, and, as of 11/7/2014, based on HDP 2.1.7.\n\n\n<table border=\"1\">\n<tr><th>Component</th><th>HDInsight Version 3.2</th><th>HDInsight Version 3.1 (Default)</th><th>HDInsight Version 3.0</th><th>HDInsight Version 2.1</th></tr>\n<tr><td>Hortonworks Data Platform</td><td>2.2</td><td>2.1.7</td><td>2.0</td><td>1.3</td></tr>\n<tr><td>Apache Hadoop & YARN</td><td>2.6.0</td><td>2.4.0</td><td>2.2.0</td><td>1.2.0</td></tr>\n<tr><td>Apache Tez</td><td>0.5.2</td><td>0.4.0</td><td></td><td></td></tr>\n<tr><td>Apache Pig</td><td>0.14.0</td><td>0.12.1</td><td>0.12.0</td><td>0.11.0</td></tr>\n<tr><td>Apache Hive & HCatalog</td><td>0.14.0</td><td>0.13.1</td><td>0.12.0</td><td>0.11.0</td></tr>\n<tr><td>Apazhe HBase </td><td>0.98.4</td><td>0.98.0</td><td></td><td></td></tr>\n<tr><td>Apache Sqoop</td><td>1.4.5</td><td>1.4.4</td><td>1.4.4</td><td>1.4.3</td></tr>\n<tr><td>Apache Oozie</td><td>4.1.0</td><td>4.0.0</td><td>4.0.0</td><td>3.3.2</td></tr>\n<tr><td>Apache Zookeeper</td><td>3.4.6</td><td>3.4.5</td><td>3.4.5</td><td></td></tr>\n<tr><td>Apache Storm</td><td>0.9.3</td><td>0.9.1</td><td></td><td></td></tr>\n<tr><td>Apache Mahout</td><td>0.9.0</td><td>0.9.0</td><td></td><td></td></tr>\n<tr><td>Apache Phoenix</td><td>4.2.0</td><td>4.0.0.2.1.7.0-2162</td><td></td><td></td></tr>\n<tr><td>Apache Spark</td><td>1.3.1</td><td></td><td></td><td></td></tr>\n</table>\n\n\n**Get current component version information**\n\nThe component versions associated with HDInsight cluster versions may change in future updates to HDInsight. One way to determine the available components and to verify which versions are being used for a cluster is to use the Ambari REST API. The **GetComponentInformation** command can be used to retrieve information about a service component. For details, see the [Ambari documentation][ambari-docs]. Another way to obtain this information is to log in to a cluster by using Remote Desktop and examine the contents of the \"C:\\apps\\dist\\\" directory directly.\n\n\n**Release notes**\n\nSee [HDInsight release notes](hdinsight-release-notes.md) for additional release notes on the latest versions of HDInsight.\n\n### Select a version when provisioning an HDInsight cluster\n\nWhen creating a cluster through the HDInsight Windows PowerShell cmdlets or the HDInsight .NET SDK, you can choose the version for the HDInsight Hadoop cluster by using the \"Version\" parameter.\n\nIf you use the **Quick Create** option, you will get version 3.1 of HDInsight, which creates a Hadoop cluster by default. If you use the **Custom Create** option from the Azure Classic Portal, you can choose the version of the cluster you will deploy from the **HDInsight Version** drop-down on the **Cluster Details** page.\n\n##Feature highlights\nSome of the salient features of the HDInsight platform include:\n\n- **Spark** - Apache Spark is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications. Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations.\n\n    Spark can also be used to perform conventional disk-based data processing. Spark improves the traditional MapReduce framework by avoiding writes to disk in the intermediate stages. Also, Spark is compatible with the Hadoop Distributed File System (HDFS) and Azure Blob storage so the existing data can easily be processed via Spark.\n\n    Spark can also be added using Script Action.  Script action adds either Spark 1.2.0 to HDInsight 3.2 cluster or Spark 1.0.2 to HDInsight 3.1 cluster. For more information, see [Install and use Spark on HDInsight Hadoop clusters](hdinsight-hadoop-spark-install.md).\n\n\n- **Storm** - Storm on Azure HDInsight is now generally available, giving a fast and easy way to deploy real-time analytics in just a few clicks and within minutes. Apache Storm on Azure HDInsight is an open-source project in the Apache Hadoop ecosystem that provides access to an analytics platform capable of reliably processing millions of events. Now Hadoop users can gain insights as events happen, along with insights from past events. Microsoft is also providing built-in integration with Visual Studio, making developer interaction with Storm easy. You can now develop, deploy, and debug Storm topologies from within Visual Studio.\n\n- **HDInsight on Linux** - Azure HDInsight provides the option of provisioning Hadoop clusters that run on Linux (Ubuntu) virtual machines (VMs). You can use this option if you are familiar with Linux or Unix, are migrating from an existing Linux-based Hadoop solution, or want easy integration with Hadoop ecosystem components built for Linux. You can provision an HDInsight cluster on Linux from a client computer running Windows or Linux by using the Azure Classic Portal, the Azure CLI, or the HDInsight .NET SDK (Windows only).\n\n- **Additional VM sizes** - HDInsight clusters are now available on more VM types and sizes. HDInsight clusters can now utilize A2 to A7 sizes built for general purposes; D-Series nodes that feature solid-state drives (SSDs) and 60-percent faster processors; and A8 and A9 sizes that have InfiniBand support for fast networking. Apache HBase on Azure HDInsight customers can benefit from the larger memory configurations of the D-Series to increase performance. Apache Storm on Azure HDInsight customers can also benefit from additional memory for loading larger reference data sets, as well as faster CPUs for higher throughput.\n\n- **Cluster scaling** - Cluster scaling enables you to change the number of nodes of a running HDInsight cluster without having to delete or re-create it. Currently, only Hadoop Query and Apache Storm have this ability, but Apache HBase is soon to follow.\n\n- **Script Action** - This cluster customization feature enables the modification of Hadoop clusters in arbitrary ways by using custom scripts. With this new feature, users can experiment with and deploy projects available from the Apache Hadoop ecosystem to Azure HDInsight clusters. This customization feature is available on all types of HDInsight clusters, including Hadoop, HBase and Storm.\n\n- **HBase** - HBase is a low-latency NoSQL database that allows online transactional processing of big data. HBase is offered as a managed cluster integrated into the Azure environment. The clusters are configured to store data directly in Azure Blob storage, which provides low latency and increased elasticity in performance/cost choices. This enables customers to build interactive websites that work with large datasets, to build services that store sensor and telemetry data from millions of end points, and to analyze this data with Hadoop jobs.\n\n- **Apache Phoenix** - Apache Phoenix is a Structured Query Language (SQL) query layer over HBase. It supports a limited subset of the SQL query language specification, including support of secondary indexes. It is delivered as a client-embedded Java Database Connectivity (JDBC) driver that targets low-latency queries over HBase data. Apache Phoenix takes your SQL query, compiles it into a series of HBase scans and coprocessors calls, and produces regular JDBC result sets. Apache Phoenix is a relational database layer over HBase. It is delivered as a client-embedded JDBC driver that targets low-latency queries over HBase data. Apache Phoenix takes your SQL query, compiles it into a series of HBase scans, and orchestrates the running of those scans to produce regular JDBC result sets.\n\n- **Cluster Dashboard** - A new web application that is deployed to your HDInsight cluster. Use it to run Hive queries, check job logs, and browse Azure Blob storage. The URL used to access the web application is <*ClusterName*>.azurehdinsight.net.\n\n- **Microsoft Avro Library** - This library implements the Apache Avro data serialization system for the Microsoft .NET environment. Apache Avro provides a compact binary data interchange format for serialization. It uses JavaScript Object Notation (JSON) to define a language-agnostic schema that underwrites language interoperability. Data serialized in one language can be read in another. Currently C, C++, C#, Java, PHP, Python, and Ruby are supported. The Apache Avro serialization format is widely used in Azure HDInsight to represent complex data structures within a Hadoop MapReduce job.\n\n- **YARN** - A new, general-purpose, distributed application management framework that has replaced the classic Apache Hadoop MapReduce framework for processing data in Hadoop clusters. It effectively serves as the Hadoop operating system, and takes Hadoop from a single-use data platform for batch processing to a multi-use platform that enables batch, interactive, online and stream processing. This new management framework improves scalability and cluster utilization according to criteria such as capacity guarantees, fairness, and service-level agreements (SLAs).\n\n- **Tez (HDInsight 3.1 and above only)** - A general-purpose and customizable framework that creates simplified data-processing tasks across both small-scale and large-scale workloads in Hadoop. It provides the ability to execute a complex directed acyclic graph (DAG) of tasks for a single job, so that projects in the Apache Hadoop ecosystem, such as Apache Hive and Apache Pig, can meet requirements for human-interactive response times and extreme throughput at petabyte scale. Note that Hive 0.13 allows Hive queries to run on top of Tez, rather than on MapReduce.\n\n- **High Availability (HA)** - A second head node has been added to the Hadoop clusters deployed by HDInsight to increase the availability of the service. Standard implementations of Hadoop clusters typically have a single head node. HDInsight removes this single point of failure with the addition of a secondary head node. The switch to a new HA cluster configuration doesn't change the price of the cluster, unless customers provision clusters with an extra-large head node instead of the default large-size node.\n\n- **Hive performance** - Order-of-magnitude improvements to Hive query response times (up to 40x) and to data compression (up to 80%) using the **Optimized Row Columnar** (ORC) format.\n\n- **Pig, Sqoop, Oozie, Ambari** - Component version upgrades for HDInsight cluster version 3.0 (HDP 2.0/Hadoop 2.2) that provide parity with HDInsight cluster version 2.1 (HDP 1.3/Hadoop 1.2). See the version table below for specifics.\n\n- **Mahout** - This library of scalable machine-learning algorithms is pre-installed on HDInsight 3.1 (and above) Hadoop clusters. So you can run Mahout jobs without the need for any additional cluster configuration.\n\n- **Virtual Network support** - HDInsight clusters can be used with Azure Virtual Network to support isolation of cloud resources or hybrid scenarios that link cloud resources with those in your datacenter.\n\n\n## Supported versions\nThe following table lists the versions of HDInsight currently available, the corresponding Hortonworks Data Platform versions that they use, and their release dates. When known, their support expiration and deprecation dates are also provided. Please note the following:\n\n* Highly available clusters with two head nodes are deployed by default for HDInsight 2.1 and above. They are not available for HDInsight 1.6 clusters.\n* Once the support has expired for a particular version, it may not be available through the Azure Classic Portal. The following table indicates which versions are available on the Azure Classic Portal. Cluster versions will continue to be available using the `Version` parameter in the Windows PowerShell [New-AzureRmHDInsightCluster](https://msdn.microsoft.com/library/mt619331.aspx) command and the .NET SDK until its deprecation date.\n\n<table border=\"1\">\n<tr><th>HDInsight Version</th><th>HDP Version</a><th>High Availability</th></th><th>Release Date</th><th>Available on Azure Classic Portal</th><th>Support Expiration Date</th><th>Deprecation Date</th></tr>\n<tr><td>HDI 3.2</td><td>HDP 2.2</td><td>Yes</td><td>2/18/2015</td><td>Yes</td><td></td><td></td></tr>\n<tr><td>HDI 3.1</td><td>HDP 2.1</td><td>Yes</td><td>6/24/2014</td><td>Yes</td><td></td><td></td></tr>\n<tr><td>HDI 3.0</td><td>HDP 2.0</td><td>Yes</td><td>02/11/2014</td><td>Yes</td><td>09/17/2014</td><td>06/30/2015</td></tr>\n<tr><td>HDI 2.1</td><td>HDP 1.3</td><td>Yes</td><td>10/28/2013</td><td>No</td><td>05/12/2014</td><td>05/31/2015</td></tr>\n<tr><td>HDI 1.6</td><td>HDP 1.1</td><td>No</td><td>10/28/2013</td><td>No</td><td>04/26/2014</td><td>05/31/2015</td></tr>\n</table><br>\n\n**Deployment of non-default clusters**\n\nHDInsight 3.1 clusters are created by default on Hadoop 2.4, so users must use the **Custom Create** option in the portal to specify other HDInsight cluster versions if they need to be created.\n\n### The service-level agreement for HDInsight cluster versions\n\nThe SLA is defined in terms of a \"Support Window\". A Support Window refers to the period of time that an HDInsight cluster version is supported by Microsoft Customer Service and Support. An HDInsight cluster is outside the Support Window if its version has a **Support Expiration Date** past the current date. A list of supported HDInsight cluster versions can be found in the table above. The support expiration date for a given HDInsight version X (once a newer X+1 version is available) is calculated as the later of:  \n\n- Formula 1: Add 180 days to the date HDInsight cluster version X was released.\n- Formula 2: Add 90 days to the date HDInsight cluster version X+1 (the subsequent version after X) is made available in the Azure Classic Portal.\n\nThe **Deprecation Date** is the date after which the cluster version cannot be created on HDInsight.\n\n> [AZURE.NOTE] Both HDInsight 2.1 and 3.0 clusters run on Azure Guest OS [Family 4](../cloud-services-guestos-update-matrix.md), which uses the 64-bit version of Windows Server 2012 R2 and supports .NET Framework 4.0, 4.5. and 4.5.1.\n\n## Hortonworks release notes associated with HDInsight versions##\n\n* HDInsight cluster version 3.2 uses a Hadoop distribution that is based on [Hortonworks Data Platform 2.2][hdp-2-2].\n\n    * Release notes for specific Apache components - [Hive 0.14](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310843&version=12326450), [Pig 0.14](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310730&version=12326954), [HBase 0.98.4](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310753&version=12326810), [Phoenix 4.2.0](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12315120&version=12327581), [M/R 2.6](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310941&version=12327180), [HDFS 2.6](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310942&version=12327181), [YARN 2.6](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12313722&version=12327197), [Common](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12310240&version=12327179), [Tez 0.5.2](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12314426&version=12328742), [Ambari 2.0](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12312020&version=12327486), [Storm 0.9.3](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12314820&version=12327112), [Oozie 4.1.0](https://issues.apache.org/jira/secure/ReleaseNote.jspa?version=12324960&projectId=12311620).\n\n\n* HDInsight cluster version 3.1 uses a Hadoop distribution that is based on [Hortonworks Data Platform 2.1.7][hdp-2-1-7]. This is the **default** Hadoop cluster created when using the Azure HDInsight portal after 11/7/2014. HDInsight 3.1 clusters created before 11/7/2014 were based on the [Hortonworks Data Platform 2.1.1][hdp-2-1-1].\n\n* HDInsight cluster version 3.0 uses a Hadoop distribution that is based on [Hortonworks Data Platform 2.0][hdp-2-0-8].\n\n* HDInsight cluster version 2.1 uses a Hadoop distribution that is based on [Hortonworks Data Platform 1.3][hdp-1-3-0].\n\n* HDInsight cluster version 1.6 uses a Hadoop distribution that is based on [Hortonworks Data Platform 1.1][hdp-1-1-0].\n\n\n[image-hdi-versioning-versionscreen]: ./media/hdinsight-component-versioning/hdi-versioning-version-screen.png\n\n[wa-forums]: http://azure.microsoft.com/support/forums/\n\n[connect-excel-with-hive-ODBC]: hdinsight-connect-excel-hive-ODBC-driver.md\n\n[hdp-2-2]: http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.2.0/HDP_2.2.0_Release_Notes_20141202_version/index.html\n\n[hdp-2-1-7]: http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1.7-Win/bk_releasenotes_HDP-Win/content/ch_relnotes-HDP-2.1.7.html\n\n[hdp-2-1-1]: http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1.1/bk_releasenotes_hdp_2.1/content/ch_relnotes-hdp-2.1.1.html\n\n[hdp-2-0-8]: http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.0.8.0/bk_releasenotes_hdp_2.0/content/ch_relnotes-hdp2.0.8.0.html\n\n[hdp-1-3-0]: http://docs.hortonworks.com/HDPDocuments/HDP1/HDP-1.3.0/bk_releasenotes_hdp_1.x/content/ch_relnotes-hdp1.3.0_1.html\n\n[hdp-1-1-0]: http://docs.hortonworks.com/HDPDocuments/HDP1/HDP-Win-1.1/bk_releasenotes_HDP-Win/content/ch_relnotes-hdp-win-1.1.0_1.html\n\n[ambari-docs]: https://github.com/apache/ambari/blob/trunk/ambari-server/docs/api/v1/index.md\n\n[zookeeper]: http://zookeeper.apache.org/\n"
}