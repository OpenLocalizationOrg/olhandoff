<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="ja-jp">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Customize Hadoop clusters for the Cortana Analytics Process | Microsoft Azure</source>
          <target state="new">Customize Hadoop clusters for the Cortana Analytics Process | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Popular Python modules made available in custom Azure HDInsight Hadoop clusters.</source>
          <target state="new">Popular Python modules made available in custom Azure HDInsight Hadoop clusters.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Customize Azure HDInsight Hadoop clusters for the Cortana Analytics Process</source>
          <target state="new">Customize Azure HDInsight Hadoop clusters for the Cortana Analytics Process</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Introduction</source>
          <target state="new">Introduction</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>This article describes how to customize an HDInsight Hadoop cluster by installing 64-bit Anaconda (Python 2.7) on each node when the cluster is being provisioned in HDInsight service.</source>
          <target state="new">This article describes how to customize an HDInsight Hadoop cluster by installing 64-bit Anaconda (Python 2.7) on each node when the cluster is being provisioned in HDInsight service.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>This customization prepares the cluster for use with the Cortana Analytics Process.</source>
          <target state="new">This customization prepares the cluster for use with the Cortana Analytics Process.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>It also shows how to access the headnode to submit custom jobs to the cluster.</source>
          <target state="new">It also shows how to access the headnode to submit custom jobs to the cluster.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>This customization makes many popular Python modules that are included in Anaconda conveniently available for use in user defined functions (UDFs) that are designed to process Hive records in the cluster.</source>
          <target state="new">This customization makes many popular Python modules that are included in Anaconda conveniently available for use in user defined functions (UDFs) that are designed to process Hive records in the cluster.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>For instructions on the procedures used in this scenario, see <bpt id="p1">[</bpt>Submit Hive Queries to HDInsight Hadoop clusters in the advanced analytics process<ept id="p1">](machine-learning-data-science-hive-queries.md)</ept>.</source>
          <target state="new">For instructions on the procedures used in this scenario, see <bpt id="p1">[</bpt>Submit Hive Queries to HDInsight Hadoop clusters in the advanced analytics process<ept id="p1">](machine-learning-data-science-hive-queries.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>The menu below links to topics that describe how to set up the various data science environments used by the Cortana Analytics Process (CAPS).</source>
          <target state="new">The menu below links to topics that describe how to set up the various data science environments used by the Cortana Analytics Process (CAPS).</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Customize Azure HDInsight Hadoop Cluster</source>
          <target state="new">Customize Azure HDInsight Hadoop Cluster</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>To create a customized HDInsight Hadoop cluster, users need to log on to <bpt id="p2">[</bpt><bpt id="p3">**</bpt>Classic Portal of Azure<ept id="p3">**</ept><ept id="p2">](https://manage.windowsazure.com/)</ept>, click <bpt id="p4">**</bpt>New<ept id="p4">**</ept><ph id="ph3" /> at the left bottom corner, and then select DATA SERVICES -&gt; HDINSIGHT -&gt; <bpt id="p5">**</bpt>CUSTOM CREATE<ept id="p5">**</ept><ph id="ph4" /> to bring up the <bpt id="p6">**</bpt>Cluster Details<ept id="p6">**</ept><ph id="ph5" /> window.</source>
          <target state="new">To create a customized HDInsight Hadoop cluster, users need to log on to <bpt id="p2">[</bpt><bpt id="p3">**</bpt>Classic Portal of Azure<ept id="p3">**</ept><ept id="p2">](https://manage.windowsazure.com/)</ept>, click <bpt id="p4">**</bpt>New<ept id="p4">**</ept><ph id="ph3" /> at the left bottom corner, and then select DATA SERVICES -&gt; HDINSIGHT -&gt; <bpt id="p5">**</bpt>CUSTOM CREATE<ept id="p5">**</ept><ph id="ph4" /> to bring up the <bpt id="p6">**</bpt>Cluster Details<ept id="p6">**</ept><ph id="ph5" /> window.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source><ph id="ph6">![</ph>Create workspace<ph id="ph7">][1]</ph></source>
          <target state="new"><ph id="ph6">![</ph>Create workspace<ph id="ph7">][1]</ph></target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Input the name of the cluster to be created on configuration page 1, and accept default values for the other fields.</source>
          <target state="new">Input the name of the cluster to be created on configuration page 1, and accept default values for the other fields.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Click on the arrow to go to the next configuration page.</source>
          <target state="new">Click on the arrow to go to the next configuration page.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source><ph id="ph8">![</ph>Create workspace<ph id="ph9">][2]</ph></source>
          <target state="new"><ph id="ph8">![</ph>Create workspace<ph id="ph9">][2]</ph></target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>On configuration page 2, input the number of <bpt id="p7">**</bpt>DATA NODES<ept id="p7">**</ept>, select the <bpt id="p8">**</bpt>REGION/VIRTUAL NETWORK<ept id="p8">**</ept>, and select the sizes of the <bpt id="p9">**</bpt>HEAD NODE<ept id="p9">**</ept><ph id="ph10" /> and the <bpt id="p10">**</bpt>DATA NODE<ept id="p10">**</ept>.</source>
          <target state="new">On configuration page 2, input the number of <bpt id="p7">**</bpt>DATA NODES<ept id="p7">**</ept>, select the <bpt id="p8">**</bpt>REGION/VIRTUAL NETWORK<ept id="p8">**</ept>, and select the sizes of the <bpt id="p9">**</bpt>HEAD NODE<ept id="p9">**</ept><ph id="ph10" /> and the <bpt id="p10">**</bpt>DATA NODE<ept id="p10">**</ept>.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Click the arrow to go to the next configuration page.</source>
          <target state="new">Click the arrow to go to the next configuration page.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><ph id="ph11">[AZURE.NOTE]</ph><ph id="ph12" /> The <bpt id="p11">**</bpt>REGION/VIRTUAL NETWORK<ept id="p11">**</ept><ph id="ph13" /> has to be the same as the region of the storage account that is going to be used for the HDInsight Hadoop cluster.</source>
          <target state="new"><ph id="ph11">[AZURE.NOTE]</ph><ph id="ph12" /> The <bpt id="p11">**</bpt>REGION/VIRTUAL NETWORK<ept id="p11">**</ept><ph id="ph13" /> has to be the same as the region of the storage account that is going to be used for the HDInsight Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Otherwise, in fourth configuration page, the storage account that the users want to use will not appear on the dropdown list of <bpt id="p12">**</bpt>ACCOUNT NAME<ept id="p12">**</ept>.</source>
          <target state="new">Otherwise, in fourth configuration page, the storage account that the users want to use will not appear on the dropdown list of <bpt id="p12">**</bpt>ACCOUNT NAME<ept id="p12">**</ept>.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source><ph id="ph14">![</ph>Create workspace<ph id="ph15">][3]</ph></source>
          <target state="new"><ph id="ph14">![</ph>Create workspace<ph id="ph15">][3]</ph></target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>On configuration page 3, provide a user name and password for the HDInsight Hadoop cluster.</source>
          <target state="new">On configuration page 3, provide a user name and password for the HDInsight Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source><bpt id="p13">**</bpt>Do not<ept id="p13">**</ept><ph id="ph16" /> select the <bpt id="p14">_</bpt>Enter the Hive/Oozie Metastore<ept id="p14">_</ept>.</source>
          <target state="new"><bpt id="p13">**</bpt>Do not<ept id="p13">**</ept><ph id="ph16" /> select the <bpt id="p14">_</bpt>Enter the Hive/Oozie Metastore<ept id="p14">_</ept>.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Then, click the arrow to go to the next configuration page.</source>
          <target state="new">Then, click the arrow to go to the next configuration page.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source><ph id="ph17">![</ph>Create workspace<ph id="ph18">][4]</ph></source>
          <target state="new"><ph id="ph17">![</ph>Create workspace<ph id="ph18">][4]</ph></target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>On configuration page 4, specify the storage account name, the default container of the HDInsight Hadoop cluster.</source>
          <target state="new">On configuration page 4, specify the storage account name, the default container of the HDInsight Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>If users select <bpt id="p15">_</bpt>Create default container<ept id="p15">_</ept><ph id="ph19" /> in the <bpt id="p16">**</bpt>DEFAULT CONTAINER<ept id="p16">**</ept><ph id="ph20" /> drop down list, a container with the same name as the cluster will be created.</source>
          <target state="new">If users select <bpt id="p15">_</bpt>Create default container<ept id="p15">_</ept><ph id="ph19" /> in the <bpt id="p16">**</bpt>DEFAULT CONTAINER<ept id="p16">**</ept><ph id="ph20" /> drop down list, a container with the same name as the cluster will be created.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Click the arrow to go to the last configuration page.</source>
          <target state="new">Click the arrow to go to the last configuration page.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source><ph id="ph21">![</ph>Create workspace<ph id="ph22">][5]</ph></source>
          <target state="new"><ph id="ph21">![</ph>Create workspace<ph id="ph22">][5]</ph></target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>On the final <bpt id="p17">**</bpt>Script Actions<ept id="p17">**</ept><ph id="ph23" /> configuration page, click <bpt id="p18">**</bpt>add script action<ept id="p18">**</ept><ph id="ph24" /> button, and fill the text fields with the following values.</source>
          <target state="new">On the final <bpt id="p17">**</bpt>Script Actions<ept id="p17">**</ept><ph id="ph23" /> configuration page, click <bpt id="p18">**</bpt>add script action<ept id="p18">**</ept><ph id="ph24" /> button, and fill the text fields with the following values.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><bpt id="p19">**</bpt>NAME<ept id="p19">**</ept><ph id="ph25" /> - any string as the name of this script action.</source>
          <target state="new"><bpt id="p19">**</bpt>NAME<ept id="p19">**</ept><ph id="ph25" /> - any string as the name of this script action.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source><bpt id="p20">**</bpt>NODE TYPE<ept id="p20">**</ept><ph id="ph26" /> - select <bpt id="p21">**</bpt>All nodes<ept id="p21">**</ept>.</source>
          <target state="new"><bpt id="p20">**</bpt>NODE TYPE<ept id="p20">**</ept><ph id="ph26" /> - select <bpt id="p21">**</bpt>All nodes<ept id="p21">**</ept>.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source><bpt id="p22">**</bpt>SCRIPT URI<ept id="p22">**</ept><ph id="ph27" /> - <bpt id="p23">*</bpt>http://getgoing.blob.core.windows.net/publicscripts/Azure_HDI_Setup_Windows.ps1<ept id="p23">*</ept></source>
          <target state="new"><bpt id="p22">**</bpt>SCRIPT URI<ept id="p22">**</ept><ph id="ph27" /> - <bpt id="p23">*</bpt>http://getgoing.blob.core.windows.net/publicscripts/Azure_HDI_Setup_Windows.ps1<ept id="p23">*</ept></target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source><bpt id="p24">*</bpt>publicscripts<ept id="p24">*</ept><ph id="ph28" /> is a public container in storage account</source>
          <target state="new"><bpt id="p24">*</bpt>publicscripts<ept id="p24">*</ept><ph id="ph28" /> is a public container in storage account</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source><bpt id="p25">*</bpt>getgoing<ept id="p25">*</ept><ph id="ph29" /> we use to share PowerShell script files to facilitate users work in Azure.</source>
          <target state="new"><bpt id="p25">*</bpt>getgoing<ept id="p25">*</ept><ph id="ph29" /> we use to share PowerShell script files to facilitate users work in Azure.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source><bpt id="p26">**</bpt>PARAMETERS<ept id="p26">**</ept><ph id="ph30" /> - (leave blank)</source>
          <target state="new"><bpt id="p26">**</bpt>PARAMETERS<ept id="p26">**</ept><ph id="ph30" /> - (leave blank)</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Finally, click on the check mark to start the creation of the customized HDInsight Hadoop cluster.</source>
          <target state="new">Finally, click on the check mark to start the creation of the customized HDInsight Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source><ph id="ph31">![</ph>Create workspace<ph id="ph32">][6]</ph></source>
          <target state="new"><ph id="ph31">![</ph>Create workspace<ph id="ph32">][6]</ph></target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Access the Head Node of Hadoop Cluster</source>
          <target state="new">Access the Head Node of Hadoop Cluster</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Users must enable remote access to the Hadoop cluster in Azure before they can access the head node of the Hadoop cluster through RDP.</source>
          <target state="new">Users must enable remote access to the Hadoop cluster in Azure before they can access the head node of the Hadoop cluster through RDP.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Log in to the <bpt id="p27">[</bpt><bpt id="p28">**</bpt>Classic Portal of Azure<ept id="p28">**</ept><ept id="p27">](https://manage.windowsazure.com/)</ept>, select <bpt id="p29">**</bpt>HDInsight<ept id="p29">**</ept><ph id="ph33" /> on the left, select your Hadoop cluster from the list of clusters, click the <bpt id="p30">**</bpt>CONFIGURATION<ept id="p30">**</ept><ph id="ph34" /> tab, and then click the <bpt id="p31">**</bpt>ENABLE REMOTE<ept id="p31">**</ept><ph id="ph35" /> icon at the bottom of the page.</source>
          <target state="new">Log in to the <bpt id="p27">[</bpt><bpt id="p28">**</bpt>Classic Portal of Azure<ept id="p28">**</ept><ept id="p27">](https://manage.windowsazure.com/)</ept>, select <bpt id="p29">**</bpt>HDInsight<ept id="p29">**</ept><ph id="ph33" /> on the left, select your Hadoop cluster from the list of clusters, click the <bpt id="p30">**</bpt>CONFIGURATION<ept id="p30">**</ept><ph id="ph34" /> tab, and then click the <bpt id="p31">**</bpt>ENABLE REMOTE<ept id="p31">**</ept><ph id="ph35" /> icon at the bottom of the page.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source><ph id="ph36">![</ph>Create workspace<ph id="ph37">][7]</ph></source>
          <target state="new"><ph id="ph36">![</ph>Create workspace<ph id="ph37">][7]</ph></target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p32">**</bpt>Configure Remote Desktop<ept id="p32">**</ept><ph id="ph38" /> window, enter the USER NAME and PASSWORD fields, and select the expiration date for remote access.</source>
          <target state="new">In the <bpt id="p32">**</bpt>Configure Remote Desktop<ept id="p32">**</ept><ph id="ph38" /> window, enter the USER NAME and PASSWORD fields, and select the expiration date for remote access.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Then click the check mark to enable the remote access to the head node of the Hadoop cluster.</source>
          <target state="new">Then click the check mark to enable the remote access to the head node of the Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>The user name and password for the remote access are not the user name and password that you use when you created the Hadoop cluster.</source>
          <target state="new">The user name and password for the remote access are not the user name and password that you use when you created the Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>These are a separate set of credentials</source>
          <target state="new">These are a separate set of credentials</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>The expiration date of the remote access has to be within 7 days from the current date.</source>
          <target state="new">The expiration date of the remote access has to be within 7 days from the current date.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source><ph id="ph40">![</ph>Create workspace<ph id="ph41">][8]</ph></source>
          <target state="new"><ph id="ph40">![</ph>Create workspace<ph id="ph41">][8]</ph></target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>After remote access is enabled, click <bpt id="p33">**</bpt>CONNECT<ept id="p33">**</ept><ph id="ph42" /> at the bottom of the page to remote into the head node.</source>
          <target state="new">After remote access is enabled, click <bpt id="p33">**</bpt>CONNECT<ept id="p33">**</ept><ph id="ph42" /> at the bottom of the page to remote into the head node.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>You log on to the head node of the Hadoop cluster by entering the credentials for the remote access user that you specified earlier.</source>
          <target state="new">You log on to the head node of the Hadoop cluster by entering the credentials for the remote access user that you specified earlier.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source><ph id="ph43">![</ph>Create workspace<ph id="ph44">][9]</ph></source>
          <target state="new"><ph id="ph43">![</ph>Create workspace<ph id="ph44">][9]</ph></target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>The next steps in the advanced analytics process are mapped in the <bpt id="p34">[</bpt>Learning Guide: Advanced data processing in Azure<ept id="p34">](machine-learning-data-science-advanced-data-processing.md)</ept><ph id="ph45" /> and may include steps that move data into HDInsight, process and sample it there in preparation for learning from the data with Azure Machine Learning.</source>
          <target state="new">The next steps in the advanced analytics process are mapped in the <bpt id="p34">[</bpt>Learning Guide: Advanced data processing in Azure<ept id="p34">](machine-learning-data-science-advanced-data-processing.md)</ept><ph id="ph45" /> and may include steps that move data into HDInsight, process and sample it there in preparation for learning from the data with Azure Machine Learning.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>See <bpt id="p35">[</bpt>Submit Hive Queries to HDInsight Hadoop clusters in the advanced analytics process<ept id="p35">](machine-learning-data-science-process-hive-tables.md)</ept><ph id="ph46" /> for instructions on how to access the Python modules that are included in Anaconda from the head node of the cluster in user defined functions (UDFs) that are used to process Hive records stored in the cluster.</source>
          <target state="new">See <bpt id="p35">[</bpt>Submit Hive Queries to HDInsight Hadoop clusters in the advanced analytics process<ept id="p35">](machine-learning-data-science-process-hive-tables.md)</ept><ph id="ph46" /> for instructions on how to access the Python modules that are included in Anaconda from the head node of the cluster in user defined functions (UDFs) that are used to process Hive records stored in the cluster.</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">6b6f43212804d525282720a867b604df0c8f6e58</xliffext:olfilehash>
  </header>
</xliff>