{
  "nodes": [
    {
      "pos": [
        28,
        89
      ],
      "content": "Use BI tools with Apache Spark on HDInsight | Microsoft Azure"
    },
    {
      "pos": [
        109,
        292
      ],
      "content": "Step-by-step instructions on how to use notebooks with Apache Spark to create schemas on raw data, save them as Hive tables, and then use BI tools on the Hive table for data analytics"
    },
    {
      "pos": [
        633,
        690
      ],
      "content": "Use BI tools with Apache Spark on Azure HDInsight (Linux)"
    },
    {
      "pos": [
        692,
        761
      ],
      "content": "Learn how to use Apache Spark in Azure HDInsight to do the following:"
    },
    {
      "pos": [
        765,
        813
      ],
      "content": "Take raw sample data and save it as a Hive table"
    },
    {
      "pos": [
        816,
        892
      ],
      "content": "Use BI tools such as Power BI and Tableau to analyze and visualize the data."
    },
    {
      "pos": [
        896,
        1360
      ],
      "content": "<ph id=\"ph2\">[AZURE.TIP]</ph><ph id=\"ph3\"/> This tutorial is also available as a Jupyter notebook on a Spark (Linux) cluster that you create in HDInsight. The notebook experience lets you run the Python snippets from the notebook itself. To perform the tutorial from within a notebook, create a Spark cluster, launch a Jupyter notebook (<ph id=\"ph4\">`https://CLUSTERNAME.azurehdinsight.net/jupyter`</ph>), and then run the notebook <bpt id=\"p1\">**</bpt>Use BI tools with Apache Spark on HDInsight.ipynb<ept id=\"p1\">**</ept><ph id=\"ph5\"/> under the <bpt id=\"p2\">**</bpt>Python<ept id=\"p2\">**</ept><ph id=\"ph6\"/> folder.",
      "nodes": [
        {
          "content": "<ph id=\"ph2\">[AZURE.TIP]</ph><ph id=\"ph3\"/> This tutorial is also available as a Jupyter notebook on a Spark (Linux) cluster that you create in HDInsight.",
          "pos": [
            0,
            154
          ]
        },
        {
          "content": "The notebook experience lets you run the Python snippets from the notebook itself.",
          "pos": [
            155,
            237
          ]
        },
        {
          "content": "To perform the tutorial from within a notebook, create a Spark cluster, launch a Jupyter notebook (<ph id=\"ph4\">`https://CLUSTERNAME.azurehdinsight.net/jupyter`</ph>), and then run the notebook <bpt id=\"p1\">**</bpt>Use BI tools with Apache Spark on HDInsight.ipynb<ept id=\"p1\">**</ept><ph id=\"ph5\"/> under the <bpt id=\"p2\">**</bpt>Python<ept id=\"p2\">**</ept><ph id=\"ph6\"/> folder.",
          "pos": [
            238,
            618
          ]
        }
      ]
    },
    {
      "pos": [
        1362,
        1380
      ],
      "content": "<bpt id=\"p3\">**</bpt>Prerequisites:<ept id=\"p3\">**</ept>"
    },
    {
      "pos": [
        1382,
        1410
      ],
      "content": "You must have the following:"
    },
    {
      "pos": [
        1414,
        1568
      ],
      "content": "An Azure subscription. See <bpt id=\"p4\">[</bpt>Get Azure free trial<ept id=\"p4\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
      "nodes": [
        {
          "content": "An Azure subscription.",
          "pos": [
            0,
            22
          ]
        },
        {
          "content": "See <bpt id=\"p4\">[</bpt>Get Azure free trial<ept id=\"p4\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
          "pos": [
            23,
            192
          ]
        }
      ]
    },
    {
      "pos": [
        1571,
        1732
      ],
      "content": "An Apache Spark cluster on HDInsight Linux. For instructions, see <bpt id=\"p5\">[</bpt>Create Apache Spark clusters in Azure HDInsight<ept id=\"p5\">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.",
      "nodes": [
        {
          "content": "An Apache Spark cluster on HDInsight Linux.",
          "pos": [
            0,
            43
          ]
        },
        {
          "content": "For instructions, see <bpt id=\"p5\">[</bpt>Create Apache Spark clusters in Azure HDInsight<ept id=\"p5\">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.",
          "pos": [
            44,
            199
          ]
        }
      ]
    },
    {
      "pos": [
        1735,
        1931
      ],
      "content": "A computer with Microsoft Spark ODBC driver installed (required for Spark on HDInsight to work with Tableau). You can install the driver from <bpt id=\"p6\">[</bpt>here<ept id=\"p6\">](http://go.microsoft.com/fwlink/?LinkId=616229)</ept>.",
      "nodes": [
        {
          "content": "A computer with Microsoft Spark ODBC driver installed (required for Spark on HDInsight to work with Tableau).",
          "pos": [
            0,
            109
          ]
        },
        {
          "content": "You can install the driver from <bpt id=\"p6\">[</bpt>here<ept id=\"p6\">](http://go.microsoft.com/fwlink/?LinkId=616229)</ept>.",
          "pos": [
            110,
            234
          ]
        }
      ]
    },
    {
      "pos": [
        1934,
        2158
      ],
      "content": "BI tools such as <bpt id=\"p7\">[</bpt>Power BI<ept id=\"p7\">](http://www.powerbi.com/)</ept><ph id=\"ph7\"/> or <bpt id=\"p8\">[</bpt>Tableau Desktop<ept id=\"p8\">](http://www.tableau.com/products/desktop)</ept>. You can get a free preview subscription of Power BI from <bpt id=\"p9\">[</bpt>http://www.powerbi.com/<ept id=\"p9\">](http://www.powerbi.com/)</ept>.",
      "nodes": [
        {
          "content": "BI tools such as <bpt id=\"p7\">[</bpt>Power BI<ept id=\"p7\">](http://www.powerbi.com/)</ept><ph id=\"ph7\"/> or <bpt id=\"p8\">[</bpt>Tableau Desktop<ept id=\"p8\">](http://www.tableau.com/products/desktop)</ept>.",
          "pos": [
            0,
            205
          ]
        },
        {
          "content": "You can get a free preview subscription of Power BI from <bpt id=\"p9\">[</bpt>http://www.powerbi.com/<ept id=\"p9\">](http://www.powerbi.com/)</ept>.",
          "pos": [
            206,
            352
          ]
        }
      ]
    },
    {
      "pos": [
        2160,
        2162
      ],
      "content": "##"
    },
    {
      "pos": [
        2186,
        2215
      ],
      "content": "Save raw data as a Hive table"
    },
    {
      "pos": [
        2217,
        2492
      ],
      "content": "In this section, we use the <bpt id=\"p10\">[</bpt>Jupyter<ept id=\"p10\">](https://jupyter.org)</ept><ph id=\"ph8\"/> notebook associated with an Apache Spark cluster in HDInsight to run jobs that process your raw sample data and save it as a Hive table. The sample data is a .csv file (hvac.csv) available on all clusters by default.",
      "nodes": [
        {
          "content": "In this section, we use the <bpt id=\"p10\">[</bpt>Jupyter<ept id=\"p10\">](https://jupyter.org)</ept><ph id=\"ph8\"/> notebook associated with an Apache Spark cluster in HDInsight to run jobs that process your raw sample data and save it as a Hive table.",
          "pos": [
            0,
            249
          ]
        },
        {
          "content": "The sample data is a .csv file (hvac.csv) available on all clusters by default.",
          "pos": [
            250,
            329
          ]
        }
      ]
    },
    {
      "pos": [
        2494,
        2633
      ],
      "content": "Once your data is saved as a Hive table, in the next section we will connect to the Hive table using BI tools such as Power BI and Tableau."
    },
    {
      "pos": [
        2638,
        2879
      ],
      "content": "From the <bpt id=\"p11\">[</bpt>Azure Preview Portal<ept id=\"p11\">](https://portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard). You can also navigate to your cluster under <bpt id=\"p12\">**</bpt>Browse All<ept id=\"p12\">**</ept><ph id=\"ph9\"/> &gt; <bpt id=\"p13\">**</bpt>HDInsight Clusters<ept id=\"p13\">**</ept>.",
      "nodes": [
        {
          "content": "From the <bpt id=\"p11\">[</bpt>Azure Preview Portal<ept id=\"p11\">](https://portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).",
          "pos": [
            0,
            196
          ]
        },
        {
          "content": "You can also navigate to your cluster under <bpt id=\"p12\">**</bpt>Browse All<ept id=\"p12\">**</ept><ph id=\"ph9\"/> &gt; <bpt id=\"p13\">**</bpt>HDInsight Clusters<ept id=\"p13\">**</ept>.",
          "pos": [
            197,
            378
          ]
        }
      ]
    },
    {
      "pos": [
        2887,
        3072
      ],
      "content": "From the Spark cluster blade, click <bpt id=\"p14\">**</bpt>Quick Links<ept id=\"p14\">**</ept>, and then from the <bpt id=\"p15\">**</bpt>Cluster Dashboard<ept id=\"p15\">**</ept><ph id=\"ph10\"/> blade, click <bpt id=\"p16\">**</bpt>Jupyter Notebook<ept id=\"p16\">**</ept>. If prompted, enter the admin credentials for the cluster.",
      "nodes": [
        {
          "content": "From the Spark cluster blade, click <bpt id=\"p14\">**</bpt>Quick Links<ept id=\"p14\">**</ept>, and then from the <bpt id=\"p15\">**</bpt>Cluster Dashboard<ept id=\"p15\">**</ept><ph id=\"ph10\"/> blade, click <bpt id=\"p16\">**</bpt>Jupyter Notebook<ept id=\"p16\">**</ept>.",
          "pos": [
            0,
            262
          ]
        },
        {
          "content": "If prompted, enter the admin credentials for the cluster.",
          "pos": [
            263,
            320
          ]
        }
      ]
    },
    {
      "pos": [
        3080,
        3250
      ],
      "content": "<ph id=\"ph11\">[AZURE.NOTE]</ph><ph id=\"ph12\"/> You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser. Replace <bpt id=\"p17\">__</bpt>CLUSTERNAME<ept id=\"p17\">__</ept><ph id=\"ph13\"/> with the name of your cluster:",
      "nodes": [
        {
          "content": "<ph id=\"ph11\">[AZURE.NOTE]</ph><ph id=\"ph12\"/> You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser.",
          "pos": [
            0,
            149
          ]
        },
        {
          "content": "Replace <bpt id=\"p17\">__</bpt>CLUSTERNAME<ept id=\"p17\">__</ept><ph id=\"ph13\"/> with the name of your cluster:",
          "pos": [
            150,
            259
          ]
        }
      ]
    },
    {
      "pos": [
        3316,
        3382
      ],
      "content": "Create a new notebook. Click <bpt id=\"p18\">**</bpt>New<ept id=\"p18\">**</ept>, and then click <bpt id=\"p19\">**</bpt>Python 2<ept id=\"p19\">**</ept>.",
      "nodes": [
        {
          "content": "Create a new notebook.",
          "pos": [
            0,
            22
          ]
        },
        {
          "content": "Click <bpt id=\"p18\">**</bpt>New<ept id=\"p18\">**</ept>, and then click <bpt id=\"p19\">**</bpt>Python 2<ept id=\"p19\">**</ept>.",
          "pos": [
            23,
            146
          ]
        }
      ]
    },
    {
      "pos": [
        3388,
        3538
      ],
      "content": "<ph id=\"ph15\">![</ph>Create a new Jupyter notebook<ph id=\"ph16\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.note.jupyter.createnotebook.png \"Create a new Jupyter notebook\")</ph>"
    },
    {
      "pos": [
        3543,
        3671
      ],
      "content": "A new notebook is created and opened with the name Untitled.pynb. Click the notebook name at the top, and enter a friendly name.",
      "nodes": [
        {
          "content": "A new notebook is created and opened with the name Untitled.pynb.",
          "pos": [
            0,
            65
          ]
        },
        {
          "content": "Click the notebook name at the top, and enter a friendly name.",
          "pos": [
            66,
            128
          ]
        }
      ]
    },
    {
      "pos": [
        3677,
        3830
      ],
      "content": "<ph id=\"ph17\">![</ph>Provide a name for the notebook<ph id=\"ph18\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.note.jupyter.notebook.name.png \"Provide a name for the notebook\")</ph>"
    },
    {
      "pos": [
        3835,
        3982
      ],
      "content": "Import the required modules and create the Spark and Hive contexts. Paste the following snippet in an empty cell, and then press <bpt id=\"p20\">**</bpt>SHIFT + ENTER<ept id=\"p20\">**</ept>.",
      "nodes": [
        {
          "content": "Import the required modules and create the Spark and Hive contexts.",
          "pos": [
            0,
            67
          ]
        },
        {
          "content": "Paste the following snippet in an empty cell, and then press <bpt id=\"p20\">**</bpt>SHIFT + ENTER<ept id=\"p20\">**</ept>.",
          "pos": [
            68,
            187
          ]
        }
      ]
    },
    {
      "pos": [
        4269,
        4545
      ],
      "content": "Everytime you run a job in Jupyter, your web browser window title will show a <bpt id=\"p21\">**</bpt>(Busy)<ept id=\"p21\">**</ept><ph id=\"ph19\"/> status along with the notebook title. You will also see a solid circle next to the <bpt id=\"p22\">**</bpt>Python 2<ept id=\"p22\">**</ept><ph id=\"ph20\"/> text in the top-right corner. After the job completes, this will change to a hollow circle.",
      "nodes": [
        {
          "content": "Everytime you run a job in Jupyter, your web browser window title will show a <bpt id=\"p21\">**</bpt>(Busy)<ept id=\"p21\">**</ept><ph id=\"ph19\"/> status along with the notebook title.",
          "pos": [
            0,
            181
          ]
        },
        {
          "content": "You will also see a solid circle next to the <bpt id=\"p22\">**</bpt>Python 2<ept id=\"p22\">**</ept><ph id=\"ph20\"/> text in the top-right corner.",
          "pos": [
            182,
            324
          ]
        },
        {
          "content": "After the job completes, this will change to a hollow circle.",
          "pos": [
            325,
            386
          ]
        }
      ]
    },
    {
      "pos": [
        4552,
        4699
      ],
      "content": "<ph id=\"ph21\">![</ph>Status of a Jupyter notebook job<ph id=\"ph22\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.jupyter.job.status.png \"Status of a Jupyter notebook job\")</ph>"
    },
    {
      "pos": [
        4704,
        4926
      ],
      "content": "Load sample data into a temporary table. When you create a Spark cluster in HDInsight, the sample data file, <bpt id=\"p23\">**</bpt>hvac.csv<ept id=\"p23\">**</ept>, is copied to the associated storage account under <bpt id=\"p24\">**</bpt>\\HdiSamples\\HdiSamples\\SensorSampleData\\hvac<ept id=\"p24\">**</ept>.",
      "nodes": [
        {
          "content": "Load sample data into a temporary table.",
          "pos": [
            0,
            40
          ]
        },
        {
          "content": "When you create a Spark cluster in HDInsight, the sample data file, <bpt id=\"p23\">**</bpt>hvac.csv<ept id=\"p23\">**</ept>, is copied to the associated storage account under <bpt id=\"p24\">**</bpt>\\HdiSamples\\HdiSamples\\SensorSampleData\\hvac<ept id=\"p24\">**</ept>.",
          "pos": [
            41,
            302
          ]
        }
      ]
    },
    {
      "pos": [
        4932,
        5073
      ],
      "content": "In an empty cell, paste the following snippet and press <bpt id=\"p25\">**</bpt>SHIFT + ENTER<ept id=\"p25\">**</ept>. This snippet registers the data into a Hive table called <bpt id=\"p26\">**</bpt>hvac<ept id=\"p26\">**</ept>.",
      "nodes": [
        {
          "content": "In an empty cell, paste the following snippet and press <bpt id=\"p25\">**</bpt>SHIFT + ENTER<ept id=\"p25\">**</ept>.",
          "pos": [
            0,
            114
          ]
        },
        {
          "content": "This snippet registers the data into a Hive table called <bpt id=\"p26\">**</bpt>hvac<ept id=\"p26\">**</ept>.",
          "pos": [
            115,
            221
          ]
        }
      ]
    },
    {
      "pos": [
        5825,
        5962
      ],
      "content": "Verify that the table was successfully created. In an empty cell in the notebook, copy the following snippet and press <bpt id=\"p27\">**</bpt>SHIFT + ENTER<ept id=\"p27\">**</ept>.",
      "nodes": [
        {
          "content": "Verify that the table was successfully created.",
          "pos": [
            0,
            47
          ]
        },
        {
          "content": "In an empty cell in the notebook, copy the following snippet and press <bpt id=\"p27\">**</bpt>SHIFT + ENTER<ept id=\"p27\">**</ept>.",
          "pos": [
            48,
            177
          ]
        }
      ]
    },
    {
      "pos": [
        6011,
        6053
      ],
      "content": "You will see an output like the following:"
    },
    {
      "pos": [
        6327,
        6556
      ],
      "content": "Only the tables that have false under the <bpt id=\"p28\">**</bpt>isTemporary<ept id=\"p28\">**</ept><ph id=\"ph23\"/> column are hive tables that will be stored in the metastore and can be accessed from the BI tools. In this tutorial, we will connect to the <bpt id=\"p29\">**</bpt>hvac<ept id=\"p29\">**</ept><ph id=\"ph24\"/> table we just created.",
      "nodes": [
        {
          "content": "Only the tables that have false under the <bpt id=\"p28\">**</bpt>isTemporary<ept id=\"p28\">**</ept><ph id=\"ph23\"/> column are hive tables that will be stored in the metastore and can be accessed from the BI tools.",
          "pos": [
            0,
            211
          ]
        },
        {
          "content": "In this tutorial, we will connect to the <bpt id=\"p29\">**</bpt>hvac<ept id=\"p29\">**</ept><ph id=\"ph24\"/> table we just created.",
          "pos": [
            212,
            339
          ]
        }
      ]
    },
    {
      "pos": [
        6561,
        6700
      ],
      "content": "Verify that the table contains the intended data. In an empty cell in the notebook, copy the following snippet and press <bpt id=\"p30\">**</bpt>SHIFT + ENTER<ept id=\"p30\">**</ept>.",
      "nodes": [
        {
          "content": "Verify that the table contains the intended data.",
          "pos": [
            0,
            49
          ]
        },
        {
          "content": "In an empty cell in the notebook, copy the following snippet and press <bpt id=\"p30\">**</bpt>SHIFT + ENTER<ept id=\"p30\">**</ept>.",
          "pos": [
            50,
            179
          ]
        }
      ]
    },
    {
      "pos": [
        6768,
        6946
      ],
      "content": "You can now shutdown the notebook to release the resources. To do so, from the <bpt id=\"p31\">**</bpt>File<ept id=\"p31\">**</ept><ph id=\"ph25\"/> menu on the notebook, click <bpt id=\"p32\">**</bpt>Close and Halt<ept id=\"p32\">**</ept>. This will shutdown and close the notebook.",
      "nodes": [
        {
          "content": "You can now shutdown the notebook to release the resources.",
          "pos": [
            0,
            59
          ]
        },
        {
          "content": "To do so, from the <bpt id=\"p31\">**</bpt>File<ept id=\"p31\">**</ept><ph id=\"ph25\"/> menu on the notebook, click <bpt id=\"p32\">**</bpt>Close and Halt<ept id=\"p32\">**</ept>.",
          "pos": [
            60,
            230
          ]
        },
        {
          "content": "This will shutdown and close the notebook.",
          "pos": [
            231,
            273
          ]
        }
      ]
    },
    {
      "pos": [
        6948,
        6950
      ],
      "content": "##"
    },
    {
      "pos": [
        6972,
        7018
      ],
      "content": "Use Power BI to analyze data in the Hive table"
    },
    {
      "pos": [
        7020,
        7162
      ],
      "content": "Once you have saved the data as a Hive table, you can use Power BI to connect to the data and visualize it to create reports, dashboards, etc."
    },
    {
      "pos": [
        7167,
        7214
      ],
      "content": "Sign in to <bpt id=\"p33\">[</bpt>Power BI<ept id=\"p33\">](http://www.powerbi.com/)</ept>."
    },
    {
      "pos": [
        7219,
        7269
      ],
      "content": "On the Welcome screen, click <bpt id=\"p34\">**</bpt>Databases &amp; More<ept id=\"p34\">**</ept>."
    },
    {
      "pos": [
        7275,
        7400
      ],
      "content": "<ph id=\"ph26\">![</ph>Get data into Power BI<ph id=\"ph27\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.powerbi.get.data.png \"Get data into Power BI\")</ph>"
    },
    {
      "pos": [
        7405,
        7609
      ],
      "content": "On the next screen, click <bpt id=\"p35\">**</bpt>Spark on Azure HDInsight<ept id=\"p35\">**</ept><ph id=\"ph28\"/> and then click <bpt id=\"p36\">**</bpt>Connect<ept id=\"p36\">**</ept>. When prompted, enter the cluster URL (<ph id=\"ph29\">`mysparkcluster.azurehdinsight.net`</ph>) and the credentials to connect to the cluster.",
      "nodes": [
        {
          "content": "On the next screen, click <bpt id=\"p35\">**</bpt>Spark on Azure HDInsight<ept id=\"p35\">**</ept><ph id=\"ph28\"/> and then click <bpt id=\"p36\">**</bpt>Connect<ept id=\"p36\">**</ept>.",
          "pos": [
            0,
            177
          ]
        },
        {
          "content": "When prompted, enter the cluster URL (<ph id=\"ph29\">`mysparkcluster.azurehdinsight.net`</ph>) and the credentials to connect to the cluster.",
          "pos": [
            178,
            318
          ]
        }
      ]
    },
    {
      "pos": [
        7615,
        7719
      ],
      "content": "After the connection is established, Power BI starts importing data from the Spark cluster on HDInsight."
    },
    {
      "pos": [
        7724,
        7982
      ],
      "content": "Power BI imports the data and adds a new Spark dataset under the <bpt id=\"p37\">**</bpt>Datasets<ept id=\"p37\">**</ept><ph id=\"ph30\"/> heading. Click the data set to open a new worksheet to visualize the data. You can also save the worksheet as a report. To save a worksheet, from the <bpt id=\"p38\">**</bpt>File<ept id=\"p38\">**</ept><ph id=\"ph31\"/> menu, click <bpt id=\"p39\">**</bpt>Save<ept id=\"p39\">**</ept>.",
      "nodes": [
        {
          "content": "Power BI imports the data and adds a new Spark dataset under the <bpt id=\"p37\">**</bpt>Datasets<ept id=\"p37\">**</ept><ph id=\"ph30\"/> heading.",
          "pos": [
            0,
            141
          ]
        },
        {
          "content": "Click the data set to open a new worksheet to visualize the data.",
          "pos": [
            142,
            207
          ]
        },
        {
          "content": "You can also save the worksheet as a report.",
          "pos": [
            208,
            252
          ]
        },
        {
          "content": "To save a worksheet, from the <bpt id=\"p38\">**</bpt>File<ept id=\"p38\">**</ept><ph id=\"ph31\"/> menu, click <bpt id=\"p39\">**</bpt>Save<ept id=\"p39\">**</ept>.",
          "pos": [
            253,
            408
          ]
        }
      ]
    },
    {
      "pos": [
        7988,
        8129
      ],
      "content": "<ph id=\"ph32\">![</ph>Spark tile on Power BI dashboard<ph id=\"ph33\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.powerbi.tile.png \"Spark tile on Power BI dashboard\")</ph>"
    },
    {
      "pos": [
        8134,
        8309
      ],
      "content": "Notice that the <bpt id=\"p40\">**</bpt>Fields<ept id=\"p40\">**</ept><ph id=\"ph34\"/> list on the right lists the <bpt id=\"p41\">**</bpt>hvac<ept id=\"p41\">**</ept><ph id=\"ph35\"/> table you created earlier. Expand the table to see the fields in the table, as you defined in notebook earlier.",
      "nodes": [
        {
          "content": "Notice that the <bpt id=\"p40\">**</bpt>Fields<ept id=\"p40\">**</ept><ph id=\"ph34\"/> list on the right lists the <bpt id=\"p41\">**</bpt>hvac<ept id=\"p41\">**</ept><ph id=\"ph35\"/> table you created earlier.",
          "pos": [
            0,
            200
          ]
        },
        {
          "content": "Expand the table to see the fields in the table, as you defined in notebook earlier.",
          "pos": [
            201,
            285
          ]
        }
      ]
    },
    {
      "pos": [
        8317,
        8436
      ],
      "content": "<ph id=\"ph36\">![</ph>List Hive tables<ph id=\"ph37\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.powerbi.display.tables.png \"List Hive tables\")</ph>"
    },
    {
      "pos": [
        8441,
        8750
      ],
      "content": "Build a visualization to show the variance between target temperature and actual temperature for each building. Select <bpt id=\"p42\">**</bpt>Area Chart<ept id=\"p42\">**</ept><ph id=\"ph38\"/> (shown in red box) to visualize your data. To define the axis, drag-and-drop the <bpt id=\"p43\">**</bpt>BuildingID<ept id=\"p43\">**</ept><ph id=\"ph39\"/> field under <bpt id=\"p44\">**</bpt>Axis<ept id=\"p44\">**</ept>, and <bpt id=\"p45\">**</bpt>ActualTemp<ept id=\"p45\">**</ept>/<bpt id=\"p46\">**</bpt>TargetTemp<ept id=\"p46\">**</ept><ph id=\"ph40\"/> fields under <bpt id=\"p47\">**</bpt>Value<ept id=\"p47\">**</ept>.",
      "nodes": [
        {
          "content": "Build a visualization to show the variance between target temperature and actual temperature for each building.",
          "pos": [
            0,
            111
          ]
        },
        {
          "content": "Select <bpt id=\"p42\">**</bpt>Area Chart<ept id=\"p42\">**</ept><ph id=\"ph38\"/> (shown in red box) to visualize your data.",
          "pos": [
            112,
            231
          ]
        },
        {
          "content": "To define the axis, drag-and-drop the <bpt id=\"p43\">**</bpt>BuildingID<ept id=\"p43\">**</ept><ph id=\"ph39\"/> field under <bpt id=\"p44\">**</bpt>Axis<ept id=\"p44\">**</ept>, and <bpt id=\"p45\">**</bpt>ActualTemp<ept id=\"p45\">**</ept>/<bpt id=\"p46\">**</bpt>TargetTemp<ept id=\"p46\">**</ept><ph id=\"ph40\"/> fields under <bpt id=\"p47\">**</bpt>Value<ept id=\"p47\">**</ept>.",
          "pos": [
            232,
            594
          ]
        }
      ]
    },
    {
      "pos": [
        8756,
        8878
      ],
      "content": "<ph id=\"ph41\">![</ph>Create visualizations<ph id=\"ph42\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.powerbi.visual1.png \"Create visualizations\")</ph>"
    },
    {
      "pos": [
        8884,
        9097
      ],
      "content": "By default the visualization shows the sum for <bpt id=\"p48\">**</bpt>ActualTemp<ept id=\"p48\">**</ept><ph id=\"ph43\"/> and <bpt id=\"p49\">**</bpt>TargetTemp<ept id=\"p49\">**</ept>. For both the fields, from the drop-down, select <bpt id=\"p50\">**</bpt>Average<ept id=\"p50\">**</ept><ph id=\"ph44\"/> to get an average of actual and target temperatures for both buildings.",
      "nodes": [
        {
          "content": "By default the visualization shows the sum for <bpt id=\"p48\">**</bpt>ActualTemp<ept id=\"p48\">**</ept><ph id=\"ph43\"/> and <bpt id=\"p49\">**</bpt>TargetTemp<ept id=\"p49\">**</ept>.",
          "pos": [
            0,
            176
          ]
        },
        {
          "content": "For both the fields, from the drop-down, select <bpt id=\"p50\">**</bpt>Average<ept id=\"p50\">**</ept><ph id=\"ph44\"/> to get an average of actual and target temperatures for both buildings.",
          "pos": [
            177,
            363
          ]
        }
      ]
    },
    {
      "pos": [
        9103,
        9201
      ],
      "content": "<ph id=\"ph45\">![</ph>Create visualizations<ph id=\"ph46\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.powerbi.visual2.png)</ph>"
    },
    {
      "pos": [
        9210,
        9346
      ],
      "content": "Your data visualization should be similar to the following. Move your cursor over the visualization to get tool tips with relevant data.",
      "nodes": [
        {
          "content": "Your data visualization should be similar to the following.",
          "pos": [
            0,
            59
          ]
        },
        {
          "content": "Move your cursor over the visualization to get tool tips with relevant data.",
          "pos": [
            60,
            136
          ]
        }
      ]
    },
    {
      "pos": [
        9352,
        9450
      ],
      "content": "<ph id=\"ph47\">![</ph>Create visualizations<ph id=\"ph48\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.powerbi.visual3.png)</ph>"
    },
    {
      "pos": [
        9456,
        9657
      ],
      "content": "Click <bpt id=\"p51\">**</bpt>Save<ept id=\"p51\">**</ept><ph id=\"ph49\"/> from the top menu and provide a report name. You can also pin the visual. When you pin a visualization, it will be stored on your dashboard so you can track the latest value at a glance.",
      "nodes": [
        {
          "content": "Click <bpt id=\"p51\">**</bpt>Save<ept id=\"p51\">**</ept><ph id=\"ph49\"/> from the top menu and provide a report name.",
          "pos": [
            0,
            114
          ]
        },
        {
          "content": "You can also pin the visual.",
          "pos": [
            115,
            143
          ]
        },
        {
          "content": "When you pin a visualization, it will be stored on your dashboard so you can track the latest value at a glance.",
          "pos": [
            144,
            256
          ]
        }
      ]
    },
    {
      "pos": [
        9664,
        10003
      ],
      "content": "You can add as many visualizations as you want for the same dataset and pin them to the dashboard for a snapshot of your data. Also, Spark clusters on HDInsight are connected to Power BI with direct connect. This means that Power BI always has the most up-to-date from your cluster so you do not need to schedule refreshes for the dataset.",
      "nodes": [
        {
          "content": "You can add as many visualizations as you want for the same dataset and pin them to the dashboard for a snapshot of your data.",
          "pos": [
            0,
            126
          ]
        },
        {
          "content": "Also, Spark clusters on HDInsight are connected to Power BI with direct connect.",
          "pos": [
            127,
            207
          ]
        },
        {
          "content": "This means that Power BI always has the most up-to-date from your cluster so you do not need to schedule refreshes for the dataset.",
          "pos": [
            208,
            339
          ]
        }
      ]
    },
    {
      "pos": [
        10005,
        10007
      ],
      "content": "##"
    },
    {
      "pos": [
        10029,
        10082
      ],
      "content": "Use Tableau Desktop to analyze data in the Hive table"
    },
    {
      "pos": [
        10091,
        10291
      ],
      "content": "Launch Tableau Desktop. In the left pane, from the list of server to connect to, click <bpt id=\"p52\">**</bpt>Spark SQL<ept id=\"p52\">**</ept>. If Spark SQL is not listed by default in the left pane, you can find it by click <bpt id=\"p53\">**</bpt>More Servers<ept id=\"p53\">**</ept>.",
      "nodes": [
        {
          "content": "Launch Tableau Desktop.",
          "pos": [
            0,
            23
          ]
        },
        {
          "content": "In the left pane, from the list of server to connect to, click <bpt id=\"p52\">**</bpt>Spark SQL<ept id=\"p52\">**</ept>.",
          "pos": [
            24,
            141
          ]
        },
        {
          "content": "If Spark SQL is not listed by default in the left pane, you can find it by click <bpt id=\"p53\">**</bpt>More Servers<ept id=\"p53\">**</ept>.",
          "pos": [
            142,
            280
          ]
        }
      ]
    },
    {
      "pos": [
        10297,
        10394
      ],
      "content": "In the Spark SQL connection dialog box, provide the values as shown below, and then click <bpt id=\"p54\">**</bpt>OK<ept id=\"p54\">**</ept>."
    },
    {
      "pos": [
        10400,
        10532
      ],
      "content": "<ph id=\"ph50\">![</ph>Connect to a Spark cluster<ph id=\"ph51\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.connect.png \"Connect to a Spark cluster\")</ph>"
    },
    {
      "pos": [
        10538,
        10744
      ],
      "content": "The authentication drop-down lists <bpt id=\"p55\">**</bpt>Microsoft Azure HDInsight Service<ept id=\"p55\">**</ept><ph id=\"ph52\"/> as an option, only if you installed the <bpt id=\"p56\">[</bpt>Microsoft Spark ODBC Driver<ept id=\"p56\">](http://go.microsoft.com/fwlink/?LinkId=616229)</ept><ph id=\"ph53\"/> on the computer."
    },
    {
      "pos": [
        10749,
        10852
      ],
      "content": "On the next screen, from the <bpt id=\"p57\">**</bpt>Schema<ept id=\"p57\">**</ept><ph id=\"ph54\"/> drop-down, click the <bpt id=\"p58\">**</bpt>Find<ept id=\"p58\">**</ept><ph id=\"ph55\"/> icon, and then click <bpt id=\"p59\">**</bpt>default<ept id=\"p59\">**</ept>."
    },
    {
      "pos": [
        10858,
        10964
      ],
      "content": "<ph id=\"ph56\">![</ph>Find schema<ph id=\"ph57\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.find.schema.png \"Find schema\")</ph>"
    },
    {
      "pos": [
        10969,
        11151
      ],
      "content": "For the <bpt id=\"p60\">**</bpt>Table<ept id=\"p60\">**</ept><ph id=\"ph58\"/> field, click the <bpt id=\"p61\">**</bpt>Find<ept id=\"p61\">**</ept><ph id=\"ph59\"/> icon again to list all the Hive tables available in the cluster. You should see the <bpt id=\"p62\">**</bpt>hvac<ept id=\"p62\">**</ept><ph id=\"ph60\"/> table you created earlier using the notebook.",
      "nodes": [
        {
          "content": "For the <bpt id=\"p60\">**</bpt>Table<ept id=\"p60\">**</ept><ph id=\"ph58\"/> field, click the <bpt id=\"p61\">**</bpt>Find<ept id=\"p61\">**</ept><ph id=\"ph59\"/> icon again to list all the Hive tables available in the cluster.",
          "pos": [
            0,
            218
          ]
        },
        {
          "content": "You should see the <bpt id=\"p62\">**</bpt>hvac<ept id=\"p62\">**</ept><ph id=\"ph60\"/> table you created earlier using the notebook.",
          "pos": [
            219,
            347
          ]
        }
      ]
    },
    {
      "pos": [
        11157,
        11262
      ],
      "content": "<ph id=\"ph61\">![</ph>Find tables<ph id=\"ph62\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.find.table.png \"Find tables\")</ph>"
    },
    {
      "pos": [
        11267,
        11399
      ],
      "content": "Drag and drop the table to the top box on the right. Tableau imports the data and displays the schema as highlighted by the red box.",
      "nodes": [
        {
          "content": "Drag and drop the table to the top box on the right.",
          "pos": [
            0,
            52
          ]
        },
        {
          "content": "Tableau imports the data and displays the schema as highlighted by the red box.",
          "pos": [
            53,
            132
          ]
        }
      ]
    },
    {
      "pos": [
        11405,
        11530
      ],
      "content": "<ph id=\"ph63\">![</ph>Add tables to Tableau<ph id=\"ph64\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.drag.table.png \"Add tables to Tableau\")</ph>"
    },
    {
      "pos": [
        11535,
        11852
      ],
      "content": "Click the <bpt id=\"p63\">**</bpt>Sheet1<ept id=\"p63\">**</ept><ph id=\"ph65\"/> tab at the bottom left. Make a visualization that shows the average target and actual temperatures for all buildings for each date. Drag <bpt id=\"p64\">**</bpt>Date<ept id=\"p64\">**</ept><ph id=\"ph66\"/> and <bpt id=\"p65\">**</bpt>Building ID<ept id=\"p65\">**</ept><ph id=\"ph67\"/> to <bpt id=\"p66\">**</bpt>Columns<ept id=\"p66\">**</ept><ph id=\"ph68\"/> and <bpt id=\"p67\">**</bpt>Actual Temp<ept id=\"p67\">**</ept>/<bpt id=\"p68\">**</bpt>Target Temp<ept id=\"p68\">**</ept><ph id=\"ph69\"/> to <bpt id=\"p69\">**</bpt>Rows<ept id=\"p69\">**</ept>. Under <bpt id=\"p70\">**</bpt>Marks<ept id=\"p70\">**</ept>, select <bpt id=\"p71\">**</bpt>Area<ept id=\"p71\">**</ept><ph id=\"ph70\"/> to use an area map visualization.",
      "nodes": [
        {
          "content": "Click the <bpt id=\"p63\">**</bpt>Sheet1<ept id=\"p63\">**</ept><ph id=\"ph65\"/> tab at the bottom left.",
          "pos": [
            0,
            99
          ]
        },
        {
          "content": "Make a visualization that shows the average target and actual temperatures for all buildings for each date.",
          "pos": [
            100,
            207
          ]
        },
        {
          "content": "Drag <bpt id=\"p64\">**</bpt>Date<ept id=\"p64\">**</ept><ph id=\"ph66\"/> and <bpt id=\"p65\">**</bpt>Building ID<ept id=\"p65\">**</ept><ph id=\"ph67\"/> to <bpt id=\"p66\">**</bpt>Columns<ept id=\"p66\">**</ept><ph id=\"ph68\"/> and <bpt id=\"p67\">**</bpt>Actual Temp<ept id=\"p67\">**</ept>/<bpt id=\"p68\">**</bpt>Target Temp<ept id=\"p68\">**</ept><ph id=\"ph69\"/> to <bpt id=\"p69\">**</bpt>Rows<ept id=\"p69\">**</ept>.",
          "pos": [
            208,
            605
          ]
        },
        {
          "content": "Under <bpt id=\"p70\">**</bpt>Marks<ept id=\"p70\">**</ept>, select <bpt id=\"p71\">**</bpt>Area<ept id=\"p71\">**</ept><ph id=\"ph70\"/> to use an area map visualization.",
          "pos": [
            606,
            767
          ]
        }
      ]
    },
    {
      "pos": [
        11859,
        11999
      ],
      "content": "<ph id=\"ph71\">![</ph>Add fields for visualization<ph id=\"ph72\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.drag.fields.png \"Add fields for visualization\")</ph>"
    },
    {
      "pos": [
        12004,
        12166
      ],
      "content": "By default, the temperature fields are shown as aggregate. If you want to show the average temperatures instead, you can do so from the drop-down, as shown below.",
      "nodes": [
        {
          "content": "By default, the temperature fields are shown as aggregate.",
          "pos": [
            0,
            58
          ]
        },
        {
          "content": "If you want to show the average temperatures instead, you can do so from the drop-down, as shown below.",
          "pos": [
            59,
            162
          ]
        }
      ]
    },
    {
      "pos": [
        12172,
        12307
      ],
      "content": "<ph id=\"ph73\">![</ph>Take average of temperature<ph id=\"ph74\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.temp.avg.png \"Take average of temperature\")</ph>"
    },
    {
      "pos": [
        12312,
        12673
      ],
      "content": "You can also super-impose one temperature map over the other to get a better feel of difference between target and actual temperatures. Move the mouse to the corner of the lower area map till you see the handle shape highlighted in a red circle. Drag the map to the other map on the top and release the mouse when you see the shape highlighted in red rectangle.",
      "nodes": [
        {
          "content": "You can also super-impose one temperature map over the other to get a better feel of difference between target and actual temperatures.",
          "pos": [
            0,
            135
          ]
        },
        {
          "content": "Move the mouse to the corner of the lower area map till you see the handle shape highlighted in a red circle.",
          "pos": [
            136,
            245
          ]
        },
        {
          "content": "Drag the map to the other map on the top and release the mouse when you see the shape highlighted in red rectangle.",
          "pos": [
            246,
            361
          ]
        }
      ]
    },
    {
      "pos": [
        12679,
        12777
      ],
      "content": "<ph id=\"ph75\">![</ph>Merge maps<ph id=\"ph76\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.merge.png \"Merge maps\")</ph>"
    },
    {
      "pos": [
        12784,
        12839
      ],
      "content": "Your data visualization should change to the following:"
    },
    {
      "pos": [
        12845,
        12956
      ],
      "content": "<ph id=\"ph77\">![</ph>Visualization<ph id=\"ph78\">](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.final.visual.png \"Visualization\")</ph>"
    },
    {
      "pos": [
        12966,
        13063
      ],
      "content": "Click <bpt id=\"p72\">**</bpt>Save<ept id=\"p72\">**</ept><ph id=\"ph79\"/> to save the worksheet. You can create dashboards and add one or more sheets to it.",
      "nodes": [
        {
          "content": "Click <bpt id=\"p72\">**</bpt>Save<ept id=\"p72\">**</ept><ph id=\"ph79\"/> to save the worksheet.",
          "pos": [
            0,
            92
          ]
        },
        {
          "content": "You can create dashboards and add one or more sheets to it.",
          "pos": [
            93,
            152
          ]
        }
      ]
    },
    {
      "pos": [
        13065,
        13067
      ],
      "content": "##"
    },
    {
      "pos": [
        13089,
        13097
      ],
      "content": "See also"
    },
    {
      "pos": [
        13101,
        13180
      ],
      "content": "<bpt id=\"p73\">[</bpt>Overview: Apache Spark on Azure HDInsight<ept id=\"p73\">](hdinsight-apache-spark-overview.md)</ept>"
    },
    {
      "pos": [
        13186,
        13195
      ],
      "content": "Scenarios"
    },
    {
      "pos": [
        13199,
        13364
      ],
      "content": "<bpt id=\"p74\">[</bpt>Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data<ept id=\"p74\">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept>"
    },
    {
      "pos": [
        13368,
        13514
      ],
      "content": "<bpt id=\"p75\">[</bpt>Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results<ept id=\"p75\">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept>"
    },
    {
      "pos": [
        13518,
        13651
      ],
      "content": "<bpt id=\"p76\">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id=\"p76\">](hdinsight-apache-spark-eventhub-streaming.md)</ept>"
    },
    {
      "pos": [
        13655,
        13765
      ],
      "content": "<bpt id=\"p77\">[</bpt>Website log analysis using Spark in HDInsight<ept id=\"p77\">](hdinsight-apache-spark-custom-library-website-log-analysis.md)</ept>"
    },
    {
      "pos": [
        13771,
        13798
      ],
      "content": "Create and run applications"
    },
    {
      "pos": [
        13802,
        13904
      ],
      "content": "<bpt id=\"p78\">[</bpt>Create a standalone application using Scala<ept id=\"p78\">](hdinsight-apache-spark-create-standalone-application.md)</ept>"
    },
    {
      "pos": [
        13908,
        14004
      ],
      "content": "<bpt id=\"p79\">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id=\"p79\">](hdinsight-apache-spark-livy-rest-interface.md)</ept>"
    },
    {
      "pos": [
        14010,
        14030
      ],
      "content": "Tools and extensions"
    },
    {
      "pos": [
        14034,
        14173
      ],
      "content": "<bpt id=\"p80\">[</bpt>Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons<ept id=\"p80\">](hdinsight-apache-spark-intellij-tool-plugin.md)</ept>"
    },
    {
      "pos": [
        14177,
        14284
      ],
      "content": "<bpt id=\"p81\">[</bpt>Use Zeppelin notebooks with a Spark cluster on HDInsight<ept id=\"p81\">](hdinsight-apache-spark-use-zeppelin-notebook.md)</ept>"
    },
    {
      "pos": [
        14288,
        14411
      ],
      "content": "<bpt id=\"p82\">[</bpt>Kernels available for Jupyter notebook in Spark cluster for HDInsight<ept id=\"p82\">](hdinsight-apache-spark-jupyter-notebook-kernels.md)</ept>"
    },
    {
      "pos": [
        14417,
        14433
      ],
      "content": "Manage resources"
    },
    {
      "pos": [
        14437,
        14547
      ],
      "content": "<bpt id=\"p83\">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id=\"p83\">](hdinsight-apache-spark-resource-manager.md)</ept>"
    }
  ],
  "content": "<properties \n    pageTitle=\"Use BI tools with Apache Spark on HDInsight | Microsoft Azure\" \n    description=\"Step-by-step instructions on how to use notebooks with Apache Spark to create schemas on raw data, save them as Hive tables, and then use BI tools on the Hive table for data analytics\" \n    services=\"hdinsight\" \n    documentationCenter=\"\" \n    authors=\"nitinme\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags \n    ms.service=\"hdinsight\" \n    ms.workload=\"big-data\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"02/05/2016\" \n    ms.author=\"nitinme\"/>\n\n\n# Use BI tools with Apache Spark on Azure HDInsight (Linux)\n\nLearn how to use Apache Spark in Azure HDInsight to do the following:\n\n* Take raw sample data and save it as a Hive table\n* Use BI tools such as Power BI and Tableau to analyze and visualize the data.\n\n> [AZURE.TIP] This tutorial is also available as a Jupyter notebook on a Spark (Linux) cluster that you create in HDInsight. The notebook experience lets you run the Python snippets from the notebook itself. To perform the tutorial from within a notebook, create a Spark cluster, launch a Jupyter notebook (`https://CLUSTERNAME.azurehdinsight.net/jupyter`), and then run the notebook **Use BI tools with Apache Spark on HDInsight.ipynb** under the **Python** folder.\n\n**Prerequisites:**\n\nYou must have the following:\n\n- An Azure subscription. See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).\n- An Apache Spark cluster on HDInsight Linux. For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).\n- A computer with Microsoft Spark ODBC driver installed (required for Spark on HDInsight to work with Tableau). You can install the driver from [here](http://go.microsoft.com/fwlink/?LinkId=616229).\n- BI tools such as [Power BI](http://www.powerbi.com/) or [Tableau Desktop](http://www.tableau.com/products/desktop). You can get a free preview subscription of Power BI from [http://www.powerbi.com/](http://www.powerbi.com/).\n\n##<a name=\"hivetable\"></a>Save raw data as a Hive table\n\nIn this section, we use the [Jupyter](https://jupyter.org) notebook associated with an Apache Spark cluster in HDInsight to run jobs that process your raw sample data and save it as a Hive table. The sample data is a .csv file (hvac.csv) available on all clusters by default.\n\nOnce your data is saved as a Hive table, in the next section we will connect to the Hive table using BI tools such as Power BI and Tableau.\n\n1. From the [Azure Preview Portal](https://portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard). You can also navigate to your cluster under **Browse All** > **HDInsight Clusters**.   \n\n2. From the Spark cluster blade, click **Quick Links**, and then from the **Cluster Dashboard** blade, click **Jupyter Notebook**. If prompted, enter the admin credentials for the cluster.\n\n    > [AZURE.NOTE] You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser. Replace __CLUSTERNAME__ with the name of your cluster:\n    >\n    > `https://CLUSTERNAME.azurehdinsight.net/jupyter`\n\n2. Create a new notebook. Click **New**, and then click **Python 2**.\n\n    ![Create a new Jupyter notebook](./media/hdinsight-apache-spark-use-bi-tools/hdispark.note.jupyter.createnotebook.png \"Create a new Jupyter notebook\")\n\n3. A new notebook is created and opened with the name Untitled.pynb. Click the notebook name at the top, and enter a friendly name.\n\n    ![Provide a name for the notebook](./media/hdinsight-apache-spark-use-bi-tools/hdispark.note.jupyter.notebook.name.png \"Provide a name for the notebook\")\n\n4. Import the required modules and create the Spark and Hive contexts. Paste the following snippet in an empty cell, and then press **SHIFT + ENTER**.\n\n        from pyspark import SparkContext\n        from pyspark.sql import *\n        from pyspark.sql import HiveContext\n        from pyspark.sql import Row\n        \n        # Create Spark and Hive contexts\n        sc = SparkContext('yarn-client')\n        hiveCtx = HiveContext(sc)\n\n    Everytime you run a job in Jupyter, your web browser window title will show a **(Busy)** status along with the notebook title. You will also see a solid circle next to the **Python 2** text in the top-right corner. After the job completes, this will change to a hollow circle.\n\n     ![Status of a Jupyter notebook job](./media/hdinsight-apache-spark-use-bi-tools/hdispark.jupyter.job.status.png \"Status of a Jupyter notebook job\")\n\n4. Load sample data into a temporary table. When you create a Spark cluster in HDInsight, the sample data file, **hvac.csv**, is copied to the associated storage account under **\\HdiSamples\\HdiSamples\\SensorSampleData\\hvac**.\n\n    In an empty cell, paste the following snippet and press **SHIFT + ENTER**. This snippet registers the data into a Hive table called **hvac**.\n\n\n        # Create an RDD from sample data\n        hvacText = sc.textFile(\"wasb:///HdiSamples/HdiSamples/SensorSampleData/hvac/HVAC.csv\")\n        \n        # Create a schema for our data\n        Entry = Row('Date', 'Time', 'TargetTemp', 'ActualTemp', 'BuildingID')\n        \n        # Parse the data and create a schema\n        hvacParts = hvacText.map(lambda s: s.split(',')).filter(lambda s: s[0] != 'Date')\n        hvac = hvacParts.map(lambda p: Entry(str(p[0]), str(p[1]), int(p[2]), int(p[3]), int(p[6])))\n        \n        # Infer the schema and create a table       \n        hvacTable = hiveCtx.createDataFrame(hvac)\n        hvacTable.registerTempTable('hvactemptable')\n        dfw = DataFrameWriter(hvacTable)\n        dfw.saveAsTable('hvac')\n\n5. Verify that the table was successfully created. In an empty cell in the notebook, copy the following snippet and press **SHIFT + ENTER**.\n\n        hiveCtx.sql(\"SHOW TABLES\").show()\n\n    You will see an output like the following:\n\n        +---------------+-----------+\n        |      tableName|isTemporary|\n        +---------------+-----------+\n        |  hvactemptable|       true|\n        |hivesampletable|      false|\n        |           hvac|      false|\n        +---------------+-----------+\n\n\n    Only the tables that have false under the **isTemporary** column are hive tables that will be stored in the metastore and can be accessed from the BI tools. In this tutorial, we will connect to the **hvac** table we just created.\n\n6. Verify that the table contains the intended data. In an empty cell in the notebook, copy the following snippet and press **SHIFT + ENTER**.\n\n        hiveCtx.sql(\"SELECT * FROM hvac LIMIT 10\").show()\n    \n7. You can now shutdown the notebook to release the resources. To do so, from the **File** menu on the notebook, click **Close and Halt**. This will shutdown and close the notebook.\n\n##<a name=\"powerbi\"></a>Use Power BI to analyze data in the Hive table\n\nOnce you have saved the data as a Hive table, you can use Power BI to connect to the data and visualize it to create reports, dashboards, etc.\n\n1. Sign in to [Power BI](http://www.powerbi.com/).\n\n2. On the Welcome screen, click **Databases & More**.\n\n    ![Get data into Power BI](./media/hdinsight-apache-spark-use-bi-tools/hdispark.powerbi.get.data.png \"Get data into Power BI\")\n\n3. On the next screen, click **Spark on Azure HDInsight** and then click **Connect**. When prompted, enter the cluster URL (`mysparkcluster.azurehdinsight.net`) and the credentials to connect to the cluster.\n\n    After the connection is established, Power BI starts importing data from the Spark cluster on HDInsight.\n\n5. Power BI imports the data and adds a new Spark dataset under the **Datasets** heading. Click the data set to open a new worksheet to visualize the data. You can also save the worksheet as a report. To save a worksheet, from the **File** menu, click **Save**.\n\n    ![Spark tile on Power BI dashboard](./media/hdinsight-apache-spark-use-bi-tools/hdispark.powerbi.tile.png \"Spark tile on Power BI dashboard\")\n\n6. Notice that the **Fields** list on the right lists the **hvac** table you created earlier. Expand the table to see the fields in the table, as you defined in notebook earlier.\n\n      ![List Hive tables](./media/hdinsight-apache-spark-use-bi-tools/hdispark.powerbi.display.tables.png \"List Hive tables\")\n\n7. Build a visualization to show the variance between target temperature and actual temperature for each building. Select **Area Chart** (shown in red box) to visualize your data. To define the axis, drag-and-drop the **BuildingID** field under **Axis**, and **ActualTemp**/**TargetTemp** fields under **Value**.\n\n    ![Create visualizations](./media/hdinsight-apache-spark-use-bi-tools/hdispark.powerbi.visual1.png \"Create visualizations\")\n\n\n8. By default the visualization shows the sum for **ActualTemp** and **TargetTemp**. For both the fields, from the drop-down, select **Average** to get an average of actual and target temperatures for both buildings.\n\n    ![Create visualizations](./media/hdinsight-apache-spark-use-bi-tools/hdispark.powerbi.visual2.png)\n    \n9. Your data visualization should be similar to the following. Move your cursor over the visualization to get tool tips with relevant data.\n\n    ![Create visualizations](./media/hdinsight-apache-spark-use-bi-tools/hdispark.powerbi.visual3.png)\n\n10. Click **Save** from the top menu and provide a report name. You can also pin the visual. When you pin a visualization, it will be stored on your dashboard so you can track the latest value at a glance. \n\n    You can add as many visualizations as you want for the same dataset and pin them to the dashboard for a snapshot of your data. Also, Spark clusters on HDInsight are connected to Power BI with direct connect. This means that Power BI always has the most up-to-date from your cluster so you do not need to schedule refreshes for the dataset.\n\n##<a name=\"tableau\"></a>Use Tableau Desktop to analyze data in the Hive table\n    \n1. Launch Tableau Desktop. In the left pane, from the list of server to connect to, click **Spark SQL**. If Spark SQL is not listed by default in the left pane, you can find it by click **More Servers**. \n\n2. In the Spark SQL connection dialog box, provide the values as shown below, and then click **OK**.\n\n    ![Connect to a Spark cluster](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.connect.png \"Connect to a Spark cluster\")\n\n    The authentication drop-down lists **Microsoft Azure HDInsight Service** as an option, only if you installed the [Microsoft Spark ODBC Driver](http://go.microsoft.com/fwlink/?LinkId=616229) on the computer.\n\n3. On the next screen, from the **Schema** drop-down, click the **Find** icon, and then click **default**.\n\n    ![Find schema](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.find.schema.png \"Find schema\")\n\n4. For the **Table** field, click the **Find** icon again to list all the Hive tables available in the cluster. You should see the **hvac** table you created earlier using the notebook.\n\n    ![Find tables](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.find.table.png \"Find tables\")\n\n5. Drag and drop the table to the top box on the right. Tableau imports the data and displays the schema as highlighted by the red box.\n\n    ![Add tables to Tableau](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.drag.table.png \"Add tables to Tableau\")\n\n6. Click the **Sheet1** tab at the bottom left. Make a visualization that shows the average target and actual temperatures for all buildings for each date. Drag **Date** and **Building ID** to **Columns** and **Actual Temp**/**Target Temp** to **Rows**. Under **Marks**, select **Area** to use an area map visualization.\n\n     ![Add fields for visualization](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.drag.fields.png \"Add fields for visualization\")\n\n7. By default, the temperature fields are shown as aggregate. If you want to show the average temperatures instead, you can do so from the drop-down, as shown below.\n\n    ![Take average of temperature](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.temp.avg.png \"Take average of temperature\")\n\n8. You can also super-impose one temperature map over the other to get a better feel of difference between target and actual temperatures. Move the mouse to the corner of the lower area map till you see the handle shape highlighted in a red circle. Drag the map to the other map on the top and release the mouse when you see the shape highlighted in red rectangle.\n\n    ![Merge maps](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.merge.png \"Merge maps\")\n\n     Your data visualization should change to the following:\n\n    ![Visualization](./media/hdinsight-apache-spark-use-bi-tools/hdispark.tableau.final.visual.png \"Visualization\")\n     \n9. Click **Save** to save the worksheet. You can create dashboards and add one or more sheets to it.\n\n##<a name=\"seealso\"></a>See also\n\n* [Overview: Apache Spark on Azure HDInsight](hdinsight-apache-spark-overview.md)\n\n### Scenarios\n\n* [Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data](hdinsight-apache-spark-ipython-notebook-machine-learning.md)\n\n* [Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results](hdinsight-apache-spark-machine-learning-mllib-ipython.md)\n\n* [Spark Streaming: Use Spark in HDInsight for building real-time streaming applications](hdinsight-apache-spark-eventhub-streaming.md)\n\n* [Website log analysis using Spark in HDInsight](hdinsight-apache-spark-custom-library-website-log-analysis.md)\n\n### Create and run applications\n\n* [Create a standalone application using Scala](hdinsight-apache-spark-create-standalone-application.md)\n\n* [Run jobs remotely on a Spark cluster using Livy](hdinsight-apache-spark-livy-rest-interface.md)\n\n### Tools and extensions\n\n* [Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons](hdinsight-apache-spark-intellij-tool-plugin.md)\n\n* [Use Zeppelin notebooks with a Spark cluster on HDInsight](hdinsight-apache-spark-use-zeppelin-notebook.md)\n\n* [Kernels available for Jupyter notebook in Spark cluster for HDInsight](hdinsight-apache-spark-jupyter-notebook-kernels.md)\n\n### Manage resources\n\n* [Manage resources for the Apache Spark cluster in Azure HDInsight](hdinsight-apache-spark-resource-manager.md)\n\n[hdinsight-versions]: hdinsight-component-versioning.md\n[hdinsight-upload-data]: hdinsight-upload-data.md\n[hdinsight-storage]: hdinsight-hadoop-use-blob-storage.md\n\n\n[azure-purchase-options]: http://azure.microsoft.com/pricing/purchase-options/\n[azure-member-offers]: http://azure.microsoft.com/pricing/member-offers/\n[azure-free-trial]: http://azure.microsoft.com/pricing/free-trial/\n[azure-management-portal]: https://manage.windowsazure.com/\n[azure-create-storageaccount]: storage-create-storage-account.md\n"
}