{
  "nodes": [
    {
      "pos": [
        28,
        120
      ],
      "content": "Vehicle telemetry analytics solution playbook: deep dive into the solution | Microsoft Azure"
    },
    {
      "pos": [
        140,
        261
      ],
      "content": "Use the capabilities of Cortana Analytics to gain real-time and predictive insights on vehicle health and driving habits."
    },
    {
      "pos": [
        599,
        673
      ],
      "content": "Vehicle telemetry analytics solution playbook: deep dive into the solution"
    },
    {
      "pos": [
        675,
        728
      ],
      "content": "This <bpt id=\"p1\">**</bpt>menu<ept id=\"p1\">**</ept><ph id=\"ph2\"/> links to the sections of this playbook:"
    },
    {
      "pos": [
        849,
        1004
      ],
      "content": "This section drills down into the details of each one of the stages depicted in the Solution Architecture with instructions and pointers for customization."
    },
    {
      "pos": [
        1010,
        1022
      ],
      "content": "Data Sources"
    },
    {
      "pos": [
        1024,
        1069
      ],
      "content": "The solution uses two different data sources:"
    },
    {
      "pos": [
        1073,
        1129
      ],
      "content": "<bpt id=\"p2\">**</bpt>simulated vehicle signals and diagnostic dataset<ept id=\"p2\">**</ept><ph id=\"ph4\"/> and"
    },
    {
      "pos": [
        1133,
        1152
      ],
      "content": "<bpt id=\"p3\">**</bpt>vehicle catalog<ept id=\"p3\">**</ept>"
    },
    {
      "pos": [
        1154,
        1635
      ],
      "content": "A vehicle telematics simulator is included as part of this solution. It emits diagnostic information and signals corresponding to the state of the vehicle and driving pattern at a given point in time. Click <bpt id=\"p4\">[</bpt>Vehicle Telematics Simulator<ept id=\"p4\">](http://go.microsoft.com/fwlink/?LinkId=717075)</ept><ph id=\"ph5\"/> to download the <bpt id=\"p5\">**</bpt>Vehicle Telematics Simulator Visual Studio Solution<ept id=\"p5\">**</ept><ph id=\"ph6\"/> for customizations based on your requirements. The vehicle catalog contains a reference dataset with a VIN to model mapping.",
      "nodes": [
        {
          "content": "A vehicle telematics simulator is included as part of this solution.",
          "pos": [
            0,
            68
          ]
        },
        {
          "content": "It emits diagnostic information and signals corresponding to the state of the vehicle and driving pattern at a given point in time.",
          "pos": [
            69,
            200
          ]
        },
        {
          "content": "Click <bpt id=\"p4\">[</bpt>Vehicle Telematics Simulator<ept id=\"p4\">](http://go.microsoft.com/fwlink/?LinkId=717075)</ept><ph id=\"ph5\"/> to download the <bpt id=\"p5\">**</bpt>Vehicle Telematics Simulator Visual Studio Solution<ept id=\"p5\">**</ept><ph id=\"ph6\"/> for customizations based on your requirements.",
          "pos": [
            201,
            507
          ]
        },
        {
          "content": "The vehicle catalog contains a reference dataset with a VIN to model mapping.",
          "pos": [
            508,
            585
          ]
        }
      ]
    },
    {
      "pos": [
        1744,
        1785
      ],
      "content": "<bpt id=\"p6\">*</bpt>Figure 2 – Vehicle Telematics Simulator<ept id=\"p6\">*</ept>"
    },
    {
      "pos": [
        1787,
        1847
      ],
      "content": "This is a JSON format dataset and contains the below schema."
    },
    {
      "pos": [
        1849,
        1855
      ],
      "content": "Column"
    },
    {
      "pos": [
        1858,
        1869
      ],
      "content": "Description"
    },
    {
      "pos": [
        1872,
        1878
      ],
      "content": "Values"
    },
    {
      "pos": [
        1919,
        1922
      ],
      "content": "VIN"
    },
    {
      "pos": [
        1925,
        1973
      ],
      "content": "Randomly generated Vehicle Identification Number"
    },
    {
      "pos": [
        1976,
        2070
      ],
      "content": "This is obtained from a master list of 10,000 randomly generated vehicle identification number"
    },
    {
      "pos": [
        2071,
        2090
      ],
      "content": "Outside temperature"
    },
    {
      "pos": [
        2093,
        2145
      ],
      "content": "The outside temperature where the vehicle is driving"
    },
    {
      "pos": [
        2148,
        2184
      ],
      "content": "Randomly generated number from 0-100"
    },
    {
      "pos": [
        2185,
        2203
      ],
      "content": "Engine temperature"
    },
    {
      "pos": [
        2206,
        2243
      ],
      "content": "The engine temperature of the vehicle"
    },
    {
      "pos": [
        2246,
        2282
      ],
      "content": "Randomly generated number from 0-500"
    },
    {
      "pos": [
        2283,
        2288
      ],
      "content": "Speed"
    },
    {
      "pos": [
        2291,
        2339
      ],
      "content": "The engine speed at which the vehicle is driving"
    },
    {
      "pos": [
        2342,
        2378
      ],
      "content": "Randomly generated number from 0-100"
    },
    {
      "pos": [
        2379,
        2383
      ],
      "content": "Fuel"
    },
    {
      "pos": [
        2386,
        2415
      ],
      "content": "The fuel level of the vehicle"
    },
    {
      "pos": [
        2418,
        2488
      ],
      "content": "Randomly generated number from 0-100 (indicates fuel level percentage)"
    },
    {
      "pos": [
        2489,
        2498
      ],
      "content": "EngineOil"
    },
    {
      "pos": [
        2501,
        2536
      ],
      "content": "The engine oil level of the vehicle"
    },
    {
      "pos": [
        2539,
        2615
      ],
      "content": "Randomly generated number from 0-100 (indicates engine oil level percentage)"
    },
    {
      "pos": [
        2616,
        2628
      ],
      "content": "Tirepressure"
    },
    {
      "pos": [
        2631,
        2662
      ],
      "content": "The tirepressure of the vehicle"
    },
    {
      "pos": [
        2665,
        2742
      ],
      "content": "Randomly generated number from 0-50 (indicates tirepressure level percentage)"
    },
    {
      "pos": [
        2743,
        2751
      ],
      "content": "Odometer"
    },
    {
      "pos": [
        2754,
        2789
      ],
      "content": "The odometer reading of the vehicle"
    },
    {
      "pos": [
        2792,
        2831
      ],
      "content": "Randomly generated number from 0-200000"
    },
    {
      "pos": [
        2832,
        2858
      ],
      "content": "Accelerator_pedal_position"
    },
    {
      "pos": [
        2861,
        2906
      ],
      "content": "The accelerator pedal position of the vehicle"
    },
    {
      "pos": [
        2909,
        2986
      ],
      "content": "Randomly generated number from 0-100 (indicates accelerator level percentage)"
    },
    {
      "pos": [
        2987,
        3007
      ],
      "content": "Parking_brake_status"
    },
    {
      "pos": [
        3010,
        3056
      ],
      "content": "Indicates whether the vehicle is parked or not"
    },
    {
      "pos": [
        3059,
        3072
      ],
      "content": "True or False"
    },
    {
      "pos": [
        3073,
        3088
      ],
      "content": "Headlamp_status"
    },
    {
      "pos": [
        3091,
        3132
      ],
      "content": "Indicates where the headlamp is on or not"
    },
    {
      "pos": [
        3135,
        3148
      ],
      "content": "True or False"
    },
    {
      "pos": [
        3149,
        3167
      ],
      "content": "Brake_pedal_status"
    },
    {
      "pos": [
        3170,
        3221
      ],
      "content": "Indicates whether the brake pedal is pressed or not"
    },
    {
      "pos": [
        3224,
        3237
      ],
      "content": "True or False"
    },
    {
      "pos": [
        3238,
        3264
      ],
      "content": "Transmission_gear_position"
    },
    {
      "pos": [
        3267,
        3312
      ],
      "content": "The transmission gear position of the vehicle"
    },
    {
      "pos": [
        3315,
        3382
      ],
      "content": "States: first, second, third, fourth, fifth, sixth, seventh, eighth"
    },
    {
      "pos": [
        3383,
        3398
      ],
      "content": "Ignition_status"
    },
    {
      "pos": [
        3401,
        3452
      ],
      "content": "Indicates whether the vehicle is running or stopped"
    },
    {
      "pos": [
        3455,
        3468
      ],
      "content": "True or False"
    },
    {
      "pos": [
        3469,
        3492
      ],
      "content": "Windshield_wiper_status"
    },
    {
      "pos": [
        3495,
        3550
      ],
      "content": "Indicates whether the windshield wiper is turned or not"
    },
    {
      "pos": [
        3553,
        3566
      ],
      "content": "True or False"
    },
    {
      "pos": [
        3567,
        3570
      ],
      "content": "ABS"
    },
    {
      "pos": [
        3573,
        3612
      ],
      "content": "Indicates whether ABS is engaged or not"
    },
    {
      "pos": [
        3615,
        3628
      ],
      "content": "True or False"
    },
    {
      "pos": [
        3629,
        3638
      ],
      "content": "Timestamp"
    },
    {
      "pos": [
        3641,
        3685
      ],
      "content": "The timestamp when the data point is created"
    },
    {
      "pos": [
        3688,
        3692
      ],
      "content": "Date"
    },
    {
      "pos": [
        3693,
        3697
      ],
      "content": "City"
    },
    {
      "pos": [
        3700,
        3727
      ],
      "content": "The location of the vehicle"
    },
    {
      "pos": [
        3730,
        3795
      ],
      "content": "4 cities in this solution : Bellevue, Redmond, Sammamish, Seattle"
    },
    {
      "pos": [
        3798,
        3868
      ],
      "content": "The vehicle model reference dataset contains VIN to the model mapping."
    },
    {
      "pos": [
        3871,
        3874
      ],
      "content": "VIN"
    },
    {
      "pos": [
        3877,
        3882
      ],
      "content": "Model"
    },
    {
      "pos": [
        3919,
        3936
      ],
      "content": "FHL3O1SA4IEHB4WU1"
    },
    {
      "pos": [
        3939,
        3944
      ],
      "content": "Sedan"
    },
    {
      "pos": [
        3947,
        3964
      ],
      "content": "8J0U8XCPRGW4Z3NQE"
    },
    {
      "pos": [
        3967,
        3973
      ],
      "content": "Hybrid"
    },
    {
      "pos": [
        3976,
        3993
      ],
      "content": "WORG68Z2PLTNZDBI7"
    },
    {
      "pos": [
        3996,
        4009
      ],
      "content": "Family Saloon"
    },
    {
      "pos": [
        4012,
        4029
      ],
      "content": "JTHMYHQTEPP4WBMRN"
    },
    {
      "pos": [
        4032,
        4037
      ],
      "content": "Sedan"
    },
    {
      "pos": [
        4040,
        4057
      ],
      "content": "W9FTHG27LZN1YWO0Y"
    },
    {
      "pos": [
        4060,
        4066
      ],
      "content": "Hybrid"
    },
    {
      "pos": [
        4069,
        4086
      ],
      "content": "MHTP9N792PHK08WJM"
    },
    {
      "pos": [
        4089,
        4102
      ],
      "content": "Family Saloon"
    },
    {
      "pos": [
        4105,
        4122
      ],
      "content": "EI4QXI2AXVQQING4I"
    },
    {
      "pos": [
        4125,
        4130
      ],
      "content": "Sedan"
    },
    {
      "pos": [
        4133,
        4150
      ],
      "content": "5KKR2VB4WHQH97PF8"
    },
    {
      "pos": [
        4153,
        4159
      ],
      "content": "Hybrid"
    },
    {
      "pos": [
        4162,
        4179
      ],
      "content": "W9NSZ423XZHAONYXB"
    },
    {
      "pos": [
        4182,
        4195
      ],
      "content": "Family Saloon"
    },
    {
      "pos": [
        4198,
        4215
      ],
      "content": "26WJSGHX4MA5ROHNL"
    },
    {
      "pos": [
        4218,
        4229
      ],
      "content": "Convertible"
    },
    {
      "pos": [
        4232,
        4249
      ],
      "content": "GHLUB6ONKMOSI7E77"
    },
    {
      "pos": [
        4252,
        4265
      ],
      "content": "Station Wagon"
    },
    {
      "pos": [
        4268,
        4285
      ],
      "content": "9C2RHVRVLMEJDBXLP"
    },
    {
      "pos": [
        4288,
        4299
      ],
      "content": "Compact Car"
    },
    {
      "pos": [
        4302,
        4319
      ],
      "content": "BRNHVMZOUJ6EOCP32"
    },
    {
      "pos": [
        4322,
        4331
      ],
      "content": "Small SUV"
    },
    {
      "pos": [
        4334,
        4351
      ],
      "content": "VCYVW0WUZNBTM594J"
    },
    {
      "pos": [
        4354,
        4364
      ],
      "content": "Sports Car"
    },
    {
      "pos": [
        4367,
        4384
      ],
      "content": "HNVCE6YFZSA5M82NY"
    },
    {
      "pos": [
        4387,
        4397
      ],
      "content": "Medium SUV"
    },
    {
      "pos": [
        4400,
        4417
      ],
      "content": "4R30FOR7NUOBL05GJ"
    },
    {
      "pos": [
        4420,
        4433
      ],
      "content": "Station Wagon"
    },
    {
      "pos": [
        4436,
        4453
      ],
      "content": "WYNIIY42VKV6OQS1J"
    },
    {
      "pos": [
        4456,
        4465
      ],
      "content": "Large SUV"
    },
    {
      "pos": [
        4468,
        4485
      ],
      "content": "8Y5QKG27QET1RBK7I"
    },
    {
      "pos": [
        4488,
        4497
      ],
      "content": "Large SUV"
    },
    {
      "pos": [
        4500,
        4517
      ],
      "content": "DF6OX2WSRA6511BVG"
    },
    {
      "pos": [
        4520,
        4525
      ],
      "content": "Coupe"
    },
    {
      "pos": [
        4528,
        4545
      ],
      "content": "Z2EOZWZBXAEW3E60T"
    },
    {
      "pos": [
        4548,
        4553
      ],
      "content": "Sedan"
    },
    {
      "pos": [
        4556,
        4573
      ],
      "content": "M4TV6IEALD5QDS3IR"
    },
    {
      "pos": [
        4576,
        4582
      ],
      "content": "Hybrid"
    },
    {
      "pos": [
        4585,
        4602
      ],
      "content": "VHRA1Y2TGTA84F00H"
    },
    {
      "pos": [
        4605,
        4618
      ],
      "content": "Family Saloon"
    },
    {
      "pos": [
        4621,
        4638
      ],
      "content": "R0JAUHT1L1R3BIKI0"
    },
    {
      "pos": [
        4641,
        4646
      ],
      "content": "Sedan"
    },
    {
      "pos": [
        4649,
        4666
      ],
      "content": "9230C202Z60XX84AU"
    },
    {
      "pos": [
        4669,
        4675
      ],
      "content": "Hybrid"
    },
    {
      "pos": [
        4678,
        4695
      ],
      "content": "T8DNDN5UDCWL7M72H"
    },
    {
      "pos": [
        4698,
        4711
      ],
      "content": "Family Saloon"
    },
    {
      "pos": [
        4714,
        4731
      ],
      "content": "4WPYRUZII5YV7YA42"
    },
    {
      "pos": [
        4734,
        4739
      ],
      "content": "Sedan"
    },
    {
      "pos": [
        4742,
        4759
      ],
      "content": "D1ZVY26UV2BFGHZNO"
    },
    {
      "pos": [
        4762,
        4768
      ],
      "content": "Hybrid"
    },
    {
      "pos": [
        4771,
        4788
      ],
      "content": "XUF99EW9OIQOMV7Q7"
    },
    {
      "pos": [
        4791,
        4804
      ],
      "content": "Family Saloon"
    },
    {
      "pos": [
        4805,
        4822
      ],
      "content": "8OMCL3LGI7XNCC21U"
    },
    {
      "pos": [
        4825,
        4836
      ],
      "content": "Convertible"
    },
    {
      "pos": [
        4839,
        4842
      ],
      "content": "……."
    },
    {
      "pos": [
        4856,
        4882
      ],
      "content": "To generate simulated data"
    },
    {
      "pos": [
        4887,
        5225
      ],
      "content": "Click on the arrow on the upper right on the Vehicle Telematics Simulator node in to download the data simulator package. Save and extract the files locally on your machine. <ph id=\"ph8\">![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig3-vehicle-telemetry-blueprint.png)</ph> <bpt id=\"p7\">*</bpt>Figure 3 – Vehicle Telemetry Analytics Solution Blueprint<ept id=\"p7\">*</ept>",
      "nodes": [
        {
          "content": "Click on the arrow on the upper right on the Vehicle Telematics Simulator node in to download the data simulator package.",
          "pos": [
            0,
            121
          ]
        },
        {
          "content": "Save and extract the files locally on your machine.",
          "pos": [
            122,
            173
          ]
        },
        {
          "content": "<ph id=\"ph8\">![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig3-vehicle-telemetry-blueprint.png)</ph> <bpt id=\"p7\">*</bpt>Figure 3 – Vehicle Telemetry Analytics Solution Blueprint<ept id=\"p7\">*</ept>",
          "pos": [
            174,
            394
          ]
        }
      ]
    },
    {
      "pos": [
        5231,
        5494
      ],
      "content": "On your local machine, go to the folder where you extracted the Vehicle Telematics Simulator package. <ph id=\"ph9\">![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig4-vehicle-telematics-simulator-folder.png)</ph> <bpt id=\"p8\">*</bpt>Figure 4 – Vehicle Telematics Simulator folder<ept id=\"p8\">*</ept>",
      "nodes": [
        {
          "content": "On your local machine, go to the folder where you extracted the Vehicle Telematics Simulator package.",
          "pos": [
            0,
            101
          ]
        },
        {
          "content": "<ph id=\"ph9\">![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig4-vehicle-telematics-simulator-folder.png)</ph> <bpt id=\"p8\">*</bpt>Figure 4 – Vehicle Telematics Simulator folder<ept id=\"p8\">*</ept>",
          "pos": [
            102,
            319
          ]
        }
      ]
    },
    {
      "pos": [
        5500,
        5550
      ],
      "content": "Execute the application <bpt id=\"p9\">**</bpt>CarEventGenerator.exe<ept id=\"p9\">**</ept>."
    },
    {
      "pos": [
        5556,
        5566
      ],
      "content": "References"
    },
    {
      "pos": [
        5568,
        5668
      ],
      "content": "<bpt id=\"p10\">[</bpt>Vehicle Telematics Simulator Visual Studio Solution<ept id=\"p10\">](http://go.microsoft.com/fwlink/?LinkId=717075)</ept>"
    },
    {
      "pos": [
        5671,
        5738
      ],
      "content": "<bpt id=\"p11\">[</bpt>Azure Event Hub<ept id=\"p11\">](https://azure.microsoft.com/services/event-hubs/)</ept>"
    },
    {
      "pos": [
        5740,
        5832
      ],
      "content": "<bpt id=\"p12\">[</bpt>Azure Data Factory<ept id=\"p12\">](https://azure.microsoft.com/documentation/learning-paths/data-factory/)</ept>"
    },
    {
      "pos": [
        5838,
        5847
      ],
      "content": "Ingestion"
    },
    {
      "pos": [
        5848,
        6104
      ],
      "content": "Combinations of Azure Event Hubs, Stream Analytics and Data Factory are leveraged to ingest the vehicle signals and the diagnostic events and real-time and batch analytics. All these components are created and configured as part of the solution deployment.",
      "nodes": [
        {
          "content": "Combinations of Azure Event Hubs, Stream Analytics and Data Factory are leveraged to ingest the vehicle signals and the diagnostic events and real-time and batch analytics.",
          "pos": [
            0,
            172
          ]
        },
        {
          "content": "All these components are created and configured as part of the solution deployment.",
          "pos": [
            173,
            256
          ]
        }
      ]
    },
    {
      "pos": [
        6111,
        6129
      ],
      "content": "Real-time analysis"
    },
    {
      "pos": [
        6130,
        6374
      ],
      "content": "The events generated by the Vehicle Telematics Simulator are published to the Event Hub using the Event Hub SDK. The Stream Analytics job ingests these events from the Event Hub and processes the data in real-time to analyze the vehicle health.",
      "nodes": [
        {
          "content": "The events generated by the Vehicle Telematics Simulator are published to the Event Hub using the Event Hub SDK.",
          "pos": [
            0,
            112
          ]
        },
        {
          "content": "The Stream Analytics job ingests these events from the Event Hub and processes the data in real-time to analyze the vehicle health.",
          "pos": [
            113,
            244
          ]
        }
      ]
    },
    {
      "pos": [
        6495,
        6527
      ],
      "content": "<bpt id=\"p13\">*</bpt>Figure 5 - Event Hub dashboard<ept id=\"p13\">*</ept>"
    },
    {
      "pos": [
        6664,
        6713
      ],
      "content": "<bpt id=\"p14\">*</bpt>Figure 6 - Stream analytics job processing data<ept id=\"p14\">*</ept>"
    },
    {
      "pos": [
        6715,
        7021
      ],
      "content": "The stream analytics job ingests data from the Event Hub, performs a join with the reference data to map the vehicle VIN to the corresponding model and also persists them into Azure blob storage for rich batch analytics. The below stream analytics query is used to persist the data into Azure blob storage.",
      "nodes": [
        {
          "content": "The stream analytics job ingests data from the Event Hub, performs a join with the reference data to map the vehicle VIN to the corresponding model and also persists them into Azure blob storage for rich batch analytics.",
          "pos": [
            0,
            220
          ]
        },
        {
          "content": "The below stream analytics query is used to persist the data into Azure blob storage.",
          "pos": [
            221,
            306
          ]
        }
      ]
    },
    {
      "pos": [
        7168,
        7226
      ],
      "content": "<bpt id=\"p15\">*</bpt>Figure 7 - Stream analytics job query for data ingestion<ept id=\"p15\">*</ept>"
    },
    {
      "pos": [
        7232,
        7246
      ],
      "content": "Batch analysis"
    },
    {
      "pos": [
        7247,
        7850
      ],
      "content": "We are also generating an additional volume of simulated vehicle signals and diagnostic dataset for richer batch analytics. This is required to ensure a good representative data volume for batch processing. For this purpose, we are using a pipeline named ‘PrepareSampleDataPipeline’ in the Azure Data Factory workflow to generate one-year worth of simulated vehicle signals and diagnostic dataset. Click <bpt id=\"p16\">[</bpt>Data Factory custom activity<ept id=\"p16\">](http://go.microsoft.com/fwlink/?LinkId=717077)</ept><ph id=\"ph13\"/> to download the Data Factory custom DotNet activity Visual Studio solution for customizations based on your requirements.",
      "nodes": [
        {
          "content": "We are also generating an additional volume of simulated vehicle signals and diagnostic dataset for richer batch analytics.",
          "pos": [
            0,
            123
          ]
        },
        {
          "content": "This is required to ensure a good representative data volume for batch processing.",
          "pos": [
            124,
            206
          ]
        },
        {
          "content": "For this purpose, we are using a pipeline named ‘PrepareSampleDataPipeline’ in the Azure Data Factory workflow to generate one-year worth of simulated vehicle signals and diagnostic dataset.",
          "pos": [
            207,
            397
          ]
        },
        {
          "content": "Click <bpt id=\"p16\">[</bpt>Data Factory custom activity<ept id=\"p16\">](http://go.microsoft.com/fwlink/?LinkId=717077)</ept><ph id=\"ph13\"/> to download the Data Factory custom DotNet activity Visual Studio solution for customizations based on your requirements.",
          "pos": [
            398,
            658
          ]
        }
      ]
    },
    {
      "pos": [
        7992,
        8054
      ],
      "content": "<bpt id=\"p17\">*</bpt>Figure 8 - Prepare Sample data for batch processing workflow<ept id=\"p17\">*</ept>"
    },
    {
      "pos": [
        8056,
        8120
      ],
      "content": "The pipeline consists of a custom ADF .Net Activity, show below:"
    },
    {
      "pos": [
        8249,
        8287
      ],
      "content": "<bpt id=\"p18\">*</bpt>Figure 9 - PrepareSampleDataPipeline<ept id=\"p18\">*</ept>"
    },
    {
      "pos": [
        8289,
        8567
      ],
      "content": "Once the pipeline executes successfully and ‘RawCarEventsTable’ dataset is marked ‘Ready’, one-year worth of simulated vehicle signals and diagnostic data are produced. You will see the following folder and file created in your storage account under the ‘connectedcar’ container",
      "nodes": [
        {
          "content": "Once the pipeline executes successfully and ‘RawCarEventsTable’ dataset is marked ‘Ready’, one-year worth of simulated vehicle signals and diagnostic data are produced.",
          "pos": [
            0,
            168
          ]
        },
        {
          "content": "You will see the following folder and file created in your storage account under the ‘connectedcar’ container",
          "pos": [
            169,
            278
          ]
        }
      ]
    },
    {
      "pos": [
        8704,
        8750
      ],
      "content": "<bpt id=\"p19\">*</bpt>Figure 10 - PrepareSampleDataPipeline Output<ept id=\"p19\">*</ept>"
    },
    {
      "pos": [
        8756,
        8766
      ],
      "content": "References"
    },
    {
      "pos": [
        8768,
        8849
      ],
      "content": "<bpt id=\"p20\">[</bpt>Azure Event Hub SDK for stream ingestion<ept id=\"p20\">](event-hubs-csharp-ephcs-getstarted.md)</ept>"
    },
    {
      "pos": [
        8851,
        9016
      ],
      "content": "<bpt id=\"p21\">[</bpt>Azure Data Factory data movement capabilities<ept id=\"p21\">](data-factory-data-movement-activities.md)</ept><bpt id=\"p22\">\n[</bpt>Azure Data Factory DotNet Activity<ept id=\"p22\">](data-factory-use-custom-activities.md)</ept>"
    },
    {
      "pos": [
        9018,
        9150
      ],
      "content": "<bpt id=\"p23\">[</bpt>Azure Data Factory DotNet activity visual studio solution for preparing sample data<ept id=\"p23\">](http://go.microsoft.com/fwlink/?LinkId=717077)</ept>"
    },
    {
      "pos": [
        9157,
        9164
      ],
      "content": "Prepare"
    },
    {
      "pos": [
        9166,
        9245
      ],
      "content": "[AZURE.ALERT] This step in the solution is applicable only to batch processing."
    },
    {
      "pos": [
        9248,
        9853
      ],
      "content": "The raw semi-structured vehicle signals and diagnostic dataset is partitioned in the data preparation step into a YEAR/MONTH format for efficient querying and scalable long term storage (i.e. it enables faulting over from one blob account to the next as the first fills up). The output data (labeled <bpt id=\"p24\">*</bpt>PartitionedCarEventsTable<ept id=\"p24\">*</ept>) is to be kept for a long period as the foundational/”rawest” form of data in the customer’s “Data Lake”.  The input data to this pipeline would typically be discarded as the output data has full fidelity to the input - it's just stored (partitioned) better for subsequent use.",
      "nodes": [
        {
          "content": "The raw semi-structured vehicle signals and diagnostic dataset is partitioned in the data preparation step into a YEAR/MONTH format for efficient querying and scalable long term storage (i.e. it enables faulting over from one blob account to the next as the first fills up).",
          "pos": [
            0,
            274
          ]
        },
        {
          "content": "The output data (labeled <bpt id=\"p24\">*</bpt>PartitionedCarEventsTable<ept id=\"p24\">*</ept>) is to be kept for a long period as the foundational/”rawest” form of data in the customer’s “Data Lake”.",
          "pos": [
            275,
            473
          ]
        },
        {
          "content": "The input data to this pipeline would typically be discarded as the output data has full fidelity to the input - it's just stored (partitioned) better for subsequent use.",
          "pos": [
            475,
            645
          ]
        }
      ]
    },
    {
      "pos": [
        9983,
        10026
      ],
      "content": "<bpt id=\"p25\">*</bpt>Figure 11 – Partition Car Events workflow<ept id=\"p25\">*</ept>"
    },
    {
      "pos": [
        10028,
        10317
      ],
      "content": "The raw data is partitioned using a Hive HDInsight activity in ‘PartitionCarEventsPipeline’. A year worth of sample data generated in step 1 is partitioned by YEAR/MONTH to generate vehicle signals and diagnostic data partitions corresponding to each month (total 12 partitions) in a year.",
      "nodes": [
        {
          "content": "The raw data is partitioned using a Hive HDInsight activity in ‘PartitionCarEventsPipeline’.",
          "pos": [
            0,
            92
          ]
        },
        {
          "content": "A year worth of sample data generated in step 1 is partitioned by YEAR/MONTH to generate vehicle signals and diagnostic data partitions corresponding to each month (total 12 partitions) in a year.",
          "pos": [
            93,
            289
          ]
        }
      ]
    },
    {
      "pos": [
        10448,
        10488
      ],
      "content": "<bpt id=\"p26\">*</bpt>Figure 12 - PartitionCarEventsPipeline<ept id=\"p26\">*</ept>"
    },
    {
      "pos": [
        10490,
        10656
      ],
      "content": "The Hive script shown below, named ‘partitioncarevents.hql’, is used for partitioning and is located at ‘\\demo\\src\\connectedcar\\scripts’ folder of the downloaded zip."
    },
    {
      "pos": [
        16291,
        16344
      ],
      "content": "<bpt id=\"p27\">*</bpt>Figure 13 - PartitionConnectedCarEvents Hive Script<ept id=\"p27\">*</ept>"
    },
    {
      "pos": [
        16346,
        16497
      ],
      "content": "Once the pipeline is executed successfully, you will see the following partitions generated in your storage account under the ‘connectedcar’ container."
    },
    {
      "pos": [
        16616,
        16648
      ],
      "content": "<bpt id=\"p28\">*</bpt>Figure 14 - Partitioned Output<ept id=\"p28\">*</ept>"
    },
    {
      "pos": [
        16650,
        16757
      ],
      "content": "The data is now optimized, is more manageable and ready for further processing to gain rich batch insights."
    },
    {
      "pos": [
        16763,
        16776
      ],
      "content": "Data Analysis"
    },
    {
      "pos": [
        16778,
        17028
      ],
      "content": "In this section, you will see how we have used the combination of Azure Stream Analytics, Azure Machine Learning, Azure Data Factory and Azure HDInsight for rich advanced analytics on vehicle health and driving habits.  There are 3 sub-sections here:",
      "nodes": [
        {
          "content": "In this section, you will see how we have used the combination of Azure Stream Analytics, Azure Machine Learning, Azure Data Factory and Azure HDInsight for rich advanced analytics on vehicle health and driving habits.",
          "pos": [
            0,
            218
          ]
        },
        {
          "content": "There are 3 sub-sections here:",
          "pos": [
            220,
            250
          ]
        }
      ]
    },
    {
      "pos": [
        17034,
        17268
      ],
      "content": "<bpt id=\"p29\">**</bpt>Machine Learning<ept id=\"p29\">**</ept>: This sub-section contains information on the anomaly detection experiment that we have used in this solution to predict vehicles requiring servicing maintenance and vehicles requiring recalls due to safety issues"
    },
    {
      "pos": [
        17273,
        17503
      ],
      "content": "<bpt id=\"p30\">**</bpt>Real-time analysis<ept id=\"p30\">**</ept>: This sub-section contains information regarding the real-time analytics using the Stream Analytics Query Language and operationalizing the machine learning experiment in real-time using a custom application"
    },
    {
      "pos": [
        17508,
        17712
      ],
      "content": "<bpt id=\"p31\">**</bpt>Batch analysis<ept id=\"p31\">**</ept>: This sub-section contains information regarding the transforming and processing of the batch data using Azure HDInsight and Azure Machine Learning operationalized by Azure Data Factory"
    },
    {
      "pos": [
        17718,
        17734
      ],
      "content": "Machine Learning"
    },
    {
      "pos": [
        17736,
        17881
      ],
      "content": "Our goal here is to predict the vehicles that require maintenance or recall based on certain heath statistics.  We make the following assumptions",
      "nodes": [
        {
          "content": "Our goal here is to predict the vehicles that require maintenance or recall based on certain heath statistics.",
          "pos": [
            0,
            110
          ]
        },
        {
          "content": "We make the following assumptions",
          "pos": [
            112,
            145
          ]
        }
      ]
    },
    {
      "pos": [
        17885,
        17978
      ],
      "content": "Vehicles require <bpt id=\"p32\">**</bpt>servicing maintenance<ept id=\"p32\">**</ept><ph id=\"ph20\"/> if one of the following three conditions are true:"
    },
    {
      "pos": [
        17985,
        18005
      ],
      "content": "Tire pressure is low"
    },
    {
      "pos": [
        18012,
        18035
      ],
      "content": "Engine oil level is low"
    },
    {
      "pos": [
        18042,
        18068
      ],
      "content": "Engine temperature is high"
    },
    {
      "pos": [
        18072,
        18176
      ],
      "content": "Vehicles may have a <bpt id=\"p33\">**</bpt>safety issue<ept id=\"p33\">**</ept><ph id=\"ph21\"/> and require <bpt id=\"p34\">**</bpt>recall<ept id=\"p34\">**</ept><ph id=\"ph22\"/> if one of the following conditions are true:"
    },
    {
      "pos": [
        18183,
        18240
      ],
      "content": "Engine temperature is high but outside temperature is low"
    },
    {
      "pos": [
        18247,
        18304
      ],
      "content": "Engine temperature is low but outside temperature is high"
    },
    {
      "pos": [
        18306,
        18584
      ],
      "content": "Based on the above requirements, we have created two separate models to detect anomalies, one for vehicle maintenance detection, and one for vehicle recall detection. In both these models, the built-in Principal Component Analysis (PCA) algorithm is used for anomaly detection .",
      "nodes": [
        {
          "content": "Based on the above requirements, we have created two separate models to detect anomalies, one for vehicle maintenance detection, and one for vehicle recall detection.",
          "pos": [
            0,
            166
          ]
        },
        {
          "content": "In both these models, the built-in Principal Component Analysis (PCA) algorithm is used for anomaly detection .",
          "pos": [
            167,
            278
          ]
        }
      ]
    },
    {
      "pos": [
        18587,
        19092
      ],
      "content": "<bpt id=\"p35\">**</bpt>Maintenance detection model<ept id=\"p35\">**</ept>\nIn the maintenance detection model, the model reports an anomaly if one of three indicators - tire pressure, engine oil, or engine temperature - satisfies its respective condition. As a result, we only need to consider these three variables in building the model. In our experiment in Azure Machine Learning, we first use a <bpt id=\"p36\">**</bpt>Project Columns<ept id=\"p36\">**</ept><ph id=\"ph23\"/> module to extract these three variables. Next we use the PCA-based anomaly detection module to build the anomaly detection model.",
      "nodes": [
        {
          "content": "<bpt id=\"p35\">**</bpt>Maintenance detection model<ept id=\"p35\">**</ept>\nIn the maintenance detection model, the model reports an anomaly if one of three indicators - tire pressure, engine oil, or engine temperature - satisfies its respective condition.",
          "pos": [
            0,
            252
          ]
        },
        {
          "content": "As a result, we only need to consider these three variables in building the model.",
          "pos": [
            253,
            335
          ]
        },
        {
          "content": "In our experiment in Azure Machine Learning, we first use a <bpt id=\"p36\">**</bpt>Project Columns<ept id=\"p36\">**</ept><ph id=\"ph23\"/> module to extract these three variables.",
          "pos": [
            336,
            511
          ]
        },
        {
          "content": "Next we use the PCA-based anomaly detection module to build the anomaly detection model.",
          "pos": [
            512,
            600
          ]
        }
      ]
    },
    {
      "pos": [
        19095,
        19524
      ],
      "content": "Principal Component Analysis (PCA) is an established technique in machine learning that can be applied to feature selection, classification, and anomaly detection. PCA converts a set of case containing possibly correlated variables, into a set of values called principal components. The key idea of PCA-based modeling is to project data onto a lower-dimensional space so that features and anomalies can be more easily identified.",
      "nodes": [
        {
          "content": "Principal Component Analysis (PCA) is an established technique in machine learning that can be applied to feature selection, classification, and anomaly detection.",
          "pos": [
            0,
            163
          ]
        },
        {
          "content": "PCA converts a set of case containing possibly correlated variables, into a set of values called principal components.",
          "pos": [
            164,
            282
          ]
        },
        {
          "content": "The key idea of PCA-based modeling is to project data onto a lower-dimensional space so that features and anomalies can be more easily identified.",
          "pos": [
            283,
            429
          ]
        }
      ]
    },
    {
      "pos": [
        19527,
        19809
      ],
      "content": "In the case of anomaly detection, for each new input, the anomaly detector first computes its projection on the eigenvectors, and then computes the normalized reconstruction error. This normalized error is the anomaly score. The higher the error, the more anomalous the instance is.",
      "nodes": [
        {
          "content": "In the case of anomaly detection, for each new input, the anomaly detector first computes its projection on the eigenvectors, and then computes the normalized reconstruction error.",
          "pos": [
            0,
            180
          ]
        },
        {
          "content": "This normalized error is the anomaly score.",
          "pos": [
            181,
            224
          ]
        },
        {
          "content": "The higher the error, the more anomalous the instance is.",
          "pos": [
            225,
            282
          ]
        }
      ]
    },
    {
      "pos": [
        19812,
        20338
      ],
      "content": "In the maintenance detection problem, each record can be considered as a point in a 3-dimensional space defined by tire pressure, engine oil, and engine temperature coordinates. To capture these anomalies, we can project the original data in the 3-dimensional onto a 2-dimensional space using PCA. Thus, we set the parameter Number of components to use in PCA to be 2. This parameter plays an important role in applying PCA-based anomaly detection. After projecting data using PCA, we can identify these anomalies more easily.",
      "nodes": [
        {
          "content": "In the maintenance detection problem, each record can be considered as a point in a 3-dimensional space defined by tire pressure, engine oil, and engine temperature coordinates.",
          "pos": [
            0,
            177
          ]
        },
        {
          "content": "To capture these anomalies, we can project the original data in the 3-dimensional onto a 2-dimensional space using PCA.",
          "pos": [
            178,
            297
          ]
        },
        {
          "content": "Thus, we set the parameter Number of components to use in PCA to be 2.",
          "pos": [
            298,
            368
          ]
        },
        {
          "content": "This parameter plays an important role in applying PCA-based anomaly detection.",
          "pos": [
            369,
            448
          ]
        },
        {
          "content": "After projecting data using PCA, we can identify these anomalies more easily.",
          "pos": [
            449,
            526
          ]
        }
      ]
    },
    {
      "pos": [
        20340,
        21111
      ],
      "content": "<bpt id=\"p37\">**</bpt>Recall anomaly detection model<ept id=\"p37\">**</ept>\nIn the recall anomaly detection model, we use the Project Columns and PCA-based anomaly detection modules in a similar way. Specifically, we first extract three variables - engine temperature, outside temperature, and speed - using the <bpt id=\"p38\">**</bpt>Project Columns<ept id=\"p38\">**</ept><ph id=\"ph24\"/> module. We also include the speed variable since the engine temperature typically is correlated to the speed. Next we use PCA-based anomaly detection module to project the data from the 3-dimensional space onto a 2-dimensional space. The recall criteria are satisfied and so the vehicle requires recall when engine temperature and outside temperature are highly negatively correlated. Using PCA-based anomaly detection algorithm, we can capture the anomalies after performing PCA.",
      "nodes": [
        {
          "content": "<bpt id=\"p37\">**</bpt>Recall anomaly detection model<ept id=\"p37\">**</ept>\nIn the recall anomaly detection model, we use the Project Columns and PCA-based anomaly detection modules in a similar way.",
          "pos": [
            0,
            198
          ]
        },
        {
          "content": "Specifically, we first extract three variables - engine temperature, outside temperature, and speed - using the <bpt id=\"p38\">**</bpt>Project Columns<ept id=\"p38\">**</ept><ph id=\"ph24\"/> module.",
          "pos": [
            199,
            393
          ]
        },
        {
          "content": "We also include the speed variable since the engine temperature typically is correlated to the speed.",
          "pos": [
            394,
            495
          ]
        },
        {
          "content": "Next we use PCA-based anomaly detection module to project the data from the 3-dimensional space onto a 2-dimensional space.",
          "pos": [
            496,
            619
          ]
        },
        {
          "content": "The recall criteria are satisfied and so the vehicle requires recall when engine temperature and outside temperature are highly negatively correlated.",
          "pos": [
            620,
            770
          ]
        },
        {
          "content": "Using PCA-based anomaly detection algorithm, we can capture the anomalies after performing PCA.",
          "pos": [
            771,
            866
          ]
        }
      ]
    },
    {
      "pos": [
        21114,
        21416
      ],
      "content": "Note that when training either model, we need to use normal data which does not require maintenance or recall as the input data to train the PCA-based anomaly detection model. In the scoring experiment, we use the trained anomaly detection model to detect if the vehicle requires maintenance or recall.",
      "nodes": [
        {
          "content": "Note that when training either model, we need to use normal data which does not require maintenance or recall as the input data to train the PCA-based anomaly detection model.",
          "pos": [
            0,
            175
          ]
        },
        {
          "content": "In the scoring experiment, we use the trained anomaly detection model to detect if the vehicle requires maintenance or recall.",
          "pos": [
            176,
            302
          ]
        }
      ]
    },
    {
      "pos": [
        21424,
        21442
      ],
      "content": "Real-time analysis"
    },
    {
      "pos": [
        21444,
        21809
      ],
      "content": "The following Stream Analytics SQL Query is used to get the average of all the important vehicle parameters like vehicle speed, fuel level, engine temperature, odometer reading, tire pressure, engine oil level etc to detect anomalies, issue alerts and determine the overall health conditions of vehicles operated in specific region and correlate it to demographics."
    },
    {
      "pos": [
        21958,
        22017
      ],
      "content": "Figure 15 – Stream analytics query for real-time processing"
    },
    {
      "pos": [
        22019,
        22188
      ],
      "content": "All the averages are calculated over a 3 seconds TumblingWindow. We are using TubmlingWindow in this case since we require non-overlapping and contiguous time intervals.",
      "nodes": [
        {
          "content": "All the averages are calculated over a 3 seconds TumblingWindow.",
          "pos": [
            0,
            64
          ]
        },
        {
          "content": "We are using TubmlingWindow in this case since we require non-overlapping and contiguous time intervals.",
          "pos": [
            65,
            169
          ]
        }
      ]
    },
    {
      "pos": [
        22191,
        22370
      ],
      "content": "To learn more about all the ‘Windowing’ capabilities in Azure Stream Analytics, click <bpt id=\"p39\">[</bpt>Windowing (Azure Stream Analytics)<ept id=\"p39\">](https://msdn.microsoft.com/library/azure/dn835019.aspx)</ept>."
    },
    {
      "pos": [
        22372,
        22396
      ],
      "content": "<bpt id=\"p40\">**</bpt>Real-time prediction<ept id=\"p40\">**</ept>"
    },
    {
      "pos": [
        22398,
        22656
      ],
      "content": "An application is included as part of the solution to operationalize the machine learning model in real-time. This application called “RealTimeDashboardApp” is created and configured as part of the solution deployment. The application performs the following:",
      "nodes": [
        {
          "content": "An application is included as part of the solution to operationalize the machine learning model in real-time.",
          "pos": [
            0,
            109
          ]
        },
        {
          "content": "This application called “RealTimeDashboardApp” is created and configured as part of the solution deployment.",
          "pos": [
            110,
            218
          ]
        },
        {
          "content": "The application performs the following:",
          "pos": [
            219,
            258
          ]
        }
      ]
    },
    {
      "pos": [
        22662,
        22996
      ],
      "content": "Listens to an Event Hub instance where Stream Analytics is publishing the events in a continuously pattern. <ph id=\"ph26\">![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig16-vehicle-telematics-stream-analytics-query-for-publishing.png)</ph><bpt id=\"p41\">*</bpt>Figure 16 – Stream analytics query for publishing the data to an output Event Hub instance<ept id=\"p41\">*</ept>",
      "nodes": [
        {
          "content": "Listens to an Event Hub instance where Stream Analytics is publishing the events in a continuously pattern.",
          "pos": [
            0,
            107
          ]
        },
        {
          "content": "<ph id=\"ph26\">![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig16-vehicle-telematics-stream-analytics-query-for-publishing.png)</ph><bpt id=\"p41\">*</bpt>Figure 16 – Stream analytics query for publishing the data to an output Event Hub instance<ept id=\"p41\">*</ept>",
          "pos": [
            108,
            393
          ]
        }
      ]
    },
    {
      "pos": [
        23003,
        23050
      ],
      "content": "For every event that this application receives:"
    },
    {
      "pos": [
        23059,
        23212
      ],
      "content": "Processes the data using Machine Learning Request-Response Scoring (RRS) endpoint. The RRS endpoint is automatically published as part of the deployment.",
      "nodes": [
        {
          "content": "Processes the data using Machine Learning Request-Response Scoring (RRS) endpoint.",
          "pos": [
            0,
            82
          ]
        },
        {
          "content": "The RRS endpoint is automatically published as part of the deployment.",
          "pos": [
            83,
            153
          ]
        }
      ]
    },
    {
      "pos": [
        23219,
        23288
      ],
      "content": "The RRS output is published to a PowerBI dataset using the push APIs."
    },
    {
      "pos": [
        23290,
        23489
      ],
      "content": "This pattern is also applicable in scenarios where you want to integrate a Line of Business application with the real-time analytics flow for scenarios such as alerts, notifications, messagings, etc."
    },
    {
      "pos": [
        23492,
        23656
      ],
      "content": "Click <bpt id=\"p42\">[</bpt>RealtimeDashboardApp download<ept id=\"p42\">](http://go.microsoft.com/fwlink/?LinkId=717078)</ept><ph id=\"ph27\"/> to download the RealtimeDashboardApp Visual Studio solution for customizations."
    },
    {
      "pos": [
        23659,
        23710
      ],
      "content": "**To execute the Real-time Dashboard Application **"
    },
    {
      "pos": [
        23716,
        24019
      ],
      "content": "Click on the PowerBI node on the diagram view and click the Download Real-time Dashboard Application’ link on the properties pane. <ph id=\"ph28\">![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig17-vehicle-telematics-powerbi-dashboard-setup.png)</ph>  <bpt id=\"p43\">*</bpt>Figure 17 – PowerBI dashboard setup instructions<ept id=\"p43\">*</ept>",
      "nodes": [
        {
          "content": "Click on the PowerBI node on the diagram view and click the Download Real-time Dashboard Application’ link on the properties pane.",
          "pos": [
            0,
            130
          ]
        },
        {
          "content": "<ph id=\"ph28\">![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig17-vehicle-telematics-powerbi-dashboard-setup.png)</ph>  <bpt id=\"p43\">*</bpt>Figure 17 – PowerBI dashboard setup instructions<ept id=\"p43\">*</ept>",
          "pos": [
            131,
            362
          ]
        }
      ]
    },
    {
      "pos": [
        24024,
        24216
      ],
      "content": "Extract and save locally <ph id=\"ph29\">![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig18-vehicle-telematics-realtimedashboardapp-folder.png)</ph>  <bpt id=\"p44\">*</bpt>Figure 18 – RealtimeDashboardApp folder<ept id=\"p44\">*</ept>"
    },
    {
      "pos": [
        24221,
        24269
      ],
      "content": "Execute the application RealtimeDashboardApp.exe"
    },
    {
      "pos": [
        24274,
        24610
      ],
      "content": "Provide valid Power BI credentials, sign in and click Accept <ph id=\"ph30\">![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig19a-vehicle-telematics-realtimedashboardapp-sign-in-to-powerbi.png)</ph> <ph id=\"ph31\">![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig19b-vehicle-telematics-realtimedashboardapp-sign-in-to-powerbi.png)</ph>"
    },
    {
      "pos": [
        24613,
        24667
      ],
      "content": "<bpt id=\"p45\">*</bpt>Figure 19 – RealtimeDashboardApp: Sign-in to PowerBI<ept id=\"p45\">*</ept>"
    },
    {
      "pos": [
        24670,
        24791
      ],
      "content": "<ph id=\"ph32\">[AZURE.NOTE]</ph><ph id=\"ph33\"/> Note: If you want to flush the PowerBI dataset, execute the RealtimeDashboardApp with ‘flushdata’ parameter:"
    },
    {
      "pos": [
        24839,
        24853
      ],
      "content": "Batch analysis"
    },
    {
      "pos": [
        24855,
        25047
      ],
      "content": "The goal here is to showcase how Contoso Motors is utilizing the Azure compute capabilities to harness big data to gain rich insights on driving pattern, usage behavior and vehicle health for:"
    },
    {
      "pos": [
        25051,
        25181
      ],
      "content": "Improving the customer experience and make it cheaper by providing insights on driving habits and fuel efficient driving behaviors"
    },
    {
      "pos": [
        25184,
        25325
      ],
      "content": "Learning proactively about customers and their driving patters to govern business decisions and provide the best in class products &amp; services"
    },
    {
      "pos": [
        25327,
        25384
      ],
      "content": "In this solution, we are targeting the following metrics:"
    },
    {
      "pos": [
        25390,
        25676
      ],
      "content": "<bpt id=\"p46\">**</bpt>Aggressive driving behavior<ept id=\"p46\">**</ept><ph id=\"ph34\"/> Identifies the trend of the models, locations, driving conditions, and time of the year to gain insights on aggressive driving pattern allowing Contoso Motors to use it for marketing campaigns, driving new personalized features and usage based insurance."
    },
    {
      "pos": [
        25681,
        26034
      ],
      "content": "<bpt id=\"p47\">**</bpt>Fuel efficient driving behavior<ept id=\"p47\">**</ept><ph id=\"ph35\"/> Identifies the trend of the models, locations, driving conditions, and time of the year to gain insights on fuel efficient driving pattern allowing Contoso Motors to use it for marketing campaigns, driving new features and proactive reporting to the drivers for cost effective and environment friendly driving habits."
    },
    {
      "pos": [
        26040,
        26163
      ],
      "content": "<bpt id=\"p48\">**</bpt>Recall models<ept id=\"p48\">**</ept><ph id=\"ph36\"/> Identifies models requiring recalls by operationalizing the anomaly detection machine learning experiment"
    },
    {
      "pos": [
        26165,
        26218
      ],
      "content": "Let’s look into the details of each of these metrics,"
    },
    {
      "pos": [
        26221,
        26251
      ],
      "content": "<bpt id=\"p49\">**</bpt>Aggressive driving pattern<ept id=\"p49\">**</ept>"
    },
    {
      "pos": [
        26253,
        26497
      ],
      "content": "The partitioned vehicle signals and diagnostic data are processed in the pipeline named ‘AggresiveDrivingPatternPipeline’ using Hive to determine the models, location, vehicle and driving conditions etc that exhibits aggressive driving pattern."
    },
    {
      "pos": [
        26499,
        26673
      ],
      "content": "<ph id=\"ph37\">![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig20-vehicle-telematics-aggressive-driving-pattern.png)</ph><bpt id=\"p50\"> \n*</bpt>Figure 20 – Aggressive driving pattern workflow<ept id=\"p50\">*</ept>"
    },
    {
      "pos": [
        26675,
        26852
      ],
      "content": "The Hive script named ‘aggresivedriving.hql’ used for analyzing aggressive driving condition pattern is located at ‘\\demo\\src\\connectedcar\\scripts’ folder of the downloaded zip."
    },
    {
      "pos": [
        29384,
        29435
      ],
      "content": "<bpt id=\"p51\">*</bpt>Figure 21 – Aggressive driving pattern Hive query<ept id=\"p51\">*</ept>"
    },
    {
      "pos": [
        29437,
        29617
      ],
      "content": "It uses the combination of vehicle’s transmission gear position, brake pedal status and speed to detect reckless/aggressive driving behavior based on braking pattern at high speed."
    },
    {
      "pos": [
        29620,
        29771
      ],
      "content": "Once the pipeline is executed successfully, you will see the following partitions generated in your storage account under the ‘connectedcar’ container."
    },
    {
      "pos": [
        29906,
        29959
      ],
      "content": "<bpt id=\"p52\">*</bpt>Figure 22 – AggressiveDrivingPatternPipeline output<ept id=\"p52\">*</ept>"
    },
    {
      "pos": [
        29962,
        29996
      ],
      "content": "<bpt id=\"p53\">**</bpt>Fuel efficient driving pattern<ept id=\"p53\">**</ept>"
    },
    {
      "pos": [
        29998,
        30250
      ],
      "content": "The partitioned vehicle signals and diagnostic data are processed in the pipeline named ‘FuelEfficientDrivingPatternPipeline’ using Hive to determine the models, location, vehicle and driving conditions etc that exhibits fuel efficient driving pattern."
    },
    {
      "pos": [
        30382,
        30435
      ],
      "content": "<bpt id=\"p54\">*</bpt>Figure 23 – Fuel efficient driving pattern workflow<ept id=\"p54\">*</ept>"
    },
    {
      "pos": [
        30437,
        30618
      ],
      "content": "The Hive script named ‘fuelefficientdriving.hql’ used for analyzing aggressive driving condition pattern is located at ‘\\demo\\src\\connectedcar\\scripts’ folder of the downloaded zip."
    },
    {
      "pos": [
        33305,
        33360
      ],
      "content": "<bpt id=\"p55\">*</bpt>Figure 24 – Fuel efficient driving pattern Hive query<ept id=\"p55\">*</ept>"
    },
    {
      "pos": [
        33362,
        33576
      ],
      "content": "It uses the combination of vehicle’s transmission gear position, brake pedal status, speed and accelerator pedal position to detect fuel efficient driving behavior based on acceleration, braking and speed patterns."
    },
    {
      "pos": [
        33579,
        33730
      ],
      "content": "Once the pipeline is executed successfully, you will see the following partitions generated in your storage account under the ‘connectedcar’ container."
    },
    {
      "pos": [
        33869,
        33925
      ],
      "content": "<bpt id=\"p56\">*</bpt>Figure 25 – FuelEfficientDrivingPatternPipeline output<ept id=\"p56\">*</ept>"
    },
    {
      "pos": [
        33928,
        33950
      ],
      "content": "<bpt id=\"p57\">**</bpt>Recall Predictions<ept id=\"p57\">**</ept>"
    },
    {
      "pos": [
        33952,
        34231
      ],
      "content": "The machine learning experiment is provisioned and published as a web service as part of the solution deployment. The batch scoring end point is leveraged in this workflow, registered as a data factory linked service and operationalized using data factory batch scoring activity.",
      "nodes": [
        {
          "content": "The machine learning experiment is provisioned and published as a web service as part of the solution deployment.",
          "pos": [
            0,
            113
          ]
        },
        {
          "content": "The batch scoring end point is leveraged in this workflow, registered as a data factory linked service and operationalized using data factory batch scoring activity.",
          "pos": [
            114,
            279
          ]
        }
      ]
    },
    {
      "pos": [
        34358,
        34444
      ],
      "content": "<bpt id=\"p58\">*</bpt>Figure 26 – Machine learning endpoint registered as a linked service in data factory<ept id=\"p58\">*</ept>"
    },
    {
      "pos": [
        34446,
        34565
      ],
      "content": "The registered linked service is used in the DetectAnomalyPipeline to score the data using the anomaly detection model."
    },
    {
      "pos": [
        34685,
        34760
      ],
      "content": "<bpt id=\"p59\">*</bpt>Figure 27 – Azure Machine Learning Batch Scoring activity in data factory<ept id=\"p59\">*</ept>"
    },
    {
      "pos": [
        34763,
        34900
      ],
      "content": "There are few steps performed in this pipeline for data preparation so that it can be operationalized with the batch scoring web service."
    },
    {
      "pos": [
        35030,
        35107
      ],
      "content": "<bpt id=\"p60\">*</bpt>Figure 28 – DetectAnomalyPipeline for predicting vehicles requiring recalls<ept id=\"p60\">*</ept>"
    },
    {
      "pos": [
        35110,
        35295
      ],
      "content": "Once the scoring is completed, an HDInsight activity is used to process and aggregate the data that are categorized as anomalies by the model with a probability score of 0.60 or higher."
    },
    {
      "pos": [
        37732,
        37776
      ],
      "content": "<bpt id=\"p61\">*</bpt>Figure 29  – Recall aggregation hive query<ept id=\"p61\">*</ept>"
    },
    {
      "pos": [
        37778,
        37929
      ],
      "content": "Once the pipeline is executed successfully, you will see the following partitions generated in your storage account under the ‘connectedcar’ container."
    },
    {
      "pos": [
        38061,
        38115
      ],
      "content": "<bpt id=\"p62\">*</bpt>Figure 30 – Figure 30 – DetectAnomalyPipeline output<ept id=\"p62\">*</ept>"
    },
    {
      "pos": [
        38121,
        38128
      ],
      "content": "Publish"
    },
    {
      "pos": [
        38134,
        38152
      ],
      "content": "Real-time analysis"
    },
    {
      "pos": [
        38154,
        38254
      ],
      "content": "One of the queries in the stream analytics job publishes the events to an output Event Hub instance."
    },
    {
      "pos": [
        38403,
        38479
      ],
      "content": "<bpt id=\"p63\">*</bpt>Figure 31 – Stream analytics job publishes to an output Event Hub instance<ept id=\"p63\">*</ept>"
    },
    {
      "pos": [
        38627,
        38707
      ],
      "content": "<bpt id=\"p64\">*</bpt>Figure 32 – Stream analytics query to publish to the output Event Hub instance<ept id=\"p64\">*</ept>"
    },
    {
      "pos": [
        38709,
        38967
      ],
      "content": "This stream of events are consumed by the RealTimeDashboardApp included in the solution. This application leverages the Machine Learning Request-Response web service for real-time scoring and publishes the resultant data to a PowerBI dataset for consumption.",
      "nodes": [
        {
          "content": "This stream of events are consumed by the RealTimeDashboardApp included in the solution.",
          "pos": [
            0,
            88
          ]
        },
        {
          "content": "This application leverages the Machine Learning Request-Response web service for real-time scoring and publishes the resultant data to a PowerBI dataset for consumption.",
          "pos": [
            89,
            258
          ]
        }
      ]
    },
    {
      "pos": [
        38974,
        38988
      ],
      "content": "Batch analysis"
    },
    {
      "pos": [
        38990,
        39204
      ],
      "content": "The results of the batch and real-time processing are published to the Azure SQL Database tables for consumption. The Azure SQL Server, Database and the tables are created automatically as part of the setup script.",
      "nodes": [
        {
          "content": "The results of the batch and real-time processing are published to the Azure SQL Database tables for consumption.",
          "pos": [
            0,
            113
          ]
        },
        {
          "content": "The Azure SQL Server, Database and the tables are created automatically as part of the setup script.",
          "pos": [
            114,
            214
          ]
        }
      ]
    },
    {
      "pos": [
        39348,
        39413
      ],
      "content": "<bpt id=\"p65\">*</bpt>Figure 33 – Batch processing results copy to data mart workflow<ept id=\"p65\">*</ept>"
    },
    {
      "pos": [
        39557,
        39614
      ],
      "content": "<bpt id=\"p66\">*</bpt>Figure 34 – Stream analytics job publishes to data mart<ept id=\"p66\">*</ept>"
    },
    {
      "pos": [
        39756,
        39811
      ],
      "content": "<bpt id=\"p67\">*</bpt>Figure 35 – Data mart setting in stream analytics job<ept id=\"p67\">*</ept>"
    },
    {
      "pos": [
        39817,
        39824
      ],
      "content": "Consume"
    },
    {
      "pos": [
        39826,
        39931
      ],
      "content": "Power BI gives this solution a rich dashboard for real-time data and predictive analytics visualizations."
    },
    {
      "pos": [
        39934,
        40060
      ],
      "content": "Click here for detailed instructions on setting up the PowerBI reports and the dashboard. The final dashboard looks like this:",
      "nodes": [
        {
          "content": "Click here for detailed instructions on setting up the PowerBI reports and the dashboard.",
          "pos": [
            0,
            89
          ]
        },
        {
          "content": "The final dashboard looks like this:",
          "pos": [
            90,
            126
          ]
        }
      ]
    },
    {
      "pos": [
        40178,
        40209
      ],
      "content": "<bpt id=\"p68\">*</bpt>Figure 36 - PowerBI Dashboard<ept id=\"p68\">*</ept>"
    },
    {
      "pos": [
        40214,
        40221
      ],
      "content": "Summary"
    },
    {
      "pos": [
        40223,
        40538
      ],
      "content": "This document contains a detailed drill-down of the Vehicle Telemetry Analytics Solution. This showcases a lambda architecture pattern for real-time and batch analytics with predictions and actions. This pattern applies to a wide range of use cases that require hot path (real-time) and cold path (batch) analytics.",
      "nodes": [
        {
          "content": "This document contains a detailed drill-down of the Vehicle Telemetry Analytics Solution.",
          "pos": [
            0,
            89
          ]
        },
        {
          "content": "This showcases a lambda architecture pattern for real-time and batch analytics with predictions and actions.",
          "pos": [
            90,
            198
          ]
        },
        {
          "content": "This pattern applies to a wide range of use cases that require hot path (real-time) and cold path (batch) analytics.",
          "pos": [
            199,
            315
          ]
        }
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"Vehicle telemetry analytics solution playbook: deep dive into the solution | Microsoft Azure\" \n    description=\"Use the capabilities of Cortana Analytics to gain real-time and predictive insights on vehicle health and driving habits.\" \n    services=\"machine-learning\" \n    documentationCenter=\"\" \n    authors=\"bradsev\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\" />\n\n<tags \n    ms.service=\"machine-learning\" \n    ms.workload=\"data-services\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"01/26/2016\" \n    ms.author=\"bradsev\" />\n\n\n# Vehicle telemetry analytics solution playbook: deep dive into the solution\n\nThis **menu** links to the sections of this playbook: \n\n[AZURE.INCLUDE [cap-vehicle-telemetry-playbook-selector](../../includes/cap-vehicle-telemetry-playbook-selector.md)]\n\nThis section drills down into the details of each one of the stages depicted in the Solution Architecture with instructions and pointers for customization. \n\n## Data Sources\n\nThe solution uses two different data sources:\n\n- **simulated vehicle signals and diagnostic dataset** and \n- **vehicle catalog**\n\nA vehicle telematics simulator is included as part of this solution. It emits diagnostic information and signals corresponding to the state of the vehicle and driving pattern at a given point in time. Click [Vehicle Telematics Simulator](http://go.microsoft.com/fwlink/?LinkId=717075) to download the **Vehicle Telematics Simulator Visual Studio Solution** for customizations based on your requirements. The vehicle catalog contains a reference dataset with a VIN to model mapping.\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig2-vehicle-telematics-simulator.png)\n\n*Figure 2 – Vehicle Telematics Simulator*\n\nThis is a JSON format dataset and contains the below schema.\n\nColumn | Description | Values   \n ------- | ----------- | ---------  \nVIN | Randomly generated Vehicle Identification Number | This is obtained from a master list of 10,000 randomly generated vehicle identification number\nOutside temperature | The outside temperature where the vehicle is driving | Randomly generated number from 0-100\nEngine temperature | The engine temperature of the vehicle | Randomly generated number from 0-500\nSpeed | The engine speed at which the vehicle is driving | Randomly generated number from 0-100\nFuel | The fuel level of the vehicle | Randomly generated number from 0-100 (indicates fuel level percentage)\nEngineOil | The engine oil level of the vehicle | Randomly generated number from 0-100 (indicates engine oil level percentage)\nTirepressure | The tirepressure of the vehicle | Randomly generated number from 0-50 (indicates tirepressure level percentage)\nOdometer | The odometer reading of the vehicle | Randomly generated number from 0-200000\nAccelerator_pedal_position | The accelerator pedal position of the vehicle | Randomly generated number from 0-100 (indicates accelerator level percentage)\nParking_brake_status | Indicates whether the vehicle is parked or not | True or False\nHeadlamp_status | Indicates where the headlamp is on or not | True or False\nBrake_pedal_status | Indicates whether the brake pedal is pressed or not | True or False\nTransmission_gear_position | The transmission gear position of the vehicle | States: first, second, third, fourth, fifth, sixth, seventh, eighth\nIgnition_status | Indicates whether the vehicle is running or stopped | True or False\nWindshield_wiper_status | Indicates whether the windshield wiper is turned or not | True or False\nABS | Indicates whether ABS is engaged or not | True or False\nTimestamp | The timestamp when the data point is created | Date\nCity | The location of the vehicle | 4 cities in this solution : Bellevue, Redmond, Sammamish, Seattle\n\n\nThe vehicle model reference dataset contains VIN to the model mapping. \n\nVIN | Model |\n--------------|------------------\nFHL3O1SA4IEHB4WU1 | Sedan |\n8J0U8XCPRGW4Z3NQE | Hybrid |\nWORG68Z2PLTNZDBI7 | Family Saloon |\nJTHMYHQTEPP4WBMRN | Sedan |\nW9FTHG27LZN1YWO0Y | Hybrid |\nMHTP9N792PHK08WJM | Family Saloon |\nEI4QXI2AXVQQING4I | Sedan |\n5KKR2VB4WHQH97PF8 | Hybrid |\nW9NSZ423XZHAONYXB | Family Saloon |\n26WJSGHX4MA5ROHNL | Convertible |\nGHLUB6ONKMOSI7E77 | Station Wagon |\n9C2RHVRVLMEJDBXLP | Compact Car |\nBRNHVMZOUJ6EOCP32 | Small SUV |\nVCYVW0WUZNBTM594J | Sports Car |\nHNVCE6YFZSA5M82NY | Medium SUV |\n4R30FOR7NUOBL05GJ | Station Wagon |\nWYNIIY42VKV6OQS1J | Large SUV |\n8Y5QKG27QET1RBK7I | Large SUV |\nDF6OX2WSRA6511BVG | Coupe |\nZ2EOZWZBXAEW3E60T | Sedan |\nM4TV6IEALD5QDS3IR | Hybrid |\nVHRA1Y2TGTA84F00H | Family Saloon |\nR0JAUHT1L1R3BIKI0 | Sedan |\n9230C202Z60XX84AU | Hybrid |\nT8DNDN5UDCWL7M72H | Family Saloon |\n4WPYRUZII5YV7YA42 | Sedan |\nD1ZVY26UV2BFGHZNO | Hybrid |\nXUF99EW9OIQOMV7Q7 | Family Saloon\n8OMCL3LGI7XNCC21U | Convertible |\n…….  |   |\n\n\n### To generate simulated data\n1.  Click on the arrow on the upper right on the Vehicle Telematics Simulator node in to download the data simulator package. Save and extract the files locally on your machine. ![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig3-vehicle-telemetry-blueprint.png) *Figure 3 – Vehicle Telemetry Analytics Solution Blueprint*\n\n2.  On your local machine, go to the folder where you extracted the Vehicle Telematics Simulator package. ![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig4-vehicle-telematics-simulator-folder.png) *Figure 4 – Vehicle Telematics Simulator folder*\n\n3.  Execute the application **CarEventGenerator.exe**.\n\n### References\n\n[Vehicle Telematics Simulator Visual Studio Solution](http://go.microsoft.com/fwlink/?LinkId=717075) \n\n[Azure Event Hub](https://azure.microsoft.com/services/event-hubs/)\n\n[Azure Data Factory](https://azure.microsoft.com/documentation/learning-paths/data-factory/)\n\n\n## Ingestion\nCombinations of Azure Event Hubs, Stream Analytics and Data Factory are leveraged to ingest the vehicle signals and the diagnostic events and real-time and batch analytics. All these components are created and configured as part of the solution deployment. \n\n### Real-time analysis\nThe events generated by the Vehicle Telematics Simulator are published to the Event Hub using the Event Hub SDK. The Stream Analytics job ingests these events from the Event Hub and processes the data in real-time to analyze the vehicle health. \n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig5-vehicle-telematics-event-hub-dashboard.png) \n\n*Figure 5 - Event Hub dashboard*\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig6-vehicle-telematics-stream-analytics-job-processing-data.png) \n\n*Figure 6 - Stream analytics job processing data*\n\nThe stream analytics job ingests data from the Event Hub, performs a join with the reference data to map the vehicle VIN to the corresponding model and also persists them into Azure blob storage for rich batch analytics. The below stream analytics query is used to persist the data into Azure blob storage. \n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig7-vehicle-telematics-stream-analytics-job-query-for-data-ingestion.png) \n\n*Figure 7 - Stream analytics job query for data ingestion*\n\n### Batch analysis\nWe are also generating an additional volume of simulated vehicle signals and diagnostic dataset for richer batch analytics. This is required to ensure a good representative data volume for batch processing. For this purpose, we are using a pipeline named ‘PrepareSampleDataPipeline’ in the Azure Data Factory workflow to generate one-year worth of simulated vehicle signals and diagnostic dataset. Click [Data Factory custom activity](http://go.microsoft.com/fwlink/?LinkId=717077) to download the Data Factory custom DotNet activity Visual Studio solution for customizations based on your requirements. \n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig8-vehicle-telematics-prepare-sample-data-for-batch-processing.png) \n\n*Figure 8 - Prepare Sample data for batch processing workflow*\n\nThe pipeline consists of a custom ADF .Net Activity, show below:\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig9-vehicle-telematics-prepare-sample-data-pipeline.png) \n\n*Figure 9 - PrepareSampleDataPipeline*\n\nOnce the pipeline executes successfully and ‘RawCarEventsTable’ dataset is marked ‘Ready’, one-year worth of simulated vehicle signals and diagnostic data are produced. You will see the following folder and file created in your storage account under the ‘connectedcar’ container\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig10-vehicle-telematics-prepare-sample-data-pipeline-output.png) \n\n*Figure 10 - PrepareSampleDataPipeline Output*\n\n### References\n\n[Azure Event Hub SDK for stream ingestion](event-hubs-csharp-ephcs-getstarted.md)\n\n[Azure Data Factory data movement capabilities](data-factory-data-movement-activities.md)\n[Azure Data Factory DotNet Activity](data-factory-use-custom-activities.md)\n\n[Azure Data Factory DotNet activity visual studio solution for preparing sample data](http://go.microsoft.com/fwlink/?LinkId=717077) \n\n\n## Prepare\n>[AZURE.ALERT] This step in the solution is applicable only to batch processing. \n\nThe raw semi-structured vehicle signals and diagnostic dataset is partitioned in the data preparation step into a YEAR/MONTH format for efficient querying and scalable long term storage (i.e. it enables faulting over from one blob account to the next as the first fills up). The output data (labeled *PartitionedCarEventsTable*) is to be kept for a long period as the foundational/”rawest” form of data in the customer’s “Data Lake”.  The input data to this pipeline would typically be discarded as the output data has full fidelity to the input - it's just stored (partitioned) better for subsequent use.\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig11-vehicle-telematics-partition-car-events-workflow.png)\n\n*Figure 11 – Partition Car Events workflow*\n\nThe raw data is partitioned using a Hive HDInsight activity in ‘PartitionCarEventsPipeline’. A year worth of sample data generated in step 1 is partitioned by YEAR/MONTH to generate vehicle signals and diagnostic data partitions corresponding to each month (total 12 partitions) in a year. \n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig12-vehicle-telematics-partition-car-events-pipeline.png)\n\n*Figure 12 - PartitionCarEventsPipeline*\n\nThe Hive script shown below, named ‘partitioncarevents.hql’, is used for partitioning and is located at ‘\\demo\\src\\connectedcar\\scripts’ folder of the downloaded zip. \n\n    SET hive.exec.dynamic.partition=true;\n    SET hive.exec.dynamic.partition.mode = nonstrict;\n    set hive.cli.print.header=true;\n\n    DROP TABLE IF EXISTS RawCarEvents; \n    CREATE EXTERNAL TABLE RawCarEvents \n    (\n                vin                             string,\n                model                           string,\n                timestamp                       string,\n                outsidetemperature              string,\n                enginetemperature               string,\n                speed                           string,\n                fuel                            string,\n                engineoil                       string,\n                tirepressure                    string,\n                odometer                        string,\n                city                            string,\n                accelerator_pedal_position      string,\n                parking_brake_status            string,\n                headlamp_status                 string,\n                brake_pedal_status              string,\n                transmission_gear_position      string,\n                ignition_status                 string,\n                windshield_wiper_status         string,\n                abs                             string,\n                gendate                         string\n                \n    ) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '10' STORED AS TEXTFILE LOCATION '${hiveconf:RAWINPUT}'; \n\n    DROP TABLE IF EXISTS PartitionedCarEvents; \n    CREATE EXTERNAL TABLE PartitionedCarEvents \n    (\n                vin                             string,\n                model                           string,\n                timestamp                       string,\n                outsidetemperature              string,\n                enginetemperature               string,\n                speed                           string,\n                fuel                            string,\n                engineoil                       string,\n                tirepressure                    string,\n                odometer                        string,\n                city                            string,\n                accelerator_pedal_position      string,\n                parking_brake_status            string,\n                headlamp_status                 string,\n                brake_pedal_status              string,\n                transmission_gear_position      string,\n                ignition_status                 string,\n                windshield_wiper_status         string,\n                abs                             string,\n                gendate                         string\n    ) partitioned by (YearNo int, MonthNo int) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '10' STORED AS TEXTFILE LOCATION '${hiveconf:PARTITIONEDOUTPUT}';\n\n    DROP TABLE IF EXISTS Stage_RawCarEvents; \n    CREATE TABLE IF NOT EXISTS Stage_RawCarEvents \n    (\n                vin                             string,\n                model                           string,\n                timestamp                       string,\n                outsidetemperature              string,\n                enginetemperature               string,\n                speed                           string,\n                fuel                            string,\n                engineoil                       string,\n                tirepressure                    string,\n                odometer                        string,\n                city                            string,\n                accelerator_pedal_position      string,\n                parking_brake_status            string,\n                headlamp_status                 string,\n                brake_pedal_status              string,\n                transmission_gear_position      string,\n                ignition_status                 string,\n                windshield_wiper_status         string,\n                abs                             string,\n                gendate                         string,\n                YearNo                          int,\n                MonthNo                         int) \n    ROW FORMAT delimited fields terminated by ',' LINES TERMINATED BY '10';\n\n    INSERT OVERWRITE TABLE Stage_RawCarEvents\n    SELECT\n        vin,            \n        model,\n        timestamp,\n        outsidetemperature,\n        enginetemperature,\n        speed,\n        fuel,\n        engineoil,\n        tirepressure,\n        odometer,\n        city,\n        accelerator_pedal_position,\n        parking_brake_status,\n        headlamp_status,\n        brake_pedal_status,\n        transmission_gear_position,\n        ignition_status,\n        windshield_wiper_status,\n        abs,\n        gendate,\n        Year(gendate),\n        Month(gendate)\n\n    FROM RawCarEvents WHERE Year(gendate) = ${hiveconf:Year} AND Month(gendate) = ${hiveconf:Month}; \n\n    INSERT OVERWRITE TABLE PartitionedCarEvents PARTITION(YearNo, MonthNo) \n    SELECT\n        vin,            \n        model,\n        timestamp,\n        outsidetemperature,\n        enginetemperature,\n        speed,\n        fuel,\n        engineoil,\n        tirepressure,\n        odometer,\n        city,\n        accelerator_pedal_position,\n        parking_brake_status,\n        headlamp_status,\n        brake_pedal_status,\n        transmission_gear_position,\n        ignition_status,\n        windshield_wiper_status,\n        abs,\n        gendate,\n        YearNo,\n        MonthNo\n    FROM Stage_RawCarEvents WHERE YearNo = ${hiveconf:Year} AND MonthNo = ${hiveconf:Month};\n\n*Figure 13 - PartitionConnectedCarEvents Hive Script*\n\nOnce the pipeline is executed successfully, you will see the following partitions generated in your storage account under the ‘connectedcar’ container.\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig14-vehicle-telematics-partitioned-output.png)\n\n*Figure 14 - Partitioned Output*\n\nThe data is now optimized, is more manageable and ready for further processing to gain rich batch insights. \n\n## Data Analysis\n\nIn this section, you will see how we have used the combination of Azure Stream Analytics, Azure Machine Learning, Azure Data Factory and Azure HDInsight for rich advanced analytics on vehicle health and driving habits.  There are 3 sub-sections here:\n\n1.  **Machine Learning**: This sub-section contains information on the anomaly detection experiment that we have used in this solution to predict vehicles requiring servicing maintenance and vehicles requiring recalls due to safety issues\n2.  **Real-time analysis**: This sub-section contains information regarding the real-time analytics using the Stream Analytics Query Language and operationalizing the machine learning experiment in real-time using a custom application\n3.  **Batch analysis**: This sub-section contains information regarding the transforming and processing of the batch data using Azure HDInsight and Azure Machine Learning operationalized by Azure Data Factory\n\n### Machine Learning\n\nOur goal here is to predict the vehicles that require maintenance or recall based on certain heath statistics.  We make the following assumptions\n\n- Vehicles require **servicing maintenance** if one of the following three conditions are true:\n    - Tire pressure is low\n    - Engine oil level is low\n    - Engine temperature is high\n\n- Vehicles may have a **safety issue** and require **recall** if one of the following conditions are true:\n    - Engine temperature is high but outside temperature is low\n    - Engine temperature is low but outside temperature is high\n\nBased on the above requirements, we have created two separate models to detect anomalies, one for vehicle maintenance detection, and one for vehicle recall detection. In both these models, the built-in Principal Component Analysis (PCA) algorithm is used for anomaly detection . \n\n**Maintenance detection model**\nIn the maintenance detection model, the model reports an anomaly if one of three indicators - tire pressure, engine oil, or engine temperature - satisfies its respective condition. As a result, we only need to consider these three variables in building the model. In our experiment in Azure Machine Learning, we first use a **Project Columns** module to extract these three variables. Next we use the PCA-based anomaly detection module to build the anomaly detection model. \n\nPrincipal Component Analysis (PCA) is an established technique in machine learning that can be applied to feature selection, classification, and anomaly detection. PCA converts a set of case containing possibly correlated variables, into a set of values called principal components. The key idea of PCA-based modeling is to project data onto a lower-dimensional space so that features and anomalies can be more easily identified.\n \nIn the case of anomaly detection, for each new input, the anomaly detector first computes its projection on the eigenvectors, and then computes the normalized reconstruction error. This normalized error is the anomaly score. The higher the error, the more anomalous the instance is. \n\nIn the maintenance detection problem, each record can be considered as a point in a 3-dimensional space defined by tire pressure, engine oil, and engine temperature coordinates. To capture these anomalies, we can project the original data in the 3-dimensional onto a 2-dimensional space using PCA. Thus, we set the parameter Number of components to use in PCA to be 2. This parameter plays an important role in applying PCA-based anomaly detection. After projecting data using PCA, we can identify these anomalies more easily.\n\n**Recall anomaly detection model**\nIn the recall anomaly detection model, we use the Project Columns and PCA-based anomaly detection modules in a similar way. Specifically, we first extract three variables - engine temperature, outside temperature, and speed - using the **Project Columns** module. We also include the speed variable since the engine temperature typically is correlated to the speed. Next we use PCA-based anomaly detection module to project the data from the 3-dimensional space onto a 2-dimensional space. The recall criteria are satisfied and so the vehicle requires recall when engine temperature and outside temperature are highly negatively correlated. Using PCA-based anomaly detection algorithm, we can capture the anomalies after performing PCA. \n\nNote that when training either model, we need to use normal data which does not require maintenance or recall as the input data to train the PCA-based anomaly detection model. In the scoring experiment, we use the trained anomaly detection model to detect if the vehicle requires maintenance or recall. \n\n\n### Real-time analysis\n\nThe following Stream Analytics SQL Query is used to get the average of all the important vehicle parameters like vehicle speed, fuel level, engine temperature, odometer reading, tire pressure, engine oil level etc to detect anomalies, issue alerts and determine the overall health conditions of vehicles operated in specific region and correlate it to demographics. \n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig15-vehicle-telematics-stream-analytics-query-for-real-time-processing.png)\n\nFigure 15 – Stream analytics query for real-time processing\n\nAll the averages are calculated over a 3 seconds TumblingWindow. We are using TubmlingWindow in this case since we require non-overlapping and contiguous time intervals. \n\nTo learn more about all the ‘Windowing’ capabilities in Azure Stream Analytics, click [Windowing (Azure Stream Analytics)](https://msdn.microsoft.com/library/azure/dn835019.aspx).\n\n**Real-time prediction**\n\nAn application is included as part of the solution to operationalize the machine learning model in real-time. This application called “RealTimeDashboardApp” is created and configured as part of the solution deployment. The application performs the following:\n\n1.  Listens to an Event Hub instance where Stream Analytics is publishing the events in a continuously pattern. ![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig16-vehicle-telematics-stream-analytics-query-for-publishing.png)*Figure 16 – Stream analytics query for publishing the data to an output Event Hub instance* \n\n2.  For every event that this application receives: \n\n    - Processes the data using Machine Learning Request-Response Scoring (RRS) endpoint. The RRS endpoint is automatically published as part of the deployment.\n    - The RRS output is published to a PowerBI dataset using the push APIs.\n\nThis pattern is also applicable in scenarios where you want to integrate a Line of Business application with the real-time analytics flow for scenarios such as alerts, notifications, messagings, etc. \n\nClick [RealtimeDashboardApp download](http://go.microsoft.com/fwlink/?LinkId=717078) to download the RealtimeDashboardApp Visual Studio solution for customizations. \n\n**To execute the Real-time Dashboard Application **\n\n1.  Click on the PowerBI node on the diagram view and click the Download Real-time Dashboard Application’ link on the properties pane. ![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig17-vehicle-telematics-powerbi-dashboard-setup.png)  *Figure 17 – PowerBI dashboard setup instructions*\n2.  Extract and save locally ![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig18-vehicle-telematics-realtimedashboardapp-folder.png)  *Figure 18 – RealtimeDashboardApp folder*\n3.  Execute the application RealtimeDashboardApp.exe\n4.  Provide valid Power BI credentials, sign in and click Accept ![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig19a-vehicle-telematics-realtimedashboardapp-sign-in-to-powerbi.png) ![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig19b-vehicle-telematics-realtimedashboardapp-sign-in-to-powerbi.png) \n\n*Figure 19 – RealtimeDashboardApp: Sign-in to PowerBI*\n\n>[AZURE.NOTE] Note: If you want to flush the PowerBI dataset, execute the RealtimeDashboardApp with ‘flushdata’ parameter: \n\n    RealtimeDashboardApp.exe -flushdata\n\n### Batch analysis\n\nThe goal here is to showcase how Contoso Motors is utilizing the Azure compute capabilities to harness big data to gain rich insights on driving pattern, usage behavior and vehicle health for:\n\n- Improving the customer experience and make it cheaper by providing insights on driving habits and fuel efficient driving behaviors\n- Learning proactively about customers and their driving patters to govern business decisions and provide the best in class products & services\n\nIn this solution, we are targeting the following metrics:\n\n1.  **Aggressive driving behavior** Identifies the trend of the models, locations, driving conditions, and time of the year to gain insights on aggressive driving pattern allowing Contoso Motors to use it for marketing campaigns, driving new personalized features and usage based insurance.\n2.  **Fuel efficient driving behavior** Identifies the trend of the models, locations, driving conditions, and time of the year to gain insights on fuel efficient driving pattern allowing Contoso Motors to use it for marketing campaigns, driving new features and proactive reporting to the drivers for cost effective and environment friendly driving habits. \n3.  **Recall models** Identifies models requiring recalls by operationalizing the anomaly detection machine learning experiment\n\nLet’s look into the details of each of these metrics,\n\n\n**Aggressive driving pattern**\n\nThe partitioned vehicle signals and diagnostic data are processed in the pipeline named ‘AggresiveDrivingPatternPipeline’ using Hive to determine the models, location, vehicle and driving conditions etc that exhibits aggressive driving pattern.\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig20-vehicle-telematics-aggressive-driving-pattern.png) \n*Figure 20 – Aggressive driving pattern workflow*\n\nThe Hive script named ‘aggresivedriving.hql’ used for analyzing aggressive driving condition pattern is located at ‘\\demo\\src\\connectedcar\\scripts’ folder of the downloaded zip. \n\n    DROP TABLE IF EXISTS PartitionedCarEvents; \n    CREATE EXTERNAL TABLE PartitionedCarEvents\n    (\n                vin                             string,\n                model                           string,\n                timestamp                       string,\n                outsidetemperature              string,\n                enginetemperature               string,\n                speed                           string,\n                fuel                            string,\n                engineoil                       string,\n                tirepressure                    string,\n                odometer                        string,\n                city                            string,\n                accelerator_pedal_position      string,\n                parking_brake_status            string,\n                headlamp_status                 string,\n                brake_pedal_status              string,\n                transmission_gear_position      string,\n                ignition_status                 string,\n                windshield_wiper_status         string,\n                abs                             string,\n                gendate                         string\n                                \n    ) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '10' STORED AS TEXTFILE LOCATION '${hiveconf:PARTITIONEDINPUT}';\n\n    DROP TABLE IF EXISTS CarEventsAggresive; \n    CREATE EXTERNAL TABLE CarEventsAggresive\n    (\n                vin                         string, \n                model                       string,\n                timestamp                   string,\n                city                        string,\n                speed                       string,\n                transmission_gear_position  string,\n                brake_pedal_status          string,\n                Year                        string,\n                Month                       string\n                                \n    ) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '10' STORED AS TEXTFILE LOCATION '${hiveconf:AGGRESIVEOUTPUT}';\n\n\n\n    INSERT OVERWRITE TABLE CarEventsAggresive\n    select\n    vin,\n    model,\n    timestamp,\n    city,\n    speed,\n    transmission_gear_position,\n    brake_pedal_status,\n    \"${hiveconf:Year}\" as Year,\n    \"${hiveconf:Month}\" as Month\n    from PartitionedCarEvents\n    where transmission_gear_position IN ('fourth', 'fifth', 'sixth', 'seventh', 'eight') AND brake_pedal_status = '1' AND speed >= '50'\n\n*Figure 21 – Aggressive driving pattern Hive query*\n\nIt uses the combination of vehicle’s transmission gear position, brake pedal status and speed to detect reckless/aggressive driving behavior based on braking pattern at high speed. \n\nOnce the pipeline is executed successfully, you will see the following partitions generated in your storage account under the ‘connectedcar’ container.\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig22-vehicle-telematics-aggressive-driving-pattern-output.png) \n\n*Figure 22 – AggressiveDrivingPatternPipeline output*\n\n\n**Fuel efficient driving pattern**\n\nThe partitioned vehicle signals and diagnostic data are processed in the pipeline named ‘FuelEfficientDrivingPatternPipeline’ using Hive to determine the models, location, vehicle and driving conditions etc that exhibits fuel efficient driving pattern.\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig23-vehicle-telematics-fuel-efficient-driving-pattern.png) \n\n*Figure 23 – Fuel efficient driving pattern workflow*\n\nThe Hive script named ‘fuelefficientdriving.hql’ used for analyzing aggressive driving condition pattern is located at ‘\\demo\\src\\connectedcar\\scripts’ folder of the downloaded zip. \n\n    DROP TABLE IF EXISTS PartitionedCarEvents; \n    CREATE EXTERNAL TABLE PartitionedCarEvents\n    (\n                vin                             string,\n                model                           string,\n                timestamp                       string,\n                outsidetemperature              string,\n                enginetemperature               string,\n                speed                           string,\n                fuel                            string,\n                engineoil                       string,\n                tirepressure                    string,\n                odometer                        string,\n                city                            string,\n                accelerator_pedal_position      string,\n                parking_brake_status            string,\n                headlamp_status                 string,\n                brake_pedal_status              string,\n                transmission_gear_position      string,\n                ignition_status                 string,\n                windshield_wiper_status         string,\n                abs                             string,\n                gendate                         string\n                                \n    ) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '10' STORED AS TEXTFILE LOCATION '${hiveconf:PARTITIONEDINPUT}';\n\n    DROP TABLE IF EXISTS FuelEfficientDriving; \n    CREATE EXTERNAL TABLE FuelEfficientDriving\n    (\n                vin                         string, \n                model                       string,\n                city                        string,\n                speed                       string,\n                transmission_gear_position  string,                \n                brake_pedal_status          string,            \n                accelerator_pedal_position  string,                             \n                Year                        string,\n                Month                       string\n                                \n    ) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '10' STORED AS TEXTFILE LOCATION '${hiveconf:FUELEFFICIENTOUTPUT}';\n\n\n\n    INSERT OVERWRITE TABLE FuelEfficientDriving\n    select\n    vin,\n    model,\n    city,\n    speed,\n    transmission_gear_position,\n    brake_pedal_status,\n    accelerator_pedal_position,\n    \"${hiveconf:Year}\" as Year,\n    \"${hiveconf:Month}\" as Month\n    from PartitionedCarEvents\n    where transmission_gear_position IN ('fourth', 'fifth', 'sixth', 'seventh', 'eight') AND parking_brake_status = '0' AND brake_pedal_status = '0' AND speed <= '60' AND accelerator_pedal_position >= '50'\n\n\n*Figure 24 – Fuel efficient driving pattern Hive query*\n\nIt uses the combination of vehicle’s transmission gear position, brake pedal status, speed and accelerator pedal position to detect fuel efficient driving behavior based on acceleration, braking and speed patterns. \n\nOnce the pipeline is executed successfully, you will see the following partitions generated in your storage account under the ‘connectedcar’ container.\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig25-vehicle-telematics-fuel-efficient-driving-pattern-output.png) \n\n*Figure 25 – FuelEfficientDrivingPatternPipeline output*\n\n\n**Recall Predictions**\n\nThe machine learning experiment is provisioned and published as a web service as part of the solution deployment. The batch scoring end point is leveraged in this workflow, registered as a data factory linked service and operationalized using data factory batch scoring activity.\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig26-vehicle-telematics-machine-learning-endpoint.png) \n\n*Figure 26 – Machine learning endpoint registered as a linked service in data factory*\n\nThe registered linked service is used in the DetectAnomalyPipeline to score the data using the anomaly detection model. \n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig27-vehicle-telematics-aml-batch-scoring.png) \n\n*Figure 27 – Azure Machine Learning Batch Scoring activity in data factory* \n\nThere are few steps performed in this pipeline for data preparation so that it can be operationalized with the batch scoring web service. \n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig28-vehicle-telematics-pipeline-predicting-recalls.png) \n\n*Figure 28 – DetectAnomalyPipeline for predicting vehicles requiring recalls* \n\nOnce the scoring is completed, an HDInsight activity is used to process and aggregate the data that are categorized as anomalies by the model with a probability score of 0.60 or higher.  \n\n    DROP TABLE IF EXISTS CarEventsAnomaly; \n    CREATE EXTERNAL TABLE CarEventsAnomaly \n    (\n                vin                         string,\n                model                       string,\n                gendate                     string,\n                outsidetemperature          string,\n                enginetemperature           string,\n                speed                       string,\n                fuel                        string,\n                engineoil                   string,\n                tirepressure                string,\n                odometer                    string,\n                city                        string,\n                accelerator_pedal_position  string,\n                parking_brake_status        string,\n                headlamp_status             string,\n                brake_pedal_status          string,\n                transmission_gear_position  string,\n                ignition_status             string,\n                windshield_wiper_status     string,\n                abs                         string,\n                maintenanceLabel            string,\n                maintenanceProbability      string,\n                RecallLabel                 string,\n                RecallProbability           string\n                                \n    ) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '10' STORED AS TEXTFILE LOCATION '${hiveconf:ANOMALYOUTPUT}';\n\n    DROP TABLE IF EXISTS RecallModel; \n    CREATE EXTERNAL TABLE RecallModel \n    (\n\n                vin                         string,\n                model                       string,\n                city                        string,\n                outsidetemperature          string,\n                enginetemperature           string,\n                speed                       string,\n                Year                        string,\n                Month                       string              \n                                \n    ) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '10' STORED AS TEXTFILE LOCATION '${hiveconf:RECALLMODELOUTPUT}';\n\n    INSERT OVERWRITE TABLE RecallModel\n    select\n    vin,\n    model,\n    city,\n    outsidetemperature,\n    enginetemperature,\n    speed,\n    \"${hiveconf:Year}\" as Year,\n    \"${hiveconf:Month}\" as Month\n    from CarEventsAnomaly\n    where RecallLabel = '1' AND RecallProbability >= '0.60'\n\n*Figure 29  – Recall aggregation hive query*\n\nOnce the pipeline is executed successfully, you will see the following partitions generated in your storage account under the ‘connectedcar’ container.\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig30-vehicle-telematics-detect-anamoly-pipeline-output.png) \n\n*Figure 30 – Figure 30 – DetectAnomalyPipeline output*\n\n\n## Publish\n\n### Real-time analysis\n\nOne of the queries in the stream analytics job publishes the events to an output Event Hub instance. \n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig31-vehicle-telematics-stream-analytics-job-publishes-output-event-hub.png)\n\n*Figure 31 – Stream analytics job publishes to an output Event Hub instance*\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig32-vehicle-telematics-stream-analytics-query-publish-output-event-hub.png)\n\n*Figure 32 – Stream analytics query to publish to the output Event Hub instance*\n\nThis stream of events are consumed by the RealTimeDashboardApp included in the solution. This application leverages the Machine Learning Request-Response web service for real-time scoring and publishes the resultant data to a PowerBI dataset for consumption. \n\n### Batch analysis\n\nThe results of the batch and real-time processing are published to the Azure SQL Database tables for consumption. The Azure SQL Server, Database and the tables are created automatically as part of the setup script. \n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig33-vehicle-telematics-batch-processing-results-copy-to-data-mart.png)\n\n*Figure 33 – Batch processing results copy to data mart workflow*\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig34-vehicle-telematics-stream-analytics-job-publishes-to-data-mart.png)\n\n*Figure 34 – Stream analytics job publishes to data mart*\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig35-vehicle-telematics-data-mart-setting-in-stream-analytics-job.png)\n\n*Figure 35 – Data mart setting in stream analytics job*\n\n\n## Consume\n\nPower BI gives this solution a rich dashboard for real-time data and predictive analytics visualizations. \n\nClick here for detailed instructions on setting up the PowerBI reports and the dashboard. The final dashboard looks like this:\n\n![](./media/cortana-analytics-playbook-vehicle-telemetry-deep-dive/fig36-vehicle-telematics-powerbi-dashboard.png)\n\n*Figure 36 - PowerBI Dashboard*\n\n## Summary\n\nThis document contains a detailed drill-down of the Vehicle Telemetry Analytics Solution. This showcases a lambda architecture pattern for real-time and batch analytics with predictions and actions. This pattern applies to a wide range of use cases that require hot path (real-time) and cold path (batch) analytics. \n"
}