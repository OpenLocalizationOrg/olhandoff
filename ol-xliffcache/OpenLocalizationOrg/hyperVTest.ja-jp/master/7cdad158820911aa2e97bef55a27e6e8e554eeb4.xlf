<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="ja-jp">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Get started with a Hadoop emulator for HDInsight | Microsoft Azure</source>
          <target state="new">Get started with a Hadoop emulator for HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Use an installed emulator with a MapReduce tutorial and other samples to learn the Hadoop ecosystem.</source>
          <target state="new">Use an installed emulator with a MapReduce tutorial and other samples to learn the Hadoop ecosystem.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>HDInsight emulator works like a Hadoop sandbox.</source>
          <target state="new">HDInsight emulator works like a Hadoop sandbox.</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Get started in the Hadoop ecosystem with the HDInsight Emulator, a Hadoop sandbox</source>
          <target state="new">Get started in the Hadoop ecosystem with the HDInsight Emulator, a Hadoop sandbox</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>This tutorial gets you started with Hadoop clusters in the Microsoft HDInsight Emulator for Azure (formerly HDInsight Server Developer Preview).</source>
          <target state="new">This tutorial gets you started with Hadoop clusters in the Microsoft HDInsight Emulator for Azure (formerly HDInsight Server Developer Preview).</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>The HDInsight Emulator comes with the same components from the Hadoop ecosystem as Azure HDInsight.</source>
          <target state="new">The HDInsight Emulator comes with the same components from the Hadoop ecosystem as Azure HDInsight.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>For details, including information on the versions deployed, see <bpt id="p1">[</bpt>What version of Hadoop is in Azure HDInsight?<ept id="p1">](hdinsight-component-versioning.md)</ept>.</source>
          <target state="new">For details, including information on the versions deployed, see <bpt id="p1">[</bpt>What version of Hadoop is in Azure HDInsight?<ept id="p1">](hdinsight-component-versioning.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Once the emulator is installed, you follow a MapReduce tutorial for word count and then run samples.</source>
          <target state="new">Once the emulator is installed, you follow a MapReduce tutorial for word count and then run samples.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source><ph id="ph2">[AZURE.NOTE]</ph><ph id="ph3" /> The HDInsight Emulator includes only a Hadoop cluster.</source>
          <target state="new"><ph id="ph2">[AZURE.NOTE]</ph><ph id="ph3" /> The HDInsight Emulator includes only a Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>It does not include HBase or Storm.</source>
          <target state="new">It does not include HBase or Storm.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>The HDInsight Emulator provides a local development environment much like a Hadoop sandbox.</source>
          <target state="new">The HDInsight Emulator provides a local development environment much like a Hadoop sandbox.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>If you are familiar with Hadoop, you can get started with the HDInsight Emulator by using the Hadoop Distributed File System (HDFS).</source>
          <target state="new">If you are familiar with Hadoop, you can get started with the HDInsight Emulator by using the Hadoop Distributed File System (HDFS).</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>In HDInsight, the default file system is Azure Blob storage.</source>
          <target state="new">In HDInsight, the default file system is Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>So eventually, you will want to develop your jobs by using Azure Blob storage.</source>
          <target state="new">So eventually, you will want to develop your jobs by using Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>To use Azure Blob storage with the HDInsight Emulator, you must make changes to the configuration of the emulator.</source>
          <target state="new">To use Azure Blob storage with the HDInsight Emulator, you must make changes to the configuration of the emulator.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source><ph id="ph4">[AZURE.NOTE]</ph><ph id="ph5" /> The HDInsight Emulator can use only a single node deployment.</source>
          <target state="new"><ph id="ph4">[AZURE.NOTE]</ph><ph id="ph5" /> The HDInsight Emulator can use only a single node deployment.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Prerequisites</source>
          <target state="new">Prerequisites</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Before you begin this tutorial, you must have the following:</source>
          <target state="new">Before you begin this tutorial, you must have the following:</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>The HDInsight Emulator requires a 64-bit version of Windows.</source>
          <target state="new">The HDInsight Emulator requires a 64-bit version of Windows.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>One of the following requirements must be satisfied:</source>
          <target state="new">One of the following requirements must be satisfied:</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Windows 10</source>
          <target state="new">Windows 10</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Windows 8</source>
          <target state="new">Windows 8</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Windows Server 2012</source>
          <target state="new">Windows Server 2012</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source><bpt id="p2">**</bpt>Azure PowerShell<ept id="p2">**</ept>.</source>
          <target state="new"><bpt id="p2">**</bpt>Azure PowerShell<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>See <bpt id="p3">[</bpt>Install and use Azure PowerShell<ept id="p3">](https://azure.microsoft.com/documentation/videos/install-and-use-azure-powershell/)</ept>.</source>
          <target state="new">See <bpt id="p3">[</bpt>Install and use Azure PowerShell<ept id="p3">](https://azure.microsoft.com/documentation/videos/install-and-use-azure-powershell/)</ept>.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Install the HDInsight Emulator</source>
          <target state="new">Install the HDInsight Emulator</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>The Microsoft HDInsight Emulator is installable via the Microsoft Web Platform Installer.</source>
          <target state="new">The Microsoft HDInsight Emulator is installable via the Microsoft Web Platform Installer.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source><ph id="ph6">[AZURE.NOTE]</ph><ph id="ph7" /> The HDInsight Emulator currently supports only English operating systems.</source>
          <target state="new"><ph id="ph6">[AZURE.NOTE]</ph><ph id="ph7" /> The HDInsight Emulator currently supports only English operating systems.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>If you have a previous version of the emulator installed, you must uninstall the following two components from Control Panel/Programs and Features before installing the latest version of the emulator:</source>
          <target state="new">If you have a previous version of the emulator installed, you must uninstall the following two components from Control Panel/Programs and Features before installing the latest version of the emulator:</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Microsoft HDInsight Emulator for Azure or HDInsight Developer Preview, whichever is installed</source>
          <target state="new">Microsoft HDInsight Emulator for Azure or HDInsight Developer Preview, whichever is installed</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Hortonworks Data Platform</source>
          <target state="new">Hortonworks Data Platform</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source><bpt id="p4">**</bpt>To install the HDInsight Emulator<ept id="p4">**</ept></source>
          <target state="new"><bpt id="p4">**</bpt>To install the HDInsight Emulator<ept id="p4">**</ept></target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Open Internet Explorer, and then browse to the <bpt id="p5">[</bpt>Microsoft HDInsight Emulator for Azure installation page<ept id="p5">][hdinsight-emulator-install]</ept>.</source>
          <target state="new">Open Internet Explorer, and then browse to the <bpt id="p5">[</bpt>Microsoft HDInsight Emulator for Azure installation page<ept id="p5">][hdinsight-emulator-install]</ept>.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p6">**</bpt>Install Now<ept id="p6">**</ept>.</source>
          <target state="new">Click <bpt id="p6">**</bpt>Install Now<ept id="p6">**</ept>.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p7">**</bpt>Run<ept id="p7">**</ept><ph id="ph8" /> when prompted for the installation of HDINSIGHT.exe at the bottom of the page.</source>
          <target state="new">Click <bpt id="p7">**</bpt>Run<ept id="p7">**</ept><ph id="ph8" /> when prompted for the installation of HDINSIGHT.exe at the bottom of the page.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Click the <bpt id="p8">**</bpt>Yes<ept id="p8">**</ept><ph id="ph9" /> button in the <bpt id="p9">**</bpt>User Account Control<ept id="p9">**</ept><ph id="ph10" /> window that pops up to complete the installation.</source>
          <target state="new">Click the <bpt id="p8">**</bpt>Yes<ept id="p8">**</ept><ph id="ph9" /> button in the <bpt id="p9">**</bpt>User Account Control<ept id="p9">**</ept><ph id="ph10" /> window that pops up to complete the installation.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>The Web Platform Installer window appears.</source>
          <target state="new">The Web Platform Installer window appears.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p10">**</bpt>Install<ept id="p10">**</ept><ph id="ph11" /> on the bottom of the page.</source>
          <target state="new">Click <bpt id="p10">**</bpt>Install<ept id="p10">**</ept><ph id="ph11" /> on the bottom of the page.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p11">**</bpt>I Accept<ept id="p11">**</ept><ph id="ph12" /> to agree to the licensing terms.</source>
          <target state="new">Click <bpt id="p11">**</bpt>I Accept<ept id="p11">**</ept><ph id="ph12" /> to agree to the licensing terms.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Verify that the Web Platform Installer shows <bpt id="p12">**</bpt>The following products were successfully installed<ept id="p12">**</ept>, and then click <bpt id="p13">**</bpt>Finish<ept id="p13">**</ept>.</source>
          <target state="new">Verify that the Web Platform Installer shows <bpt id="p12">**</bpt>The following products were successfully installed<ept id="p12">**</ept>, and then click <bpt id="p13">**</bpt>Finish<ept id="p13">**</ept>.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p14">**</bpt>Exit<ept id="p14">**</ept><ph id="ph13" /> to close the Web Platform Installer window.</source>
          <target state="new">Click <bpt id="p14">**</bpt>Exit<ept id="p14">**</ept><ph id="ph13" /> to close the Web Platform Installer window.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source><bpt id="p15">**</bpt>To verify the HDInsight Emulator installation<ept id="p15">**</ept></source>
          <target state="new"><bpt id="p15">**</bpt>To verify the HDInsight Emulator installation<ept id="p15">**</ept></target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>The installation should have installed three icons on your desktop.</source>
          <target state="new">The installation should have installed three icons on your desktop.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>The three icons are linked as follows:</source>
          <target state="new">The three icons are linked as follows:</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source><bpt id="p16">**</bpt>Hadoop Command Line<ept id="p16">**</ept><ph id="ph14" /> - The Hadoop command prompt from which MapReduce, Pig and Hive jobs are run in the HDInsight Emulator.</source>
          <target state="new"><bpt id="p16">**</bpt>Hadoop Command Line<ept id="p16">**</ept><ph id="ph14" /> - The Hadoop command prompt from which MapReduce, Pig and Hive jobs are run in the HDInsight Emulator.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source><bpt id="p17">**</bpt>Hadoop NameNode Status<ept id="p17">**</ept><ph id="ph15" /> - The NameNode maintains a tree-based directory for all the files in HDFS.</source>
          <target state="new"><bpt id="p17">**</bpt>Hadoop NameNode Status<ept id="p17">**</ept><ph id="ph15" /> - The NameNode maintains a tree-based directory for all the files in HDFS.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>It also keeps track of where the data for all the files are kept in a Hadoop cluster.</source>
          <target state="new">It also keeps track of where the data for all the files are kept in a Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Clients communicate with the NameNode in order to figure out where the data nodes for all the files are stored.</source>
          <target state="new">Clients communicate with the NameNode in order to figure out where the data nodes for all the files are stored.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source><bpt id="p18">**</bpt>Hadoop Yarn Status<ept id="p18">**</ept><ph id="ph16" /> - The job tracker that allocates MapReduce tasks to nodes in a cluster.</source>
          <target state="new"><bpt id="p18">**</bpt>Hadoop Yarn Status<ept id="p18">**</ept><ph id="ph16" /> - The job tracker that allocates MapReduce tasks to nodes in a cluster.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>The installation should have also installed several local services.</source>
          <target state="new">The installation should have also installed several local services.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>The following is a screenshot of the Services window:</source>
          <target state="new">The following is a screenshot of the Services window:</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source><ph id="ph17">![</ph>Hadoop ecosystem services listed in the emulator window.<ph id="ph18">][image-hdi-emulator-services]</ph></source>
          <target state="new"><ph id="ph17">![</ph>Hadoop ecosystem services listed in the emulator window.<ph id="ph18">][image-hdi-emulator-services]</ph></target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>The services related to the HDInsight Emulator are not started by default.</source>
          <target state="new">The services related to the HDInsight Emulator are not started by default.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>To start the services, from the Hadoop command line, run <bpt id="p19">**</bpt>start\_local\_hdp_services.cmd<ept id="p19">**</ept><ph id="ph19" /> under C:\hdp (default location).</source>
          <target state="new">To start the services, from the Hadoop command line, run <bpt id="p19">**</bpt>start\_local\_hdp_services.cmd<ept id="p19">**</ept><ph id="ph19" /> under C:\hdp (default location).</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>To automatically start the services after the computer restarts, run <bpt id="p20">**</bpt>set-onebox-autostart.cmd<ept id="p20">**</ept>.</source>
          <target state="new">To automatically start the services after the computer restarts, run <bpt id="p20">**</bpt>set-onebox-autostart.cmd<ept id="p20">**</ept>.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>For known issues with installing and running the HDInsight Emulator, see the <bpt id="p21">[</bpt>HDInsight Emulator Release Notes<ept id="p21">](hdinsight-emulator-release-notes.md)</ept>.</source>
          <target state="new">For known issues with installing and running the HDInsight Emulator, see the <bpt id="p21">[</bpt>HDInsight Emulator Release Notes<ept id="p21">](hdinsight-emulator-release-notes.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>The installation log is located at <bpt id="p22">**</bpt>C:\HadoopFeaturePackSetup\HadoopFeaturePackSetupTools\gettingStarted.winpkg.install.log<ept id="p22">**</ept>.</source>
          <target state="new">The installation log is located at <bpt id="p22">**</bpt>C:\HadoopFeaturePackSetup\HadoopFeaturePackSetupTools\gettingStarted.winpkg.install.log<ept id="p22">**</ept>.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Use Emulator with HDInsight Tools for Visual Studio</source>
          <target state="new">Use Emulator with HDInsight Tools for Visual Studio</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>You can use HDInsight tools for Visual Studio to connect to the HDInsight Emulator.</source>
          <target state="new">You can use HDInsight tools for Visual Studio to connect to the HDInsight Emulator.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>For information on how to use the Visual Studio tools with HDInsight clusters on Azure, see <bpt id="p23">[</bpt>Get started using HDInsight Hadoop Tools for Visual Studio<ept id="p23">](../HDInsight/hdinsight-hadoop-visual-studio-tools-get-started.md)</ept>.</source>
          <target state="new">For information on how to use the Visual Studio tools with HDInsight clusters on Azure, see <bpt id="p23">[</bpt>Get started using HDInsight Hadoop Tools for Visual Studio<ept id="p23">](../HDInsight/hdinsight-hadoop-visual-studio-tools-get-started.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Install the HDInsight tools for Emulator</source>
          <target state="new">Install the HDInsight tools for Emulator</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>For instructions on how to install the HDInsight Visual Studio tools, see <bpt id="p24">[</bpt>here<ept id="p24">](../HDInsight/hdinsight-hadoop-visual-studio-tools-get-started.md#installation)</ept>.</source>
          <target state="new">For instructions on how to install the HDInsight Visual Studio tools, see <bpt id="p24">[</bpt>here<ept id="p24">](../HDInsight/hdinsight-hadoop-visual-studio-tools-get-started.md#installation)</ept>.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Connect to the HDInsight Emulator</source>
          <target state="new">Connect to the HDInsight Emulator</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Open Visual Studio.</source>
          <target state="new">Open Visual Studio.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>From the <bpt id="p25">**</bpt>View<ept id="p25">**</ept><ph id="ph20" /> menu, click <bpt id="p26">**</bpt>Server Explorer<ept id="p26">**</ept><ph id="ph21" /> to open the Server Explorer window.</source>
          <target state="new">From the <bpt id="p25">**</bpt>View<ept id="p25">**</ept><ph id="ph20" /> menu, click <bpt id="p26">**</bpt>Server Explorer<ept id="p26">**</ept><ph id="ph21" /> to open the Server Explorer window.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Expand <bpt id="p27">**</bpt>Azure<ept id="p27">**</ept>, right-click <bpt id="p28">**</bpt>HDInsight<ept id="p28">**</ept>, and then click <bpt id="p29">**</bpt>Connect to HDInsight Emulator<ept id="p29">**</ept>.</source>
          <target state="new">Expand <bpt id="p27">**</bpt>Azure<ept id="p27">**</ept>, right-click <bpt id="p28">**</bpt>HDInsight<ept id="p28">**</ept>, and then click <bpt id="p29">**</bpt>Connect to HDInsight Emulator<ept id="p29">**</ept>.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source><ph id="ph22">![</ph>Visual Studio view: Connect to HDInsight emulator on menu.<ph id="ph23">](./media/hdinsight-hadoop-emulator-get-started/hdi.emulator.connect.vs.png)</ph></source>
          <target state="new"><ph id="ph22">![</ph>Visual Studio view: Connect to HDInsight emulator on menu.<ph id="ph23">](./media/hdinsight-hadoop-emulator-get-started/hdi.emulator.connect.vs.png)</ph></target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>In the Connect to HDInsight Emulator dialog box, verify the values for WebHCat, HiveServer2, and WebHDFS endpoints, and then click <bpt id="p30">**</bpt>Next<ept id="p30">**</ept>.</source>
          <target state="new">In the Connect to HDInsight Emulator dialog box, verify the values for WebHCat, HiveServer2, and WebHDFS endpoints, and then click <bpt id="p30">**</bpt>Next<ept id="p30">**</ept>.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>The values populated by default should work if you did not make any changes to the default configuration of the Emulator.</source>
          <target state="new">The values populated by default should work if you did not make any changes to the default configuration of the Emulator.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>If you made any changes, update the values in the dialog box and then click Next.</source>
          <target state="new">If you made any changes, update the values in the dialog box and then click Next.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source><ph id="ph24">![</ph>Connect to HDInsight emulator dialog box with settings.<ph id="ph25">](./media/hdinsight-hadoop-emulator-get-started/hdi.emulator.connect.vs.dialog.png)</ph></source>
          <target state="new"><ph id="ph24">![</ph>Connect to HDInsight emulator dialog box with settings.<ph id="ph25">](./media/hdinsight-hadoop-emulator-get-started/hdi.emulator.connect.vs.dialog.png)</ph></target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>Once the connection is successfully established, click <bpt id="p31">**</bpt>Finish<ept id="p31">**</ept>.</source>
          <target state="new">Once the connection is successfully established, click <bpt id="p31">**</bpt>Finish<ept id="p31">**</ept>.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>You should now see the HDInsight Emulator in the Server Explorer.</source>
          <target state="new">You should now see the HDInsight Emulator in the Server Explorer.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source><ph id="ph26">![</ph>Server Explorer showing HDInsight local emulator - a Hadoop sanbox - connected.<ph id="ph27">](./media/hdinsight-hadoop-emulator-get-started/hdi.emulator.vs.connected.png)</ph></source>
          <target state="new"><ph id="ph26">![</ph>Server Explorer showing HDInsight local emulator - a Hadoop sanbox - connected.<ph id="ph27">](./media/hdinsight-hadoop-emulator-get-started/hdi.emulator.vs.connected.png)</ph></target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>Once the connection is successfully established, you can use the HDInsight VS tools with Emulator, just like you would use it with an Azure HDInsight cluster.</source>
          <target state="new">Once the connection is successfully established, you can use the HDInsight VS tools with Emulator, just like you would use it with an Azure HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>For instructions on how to use VS tools with Azure HDInsight clusters, see <bpt id="p32">[</bpt>Using HDInsight Hadoop Tools for Visual Studio<ept id="p32">](../HDInsight/hdinsight-hadoop-visual-studio-tools-get-started.md)</ept>.</source>
          <target state="new">For instructions on how to use VS tools with Azure HDInsight clusters, see <bpt id="p32">[</bpt>Using HDInsight Hadoop Tools for Visual Studio<ept id="p32">](../HDInsight/hdinsight-hadoop-visual-studio-tools-get-started.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>Troubleshoot: Connecting HDInsight Tools to the HDInsight Emulator</source>
          <target state="new">Troubleshoot: Connecting HDInsight Tools to the HDInsight Emulator</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>While connecting to the HDInsight Emulator, even though the dialog box shows that HiveServer2 connected successfully, you must manually set <bpt id="p33">**</bpt>hive.security.authorization.enabled property<ept id="p33">**</ept><ph id="ph28" /> to <bpt id="p34">**</bpt>false<ept id="p34">**</ept><ph id="ph29" /> in the Hive configuration file at C:\hdp\hive-<bpt id="p35">*</bpt>version<ept id="p35">*</ept>\conf\hive-site.xml, and then restart the local Emulator.</source>
          <target state="new">While connecting to the HDInsight Emulator, even though the dialog box shows that HiveServer2 connected successfully, you must manually set <bpt id="p33">**</bpt>hive.security.authorization.enabled property<ept id="p33">**</ept><ph id="ph28" /> to <bpt id="p34">**</bpt>false<ept id="p34">**</ept><ph id="ph29" /> in the Hive configuration file at C:\hdp\hive-<bpt id="p35">*</bpt>version<ept id="p35">*</ept>\conf\hive-site.xml, and then restart the local Emulator.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>HDInsight Tools for Visual Studio connects to HiveServer2 only when you are previewing the top 100 rows of your table.</source>
          <target state="new">HDInsight Tools for Visual Studio connects to HiveServer2 only when you are previewing the top 100 rows of your table.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>If you do not intend to use such a query, you can leave hive configuration as-is.</source>
          <target state="new">If you do not intend to use such a query, you can leave hive configuration as-is.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>If you are using dynamic IP allocation (DHCP) on the computer running the HDInsight Emulator, you might need to update C:\hdp\hadoop-<bpt id="p36">*</bpt>version<ept id="p36">*</ept>\etc\hadoop\core-site.xml and change the value of property <bpt id="p37">**</bpt>hadoop.proxyuser.hadoop.hosts<ept id="p37">**</ept><ph id="ph30" /> to (*).</source>
          <target state="new">If you are using dynamic IP allocation (DHCP) on the computer running the HDInsight Emulator, you might need to update C:\hdp\hadoop-<bpt id="p36">*</bpt>version<ept id="p36">*</ept>\etc\hadoop\core-site.xml and change the value of property <bpt id="p37">**</bpt>hadoop.proxyuser.hadoop.hosts<ept id="p37">**</ept><ph id="ph30" /> to (*).</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>This enables Hadoop user to connect from all hosts to impersonate the user you entered in Visual Studio.</source>
          <target state="new">This enables Hadoop user to connect from all hosts to impersonate the user you entered in Visual Studio.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>You might get an error when Visual Studio tries to connect to WebHCat service (“error”: “Could not find job job_XXXX_0001”).</source>
          <target state="new">You might get an error when Visual Studio tries to connect to WebHCat service (“error”: “Could not find job job_XXXX_0001”).</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>In this case, you must restart the WebHCat service and try again.</source>
          <target state="new">In this case, you must restart the WebHCat service and try again.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>To restart the WebHCat service, start the <bpt id="p38">**</bpt>Services<ept id="p38">**</ept><ph id="ph31" /> MMC, right-click <bpt id="p39">**</bpt>Apache Hadoop Templeton<ept id="p39">**</ept><ph id="ph32" /> (this is the old name for WebHCat service), and click <bpt id="p40">**</bpt>Restart<ept id="p40">**</ept>.</source>
          <target state="new">To restart the WebHCat service, start the <bpt id="p38">**</bpt>Services<ept id="p38">**</ept><ph id="ph31" /> MMC, right-click <bpt id="p39">**</bpt>Apache Hadoop Templeton<ept id="p39">**</ept><ph id="ph32" /> (this is the old name for WebHCat service), and click <bpt id="p40">**</bpt>Restart<ept id="p40">**</ept>.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>A word-count MapReduce tutorial</source>
          <target state="new">A word-count MapReduce tutorial</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>Now that you have the HDInsight Emulator configured on your workstation, try this MapReduce tutorial to test the installation.</source>
          <target state="new">Now that you have the HDInsight Emulator configured on your workstation, try this MapReduce tutorial to test the installation.</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>You will first upload some data files to HDFS, and then run a word count MapReduce job to count the frequency of specific words in those files.</source>
          <target state="new">You will first upload some data files to HDFS, and then run a word count MapReduce job to count the frequency of specific words in those files.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>The word-counting MapReduce program has been packaged into <bpt id="p41">*</bpt>hadoop-mapreduce-examples-2.4.0.2.1.3.0-1981.jar<ept id="p41">*</ept>.</source>
          <target state="new">The word-counting MapReduce program has been packaged into <bpt id="p41">*</bpt>hadoop-mapreduce-examples-2.4.0.2.1.3.0-1981.jar<ept id="p41">*</ept>.</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>The jar file is located at the <bpt id="p42">*</bpt>C:\hdp\hadoop-2.4.0.2.1.3.0-1981\share\hadoop\mapreduce<ept id="p42">*</ept><ph id="ph33" /> folder.</source>
          <target state="new">The jar file is located at the <bpt id="p42">*</bpt>C:\hdp\hadoop-2.4.0.2.1.3.0-1981\share\hadoop\mapreduce<ept id="p42">*</ept><ph id="ph33" /> folder.</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>The MapReduce job to count words takes two arguments:</source>
          <target state="new">The MapReduce job to count words takes two arguments:</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>An input folder.</source>
          <target state="new">An input folder.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>You will use <bpt id="p43">*</bpt>hdfs://localhost/user/HDIUser<ept id="p43">*</ept><ph id="ph34" /> as the input folder.</source>
          <target state="new">You will use <bpt id="p43">*</bpt>hdfs://localhost/user/HDIUser<ept id="p43">*</ept><ph id="ph34" /> as the input folder.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>An output folder.</source>
          <target state="new">An output folder.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>You will use <bpt id="p44">*</bpt>hdfs://localhost/user/HDIUser/WordCount_Output<ept id="p44">*</ept><ph id="ph35" /> as the output folder.</source>
          <target state="new">You will use <bpt id="p44">*</bpt>hdfs://localhost/user/HDIUser/WordCount_Output<ept id="p44">*</ept><ph id="ph35" /> as the output folder.</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>The output folder cannot be an existing folder, or the MapReduce job will fail.</source>
          <target state="new">The output folder cannot be an existing folder, or the MapReduce job will fail.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>If you want to run the MapReduce job for the second time, you must either specify a different output folder or delete the existing output folder.</source>
          <target state="new">If you want to run the MapReduce job for the second time, you must either specify a different output folder or delete the existing output folder.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source><bpt id="p45">**</bpt>To run the word-count MapReduce job<ept id="p45">**</ept></source>
          <target state="new"><bpt id="p45">**</bpt>To run the word-count MapReduce job<ept id="p45">**</ept></target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>From the desktop, double-click <bpt id="p46">**</bpt>Hadoop Command Line<ept id="p46">**</ept><ph id="ph36" /> to open the Hadoop command-line window.</source>
          <target state="new">From the desktop, double-click <bpt id="p46">**</bpt>Hadoop Command Line<ept id="p46">**</ept><ph id="ph36" /> to open the Hadoop command-line window.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>The current folder should be:</source>
          <target state="new">The current folder should be:</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>If not, run the following command:</source>
          <target state="new">If not, run the following command:</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>Run the following Hadoop commands to make an HDFS folder for storing the input and output files:</source>
          <target state="new">Run the following Hadoop commands to make an HDFS folder for storing the input and output files:</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>Run the following Hadoop command to copy some local text files to HDFS:</source>
          <target state="new">Run the following Hadoop command to copy some local text files to HDFS:</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>Run the following command to list the files in the /user/HDIUser folder:</source>
          <target state="new">Run the following command to list the files in the /user/HDIUser folder:</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>You should see the following files:</source>
          <target state="new">You should see the following files:</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>Run the following command to run the word-count MapReduce job:</source>
          <target state="new">Run the following command to run the word-count MapReduce job:</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>Run the following command to list the number of words with "windows" in them from the output file:</source>
          <target state="new">Run the following command to list the number of words with "windows" in them from the output file:</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>The output should be:</source>
          <target state="new">The output should be:</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>For more information on Hadoop commands, see <bpt id="p47">[</bpt>Hadoop commands manual<ept id="p47">][hadoop-commands-manual]</ept>.</source>
          <target state="new">For more information on Hadoop commands, see <bpt id="p47">[</bpt>Hadoop commands manual<ept id="p47">][hadoop-commands-manual]</ept>.</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>Analyze sample web log data</source>
          <target state="new">Analyze sample web log data</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>The HDInsight Emulator installation provides some samples to get users started with learning Apache Hadoop-based services on Windows.</source>
          <target state="new">The HDInsight Emulator installation provides some samples to get users started with learning Apache Hadoop-based services on Windows.</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>These samples cover some tasks that are typically needed when processing a big dataset.</source>
          <target state="new">These samples cover some tasks that are typically needed when processing a big dataset.</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>Building on the MapReduce tutorial above, the the samples will help you become more familiar with the MapReduce programming model and its ecosystem.</source>
          <target state="new">Building on the MapReduce tutorial above, the the samples will help you become more familiar with the MapReduce programming model and its ecosystem.</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>The sample data is organized around processing IIS World Wide Web Consortium (W3C) log data.</source>
          <target state="new">The sample data is organized around processing IIS World Wide Web Consortium (W3C) log data.</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>A data generation tool is provided to create and import the datasets in various sizes to HDFS or Azure Blob storage.</source>
          <target state="new">A data generation tool is provided to create and import the datasets in various sizes to HDFS or Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>(See <bpt id="p48">[</bpt>Use Azure Blob storage for HDInsight<ept id="p48">](hdinsight-hadoop-use-blob-storage.md)</ept><ph id="ph37" /> for more information).</source>
          <target state="new">(See <bpt id="p48">[</bpt>Use Azure Blob storage for HDInsight<ept id="p48">](hdinsight-hadoop-use-blob-storage.md)</ept><ph id="ph37" /> for more information).</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>MapReduce, Pig, or Hive jobs can then be run on the pages of data generated by the Azure PowerShell script.</source>
          <target state="new">MapReduce, Pig, or Hive jobs can then be run on the pages of data generated by the Azure PowerShell script.</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>Pig and Hive scripts are a layer of abstraction over MapReduce, and eventually compile to MapReduce programs.</source>
          <target state="new">Pig and Hive scripts are a layer of abstraction over MapReduce, and eventually compile to MapReduce programs.</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>You can run a series of jobs to observe the effects of using these different technologies and how the data size affects the execution of the processing tasks.</source>
          <target state="new">You can run a series of jobs to observe the effects of using these different technologies and how the data size affects the execution of the processing tasks.</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>In this section</source>
          <target state="new">In this section</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source><bpt id="p49">[</bpt>The IIS W3C log-data scenario<ept id="p49">](#scenarios)</ept></source>
          <target state="new"><bpt id="p49">[</bpt>The IIS W3C log-data scenario<ept id="p49">](#scenarios)</ept></target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source><bpt id="p50">[</bpt>Load sample W3C log data<ept id="p50">](#loaddata)</ept></source>
          <target state="new"><bpt id="p50">[</bpt>Load sample W3C log data<ept id="p50">](#loaddata)</ept></target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source><bpt id="p51">[</bpt>Run Java MapReduce job<ept id="p51">](#javamapreduce)</ept></source>
          <target state="new"><bpt id="p51">[</bpt>Run Java MapReduce job<ept id="p51">](#javamapreduce)</ept></target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source><bpt id="p52">[</bpt>Run Hive job<ept id="p52">](#hive)</ept></source>
          <target state="new"><bpt id="p52">[</bpt>Run Hive job<ept id="p52">](#hive)</ept></target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source><bpt id="p53">[</bpt>Run Pig job<ept id="p53">](#pig)</ept></source>
          <target state="new"><bpt id="p53">[</bpt>Run Pig job<ept id="p53">](#pig)</ept></target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source><bpt id="p54">[</bpt>Rebuild the samples<ept id="p54">](#rebuild)</ept></source>
          <target state="new"><bpt id="p54">[</bpt>Rebuild the samples<ept id="p54">](#rebuild)</ept></target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>The IIS W3C log-data scenarios</source>
          <target state="new">The IIS W3C log-data scenarios</target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>The W3C scenario generates and imports IIS W3C log data in three sizes into HDFS or Azure Blob storage: 1MB (small), 500MB (medium), and 2GB (large).</source>
          <target state="new">The W3C scenario generates and imports IIS W3C log data in three sizes into HDFS or Azure Blob storage: 1MB (small), 500MB (medium), and 2GB (large).</target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>It provides three job types and implements each of them in C#, Java, Pig and Hive.</source>
          <target state="new">It provides three job types and implements each of them in C#, Java, Pig and Hive.</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source><bpt id="p55">**</bpt>totalhits<ept id="p55">**</ept><ph id="ph38" /> - Calculates the total number of requests for a given page.</source>
          <target state="new"><bpt id="p55">**</bpt>totalhits<ept id="p55">**</ept><ph id="ph38" /> - Calculates the total number of requests for a given page.</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source><bpt id="p56">**</bpt>avgtime<ept id="p56">**</ept><ph id="ph39" /> - Calculates the average time taken (in seconds) for a request per page.</source>
          <target state="new"><bpt id="p56">**</bpt>avgtime<ept id="p56">**</ept><ph id="ph39" /> - Calculates the average time taken (in seconds) for a request per page.</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source><bpt id="p57">**</bpt>errors<ept id="p57">**</ept><ph id="ph40" /> - Calculates the number of errors per page, per hour, for requests whose status was 404 or 500.</source>
          <target state="new"><bpt id="p57">**</bpt>errors<ept id="p57">**</ept><ph id="ph40" /> - Calculates the number of errors per page, per hour, for requests whose status was 404 or 500.</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>These samples and their documentation do not provide an in-depth study or full implementation of the key Hadoop technologies.</source>
          <target state="new">These samples and their documentation do not provide an in-depth study or full implementation of the key Hadoop technologies.</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>The cluster used has only a single node and so the effect of adding more nodes cannot, with this release, be observed.</source>
          <target state="new">The cluster used has only a single node and so the effect of adding more nodes cannot, with this release, be observed.</target>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>Load sample W3C log data</source>
          <target state="new">Load sample W3C log data</target>
        </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>Generating and importing the data to HDFS is done via the Azure PowerShell script importdata.ps1.</source>
          <target state="new">Generating and importing the data to HDFS is done via the Azure PowerShell script importdata.ps1.</target>
        </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source><bpt id="p58">**</bpt>To import sample W3C log data<ept id="p58">**</ept></source>
          <target state="new"><bpt id="p58">**</bpt>To import sample W3C log data<ept id="p58">**</ept></target>
        </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source>Open a Hadoop command line from the desktop.</source>
          <target state="new">Open a Hadoop command line from the desktop.</target>
        </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source>Change the directory to <bpt id="p59">**</bpt>C:\hdp\GettingStarted<ept id="p59">**</ept>.</source>
          <target state="new">Change the directory to <bpt id="p59">**</bpt>C:\hdp\GettingStarted<ept id="p59">**</ept>.</target>
        </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>Run the following command to generate and import data to HDFS:</source>
          <target state="new">Run the following command to generate and import data to HDFS:</target>
        </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>If you want to load data into Azure Blob storage instead, see <bpt id="p60">[</bpt>Connect to Azure Blob storage<ept id="p60">](#blobstorage)</ept>.</source>
          <target state="new">If you want to load data into Azure Blob storage instead, see <bpt id="p60">[</bpt>Connect to Azure Blob storage<ept id="p60">](#blobstorage)</ept>.</target>
        </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve">
          <source>Run the following command from the Hadoop command line to list the imported files on HDFS:</source>
          <target state="new">Run the following command from the Hadoop command line to list the imported files on HDFS:</target>
        </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve">
          <source>The output should be similar to the following:</source>
          <target state="new">The output should be similar to the following:</target>
        </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve">
          <source>If you want to verify the file contents, run the following command to display one of the data files to the console window:</source>
          <target state="new">If you want to verify the file contents, run the following command to display one of the data files to the console window:</target>
        </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve">
          <source>You now have the data files created and imported to HDFS.</source>
          <target state="new">You now have the data files created and imported to HDFS.</target>
        </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve">
          <source>You can start running different Hadoop jobs.</source>
          <target state="new">You can start running different Hadoop jobs.</target>
        </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>Run Java MapReduce jobs</source>
          <target state="new">Run Java MapReduce jobs</target>
        </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve">
          <source>MapReduce is the basic compute engine for Hadoop.</source>
          <target state="new">MapReduce is the basic compute engine for Hadoop.</target>
        </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve">
          <source>By default, it is implemented in Java, but there are also examples that leverage .NET and Hadoop Streaming that use C#.</source>
          <target state="new">By default, it is implemented in Java, but there are also examples that leverage .NET and Hadoop Streaming that use C#.</target>
        </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve">
          <source>The syntax for running a MapReduce job is:</source>
          <target state="new">The syntax for running a MapReduce job is:</target>
        </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve">
          <source>The jar file and the source files are located in the C:\Hadoop\GettingStarted\Java folder.</source>
          <target state="new">The jar file and the source files are located in the C:\Hadoop\GettingStarted\Java folder.</target>
        </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve">
          <source><bpt id="p61">**</bpt>To run a MapReduce job for calculating webpage hits<ept id="p61">**</ept></source>
          <target state="new"><bpt id="p61">**</bpt>To run a MapReduce job for calculating webpage hits<ept id="p61">**</ept></target>
        </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve">
          <source>Open the Hadoop command line.</source>
          <target state="new">Open the Hadoop command line.</target>
        </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve">
          <source>Change the directory to <bpt id="p62">**</bpt>C:\hdp\GettingStarted<ept id="p62">**</ept>.</source>
          <target state="new">Change the directory to <bpt id="p62">**</bpt>C:\hdp\GettingStarted<ept id="p62">**</ept>.</target>
        </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve">
          <source>Run the following command to remove the output directory in case the folder exists.</source>
          <target state="new">Run the following command to remove the output directory in case the folder exists.</target>
        </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve">
          <source>The MapReduce job will fail if the output folder already exists.</source>
          <target state="new">The MapReduce job will fail if the output folder already exists.</target>
        </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve">
          <source>Run the following command:</source>
          <target state="new">Run the following command:</target>
        </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve">
          <source>The following table describes the elements of the command:
 <ph id="ph41">&lt;table border="1"&gt;</ph><ph id="ph42">
 &lt;tr&gt;</ph><ph id="ph43">&lt;td&gt;</ph>Parameter<ph id="ph44">&lt;/td&gt;</ph><ph id="ph45">&lt;td&gt;</ph>Note<ph id="ph46">&lt;/td&gt;</ph><ph id="ph47">&lt;/tr&gt;</ph><ph id="ph48">
 &lt;tr&gt;</ph><ph id="ph49">&lt;td&gt;</ph>w3c_scenarios.jar<ph id="ph50">&lt;/td&gt;</ph><ph id="ph51">&lt;td&gt;</ph>The jar file is located in the C:\hdp\GettingStarted\Java folder.<ph id="ph52">&lt;/td&gt;</ph><ph id="ph53">&lt;/tr&gt;</ph><ph id="ph54">
 &lt;tr&gt;</ph><ph id="ph55">&lt;td&gt;</ph>microsoft.hadoop.w3c.TotalHitsForPage<ph id="ph56">&lt;/td&gt;</ph><ph id="ph57">&lt;td&gt;</ph>The type can be substituted by one of the following:
 <ph id="ph58">&lt;ul&gt;</ph><ph id="ph59">
 &lt;li&gt;</ph>microsoft.hadoop.w3c.AverageTimeTaken<ph id="ph60">&lt;/li&gt;</ph><ph id="ph61">
 &lt;li&gt;</ph>microsoft.hadoop.w3c.ErrorsByPage<ph id="ph62">&lt;/li&gt;</ph><ph id="ph63">
 &lt;/ul&gt;</ph><ph id="ph64">&lt;/td&gt;</ph><ph id="ph65">&lt;/tr&gt;</ph><ph id="ph66">
 &lt;tr&gt;</ph><ph id="ph67">&lt;td&gt;</ph>/w3c/input/small/data_w3c_small.txt<ph id="ph68">&lt;/td&gt;</ph><ph id="ph69">&lt;td&gt;</ph>The input file can be substituted by the following:
 <ph id="ph70">&lt;ul&gt;</ph><ph id="ph71">
 &lt;li&gt;</ph>/w3c/input/medium/data_w3c_medium.txt<ph id="ph72">&lt;/li&gt;</ph><ph id="ph73">
 &lt;li&gt;</ph>/w3c/input/large/data_w3c_large.txt<ph id="ph74">&lt;/li&gt;</ph><ph id="ph75">
 &lt;/ul&gt;</ph><ph id="ph76">&lt;/td&gt;</ph><ph id="ph77">&lt;/tr&gt;</ph><ph id="ph78">
 &lt;tr&gt;</ph><ph id="ph79">&lt;td&gt;</ph>/w3c/output<ph id="ph80">&lt;/td&gt;</ph><ph id="ph81">&lt;td&gt;</ph>This is the output folder name.<ph id="ph82">&lt;/td&gt;</ph><ph id="ph83">&lt;/tr&gt;</ph><ph id="ph84">
 &lt;/table&gt;</ph></source>
          <target state="new">The following table describes the elements of the command:
 <ph id="ph41">&lt;table border="1"&gt;</ph><ph id="ph42">
 &lt;tr&gt;</ph><ph id="ph43">&lt;td&gt;</ph>Parameter<ph id="ph44">&lt;/td&gt;</ph><ph id="ph45">&lt;td&gt;</ph>Note<ph id="ph46">&lt;/td&gt;</ph><ph id="ph47">&lt;/tr&gt;</ph><ph id="ph48">
 &lt;tr&gt;</ph><ph id="ph49">&lt;td&gt;</ph>w3c_scenarios.jar<ph id="ph50">&lt;/td&gt;</ph><ph id="ph51">&lt;td&gt;</ph>The jar file is located in the C:\hdp\GettingStarted\Java folder.<ph id="ph52">&lt;/td&gt;</ph><ph id="ph53">&lt;/tr&gt;</ph><ph id="ph54">
 &lt;tr&gt;</ph><ph id="ph55">&lt;td&gt;</ph>microsoft.hadoop.w3c.TotalHitsForPage<ph id="ph56">&lt;/td&gt;</ph><ph id="ph57">&lt;td&gt;</ph>The type can be substituted by one of the following:
 <ph id="ph58">&lt;ul&gt;</ph><ph id="ph59">
 &lt;li&gt;</ph>microsoft.hadoop.w3c.AverageTimeTaken<ph id="ph60">&lt;/li&gt;</ph><ph id="ph61">
 &lt;li&gt;</ph>microsoft.hadoop.w3c.ErrorsByPage<ph id="ph62">&lt;/li&gt;</ph><ph id="ph63">
 &lt;/ul&gt;</ph><ph id="ph64">&lt;/td&gt;</ph><ph id="ph65">&lt;/tr&gt;</ph><ph id="ph66">
 &lt;tr&gt;</ph><ph id="ph67">&lt;td&gt;</ph>/w3c/input/small/data_w3c_small.txt<ph id="ph68">&lt;/td&gt;</ph><ph id="ph69">&lt;td&gt;</ph>The input file can be substituted by the following:
 <ph id="ph70">&lt;ul&gt;</ph><ph id="ph71">
 &lt;li&gt;</ph>/w3c/input/medium/data_w3c_medium.txt<ph id="ph72">&lt;/li&gt;</ph><ph id="ph73">
 &lt;li&gt;</ph>/w3c/input/large/data_w3c_large.txt<ph id="ph74">&lt;/li&gt;</ph><ph id="ph75">
 &lt;/ul&gt;</ph><ph id="ph76">&lt;/td&gt;</ph><ph id="ph77">&lt;/tr&gt;</ph><ph id="ph78">
 &lt;tr&gt;</ph><ph id="ph79">&lt;td&gt;</ph>/w3c/output<ph id="ph80">&lt;/td&gt;</ph><ph id="ph81">&lt;td&gt;</ph>This is the output folder name.<ph id="ph82">&lt;/td&gt;</ph><ph id="ph83">&lt;/tr&gt;</ph><ph id="ph84">
 &lt;/table&gt;</ph></target>
        </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve">
          <source>Run the following command to display the output file:</source>
          <target state="new">Run the following command to display the output file:</target>
        </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve">
          <source>The output shall be similar to:</source>
          <target state="new">The output shall be similar to:</target>
        </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve">
          <source>The Default.aspx page gets 3360 hits and so on.</source>
          <target state="new">The Default.aspx page gets 3360 hits and so on.</target>
        </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve">
          <source>Try running the commands again by replacing the values as suggested in the table above and notice how the output changes based on the type of job and size of data.</source>
          <target state="new">Try running the commands again by replacing the values as suggested in the table above and notice how the output changes based on the type of job and size of data.</target>
        </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve">
          <source>Run Hive jobs</source>
          <target state="new">Run Hive jobs</target>
        </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve">
          <source>The Hive query engine might feel familiar to analysts with strong Structured Query Language (SQL) skills.</source>
          <target state="new">The Hive query engine might feel familiar to analysts with strong Structured Query Language (SQL) skills.</target>
        </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve">
          <source>It provides a SQL-like interface and a relational data model for HDFS.</source>
          <target state="new">It provides a SQL-like interface and a relational data model for HDFS.</target>
        </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve">
          <source>Hive uses a language called HiveQL, which is very similar to SQL.</source>
          <target state="new">Hive uses a language called HiveQL, which is very similar to SQL.</target>
        </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve">
          <source>Hive provides a layer of abstraction over the Java-based MapReduce framework, and the Hive queries are compiled to MapReduce at run time.</source>
          <target state="new">Hive provides a layer of abstraction over the Java-based MapReduce framework, and the Hive queries are compiled to MapReduce at run time.</target>
        </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve">
          <source><bpt id="p63">**</bpt>To run a Hive job<ept id="p63">**</ept></source>
          <target state="new"><bpt id="p63">**</bpt>To run a Hive job<ept id="p63">**</ept></target>
        </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve">
          <source>Open a Hadoop command line.</source>
          <target state="new">Open a Hadoop command line.</target>
        </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve">
          <source>Change the directory to <bpt id="p64">**</bpt>C:\hdp\GettingStarted<ept id="p64">**</ept>.</source>
          <target state="new">Change the directory to <bpt id="p64">**</bpt>C:\hdp\GettingStarted<ept id="p64">**</ept>.</target>
        </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve">
          <source>Run the following command to remove the <bpt id="p65">**</bpt>/w3c/hive/input<ept id="p65">**</ept><ph id="ph85" /> folder in case the folder exists.</source>
          <target state="new">Run the following command to remove the <bpt id="p65">**</bpt>/w3c/hive/input<ept id="p65">**</ept><ph id="ph85" /> folder in case the folder exists.</target>
        </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve">
          <source>The Hive job will fail if the folder exists.</source>
          <target state="new">The Hive job will fail if the folder exists.</target>
        </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve">
          <source>Run the following command to create the <bpt id="p66">**</bpt>/w3c/hive/input<ept id="p66">**</ept><ph id="ph86" /> folders and then copy the data files to the /hive/input folder:</source>
          <target state="new">Run the following command to create the <bpt id="p66">**</bpt>/w3c/hive/input<ept id="p66">**</ept><ph id="ph86" /> folders and then copy the data files to the /hive/input folder:</target>
        </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve">
          <source>Run the following command to execute the <bpt id="p67">**</bpt>w3ccreate.hql<ept id="p67">**</ept><ph id="ph87" /> script file.</source>
          <target state="new">Run the following command to execute the <bpt id="p67">**</bpt>w3ccreate.hql<ept id="p67">**</ept><ph id="ph87" /> script file.</target>
        </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve">
          <source>The script creates a Hive table, and loads data to the Hive table:</source>
          <target state="new">The script creates a Hive table, and loads data to the Hive table:</target>
        </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve">
          <source><ph id="ph88">[AZURE.NOTE]</ph><ph id="ph89" /> At this stage, you can also use the HDInsight Visual Studio tools to run the Hive query.</source>
          <target state="new"><ph id="ph88">[AZURE.NOTE]</ph><ph id="ph89" /> At this stage, you can also use the HDInsight Visual Studio tools to run the Hive query.</target>
        </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve">
          <source>Open Visual Studio, create a new Project, and from the HDInsight template, select <bpt id="p68">**</bpt>Hive Application<ept id="p68">**</ept>.</source>
          <target state="new">Open Visual Studio, create a new Project, and from the HDInsight template, select <bpt id="p68">**</bpt>Hive Application<ept id="p68">**</ept>.</target>
        </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve">
          <source>Once the project opens, add the query as a new item.</source>
          <target state="new">Once the project opens, add the query as a new item.</target>
        </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve">
          <source>The query is available at <bpt id="p69">**</bpt>C:/hdp/GettingStarted/Hive/w3c<ept id="p69">**</ept>.</source>
          <target state="new">The query is available at <bpt id="p69">**</bpt>C:/hdp/GettingStarted/Hive/w3c<ept id="p69">**</ept>.</target>
        </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve">
          <source>Once the query is added to the project, replace <bpt id="p70">**</bpt>${hiveconf:input}<ept id="p70">**</ept><ph id="ph90" /> with <bpt id="p71">**</bpt>/w3c/hive/input<ept id="p71">**</ept>, and then press <bpt id="p72">**</bpt>Submit<ept id="p72">**</ept>.</source>
          <target state="new">Once the query is added to the project, replace <bpt id="p70">**</bpt>${hiveconf:input}<ept id="p70">**</ept><ph id="ph90" /> with <bpt id="p71">**</bpt>/w3c/hive/input<ept id="p71">**</ept>, and then press <bpt id="p72">**</bpt>Submit<ept id="p72">**</ept>.</target>
        </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve">
          <source>The output shall be similar to the following:</source>
          <target state="new">The output shall be similar to the following:</target>
        </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve">
          <source>Run the following command to run the <bpt id="p73">**</bpt>w3ctotalhitsbypage.hql<ept id="p73">**</ept><ph id="ph91" /> HiveQL script file:</source>
          <target state="new">Run the following command to run the <bpt id="p73">**</bpt>w3ctotalhitsbypage.hql<ept id="p73">**</ept><ph id="ph91" /> HiveQL script file:</target>
        </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve">
          <source><ph id="ph92">[AZURE.NOTE]</ph><ph id="ph93" /> As explained earlier, you can run this query using the HDInsight Visual Studio Tools as well.</source>
          <target state="new"><ph id="ph92">[AZURE.NOTE]</ph><ph id="ph93" /> As explained earlier, you can run this query using the HDInsight Visual Studio Tools as well.</target>
        </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve">
          <source>The following table describes the elements of the command:
 <ph id="ph94">&lt;table border="1"&gt;</ph><ph id="ph95">
 &lt;tr&gt;</ph><ph id="ph96">&lt;td&gt;</ph>File<ph id="ph97">&lt;/td&gt;</ph><ph id="ph98">&lt;td&gt;</ph>Description<ph id="ph99">&lt;/td&gt;</ph><ph id="ph100">&lt;/tr&gt;</ph><ph id="ph101">
 &lt;tr&gt;</ph><ph id="ph102">&lt;td&gt;</ph>C:\hdp\hive-0.13.0.2.1.3.0-1981\bin\hive.cmd<ph id="ph103">&lt;/td&gt;</ph><ph id="ph104">&lt;td&gt;</ph>The Hive command script.<ph id="ph105">&lt;/td&gt;</ph><ph id="ph106">&lt;/tr&gt;</ph><ph id="ph107">
 &lt;tr&gt;</ph><ph id="ph108">&lt;td&gt;</ph>C:\hdp\GettingStarted\Hive\w3c\w3ctotalhitsbypage.hql<ph id="ph109">&lt;/td&gt;</ph><ph id="ph110">&lt;td&gt;</ph><ph id="ph111" /> You can substitute the Hive script file with one of the following:
 <ph id="ph112">&lt;ul&gt;</ph><ph id="ph113">
 &lt;li&gt;</ph>C:\hdp\GettingStarted\Hive\w3c\w3caveragetimetaken.hql<ph id="ph114">&lt;/li&gt;</ph><ph id="ph115">
 &lt;li&gt;</ph>C:\hdp\GettingStarted\Hive\w3c\w3cerrorsbypage.hql<ph id="ph116">&lt;/li&gt;</ph><ph id="ph117">
 &lt;/ul&gt;</ph><ph id="ph118">
 &lt;/td&gt;</ph><ph id="ph119">&lt;/tr&gt;</ph></source>
          <target state="new">The following table describes the elements of the command:
 <ph id="ph94">&lt;table border="1"&gt;</ph><ph id="ph95">
 &lt;tr&gt;</ph><ph id="ph96">&lt;td&gt;</ph>File<ph id="ph97">&lt;/td&gt;</ph><ph id="ph98">&lt;td&gt;</ph>Description<ph id="ph99">&lt;/td&gt;</ph><ph id="ph100">&lt;/tr&gt;</ph><ph id="ph101">
 &lt;tr&gt;</ph><ph id="ph102">&lt;td&gt;</ph>C:\hdp\hive-0.13.0.2.1.3.0-1981\bin\hive.cmd<ph id="ph103">&lt;/td&gt;</ph><ph id="ph104">&lt;td&gt;</ph>The Hive command script.<ph id="ph105">&lt;/td&gt;</ph><ph id="ph106">&lt;/tr&gt;</ph><ph id="ph107">
 &lt;tr&gt;</ph><ph id="ph108">&lt;td&gt;</ph>C:\hdp\GettingStarted\Hive\w3c\w3ctotalhitsbypage.hql<ph id="ph109">&lt;/td&gt;</ph><ph id="ph110">&lt;td&gt;</ph><ph id="ph111" /> You can substitute the Hive script file with one of the following:
 <ph id="ph112">&lt;ul&gt;</ph><ph id="ph113">
 &lt;li&gt;</ph>C:\hdp\GettingStarted\Hive\w3c\w3caveragetimetaken.hql<ph id="ph114">&lt;/li&gt;</ph><ph id="ph115">
 &lt;li&gt;</ph>C:\hdp\GettingStarted\Hive\w3c\w3cerrorsbypage.hql<ph id="ph116">&lt;/li&gt;</ph><ph id="ph117">
 &lt;/ul&gt;</ph><ph id="ph118">
 &lt;/td&gt;</ph><ph id="ph119">&lt;/tr&gt;</ph></target>
        </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve">
          <source>The w3ctotalhitsbypage.hql HiveQL script is:</source>
          <target state="new">The w3ctotalhitsbypage.hql HiveQL script is:</target>
        </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve">
          <source>The end of the output shall be similar to the following:</source>
          <target state="new">The end of the output shall be similar to the following:</target>
        </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve">
          <source>Note that as a first step in each of the jobs, a table will be created and data will be loaded into the table from the file created earlier.</source>
          <target state="new">Note that as a first step in each of the jobs, a table will be created and data will be loaded into the table from the file created earlier.</target>
        </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve">
          <source>You can browse the file that was created by looking under the /Hive node in HDFS, using the following command:</source>
          <target state="new">You can browse the file that was created by looking under the /Hive node in HDFS, using the following command:</target>
        </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve">
          <source>Run Pig jobs</source>
          <target state="new">Run Pig jobs</target>
        </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve">
          <source>Pig processing uses a data-flow language called <bpt id="p74">*</bpt>Pig Latin<ept id="p74">*</ept>.</source>
          <target state="new">Pig processing uses a data-flow language called <bpt id="p74">*</bpt>Pig Latin<ept id="p74">*</ept>.</target>
        </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve">
          <source>Pig Latin abstractions provide richer data structures than MapReduce, and perform for Hadoop what SQL performs for relational database management systems.</source>
          <target state="new">Pig Latin abstractions provide richer data structures than MapReduce, and perform for Hadoop what SQL performs for relational database management systems.</target>
        </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve">
          <source><bpt id="p75">**</bpt>To run the pig jobs<ept id="p75">**</ept></source>
          <target state="new"><bpt id="p75">**</bpt>To run the pig jobs<ept id="p75">**</ept></target>
        </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve">
          <source>Open a Hadoop command line.</source>
          <target state="new">Open a Hadoop command line.</target>
        </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve">
          <source>Change the directory to the <bpt id="p76">**</bpt>C:\hdp\GettingStarted<ept id="p76">**</ept><ph id="ph121" /> folder.</source>
          <target state="new">Change the directory to the <bpt id="p76">**</bpt>C:\hdp\GettingStarted<ept id="p76">**</ept><ph id="ph121" /> folder.</target>
        </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve">
          <source>Run the following command to submit a Pig job:</source>
          <target state="new">Run the following command to submit a Pig job:</target>
        </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve">
          <source>The following table shows the elements of the command:
 <ph id="ph122">&lt;table border="1"&gt;</ph><ph id="ph123">
 &lt;tr&gt;</ph><ph id="ph124">&lt;td&gt;</ph>File<ph id="ph125">&lt;/td&gt;</ph><ph id="ph126">&lt;td&gt;</ph>Description<ph id="ph127">&lt;/td&gt;</ph><ph id="ph128">&lt;/tr&gt;</ph><ph id="ph129">
 &lt;tr&gt;</ph><ph id="ph130">&lt;td&gt;</ph>C:\hdp\pig-0.12.1.2.1.3.0-1981\bin\pig.cmd<ph id="ph131">&lt;/td&gt;</ph><ph id="ph132">&lt;td&gt;</ph>The Pig command script.<ph id="ph133">&lt;/td&gt;</ph><ph id="ph134">&lt;/tr&gt;</ph><ph id="ph135">
 &lt;tr&gt;</ph><ph id="ph136">&lt;td&gt;</ph>C:\hdp\GettingStarted\Pig\w3c\TotalHitsForPage.pig<ph id="ph137">&lt;/td&gt;</ph><ph id="ph138">&lt;td&gt;</ph><ph id="ph139" /> You can substitute the Pig Latin script file with one of the following:
 <ph id="ph140">&lt;ul&gt;</ph><ph id="ph141">
 &lt;li&gt;</ph>C:\hdp\GettingStarted\Pig\w3c\AverageTimeTaken.pig<ph id="ph142">&lt;/li&gt;</ph><ph id="ph143">
 &lt;li&gt;</ph>C:\hdp\GettingStarted\Pig\w3c\ErrorsByPage.pig<ph id="ph144">&lt;/li&gt;</ph><ph id="ph145">
 &lt;/ul&gt;</ph><ph id="ph146">
 &lt;/td&gt;</ph><ph id="ph147">&lt;/tr&gt;</ph><ph id="ph148">
 &lt;tr&gt;</ph><ph id="ph149">&lt;td&gt;</ph>/w3c/input/small/data_w3c_small.txt<ph id="ph150">&lt;/td&gt;</ph><ph id="ph151">&lt;td&gt;</ph><ph id="ph152" /> You can substitute the parameter with a larger file:</source>
          <target state="new">The following table shows the elements of the command:
 <ph id="ph122">&lt;table border="1"&gt;</ph><ph id="ph123">
 &lt;tr&gt;</ph><ph id="ph124">&lt;td&gt;</ph>File<ph id="ph125">&lt;/td&gt;</ph><ph id="ph126">&lt;td&gt;</ph>Description<ph id="ph127">&lt;/td&gt;</ph><ph id="ph128">&lt;/tr&gt;</ph><ph id="ph129">
 &lt;tr&gt;</ph><ph id="ph130">&lt;td&gt;</ph>C:\hdp\pig-0.12.1.2.1.3.0-1981\bin\pig.cmd<ph id="ph131">&lt;/td&gt;</ph><ph id="ph132">&lt;td&gt;</ph>The Pig command script.<ph id="ph133">&lt;/td&gt;</ph><ph id="ph134">&lt;/tr&gt;</ph><ph id="ph135">
 &lt;tr&gt;</ph><ph id="ph136">&lt;td&gt;</ph>C:\hdp\GettingStarted\Pig\w3c\TotalHitsForPage.pig<ph id="ph137">&lt;/td&gt;</ph><ph id="ph138">&lt;td&gt;</ph><ph id="ph139" /> You can substitute the Pig Latin script file with one of the following:
 <ph id="ph140">&lt;ul&gt;</ph><ph id="ph141">
 &lt;li&gt;</ph>C:\hdp\GettingStarted\Pig\w3c\AverageTimeTaken.pig<ph id="ph142">&lt;/li&gt;</ph><ph id="ph143">
 &lt;li&gt;</ph>C:\hdp\GettingStarted\Pig\w3c\ErrorsByPage.pig<ph id="ph144">&lt;/li&gt;</ph><ph id="ph145">
 &lt;/ul&gt;</ph><ph id="ph146">
 &lt;/td&gt;</ph><ph id="ph147">&lt;/tr&gt;</ph><ph id="ph148">
 &lt;tr&gt;</ph><ph id="ph149">&lt;td&gt;</ph>/w3c/input/small/data_w3c_small.txt<ph id="ph150">&lt;/td&gt;</ph><ph id="ph151">&lt;td&gt;</ph><ph id="ph152" /> You can substitute the parameter with a larger file:</target>
        </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve">
          <source><ph id="ph153">&lt;ul&gt;</ph><ph id="ph154">
 &lt;li&gt;</ph>/w3c/input/medium/data_w3c_medium.txt<ph id="ph155">&lt;/li&gt;</ph><ph id="ph156">
 &lt;li&gt;</ph>/w3c/input/large/data_w3c_large.txt<ph id="ph157">&lt;/li&gt;</ph><ph id="ph158">
 &lt;/ul&gt;</ph></source>
          <target state="new"><ph id="ph153">&lt;ul&gt;</ph><ph id="ph154">
 &lt;li&gt;</ph>/w3c/input/medium/data_w3c_medium.txt<ph id="ph155">&lt;/li&gt;</ph><ph id="ph156">
 &lt;li&gt;</ph>/w3c/input/large/data_w3c_large.txt<ph id="ph157">&lt;/li&gt;</ph><ph id="ph158">
 &lt;/ul&gt;</ph></target>
        </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve">
          <source>The output should be similar to the following:</source>
          <target state="new">The output should be similar to the following:</target>
        </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve">
          <source>Note that since Pig scripts compile to MapReduce jobs, and potentially to more than one such job, you might see multiple MapReduce jobs executing in the course of processing a Pig job.</source>
          <target state="new">Note that since Pig scripts compile to MapReduce jobs, and potentially to more than one such job, you might see multiple MapReduce jobs executing in the course of processing a Pig job.</target>
        </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve">
          <source><bpt id="p77">**</bpt>To rebuild the samples<ept id="p77">**</ept></source>
          <target state="new"><bpt id="p77">**</bpt>To rebuild the samples<ept id="p77">**</ept></target>
        </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve">
          <source>Open a Hadoop command line.</source>
          <target state="new">Open a Hadoop command line.</target>
        </trans-unit>
        <trans-unit id="312" translate="yes" xml:space="preserve">
          <source>Run the following command:</source>
          <target state="new">Run the following command:</target>
        </trans-unit>
        <trans-unit id="313" translate="yes" xml:space="preserve">
          <source>---&gt;</source>
          <target state="new">---&gt;</target>
        </trans-unit>
        <trans-unit id="315" translate="yes" xml:space="preserve">
          <source>Connect to Azure Blob storage</source>
          <target state="new">Connect to Azure Blob storage</target>
        </trans-unit>
        <trans-unit id="316" translate="yes" xml:space="preserve">
          <source>The HDInsight Emulator uses HDFS as the default file system.</source>
          <target state="new">The HDInsight Emulator uses HDFS as the default file system.</target>
        </trans-unit>
        <trans-unit id="317" translate="yes" xml:space="preserve">
          <source>However, Azure HDInsight uses Azure Blob storage as the default file system.</source>
          <target state="new">However, Azure HDInsight uses Azure Blob storage as the default file system.</target>
        </trans-unit>
        <trans-unit id="318" translate="yes" xml:space="preserve">
          <source>It is possible to configure the HDInsight Emulator to use Azure Blob storage instead of local storage.</source>
          <target state="new">It is possible to configure the HDInsight Emulator to use Azure Blob storage instead of local storage.</target>
        </trans-unit>
        <trans-unit id="319" translate="yes" xml:space="preserve">
          <source>Follow the instructions below to create a storage container in Azure and to connect it to the HDInsight Emulator.</source>
          <target state="new">Follow the instructions below to create a storage container in Azure and to connect it to the HDInsight Emulator.</target>
        </trans-unit>
        <trans-unit id="320" translate="yes" xml:space="preserve">
          <source><ph id="ph163">[AZURE.NOTE]</ph><ph id="ph164" /> For more information on how HDInsight uses Azure Blob storage, see <bpt id="p78">[</bpt>Use Azure Blob storage with HDInsight<ept id="p78">](hdinsight-hadoop-use-blob-storage.md)</ept>.</source>
          <target state="new"><ph id="ph163">[AZURE.NOTE]</ph><ph id="ph164" /> For more information on how HDInsight uses Azure Blob storage, see <bpt id="p78">[</bpt>Use Azure Blob storage with HDInsight<ept id="p78">](hdinsight-hadoop-use-blob-storage.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="321" translate="yes" xml:space="preserve">
          <source>Before you start with the instructions below, you must have created a storage account.</source>
          <target state="new">Before you start with the instructions below, you must have created a storage account.</target>
        </trans-unit>
        <trans-unit id="322" translate="yes" xml:space="preserve">
          <source>For instructions, see <bpt id="p79">[</bpt>How To Create a Storage Account<ept id="p79">](../storage/storage-create-storage-account.md)</ept>.</source>
          <target state="new">For instructions, see <bpt id="p79">[</bpt>How To Create a Storage Account<ept id="p79">](../storage/storage-create-storage-account.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="323" translate="yes" xml:space="preserve">
          <source><bpt id="p80">**</bpt>To create a container<ept id="p80">**</ept></source>
          <target state="new"><bpt id="p80">**</bpt>To create a container<ept id="p80">**</ept></target>
        </trans-unit>
        <trans-unit id="324" translate="yes" xml:space="preserve">
          <source>Sign in to the <bpt id="p81">[</bpt>Azure Portal<ept id="p81">](https://ms.portal.azure.com/)</ept>.</source>
          <target state="new">Sign in to the <bpt id="p81">[</bpt>Azure Portal<ept id="p81">](https://ms.portal.azure.com/)</ept>.</target>
        </trans-unit>
        <trans-unit id="325" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p82">**</bpt>NEW<ept id="p82">**</ept><ph id="ph165" /> on the left, click <bpt id="p83">**</bpt>Data + Storage<ept id="p83">**</ept>, and then click <bpt id="p84">**</bpt>Storage<ept id="p84">**</ept>.</source>
          <target state="new">Click <bpt id="p82">**</bpt>NEW<ept id="p82">**</ept><ph id="ph165" /> on the left, click <bpt id="p83">**</bpt>Data + Storage<ept id="p83">**</ept>, and then click <bpt id="p84">**</bpt>Storage<ept id="p84">**</ept>.</target>
        </trans-unit>
        <trans-unit id="326" translate="yes" xml:space="preserve">
          <source>In the Storage Account blade, configure the properties as shown in the screen capture below.</source>
          <target state="new">In the Storage Account blade, configure the properties as shown in the screen capture below.</target>
        </trans-unit>
        <trans-unit id="327" translate="yes" xml:space="preserve">
          <source><ph id="ph166">![</ph>Create a storage account<ph id="ph167">](./media/hdinsight-hadoop-emulator-get-started/hdi.emulator.create.storage.png)</ph></source>
          <target state="new"><ph id="ph166">![</ph>Create a storage account<ph id="ph167">](./media/hdinsight-hadoop-emulator-get-started/hdi.emulator.create.storage.png)</ph></target>
        </trans-unit>
        <trans-unit id="328" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p85">**</bpt>Pin to Startboard<ept id="p85">**</ept>, and the click <bpt id="p86">**</bpt>Create<ept id="p86">**</ept>.</source>
          <target state="new">Select <bpt id="p85">**</bpt>Pin to Startboard<ept id="p85">**</ept>, and the click <bpt id="p86">**</bpt>Create<ept id="p86">**</ept>.</target>
        </trans-unit>
        <trans-unit id="329" translate="yes" xml:space="preserve">
          <source>Once the storage account is created, from the new storage account blade, click <bpt id="p87">**</bpt>Containers<ept id="p87">**</ept><ph id="ph168" /> to open the containers blade, click <bpt id="p88">**</bpt>Add<ept id="p88">**</ept>.</source>
          <target state="new">Once the storage account is created, from the new storage account blade, click <bpt id="p87">**</bpt>Containers<ept id="p87">**</ept><ph id="ph168" /> to open the containers blade, click <bpt id="p88">**</bpt>Add<ept id="p88">**</ept>.</target>
        </trans-unit>
        <trans-unit id="330" translate="yes" xml:space="preserve">
          <source>Enter the name of the container and then click <bpt id="p89">**</bpt>Select<ept id="p89">**</ept>.</source>
          <target state="new">Enter the name of the container and then click <bpt id="p89">**</bpt>Select<ept id="p89">**</ept>.</target>
        </trans-unit>
        <trans-unit id="331" translate="yes" xml:space="preserve">
          <source><ph id="ph169">![</ph>Create a container<ph id="ph170">](./media/hdinsight-hadoop-emulator-get-started/hdi.emulator.create.container.png)</ph></source>
          <target state="new"><ph id="ph169">![</ph>Create a container<ph id="ph170">](./media/hdinsight-hadoop-emulator-get-started/hdi.emulator.create.container.png)</ph></target>
        </trans-unit>
        <trans-unit id="332" translate="yes" xml:space="preserve">
          <source>Before you can access an Azure Storage account, you must add the account name and the account key to the configuration file.</source>
          <target state="new">Before you can access an Azure Storage account, you must add the account name and the account key to the configuration file.</target>
        </trans-unit>
        <trans-unit id="333" translate="yes" xml:space="preserve">
          <source><bpt id="p90">**</bpt>To configure the connection to an Azure Storage account<ept id="p90">**</ept></source>
          <target state="new"><bpt id="p90">**</bpt>To configure the connection to an Azure Storage account<ept id="p90">**</ept></target>
        </trans-unit>
        <trans-unit id="334" translate="yes" xml:space="preserve">
          <source>Open <bpt id="p91">**</bpt>C:\hdp\hadoop-2.4.0.2.1.3.0-1981\etc\hadoop\core-site.xml<ept id="p91">**</ept><ph id="ph171" /> in Notepad.</source>
          <target state="new">Open <bpt id="p91">**</bpt>C:\hdp\hadoop-2.4.0.2.1.3.0-1981\etc\hadoop\core-site.xml<ept id="p91">**</ept><ph id="ph171" /> in Notepad.</target>
        </trans-unit>
        <trans-unit id="335" translate="yes" xml:space="preserve">
          <source>Add the following &lt;property\&gt; tag next to the other &lt;property\&gt; tags:</source>
          <target state="new">Add the following &lt;property\&gt; tag next to the other &lt;property\&gt; tags:</target>
        </trans-unit>
        <trans-unit id="336" translate="yes" xml:space="preserve">
          <source>You must substitute &lt;StorageAccountName\&gt; and &lt;StorageAccountKey\&gt; with the values that match your Storage account information.</source>
          <target state="new">You must substitute &lt;StorageAccountName\&gt; and &lt;StorageAccountKey\&gt; with the values that match your Storage account information.</target>
        </trans-unit>
        <trans-unit id="337" translate="yes" xml:space="preserve">
          <source>Save the change.</source>
          <target state="new">Save the change.</target>
        </trans-unit>
        <trans-unit id="338" translate="yes" xml:space="preserve">
          <source>You don't need to restart the Hadoop services.</source>
          <target state="new">You don't need to restart the Hadoop services.</target>
        </trans-unit>
        <trans-unit id="339" translate="yes" xml:space="preserve">
          <source>Use the following syntax to access the Storage account:</source>
          <target state="new">Use the following syntax to access the Storage account:</target>
        </trans-unit>
        <trans-unit id="340" translate="yes" xml:space="preserve">
          <source>For example:</source>
          <target state="new">For example:</target>
        </trans-unit>
        <trans-unit id="342" translate="yes" xml:space="preserve">
          <source>Run Azure PowerShell</source>
          <target state="new">Run Azure PowerShell</target>
        </trans-unit>
        <trans-unit id="343" translate="yes" xml:space="preserve">
          <source>Some of the Azure PowerShell cmdlets are also supported on the HDInsight Emulator.</source>
          <target state="new">Some of the Azure PowerShell cmdlets are also supported on the HDInsight Emulator.</target>
        </trans-unit>
        <trans-unit id="344" translate="yes" xml:space="preserve">
          <source>These cmdlets include:</source>
          <target state="new">These cmdlets include:</target>
        </trans-unit>
        <trans-unit id="345" translate="yes" xml:space="preserve">
          <source>HDInsight job definition cmdlets</source>
          <target state="new">HDInsight job definition cmdlets</target>
        </trans-unit>
        <trans-unit id="346" translate="yes" xml:space="preserve">
          <source>New-AzureHDInsightSqoopJobDefinition</source>
          <target state="new">New-AzureHDInsightSqoopJobDefinition</target>
        </trans-unit>
        <trans-unit id="347" translate="yes" xml:space="preserve">
          <source>New-AzureHDInsightStreamingMapReduceJobDefinition</source>
          <target state="new">New-AzureHDInsightStreamingMapReduceJobDefinition</target>
        </trans-unit>
        <trans-unit id="348" translate="yes" xml:space="preserve">
          <source>New-AzureHDInsightPigJobDefinition</source>
          <target state="new">New-AzureHDInsightPigJobDefinition</target>
        </trans-unit>
        <trans-unit id="349" translate="yes" xml:space="preserve">
          <source>New-AzureHDInsightHiveJobDefinition</source>
          <target state="new">New-AzureHDInsightHiveJobDefinition</target>
        </trans-unit>
        <trans-unit id="350" translate="yes" xml:space="preserve">
          <source>New-AzureHDInsightMapReduceJobDefinition</source>
          <target state="new">New-AzureHDInsightMapReduceJobDefinition</target>
        </trans-unit>
        <trans-unit id="351" translate="yes" xml:space="preserve">
          <source>Start-AzureHDInsightJob</source>
          <target state="new">Start-AzureHDInsightJob</target>
        </trans-unit>
        <trans-unit id="352" translate="yes" xml:space="preserve">
          <source>Get-AzureHDInsightJob</source>
          <target state="new">Get-AzureHDInsightJob</target>
        </trans-unit>
        <trans-unit id="353" translate="yes" xml:space="preserve">
          <source>Wait-AzureHDInsightJob</source>
          <target state="new">Wait-AzureHDInsightJob</target>
        </trans-unit>
        <trans-unit id="354" translate="yes" xml:space="preserve">
          <source>Here is a sample for submitting a Hadoop job:</source>
          <target state="new">Here is a sample for submitting a Hadoop job:</target>
        </trans-unit>
        <trans-unit id="355" translate="yes" xml:space="preserve">
          <source>You will get a prompt when calling Get-Credential.</source>
          <target state="new">You will get a prompt when calling Get-Credential.</target>
        </trans-unit>
        <trans-unit id="356" translate="yes" xml:space="preserve">
          <source>You must use <bpt id="p92">**</bpt>hadoop<ept id="p92">**</ept><ph id="ph172" /> as the user name.</source>
          <target state="new">You must use <bpt id="p92">**</bpt>hadoop<ept id="p92">**</ept><ph id="ph172" /> as the user name.</target>
        </trans-unit>
        <trans-unit id="357" translate="yes" xml:space="preserve">
          <source>The password can be any string.</source>
          <target state="new">The password can be any string.</target>
        </trans-unit>
        <trans-unit id="358" translate="yes" xml:space="preserve">
          <source>The cluster name is always <bpt id="p93">**</bpt>http://localhost:50111<ept id="p93">**</ept>.</source>
          <target state="new">The cluster name is always <bpt id="p93">**</bpt>http://localhost:50111<ept id="p93">**</ept>.</target>
        </trans-unit>
        <trans-unit id="359" translate="yes" xml:space="preserve">
          <source>For more information about submitting Hadoop jobs, see <bpt id="p94">[</bpt>Submit Hadoop jobs programmatically<ept id="p94">](hdinsight-submit-hadoop-jobs-programmatically.md)</ept>.</source>
          <target state="new">For more information about submitting Hadoop jobs, see <bpt id="p94">[</bpt>Submit Hadoop jobs programmatically<ept id="p94">](hdinsight-submit-hadoop-jobs-programmatically.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="360" translate="yes" xml:space="preserve">
          <source>For more information about the Azure PowerShell cmdlets for HDInsight, see <bpt id="p95">[</bpt>HDInsight cmdlet reference<ept id="p95">][hdinsight-powershell-reference]</ept>.</source>
          <target state="new">For more information about the Azure PowerShell cmdlets for HDInsight, see <bpt id="p95">[</bpt>HDInsight cmdlet reference<ept id="p95">][hdinsight-powershell-reference]</ept>.</target>
        </trans-unit>
        <trans-unit id="361" translate="yes" xml:space="preserve">
          <source><ph id="ph173">&lt;a name="remove"&gt;</ph><ph id="ph174">&lt;/a&gt;</ph><ph id="ph175" /> Remove the HDInsight Emulator
On the computer where you have the emulator installed, open Control Panel and under <bpt id="p96">**</bpt>Programs<ept id="p96">**</ept>, click <bpt id="p97">**</bpt>Uninstall a Program<ept id="p97">**</ept>.</source>
          <target state="new"><ph id="ph173">&lt;a name="remove"&gt;</ph><ph id="ph174">&lt;/a&gt;</ph><ph id="ph175" /> Remove the HDInsight Emulator
On the computer where you have the emulator installed, open Control Panel and under <bpt id="p96">**</bpt>Programs<ept id="p96">**</ept>, click <bpt id="p97">**</bpt>Uninstall a Program<ept id="p97">**</ept>.</target>
        </trans-unit>
        <trans-unit id="362" translate="yes" xml:space="preserve">
          <source>From the list of installed programs, right-click <bpt id="p98">**</bpt>Microsoft HDInsight Emulator for Azure<ept id="p98">**</ept>, and then click <bpt id="p99">**</bpt>Uninstall<ept id="p99">**</ept>.</source>
          <target state="new">From the list of installed programs, right-click <bpt id="p98">**</bpt>Microsoft HDInsight Emulator for Azure<ept id="p98">**</ept>, and then click <bpt id="p99">**</bpt>Uninstall<ept id="p99">**</ept>.</target>
        </trans-unit>
        <trans-unit id="364" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="365" translate="yes" xml:space="preserve">
          <source>In this MapReduce tutorial, you installed the HDInsight Emulator - a Hadoop sandbox - and ran some Hadoop jobs.</source>
          <target state="new">In this MapReduce tutorial, you installed the HDInsight Emulator - a Hadoop sandbox - and ran some Hadoop jobs.</target>
        </trans-unit>
        <trans-unit id="366" translate="yes" xml:space="preserve">
          <source>To learn more, see the following articles:</source>
          <target state="new">To learn more, see the following articles:</target>
        </trans-unit>
        <trans-unit id="367" translate="yes" xml:space="preserve">
          <source><bpt id="p100">[</bpt>Get started using Azure HDInsight<ept id="p100">](hdinsight-hadoop-linux-tutorial-get-started.md)</ept></source>
          <target state="new"><bpt id="p100">[</bpt>Get started using Azure HDInsight<ept id="p100">](hdinsight-hadoop-linux-tutorial-get-started.md)</ept></target>
        </trans-unit>
        <trans-unit id="368" translate="yes" xml:space="preserve">
          <source><bpt id="p101">[</bpt>Develop Java MapReduce programs for HDInsight<ept id="p101">](hdinsight-develop-deploy-java-mapreduce.md)</ept></source>
          <target state="new"><bpt id="p101">[</bpt>Develop Java MapReduce programs for HDInsight<ept id="p101">](hdinsight-develop-deploy-java-mapreduce.md)</ept></target>
        </trans-unit>
        <trans-unit id="369" translate="yes" xml:space="preserve">
          <source><bpt id="p102">[</bpt>Develop C# Hadoop streaming MapReduce programs for HDInsight<ept id="p102">](hdinsight-hadoop-develop-deploy-streaming-jobs.md)</ept></source>
          <target state="new"><bpt id="p102">[</bpt>Develop C# Hadoop streaming MapReduce programs for HDInsight<ept id="p102">](hdinsight-hadoop-develop-deploy-streaming-jobs.md)</ept></target>
        </trans-unit>
        <trans-unit id="370" translate="yes" xml:space="preserve">
          <source><bpt id="p103">[</bpt>HDInsight Emulator release notes<ept id="p103">](hdinsight-emulator-release-notes.md)</ept></source>
          <target state="new"><bpt id="p103">[</bpt>HDInsight Emulator release notes<ept id="p103">](hdinsight-emulator-release-notes.md)</ept></target>
        </trans-unit>
        <trans-unit id="371" translate="yes" xml:space="preserve">
          <source><bpt id="p104">[</bpt>MSDN forum for discussing HDInsight<ept id="p104">](http://social.msdn.microsoft.com/Forums/hdinsight)</ept></source>
          <target state="new"><bpt id="p104">[</bpt>MSDN forum for discussing HDInsight<ept id="p104">](http://social.msdn.microsoft.com/Forums/hdinsight)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">7cdad158820911aa2e97bef55a27e6e8e554eeb4</xliffext:olfilehash>
  </header>
</xliff>