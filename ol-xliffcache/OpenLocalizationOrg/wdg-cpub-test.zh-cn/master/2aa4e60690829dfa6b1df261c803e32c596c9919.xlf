<?xml version="1.0" encoding="utf-8"?>
<xliff srcLang="en-US" trgLang="zh-cn" version="2.0" xmlns="urn:oasis:names:tc:xliff:document:2.0" xmlns:mda="urn:oasis:names:tc:xliff:metadata:2.0">
  <file id="1">
    <mda:metadata>
      <mda:metaGroup>
        <mda:meta type="olfilehash">2aa4e60690829dfa6b1df261c803e32c596c9919</mda:meta>
      </mda:metaGroup>
    </mda:metadata>
    <group id="content">
      <unit id="101">
        <segment state="initial">
          <source xml:space="preserve">ms.assetid: B5D915E4-4280-422C-BA0E-D574C534410B</source>
          <target xml:space="preserve">ms.assetid: B5D915E4-4280-422C-BA0E-D574C534410B</target>
        </segment>
      </unit>
      <unit id="102">
        <segment state="initial">
          <source xml:space="preserve">description: This article describes how to use the SceneAnalysisEffect and the FaceDetectionEffect to analyze the content of the media capture preview stream.</source>
          <target xml:space="preserve">description: This article describes how to use the SceneAnalysisEffect and the FaceDetectionEffect to analyze the content of the media capture preview stream.</target>
        </segment>
      </unit>
      <unit id="103">
        <segment state="initial">
          <source xml:space="preserve">title: Scene analysis for media capture</source>
          <target xml:space="preserve">title: Scene analysis for media capture</target>
        </segment>
      </unit>
      <unit id="104">
        <segment state="initial">
          <source xml:space="preserve">Scene analysis for media capture</source>
          <target xml:space="preserve">Scene analysis for media capture</target>
        </segment>
      </unit>
      <unit id="105">
        <segment state="initial">
          <source xml:space="preserve">\[ Updated for UWP apps on Windows 10.</source>
          <target xml:space="preserve">\[ Updated for UWP apps on Windows 10.</target>
        </segment>
      </unit>
      <unit id="106">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](http://go.microsoft.com/fwlink/p/?linkid=619132)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">For Windows 8.x articles, see the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">archive</pc> \]</source>
          <target xml:space="preserve">For Windows 8.x articles, see the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">archive</pc> \]</target>
        </segment>
      </unit>
      <unit id="107">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948902)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn948776)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">This article describes how to use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SceneAnalysisEffect</pc></pc> and the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">FaceDetectionEffect</pc></pc> to analyze the content of the media capture preview stream.</source>
          <target xml:space="preserve">This article describes how to use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SceneAnalysisEffect</pc></pc> and the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">FaceDetectionEffect</pc></pc> to analyze the content of the media capture preview stream.</target>
        </segment>
      </unit>
      <unit id="108">
        <segment state="initial">
          <source xml:space="preserve">Scene analysis effect</source>
          <target xml:space="preserve">Scene analysis effect</target>
        </segment>
      </unit>
      <unit id="109">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948902)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SceneAnalysisEffect</pc></pc> analyzes the video frames in the media capture preview stream and recommends processing options to improve the capture result.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SceneAnalysisEffect</pc></pc> analyzes the video frames in the media capture preview stream and recommends processing options to improve the capture result.</target>
        </segment>
      </unit>
      <unit id="110">
        <segment state="initial">
          <source xml:space="preserve">Currently, the effect supports detecting whether the capture would be improved by using High Dynamic Range (HDR) processing.</source>
          <target xml:space="preserve">Currently, the effect supports detecting whether the capture would be improved by using High Dynamic Range (HDR) processing.</target>
        </segment>
      </unit>
      <unit id="111">
        <segment state="initial">
          <source xml:space="preserve">If the effect recommends using HDR, you can do this in the following ways:</source>
          <target xml:space="preserve">If the effect recommends using HDR, you can do this in the following ways:</target>
        </segment>
      </unit>
      <unit id="112">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/mt181386)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AdvancedPhotoCapture</pc></pc> class to capture photos using the Windows built-in HDR processing algorithm.</source>
          <target xml:space="preserve">Use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AdvancedPhotoCapture</pc></pc> class to capture photos using the Windows built-in HDR processing algorithm.</target>
        </segment>
      </unit>
      <unit id="113">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](high-dynamic-range-hdr-photo-capture.md)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">For more information, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">High Dynamic Range (HDR) photo capture</pc>.</source>
          <target xml:space="preserve">For more information, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">High Dynamic Range (HDR) photo capture</pc>.</target>
        </segment>
      </unit>
      <unit id="114">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn926680)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">HdrVideoControl</pc></pc> to capture video using the Windows built-in HDR processing algorithm.</source>
          <target xml:space="preserve">Use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">HdrVideoControl</pc></pc> to capture video using the Windows built-in HDR processing algorithm.</target>
        </segment>
      </unit>
      <unit id="115">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](capture-device-controls-for-video-capture.md)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">For more information, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Capture device controls for video capture</pc>.</source>
          <target xml:space="preserve">For more information, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Capture device controls for video capture</pc>.</target>
        </segment>
      </unit>
      <unit id="116">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn640573)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">VariablePhotoSequenceControl</pc></pc> to capture a sequence of frames that you can then composite using a custom HDR implementation.</source>
          <target xml:space="preserve">Use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">VariablePhotoSequenceControl</pc></pc> to capture a sequence of frames that you can then composite using a custom HDR implementation.</target>
        </segment>
      </unit>
      <unit id="117">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](variable-photo-sequence.md)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">For more information, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Variable photo sequence</pc>.</source>
          <target xml:space="preserve">For more information, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Variable photo sequence</pc>.</target>
        </segment>
      </unit>
      <unit id="118">
        <segment state="initial">
          <source xml:space="preserve">Scene analysis namespaces</source>
          <target xml:space="preserve">Scene analysis namespaces</target>
        </segment>
      </unit>
      <unit id="119">
        <segment state="initial">
          <source xml:space="preserve">To use scene analysis, your app must include the following namespaces in addition to the namespaces required for basic media capture.</source>
          <target xml:space="preserve">To use scene analysis, your app must include the following namespaces in addition to the namespaces required for basic media capture.</target>
        </segment>
      </unit>
      <unit id="120">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/BasicMediaCaptureWin10/cs/MainPage.xaml.cs#SnippetSceneAnalysisUsing)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">SceneAnalysisUsing</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">SceneAnalysisUsing</pc>]</target>
        </segment>
      </unit>
      <unit id="121">
        <segment state="initial">
          <source xml:space="preserve">Initialize the scene analysis effect and add it to the preview stream</source>
          <target xml:space="preserve">Initialize the scene analysis effect and add it to the preview stream</target>
        </segment>
      </unit>
      <unit id="122">
        <segment state="initial">
          <source xml:space="preserve">Video effects are implemented using two APIs, an effect definition, which provides settings that the capture device needs to initialize the effect, and an effect instance, which can be used to control the effect.</source>
          <target xml:space="preserve">Video effects are implemented using two APIs, an effect definition, which provides settings that the capture device needs to initialize the effect, and an effect instance, which can be used to control the effect.</target>
        </segment>
      </unit>
      <unit id="123">
        <segment state="initial">
          <source xml:space="preserve">Since you may want to access the effect instance from multiple places within your code, you should typically declare a member variable to hold the object.</source>
          <target xml:space="preserve">Since you may want to access the effect instance from multiple places within your code, you should typically declare a member variable to hold the object.</target>
        </segment>
      </unit>
      <unit id="124">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/BasicMediaCaptureWin10/cs/MainPage.xaml.cs#SnippetDeclareSceneAnalysisEffect)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareSceneAnalysisEffect</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareSceneAnalysisEffect</pc>]</target>
        </segment>
      </unit>
      <unit id="125">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
          <data id="id3">[</data>
          <data id="id4">](https://msdn.microsoft.com/library/windows/apps/dn948903)</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">In your app, after you have initialized the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaCapture</pc> object, create a new instance of <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">SceneAnalysisEffectDefinition</pc></pc>.</source>
          <target xml:space="preserve">In your app, after you have initialized the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaCapture</pc> object, create a new instance of <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">SceneAnalysisEffectDefinition</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="126">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn878035)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
          <data id="id9">[</data>
          <data id="id10">](https://msdn.microsoft.com/library/windows/apps/br226640)</data>
          <data id="id11">**</data>
          <data id="id12">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Register the effect with the capture device by calling <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AddVideoEffectAsync</pc></pc> on your <pc dataRefEnd="id6" dataRefStart="id5" id="p3">MediaCapture</pc> object, providing the <pc dataRefEnd="id8" dataRefStart="id7" id="p4">SceneAnalysisEffectDefinition</pc> and specifying <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">MediaStreamType.VideoPreview</pc></pc> to indicate that the effect should be applied to the video preview stream, as opposed to the capture stream.</source>
          <target xml:space="preserve">Register the effect with the capture device by calling <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AddVideoEffectAsync</pc></pc> on your <pc dataRefEnd="id6" dataRefStart="id5" id="p3">MediaCapture</pc> object, providing the <pc dataRefEnd="id8" dataRefStart="id7" id="p4">SceneAnalysisEffectDefinition</pc> and specifying <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">MediaStreamType.VideoPreview</pc></pc> to indicate that the effect should be applied to the video preview stream, as opposed to the capture stream.</target>
        </segment>
      </unit>
      <unit id="127">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">
						<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddVideoEffectAsync</pc> returns an instance of the added effect.</source>
          <target xml:space="preserve">
						<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddVideoEffectAsync</pc> returns an instance of the added effect.</target>
        </segment>
      </unit>
      <unit id="128">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948902)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Because this method can be used with multiple effect types, you must cast the returned instance to a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SceneAnalysisEffect</pc></pc> object.</source>
          <target xml:space="preserve">Because this method can be used with multiple effect types, you must cast the returned instance to a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SceneAnalysisEffect</pc></pc> object.</target>
        </segment>
      </unit>
      <unit id="129">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948920)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">To receive the results of the scene analysis, you must register a handler for the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SceneAnalyzed</pc></pc> event.</source>
          <target xml:space="preserve">To receive the results of the scene analysis, you must register a handler for the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SceneAnalyzed</pc></pc> event.</target>
        </segment>
      </unit>
      <unit id="130">
        <segment state="initial">
          <source xml:space="preserve">Currently, the scene analysis effect only includes the high dynamic range analyzer.</source>
          <target xml:space="preserve">Currently, the scene analysis effect only includes the high dynamic range analyzer.</target>
        </segment>
      </unit>
      <unit id="131">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948827)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Enable HDR analysis by setting the effect's <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">HighDynamicRangeControl.Enabled</pc></pc> to true.</source>
          <target xml:space="preserve">Enable HDR analysis by setting the effect's <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">HighDynamicRangeControl.Enabled</pc></pc> to true.</target>
        </segment>
      </unit>
      <unit id="132">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/BasicMediaCaptureWin10/cs/MainPage.xaml.cs#SnippetCreateSceneAnalysisEffectAsync)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateSceneAnalysisEffectAsync</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateSceneAnalysisEffectAsync</pc>]</target>
        </segment>
      </unit>
      <unit id="133">
        <segment state="initial">
          <source xml:space="preserve">Implement the SceneAnalyzed event handler</source>
          <target xml:space="preserve">Implement the SceneAnalyzed event handler</target>
        </segment>
      </unit>
      <unit id="134">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The results of the scene analysis are returned in the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">SceneAnalyzed</pc> event handler.</source>
          <target xml:space="preserve">The results of the scene analysis are returned in the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">SceneAnalyzed</pc> event handler.</target>
        </segment>
      </unit>
      <unit id="135">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948922)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn948907)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
          <data id="id9">[</data>
          <data id="id10">](https://msdn.microsoft.com/library/windows/apps/dn948830)</data>
          <data id="id11">**</data>
          <data id="id12">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SceneAnalyzedEventArgs</pc></pc> object passed into the handler has a <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">SceneAnalysisEffectFrame</pc></pc> object which has a <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">HighDynamicRangeOutput</pc></pc> object.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SceneAnalyzedEventArgs</pc></pc> object passed into the handler has a <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">SceneAnalysisEffectFrame</pc></pc> object which has a <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">HighDynamicRangeOutput</pc></pc> object.</target>
        </segment>
      </unit>
      <unit id="136">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948833)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Certainty</pc></pc> property of the high dynamic range output provides a value between 0 and 1.0 where 0 indicates that HDR processing would not help improve the capture result and 1.0 indicates that HDR processing would help.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Certainty</pc></pc> property of the high dynamic range output provides a value between 0 and 1.0 where 0 indicates that HDR processing would not help improve the capture result and 1.0 indicates that HDR processing would help.</target>
        </segment>
      </unit>
      <unit id="137">
        <segment state="initial">
          <source xml:space="preserve">Your can decide the threshold point at which you want to use HDR or show the results to the user and let the user decide.</source>
          <target xml:space="preserve">Your can decide the threshold point at which you want to use HDR or show the results to the user and let the user decide.</target>
        </segment>
      </unit>
      <unit id="138">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/BasicMediaCaptureWin10/cs/MainPage.xaml.cs#SnippetSceneAnalyzed)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">SceneAnalyzed</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">SceneAnalyzed</pc>]</target>
        </segment>
      </unit>
      <unit id="139">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948830)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn948834)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">HighDynamicRangeOutput</pc></pc> object passed into the handler also has a <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">FrameControllers</pc></pc> property which contains suggested frame controllers for capturing a variable photo sequence for HDR processing.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">HighDynamicRangeOutput</pc></pc> object passed into the handler also has a <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">FrameControllers</pc></pc> property which contains suggested frame controllers for capturing a variable photo sequence for HDR processing.</target>
        </segment>
      </unit>
      <unit id="140">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](variable-photo-sequence.md)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">For more information, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Variable photo sequence</pc>.</source>
          <target xml:space="preserve">For more information, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Variable photo sequence</pc>.</target>
        </segment>
      </unit>
      <unit id="141">
        <segment state="initial">
          <source xml:space="preserve">Clean up the scene analysis effect</source>
          <target xml:space="preserve">Clean up the scene analysis effect</target>
        </segment>
      </unit>
      <unit id="142">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
          <data id="id3">[</data>
          <data id="id4">](https://msdn.microsoft.com/library/windows/apps/dn948827)</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
          <data id="id7">[</data>
          <data id="id8">](https://msdn.microsoft.com/library/windows/apps/dn948920)</data>
          <data id="id9">**</data>
          <data id="id10">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">When your app is done capturing, before disposing of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaCapture</pc> object, you should disable the scene analysis effect by setting the effect's <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">HighDynamicRangeAnalyzer.Enabled</pc></pc> property to false and unregister your <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">SceneAnalyzed</pc></pc> event handler.</source>
          <target xml:space="preserve">When your app is done capturing, before disposing of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaCapture</pc> object, you should disable the scene analysis effect by setting the effect's <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">HighDynamicRangeAnalyzer.Enabled</pc></pc> property to false and unregister your <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">SceneAnalyzed</pc></pc> event handler.</target>
        </segment>
      </unit>
      <unit id="143">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/br226592)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Call <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">MediaCapture.ClearEffectsAsync</pc></pc>, specifying the video preview stream since that was the stream to which the effect was added.</source>
          <target xml:space="preserve">Call <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">MediaCapture.ClearEffectsAsync</pc></pc>, specifying the video preview stream since that was the stream to which the effect was added.</target>
        </segment>
      </unit>
      <unit id="144">
        <segment state="initial">
          <source xml:space="preserve">Finally, set your member variable to null.</source>
          <target xml:space="preserve">Finally, set your member variable to null.</target>
        </segment>
      </unit>
      <unit id="145">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/BasicMediaCaptureWin10/cs/MainPage.xaml.cs#SnippetCleanUpSceneAnalysisEffectAsync)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CleanUpSceneAnalysisEffectAsync</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CleanUpSceneAnalysisEffectAsync</pc>]</target>
        </segment>
      </unit>
      <unit id="146">
        <segment state="initial">
          <source xml:space="preserve">Face detection effect</source>
          <target xml:space="preserve">Face detection effect</target>
        </segment>
      </unit>
      <unit id="147">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948776)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FaceDetectionEffect</pc></pc> identifies the location of faces within the media capture preview stream.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FaceDetectionEffect</pc></pc> identifies the location of faces within the media capture preview stream.</target>
        </segment>
      </unit>
      <unit id="148">
        <segment state="initial">
          <source xml:space="preserve">The effect allows you to receive a notification whenever a face is detected in the preview stream and provides the bounding box for each detected face within the preview frame.</source>
          <target xml:space="preserve">The effect allows you to receive a notification whenever a face is detected in the preview stream and provides the bounding box for each detected face within the preview frame.</target>
        </segment>
      </unit>
      <unit id="149">
        <segment state="initial">
          <source xml:space="preserve">On supported devices, the face detection effect also provides enhanced exposure and focus on the most important face in the scene.</source>
          <target xml:space="preserve">On supported devices, the face detection effect also provides enhanced exposure and focus on the most important face in the scene.</target>
        </segment>
      </unit>
      <unit id="150">
        <segment state="initial">
          <source xml:space="preserve">Face detection namespaces</source>
          <target xml:space="preserve">Face detection namespaces</target>
        </segment>
      </unit>
      <unit id="151">
        <segment state="initial">
          <source xml:space="preserve">To use face detection, your app must include the following namespaces in addition to the namespaces required for basic media capture.</source>
          <target xml:space="preserve">To use face detection, your app must include the following namespaces in addition to the namespaces required for basic media capture.</target>
        </segment>
      </unit>
      <unit id="152">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/BasicMediaCaptureWin10/cs/MainPage.xaml.cs#SnippetFaceDetectionUsing)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">FaceDetectionUsing</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">FaceDetectionUsing</pc>]</target>
        </segment>
      </unit>
      <unit id="153">
        <segment state="initial">
          <source xml:space="preserve">Initialize the face detection effect and add it to the preview stream</source>
          <target xml:space="preserve">Initialize the face detection effect and add it to the preview stream</target>
        </segment>
      </unit>
      <unit id="154">
        <segment state="initial">
          <source xml:space="preserve">Video effects are implemented using two APIs, an effect definition, which provides settings that the capture device needs to initialize the effect, and an effect instance, which can be used to control the effect.</source>
          <target xml:space="preserve">Video effects are implemented using two APIs, an effect definition, which provides settings that the capture device needs to initialize the effect, and an effect instance, which can be used to control the effect.</target>
        </segment>
      </unit>
      <unit id="155">
        <segment state="initial">
          <source xml:space="preserve">Since you may want to access the effect instance from multiple places within your code, you should typically declare a member variable to hold the object.</source>
          <target xml:space="preserve">Since you may want to access the effect instance from multiple places within your code, you should typically declare a member variable to hold the object.</target>
        </segment>
      </unit>
      <unit id="156">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/BasicMediaCaptureWin10/cs/MainPage.xaml.cs#SnippetDeclareFaceDetectionEffect)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareFaceDetectionEffect</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareFaceDetectionEffect</pc>]</target>
        </segment>
      </unit>
      <unit id="157">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
          <data id="id3">[</data>
          <data id="id4">](https://msdn.microsoft.com/library/windows/apps/dn948778)</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">In your app, after you have initialized the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaCapture</pc> object, create a new instance of <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">FaceDetectionEffectDefinition</pc></pc>.</source>
          <target xml:space="preserve">In your app, after you have initialized the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaCapture</pc> object, create a new instance of <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">FaceDetectionEffectDefinition</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="158">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948781)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Set the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">DetectionMode</pc></pc> property to prioritize faster face detection or more accurate face detection.</source>
          <target xml:space="preserve">Set the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">DetectionMode</pc></pc> property to prioritize faster face detection or more accurate face detection.</target>
        </segment>
      </unit>
      <unit id="159">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948786)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Set <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SynchronousDetectionEnabled</pc></pc> to specify that incoming frames are not delayed waiting for face detection to complete as this can result in a choppy preview experience.</source>
          <target xml:space="preserve">Set <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SynchronousDetectionEnabled</pc></pc> to specify that incoming frames are not delayed waiting for face detection to complete as this can result in a choppy preview experience.</target>
        </segment>
      </unit>
      <unit id="160">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn878035)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
          <data id="id9">[</data>
          <data id="id10">](https://msdn.microsoft.com/library/windows/apps/br226640)</data>
          <data id="id11">**</data>
          <data id="id12">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Register the effect with the capture device by calling <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AddVideoEffectAsync</pc></pc> on your <pc dataRefEnd="id6" dataRefStart="id5" id="p3">MediaCapture</pc> object, providing the <pc dataRefEnd="id8" dataRefStart="id7" id="p4">FaceDetectionEffectDefinition</pc> and specifying <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">MediaStreamType.VideoPreview</pc></pc> to indicate that the effect should be applied to the video preview stream, as opposed to the capture stream.</source>
          <target xml:space="preserve">Register the effect with the capture device by calling <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AddVideoEffectAsync</pc></pc> on your <pc dataRefEnd="id6" dataRefStart="id5" id="p3">MediaCapture</pc> object, providing the <pc dataRefEnd="id8" dataRefStart="id7" id="p4">FaceDetectionEffectDefinition</pc> and specifying <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">MediaStreamType.VideoPreview</pc></pc> to indicate that the effect should be applied to the video preview stream, as opposed to the capture stream.</target>
        </segment>
      </unit>
      <unit id="161">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">
						<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddVideoEffectAsync</pc> returns an instance of the added effect.</source>
          <target xml:space="preserve">
						<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddVideoEffectAsync</pc> returns an instance of the added effect.</target>
        </segment>
      </unit>
      <unit id="162">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948776)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Because this method can be used with multiple effect types, you must cast the returned instance to a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FaceDetectionEffect</pc></pc> object.</source>
          <target xml:space="preserve">Because this method can be used with multiple effect types, you must cast the returned instance to a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FaceDetectionEffect</pc></pc> object.</target>
        </segment>
      </unit>
      <unit id="163">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948818)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Enable or disable the effect by setting the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FaceDetectionEffect.Enabled</pc></pc> property.</source>
          <target xml:space="preserve">Enable or disable the effect by setting the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FaceDetectionEffect.Enabled</pc></pc> property.</target>
        </segment>
      </unit>
      <unit id="164">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948814)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Adjust how often the effect analyzes frames by setting the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FaceDetectionEffect.DesiredDetectionInterval</pc></pc> property.</source>
          <target xml:space="preserve">Adjust how often the effect analyzes frames by setting the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FaceDetectionEffect.DesiredDetectionInterval</pc></pc> property.</target>
        </segment>
      </unit>
      <unit id="165">
        <segment state="initial">
          <source xml:space="preserve">Both of these properties can be adjusted while media capture is ongoing.</source>
          <target xml:space="preserve">Both of these properties can be adjusted while media capture is ongoing.</target>
        </segment>
      </unit>
      <unit id="166">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/BasicMediaCaptureWin10/cs/MainPage.xaml.cs#SnippetCreateFaceDetectionEffectAsync)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateFaceDetectionEffectAsync</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateFaceDetectionEffectAsync</pc>]</target>
        </segment>
      </unit>
      <unit id="167">
        <segment state="initial">
          <source xml:space="preserve">Receive notifications when faces are detected</source>
          <target xml:space="preserve">Receive notifications when faces are detected</target>
        </segment>
      </unit>
      <unit id="168">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948820)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">If you want to perform some action when faces are detected, such as drawing a box around detected faces in the video preview, you can register for the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FaceDetected</pc></pc> event.</source>
          <target xml:space="preserve">If you want to perform some action when faces are detected, such as drawing a box around detected faces in the video preview, you can register for the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FaceDetected</pc></pc> event.</target>
        </segment>
      </unit>
      <unit id="169">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/BasicMediaCaptureWin10/cs/MainPage.xaml.cs#SnippetRegisterFaceDetectionHandler)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">RegisterFaceDetectionHandler</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">RegisterFaceDetectionHandler</pc>]</target>
        </segment>
      </unit>
      <unit id="170">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn948792)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn948774)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">In the handler for the event, you can get a list of all faces detected in a frame by accessing the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FaceDetectionEffectFrame.DetectedFaces</pc></pc> property of the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">FaceDetectedEventArgs</pc></pc>.</source>
          <target xml:space="preserve">In the handler for the event, you can get a list of all faces detected in a frame by accessing the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FaceDetectionEffectFrame.DetectedFaces</pc></pc> property of the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">FaceDetectedEventArgs</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="171">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn974126)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/br226169)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FaceBox</pc></pc> property is a <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">BitmapBounds</pc></pc> structure that describes the rectangle containing the detected face in units relative to the preview stream dimensions.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FaceBox</pc></pc> property is a <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">BitmapBounds</pc></pc> structure that describes the rectangle containing the detected face in units relative to the preview stream dimensions.</target>
        </segment>
      </unit>
      <unit id="172">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](http://go.microsoft.com/fwlink/?LinkId=619486)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">To view sample code that transforms the preview stream coordinates into screen coordinates, see the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">face detection UWP sample</pc>.</source>
          <target xml:space="preserve">To view sample code that transforms the preview stream coordinates into screen coordinates, see the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">face detection UWP sample</pc>.</target>
        </segment>
      </unit>
      <unit id="173">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/BasicMediaCaptureWin10/cs/MainPage.xaml.cs#SnippetFaceDetected)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">FaceDetected</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">FaceDetected</pc>]</target>
        </segment>
      </unit>
      <unit id="174">
        <segment state="initial">
          <source xml:space="preserve">Clean up the face detection effect</source>
          <target xml:space="preserve">Clean up the face detection effect</target>
        </segment>
      </unit>
      <unit id="175">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
          <data id="id3">[</data>
          <data id="id4">](https://msdn.microsoft.com/library/windows/apps/dn948818)</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
          <data id="id7">[</data>
          <data id="id8">](https://msdn.microsoft.com/library/windows/apps/dn948820)</data>
          <data id="id9">**</data>
          <data id="id10">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">When your app is done capturing, before disposing of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaCapture</pc> object, you should disable the face detection effect with <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">FaceDetectionEffect.Enabled</pc></pc> and unregister your <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">FaceDetected</pc></pc> event handler if you previously registered one.</source>
          <target xml:space="preserve">When your app is done capturing, before disposing of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">MediaCapture</pc> object, you should disable the face detection effect with <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">FaceDetectionEffect.Enabled</pc></pc> and unregister your <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">FaceDetected</pc></pc> event handler if you previously registered one.</target>
        </segment>
      </unit>
      <unit id="176">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/br226592)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Call <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">MediaCapture.ClearEffectsAsync</pc></pc>, specifying the video preview stream since that was the stream to which the effect was added.</source>
          <target xml:space="preserve">Call <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">MediaCapture.ClearEffectsAsync</pc></pc>, specifying the video preview stream since that was the stream to which the effect was added.</target>
        </segment>
      </unit>
      <unit id="177">
        <segment state="initial">
          <source xml:space="preserve">Finally, set your member variable to null.</source>
          <target xml:space="preserve">Finally, set your member variable to null.</target>
        </segment>
      </unit>
      <unit id="178">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/BasicMediaCaptureWin10/cs/MainPage.xaml.cs#SnippetCleanUpFaceDetectionEffectAsync)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CleanUpFaceDetectionEffectAsync</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CleanUpFaceDetectionEffectAsync</pc>]</target>
        </segment>
      </unit>
      <unit id="179">
        <segment state="initial">
          <source xml:space="preserve">Check for focus and exposure support for detected faces</source>
          <target xml:space="preserve">Check for focus and exposure support for detected faces</target>
        </segment>
      </unit>
      <unit id="180">
        <segment state="initial">
          <source xml:space="preserve">Not all devices have a capture device that can adjust its focus and exposure based on detected faces.</source>
          <target xml:space="preserve">Not all devices have a capture device that can adjust its focus and exposure based on detected faces.</target>
        </segment>
      </unit>
      <unit id="181">
        <segment state="initial">
          <source xml:space="preserve">Because face detection consumes device resources, you may only want to enable face detection on devices that can use the feature to enhance capture.</source>
          <target xml:space="preserve">Because face detection consumes device resources, you may only want to enable face detection on devices that can use the feature to enhance capture.</target>
        </segment>
      </unit>
      <unit id="182">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/br226825)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](capture-photos-and-video-with-mediacapture.md)</data>
          <data id="id7">[</data>
          <data id="id8">](https://msdn.microsoft.com/library/windows/apps/dn279064)</data>
          <data id="id9">**</data>
          <data id="id10">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">To see if face-based capture optimization is available, get the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">VideoDeviceController</pc></pc> for your initialized <pc dataRefEnd="id6" dataRefStart="id5" id="p3">MediaCapture</pc> and then get the video device controller's <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">RegionsOfInterestControl</pc></pc>.</source>
          <target xml:space="preserve">To see if face-based capture optimization is available, get the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">VideoDeviceController</pc></pc> for your initialized <pc dataRefEnd="id6" dataRefStart="id5" id="p3">MediaCapture</pc> and then get the video device controller's <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">RegionsOfInterestControl</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="183">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn279069)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Check to see if the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">MaxRegions</pc></pc> supports at least one region.</source>
          <target xml:space="preserve">Check to see if the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">MaxRegions</pc></pc> supports at least one region.</target>
        </segment>
      </unit>
      <unit id="184">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn279065)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn279066)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Then check to see if either <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AutoExposureSupported</pc></pc> or <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AutoFocusSupported</pc></pc> are true.</source>
          <target xml:space="preserve">Then check to see if either <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AutoExposureSupported</pc></pc> or <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AutoFocusSupported</pc></pc> are true.</target>
        </segment>
      </unit>
      <unit id="185">
        <segment state="initial">
          <source xml:space="preserve">If these conditions are met, then the device can take advantage of face detection to enhance capture.</source>
          <target xml:space="preserve">If these conditions are met, then the device can take advantage of face detection to enhance capture.</target>
        </segment>
      </unit>
      <unit id="186">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/BasicMediaCaptureWin10/cs/MainPage.xaml.cs#SnippetAreFaceFocusAndExposureSupported)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AreFaceFocusAndExposureSupported</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AreFaceFocusAndExposureSupported</pc>]</target>
        </segment>
      </unit>
      <unit id="187">
        <segment state="initial">
          <source xml:space="preserve">Related topics</source>
          <target xml:space="preserve">Related topics</target>
        </segment>
      </unit>
      <unit id="188">
        <segment state="initial">
          <source xml:space="preserve">Capture photos and video with MediaCapture</source>
          <target xml:space="preserve">Capture photos and video with MediaCapture</target>
        </segment>
      </unit>
    </group>
  </file>
</xliff>