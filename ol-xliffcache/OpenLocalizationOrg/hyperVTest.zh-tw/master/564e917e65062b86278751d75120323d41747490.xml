{
  "nodes": [
    {
      "pos": [
        28,
        67
      ],
      "content": "Scaling API Endpoints | Microsoft Azure"
    },
    {
      "pos": [
        87,
        142
      ],
      "content": "Scaling web service endpoints in Azure Machine Learning"
    },
    {
      "pos": [
        458,
        479
      ],
      "content": "Scaling API Endpoints"
    },
    {
      "pos": [
        481,
        618
      ],
      "content": "Web service endpoints in Azure Machine Learning have selectable throttle levels to match the rate at which the endpoint will be consumed."
    },
    {
      "pos": [
        620,
        758
      ],
      "content": "To control the amount of throttling on the endpoint, use the slider on Azure Classic Portal to set the max concurrent calls between 20-200"
    },
    {
      "pos": [
        762,
        1308
      ],
      "content": "The synchronous APIs are typically used in situations where a low latency is desired. Latency here implies the time it takes for the API to complete one request, and doesn't account for any network delays. Let's say you have an API with a 50ms latency. To fully consume the available capacity with throttle level High and Max Concurrent Calls = 20, you need to call this API 20 * 1000 / 50 = 400 times per second. Extending this further, a Max Concurrent Calls of 200 will allow you to call the API 4000 times per second, assuming a 50ms latency.",
      "nodes": [
        {
          "content": "The synchronous APIs are typically used in situations where a low latency is desired.",
          "pos": [
            0,
            85
          ]
        },
        {
          "content": "Latency here implies the time it takes for the API to complete one request, and doesn't account for any network delays.",
          "pos": [
            86,
            205
          ]
        },
        {
          "content": "Let's say you have an API with a 50ms latency.",
          "pos": [
            206,
            252
          ]
        },
        {
          "content": "To fully consume the available capacity with throttle level High and Max Concurrent Calls = 20, you need to call this API 20 * 1000 / 50 = 400 times per second.",
          "pos": [
            253,
            413
          ]
        },
        {
          "content": "Extending this further, a Max Concurrent Calls of 200 will allow you to call the API 4000 times per second, assuming a 50ms latency.",
          "pos": [
            414,
            546
          ]
        }
      ]
    },
    {
      "pos": [
        1310,
        1528
      ],
      "content": "If you plan to call the API with a higher load than what Max Concurrent Calls of 200 will support, then you should create multiple endpoints on the same web service and randomly distribute your load across all of them."
    },
    {
      "pos": [
        1530,
        1796
      ],
      "content": "Keep in mind that using a very high concurrency count can be detrimental if you're not hitting the API with a correspondingly high rate. You might see sporadic timeouts and/or spikes in the latency if you put a relatively low load on an API configured for high load.",
      "nodes": [
        {
          "content": "Keep in mind that using a very high concurrency count can be detrimental if you're not hitting the API with a correspondingly high rate.",
          "pos": [
            0,
            136
          ]
        },
        {
          "content": "You might see sporadic timeouts and/or spikes in the latency if you put a relatively low load on an API configured for high load.",
          "pos": [
            137,
            266
          ]
        }
      ]
    },
    {
      "pos": [
        1798,
        2003
      ],
      "content": "Note that tweaking throttle settings only influences the behavior of the Synchronous API (RRS). You should tweak these settings if you see frequent 503 Service Unavailable responses on the Synchronous API.",
      "nodes": [
        {
          "content": "Note that tweaking throttle settings only influences the behavior of the Synchronous API (RRS).",
          "pos": [
            0,
            95
          ]
        },
        {
          "content": "You should tweak these settings if you see frequent 503 Service Unavailable responses on the Synchronous API.",
          "pos": [
            96,
            205
          ]
        }
      ]
    },
    {
      "pos": [
        2005,
        2127
      ],
      "content": "The management UI allows to provide a custom concurrency number for scaling the endpoint beyond default concurrency of 20."
    },
    {
      "pos": [
        2132,
        2163
      ],
      "content": "Open up manage.windowsazure.com"
    },
    {
      "pos": [
        2167,
        2203
      ],
      "content": "Navigate to the Machine Learning tab"
    },
    {
      "pos": [
        2207,
        2231
      ],
      "content": "Click on your workspace."
    },
    {
      "pos": [
        2235,
        2370
      ],
      "content": "Navigate to the web service which has your endpoint\n<ph id=\"ph2\">![</ph>Navigate to web service<ph id=\"ph3\">](./media/machine-learning-scaling-endpoints/figure-1.png)</ph>"
    },
    {
      "pos": [
        2375,
        2532
      ],
      "content": "Click on the endpoint, and then click on the Configure tab\n<ph id=\"ph4\">![</ph>Navigate to endpoint configuration<ph id=\"ph5\">](./media/machine-learning-scaling-webservice/machlearn-2.png)</ph>"
    },
    {
      "pos": [
        2538,
        2611
      ],
      "content": "Change the slider to increase the level of concurrency and click on Save."
    }
  ],
  "content": "<properties \n    pageTitle=\"Scaling API Endpoints | Microsoft Azure\" \n    description=\"Scaling web service endpoints in Azure Machine Learning\" \n    services=\"machine-learning\"\n    documentationCenter=\"\" \n    authors=\"hiteshmadan\" \n    manager=\"padou\" \n    editor=\"\"/>\n\n<tags\n    ms.service=\"machine-learning\"\n    ms.devlang=\"multiple\"\n    ms.topic=\"article\"\n    ms.tgt_pltfrm=\"na\"\n    ms.workload=\"tbd\" \n    ms.date=\"06/29/2015\"\n    ms.author=\"himad\"/>\n\n\n# Scaling API Endpoints\n\nWeb service endpoints in Azure Machine Learning have selectable throttle levels to match the rate at which the endpoint will be consumed.\n\nTo control the amount of throttling on the endpoint, use the slider on Azure Classic Portal to set the max concurrent calls between 20-200 \n\n\nThe synchronous APIs are typically used in situations where a low latency is desired. Latency here implies the time it takes for the API to complete one request, and doesn't account for any network delays. Let's say you have an API with a 50ms latency. To fully consume the available capacity with throttle level High and Max Concurrent Calls = 20, you need to call this API 20 * 1000 / 50 = 400 times per second. Extending this further, a Max Concurrent Calls of 200 will allow you to call the API 4000 times per second, assuming a 50ms latency.\n\nIf you plan to call the API with a higher load than what Max Concurrent Calls of 200 will support, then you should create multiple endpoints on the same web service and randomly distribute your load across all of them.\n\nKeep in mind that using a very high concurrency count can be detrimental if you're not hitting the API with a correspondingly high rate. You might see sporadic timeouts and/or spikes in the latency if you put a relatively low load on an API configured for high load.\n\nNote that tweaking throttle settings only influences the behavior of the Synchronous API (RRS). You should tweak these settings if you see frequent 503 Service Unavailable responses on the Synchronous API.\n\nThe management UI allows to provide a custom concurrency number for scaling the endpoint beyond default concurrency of 20.\n\n1. Open up manage.windowsazure.com\n2. Navigate to the Machine Learning tab\n3. Click on your workspace.\n4. Navigate to the web service which has your endpoint\n![Navigate to web service](./media/machine-learning-scaling-endpoints/figure-1.png)\n\n5. Click on the endpoint, and then click on the Configure tab\n![Navigate to endpoint configuration](./media/machine-learning-scaling-webservice/machlearn-2.png)\n\n\n6. Change the slider to increase the level of concurrency and click on Save.\n\n\n \n"
}