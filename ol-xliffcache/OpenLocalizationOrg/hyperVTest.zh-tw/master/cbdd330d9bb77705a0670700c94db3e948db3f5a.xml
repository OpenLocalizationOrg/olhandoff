{
  "nodes": [
    {
      "pos": [
        28,
        96
      ],
      "content": "Use Zeppelin notebooks with Spark cluster on HDInsight Linux | Azure"
    },
    {
      "pos": [
        116,
        214
      ],
      "content": "Step-by-step instructions on how to use Zeppelin notebooks with Spark clusters on HDInsight Linux."
    },
    {
      "pos": [
        531,
        593
      ],
      "content": "Use Zeppelin notebooks with Spark cluster on HDInsight (Linux)"
    },
    {
      "pos": [
        595,
        691
      ],
      "content": "Learn how to install Zeppelin notebooks on Spark clusters and how to use the Zeppelin notebooks."
    },
    {
      "pos": [
        695,
        1261
      ],
      "content": "<ph id=\"ph2\">[AZURE.IMPORTANT]</ph><ph id=\"ph3\"/> Zeppelin notebook for HDInsight Spark cluster is an offering just to showcase how to use Zeppelin in an Azure HDInsight Spark environment. If you want to use notebooks to work with HDInsight Spark, we recommend that you use Jupyter notebooks instead. Jupyter notebooks also provide different kernel options, such as Scala, and will continue to have feature improvements. For instructions on how to use Jupyter notebooks with HDInsight spark, see <bpt id=\"p1\">[</bpt>Run Spark SQL queries using a Jupyter notebook<ept id=\"p1\">](hdinsight-apache-spark-jupyter-spark-sql.md#jupyter)</ept>.",
      "nodes": [
        {
          "content": "<ph id=\"ph2\">[AZURE.IMPORTANT]</ph><ph id=\"ph3\"/> Zeppelin notebook for HDInsight Spark cluster is an offering just to showcase how to use Zeppelin in an Azure HDInsight Spark environment.",
          "pos": [
            0,
            188
          ]
        },
        {
          "content": "If you want to use notebooks to work with HDInsight Spark, we recommend that you use Jupyter notebooks instead.",
          "pos": [
            189,
            300
          ]
        },
        {
          "content": "Jupyter notebooks also provide different kernel options, such as Scala, and will continue to have feature improvements.",
          "pos": [
            301,
            420
          ]
        },
        {
          "content": "For instructions on how to use Jupyter notebooks with HDInsight spark, see <bpt id=\"p1\">[</bpt>Run Spark SQL queries using a Jupyter notebook<ept id=\"p1\">](hdinsight-apache-spark-jupyter-spark-sql.md#jupyter)</ept>.",
          "pos": [
            421,
            636
          ]
        }
      ]
    },
    {
      "pos": [
        1264,
        1282
      ],
      "content": "<bpt id=\"p2\">**</bpt>Prerequisites:<ept id=\"p2\">**</ept>"
    },
    {
      "pos": [
        1286,
        1486
      ],
      "content": "Before you begin this tutorial, you must have an Azure subscription. See <bpt id=\"p3\">[</bpt>Get Azure free trial<ept id=\"p3\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
      "nodes": [
        {
          "content": "Before you begin this tutorial, you must have an Azure subscription.",
          "pos": [
            0,
            68
          ]
        },
        {
          "content": "See <bpt id=\"p3\">[</bpt>Get Azure free trial<ept id=\"p3\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
          "pos": [
            69,
            238
          ]
        }
      ]
    },
    {
      "pos": [
        1489,
        1632
      ],
      "content": "An Apache Spark cluster. For instructions, see <bpt id=\"p4\">[</bpt>Create Apache Spark clusters in Azure HDInsight<ept id=\"p4\">](hdinsight-apache-spark-provision-clusters.md)</ept>.",
      "nodes": [
        {
          "content": "An Apache Spark cluster.",
          "pos": [
            0,
            24
          ]
        },
        {
          "content": "For instructions, see <bpt id=\"p4\">[</bpt>Create Apache Spark clusters in Azure HDInsight<ept id=\"p4\">](hdinsight-apache-spark-provision-clusters.md)</ept>.",
          "pos": [
            25,
            181
          ]
        }
      ]
    },
    {
      "pos": [
        1635,
        1857
      ],
      "content": "An SSH client. For Linux and Unix distributions or Macintosh OS X, the <ph id=\"ph4\">`ssh`</ph><ph id=\"ph5\"/> command is provided with the operating system. For Windows, we recommend <bpt id=\"p5\">[</bpt>PuTTY<ept id=\"p5\">](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html)</ept>",
      "nodes": [
        {
          "content": "An SSH client.",
          "pos": [
            0,
            14
          ]
        },
        {
          "content": "For Linux and Unix distributions or Macintosh OS X, the <ph id=\"ph4\">`ssh`</ph><ph id=\"ph5\"/> command is provided with the operating system.",
          "pos": [
            15,
            155
          ]
        },
        {
          "content": "For Windows, we recommend <bpt id=\"p5\">[</bpt>PuTTY<ept id=\"p5\">](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html)</ept>",
          "pos": [
            156,
            292
          ]
        }
      ]
    },
    {
      "pos": [
        1865,
        2021
      ],
      "content": "<ph id=\"ph6\">[AZURE.NOTE]</ph><ph id=\"ph7\"/> If you want to use an SSH client other than <ph id=\"ph8\">`ssh`</ph><ph id=\"ph9\"/> or PuTTY, please consult the documentation for your client on how to establish an SSH tunnel."
    },
    {
      "pos": [
        2025,
        2082
      ],
      "content": "A web browser that can be configured to use a SOCKS proxy"
    },
    {
      "pos": [
        2086,
        2232
      ],
      "content": "<bpt id=\"p6\">__</bpt>(optional)<ept id=\"p6\">__</ept>: A plugin such as <bpt id=\"p7\">[</bpt>FoxyProxy<ept id=\"p7\">](http://getfoxyproxy.org/,)</ept><ph id=\"ph10\"/> that can apply rules that only route specific requests through the tunnel."
    },
    {
      "pos": [
        2240,
        2427
      ],
      "content": "<ph id=\"ph11\">[AZURE.WARNING]</ph><ph id=\"ph12\"/> Without a plugin such as FoxyProxy, all requests made through the browser may be routed through the tunnel. This can result in slower loading of web pages in your browser.",
      "nodes": [
        {
          "content": "<ph id=\"ph11\">[AZURE.WARNING]</ph><ph id=\"ph12\"/> Without a plugin such as FoxyProxy, all requests made through the browser may be routed through the tunnel.",
          "pos": [
            0,
            157
          ]
        },
        {
          "content": "This can result in slower loading of web pages in your browser.",
          "pos": [
            158,
            221
          ]
        }
      ]
    },
    {
      "pos": [
        2432,
        2476
      ],
      "content": "Install Zeppelin as part of cluster creation"
    },
    {
      "pos": [
        2478,
        2832
      ],
      "content": "You can install Zeppelin on a Spark cluster using script action. Script action uses custom scripts to install components on the cluster that are not available by default. The custom script to install Zeppelin on a Spark cluster is available at <bpt id=\"p8\">**</bpt>https://hdiconfigactions.blob.core.windows.net/linuxincubatorzeppelinv01/install-zeppelin-spark151-v01.sh<ept id=\"p8\">**</ept>.",
      "nodes": [
        {
          "content": "You can install Zeppelin on a Spark cluster using script action.",
          "pos": [
            0,
            64
          ]
        },
        {
          "content": "Script action uses custom scripts to install components on the cluster that are not available by default.",
          "pos": [
            65,
            170
          ]
        },
        {
          "content": "The custom script to install Zeppelin on a Spark cluster is available at <bpt id=\"p8\">**</bpt>https://hdiconfigactions.blob.core.windows.net/linuxincubatorzeppelinv01/install-zeppelin-spark151-v01.sh<ept id=\"p8\">**</ept>.",
          "pos": [
            171,
            392
          ]
        }
      ]
    },
    {
      "pos": [
        2838,
        2860
      ],
      "content": "Using the Azure Portal"
    },
    {
      "pos": [
        2862,
        3167
      ],
      "content": "For instructions on how to use HDInsight .NET SDK to run script action to install Zeppelin, see <bpt id=\"p9\">[</bpt>Customize HDInsight clusters using Script Action<ept id=\"p9\">](hdinsight-hadoop-customize-cluster-linux.md#use-a-script-action-from-the-azure-portal)</ept>. You must make a couple of changes to the instructions in that article.",
      "nodes": [
        {
          "content": "For instructions on how to use HDInsight .NET SDK to run script action to install Zeppelin, see <bpt id=\"p9\">[</bpt>Customize HDInsight clusters using Script Action<ept id=\"p9\">](hdinsight-hadoop-customize-cluster-linux.md#use-a-script-action-from-the-azure-portal)</ept>.",
          "pos": [
            0,
            272
          ]
        },
        {
          "content": "You must make a couple of changes to the instructions in that article.",
          "pos": [
            273,
            343
          ]
        }
      ]
    },
    {
      "pos": [
        3171,
        3351
      ],
      "content": "You must use the script for installing Zeppelin. The script to use is <bpt id=\"p10\">**</bpt>https://hdiconfigactions.blob.core.windows.net/linuxincubatorzeppelinv01/install-zeppelin-spark151-v01.sh<ept id=\"p10\">**</ept>.",
      "nodes": [
        {
          "content": "You must use the script for installing Zeppelin.",
          "pos": [
            0,
            48
          ]
        },
        {
          "content": "The script to use is <bpt id=\"p10\">**</bpt>https://hdiconfigactions.blob.core.windows.net/linuxincubatorzeppelinv01/install-zeppelin-spark151-v01.sh<ept id=\"p10\">**</ept>.",
          "pos": [
            49,
            220
          ]
        }
      ]
    },
    {
      "pos": [
        3355,
        3407
      ],
      "content": "You must run the script action only on the headnode."
    },
    {
      "pos": [
        3411,
        3451
      ],
      "content": "The script does not need any parameters."
    },
    {
      "pos": [
        3458,
        3482
      ],
      "content": "Using HDInsight .NET SDK"
    },
    {
      "pos": [
        3484,
        3794
      ],
      "content": "For instructions on how to use HDInsight .NET SDK to run script action to install Zeppelin, see <bpt id=\"p11\">[</bpt>Customize HDInsight clusters using Script Action<ept id=\"p11\">](hdinsight-hadoop-customize-cluster-linux.md#use-a-script-action-from-the-hdinsight-net-sdk)</ept>. You must make a couple of changes to the instructions in that article.",
      "nodes": [
        {
          "content": "For instructions on how to use HDInsight .NET SDK to run script action to install Zeppelin, see <bpt id=\"p11\">[</bpt>Customize HDInsight clusters using Script Action<ept id=\"p11\">](hdinsight-hadoop-customize-cluster-linux.md#use-a-script-action-from-the-hdinsight-net-sdk)</ept>.",
          "pos": [
            0,
            279
          ]
        },
        {
          "content": "You must make a couple of changes to the instructions in that article.",
          "pos": [
            280,
            350
          ]
        }
      ]
    },
    {
      "pos": [
        3798,
        3978
      ],
      "content": "You must use the script for installing Zeppelin. The script to use is <bpt id=\"p12\">**</bpt>https://hdiconfigactions.blob.core.windows.net/linuxincubatorzeppelinv01/install-zeppelin-spark151-v01.sh<ept id=\"p12\">**</ept>.",
      "nodes": [
        {
          "content": "You must use the script for installing Zeppelin.",
          "pos": [
            0,
            48
          ]
        },
        {
          "content": "The script to use is <bpt id=\"p12\">**</bpt>https://hdiconfigactions.blob.core.windows.net/linuxincubatorzeppelinv01/install-zeppelin-spark151-v01.sh<ept id=\"p12\">**</ept>.",
          "pos": [
            49,
            220
          ]
        }
      ]
    },
    {
      "pos": [
        3982,
        4022
      ],
      "content": "The script does not need any parameters."
    },
    {
      "pos": [
        4027,
        4074
      ],
      "content": "Set the cluster type you are creating to Spark."
    },
    {
      "pos": [
        4080,
        4102
      ],
      "content": "Using Azure PowerShell"
    },
    {
      "pos": [
        4104,
        4369
      ],
      "content": "Use the following PowerShell snippet to create a Spark cluster on HDInsight Linux with Zeppelin installed. Make sure you have PowerShell installed before you proceed. See <bpt id=\"p13\">[</bpt>Install and configure Azure PowerShell<ept id=\"p13\">](../powershell-install-configure.md)</ept><ph id=\"ph13\"/> for instructions.",
      "nodes": [
        {
          "content": "Use the following PowerShell snippet to create a Spark cluster on HDInsight Linux with Zeppelin installed.",
          "pos": [
            0,
            106
          ]
        },
        {
          "content": "Make sure you have PowerShell installed before you proceed.",
          "pos": [
            107,
            166
          ]
        },
        {
          "content": "See <bpt id=\"p13\">[</bpt>Install and configure Azure PowerShell<ept id=\"p13\">](../powershell-install-configure.md)</ept><ph id=\"ph13\"/> for instructions.",
          "pos": [
            167,
            320
          ]
        }
      ]
    },
    {
      "pos": [
        6238,
        6288
      ],
      "content": "Set up SSH tunneling to access a Zeppelin notebook"
    },
    {
      "pos": [
        6290,
        6500
      ],
      "content": "You will use SSH tunnels to access the Zeppelin notebooks running on Spark cluster on HDInsight Linux. The steps below demonstrate how to create an SSH tunnel using ssh command line (Linux) and PuTTY (Windows).",
      "nodes": [
        {
          "content": "You will use SSH tunnels to access the Zeppelin notebooks running on Spark cluster on HDInsight Linux.",
          "pos": [
            0,
            102
          ]
        },
        {
          "content": "The steps below demonstrate how to create an SSH tunnel using ssh command line (Linux) and PuTTY (Windows).",
          "pos": [
            103,
            210
          ]
        }
      ]
    },
    {
      "pos": [
        6506,
        6551
      ],
      "content": "Create a tunnel using the SSH command (Linux)"
    },
    {
      "pos": [
        6553,
        6761
      ],
      "content": "Use the following command to create an SSH tunnel using the <ph id=\"ph14\">`ssh`</ph><ph id=\"ph15\"/> command. Replace <bpt id=\"p14\">__</bpt>USERNAME<ept id=\"p14\">__</ept><ph id=\"ph16\"/> with an SSH user for your HDInsight cluster, and replace <bpt id=\"p15\">__</bpt>CLUSTERNAME<ept id=\"p15\">__</ept><ph id=\"ph17\"/> with the name of your HDInsight cluster",
      "nodes": [
        {
          "content": "Use the following command to create an SSH tunnel using the <ph id=\"ph14\">`ssh`</ph><ph id=\"ph15\"/> command.",
          "pos": [
            0,
            108
          ]
        },
        {
          "content": "Replace <bpt id=\"p14\">__</bpt>USERNAME<ept id=\"p14\">__</ept><ph id=\"ph16\"/> with an SSH user for your HDInsight cluster, and replace <bpt id=\"p15\">__</bpt>CLUSTERNAME<ept id=\"p15\">__</ept><ph id=\"ph17\"/> with the name of your HDInsight cluster",
          "pos": [
            109,
            352
          ]
        }
      ]
    },
    {
      "pos": [
        6833,
        6939
      ],
      "content": "This creates a connection that routes traffic to local port 9876 to the cluster over SSH. The options are:",
      "nodes": [
        {
          "content": "This creates a connection that routes traffic to local port 9876 to the cluster over SSH.",
          "pos": [
            0,
            89
          ]
        },
        {
          "content": "The options are:",
          "pos": [
            90,
            106
          ]
        }
      ]
    },
    {
      "pos": [
        6943,
        7014
      ],
      "content": "<bpt id=\"p16\">**</bpt>D 9876<ept id=\"p16\">**</ept><ph id=\"ph18\"/> - The local port that will route traffic through the tunnel."
    },
    {
      "pos": [
        7018,
        7080
      ],
      "content": "<bpt id=\"p17\">**</bpt>C<ept id=\"p17\">**</ept><ph id=\"ph19\"/> - Compress all data, because web traffic is mostly text."
    },
    {
      "pos": [
        7084,
        7133
      ],
      "content": "<bpt id=\"p18\">**</bpt>2<ept id=\"p18\">**</ept><ph id=\"ph20\"/> - Force SSH to try protocol version 2 only."
    },
    {
      "pos": [
        7137,
        7156
      ],
      "content": "<bpt id=\"p19\">**</bpt>q<ept id=\"p19\">**</ept><ph id=\"ph21\"/> - Quiet mode."
    },
    {
      "pos": [
        7160,
        7235
      ],
      "content": "<bpt id=\"p20\">**</bpt>T<ept id=\"p20\">**</ept><ph id=\"ph22\"/> - Disable pseudo-tty allocation, since we are just forwarding a port."
    },
    {
      "pos": [
        7239,
        7309
      ],
      "content": "<bpt id=\"p21\">**</bpt>n<ept id=\"p21\">**</ept><ph id=\"ph23\"/> - Prevent reading of STDIN, since we are just forwarding a port."
    },
    {
      "pos": [
        7313,
        7390
      ],
      "content": "<bpt id=\"p22\">**</bpt>N<ept id=\"p22\">**</ept><ph id=\"ph24\"/> - Do not execute a remote command, since we are just forwarding a port."
    },
    {
      "pos": [
        7394,
        7424
      ],
      "content": "<bpt id=\"p23\">**</bpt>f<ept id=\"p23\">**</ept><ph id=\"ph25\"/> - Run in the background."
    },
    {
      "pos": [
        7426,
        7553
      ],
      "content": "If you configured the cluster with an SSH key, you may need use the <ph id=\"ph26\">`-i`</ph><ph id=\"ph27\"/> parameter and specify the path to the private SSH key."
    },
    {
      "pos": [
        7555,
        7732
      ],
      "content": "Once the command finishes, traffic sent to port 9876 on the local computer will be routed over Secure Sockets Layer (SSL) to the cluster head node and appear to originate there."
    },
    {
      "pos": [
        7738,
        7775
      ],
      "content": "Create a tunnel using PuTTY (Windows)"
    },
    {
      "pos": [
        7777,
        7837
      ],
      "content": "Use the following steps to create an SSH tunnel using PuTTY."
    },
    {
      "pos": [
        7842,
        8084
      ],
      "content": "Open PuTTY, and enter your connection information. If you are not familiar with PuTTY, see <bpt id=\"p24\">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id=\"p24\">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept><ph id=\"ph28\"/> for information on how to use it with HDInsight.",
      "nodes": [
        {
          "content": "Open PuTTY, and enter your connection information.",
          "pos": [
            0,
            50
          ]
        },
        {
          "content": "If you are not familiar with PuTTY, see <bpt id=\"p24\">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id=\"p24\">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept><ph id=\"ph28\"/> for information on how to use it with HDInsight.",
          "pos": [
            51,
            297
          ]
        }
      ]
    },
    {
      "pos": [
        8089,
        8211
      ],
      "content": "In the <bpt id=\"p25\">**</bpt>Category<ept id=\"p25\">**</ept><ph id=\"ph29\"/> section to the left of the dialog, expand <bpt id=\"p26\">**</bpt>Connection<ept id=\"p26\">**</ept>, expand <bpt id=\"p27\">**</bpt>SSH<ept id=\"p27\">**</ept>, and then select <bpt id=\"p28\">**</bpt>Tunnels<ept id=\"p28\">**</ept>."
    },
    {
      "pos": [
        8216,
        8306
      ],
      "content": "Provide the following information on the <bpt id=\"p29\">**</bpt>Options controlling SSH port forwarding<ept id=\"p29\">**</ept><ph id=\"ph30\"/> form:"
    },
    {
      "pos": [
        8314,
        8403
      ],
      "content": "<bpt id=\"p30\">**</bpt>Source port<ept id=\"p30\">**</ept><ph id=\"ph31\"/> - The port on the client that you wish to forward. For example, <bpt id=\"p31\">**</bpt>9876<ept id=\"p31\">**</ept>.",
      "nodes": [
        {
          "content": "<bpt id=\"p30\">**</bpt>Source port<ept id=\"p30\">**</ept><ph id=\"ph31\"/> - The port on the client that you wish to forward.",
          "pos": [
            0,
            121
          ]
        },
        {
          "content": "For example, <bpt id=\"p31\">**</bpt>9876<ept id=\"p31\">**</ept>.",
          "pos": [
            122,
            184
          ]
        }
      ]
    },
    {
      "pos": [
        8411,
        8534
      ],
      "content": "<bpt id=\"p32\">**</bpt>Destination<ept id=\"p32\">**</ept><ph id=\"ph32\"/> - The SSH address for the Linux-based HDInsight cluster. For example, <bpt id=\"p33\">**</bpt>mycluster-ssh.azurehdinsight.net<ept id=\"p33\">**</ept>.",
      "nodes": [
        {
          "content": "<bpt id=\"p32\">**</bpt>Destination<ept id=\"p32\">**</ept><ph id=\"ph32\"/> - The SSH address for the Linux-based HDInsight cluster.",
          "pos": [
            0,
            127
          ]
        },
        {
          "content": "For example, <bpt id=\"p33\">**</bpt>mycluster-ssh.azurehdinsight.net<ept id=\"p33\">**</ept>.",
          "pos": [
            128,
            218
          ]
        }
      ]
    },
    {
      "pos": [
        8542,
        8592
      ],
      "content": "<bpt id=\"p34\">**</bpt>Dynamic<ept id=\"p34\">**</ept><ph id=\"ph33\"/> - Enables dynamic SOCKS proxy routing."
    },
    {
      "pos": [
        8598,
        8697
      ],
      "content": "<ph id=\"ph34\">![</ph>image of tunneling options<ph id=\"ph35\">](./media/hdinsight-apache-spark-use-zeppelin-notebook/puttytunnel.png)</ph>"
    },
    {
      "pos": [
        8702,
        8787
      ],
      "content": "Click <bpt id=\"p35\">**</bpt>Add<ept id=\"p35\">**</ept><ph id=\"ph36\"/> to add the settings, and then click <bpt id=\"p36\">**</bpt>Open<ept id=\"p36\">**</ept><ph id=\"ph37\"/> to open an SSH connection."
    },
    {
      "pos": [
        8792,
        8886
      ],
      "content": "When prompted, log in to the server. This will establish an SSH session and enable the tunnel.",
      "nodes": [
        {
          "content": "When prompted, log in to the server.",
          "pos": [
            0,
            36
          ]
        },
        {
          "content": "This will establish an SSH session and enable the tunnel.",
          "pos": [
            37,
            94
          ]
        }
      ]
    },
    {
      "pos": [
        8892,
        8924
      ],
      "content": "Use the tunnel from your browser"
    },
    {
      "pos": [
        8928,
        9256
      ],
      "content": "<ph id=\"ph38\">[AZURE.NOTE]</ph><ph id=\"ph39\"/> The steps in this section use the FireFox browser, as it is freely available for Linux, Unix, Macintosh OS X and Windows systems. Other modern browsers such as Google Chrome, Microsoft Edge, or Apple Safari should work as well; however, the FoxyProxy plugin used in some steps may not be available for all browsers.",
      "nodes": [
        {
          "content": "<ph id=\"ph38\">[AZURE.NOTE]</ph><ph id=\"ph39\"/> The steps in this section use the FireFox browser, as it is freely available for Linux, Unix, Macintosh OS X and Windows systems.",
          "pos": [
            0,
            176
          ]
        },
        {
          "content": "Other modern browsers such as Google Chrome, Microsoft Edge, or Apple Safari should work as well; however, the FoxyProxy plugin used in some steps may not be available for all browsers.",
          "pos": [
            177,
            362
          ]
        }
      ]
    },
    {
      "pos": [
        9261,
        9454
      ],
      "content": "Configure the browser to use <bpt id=\"p37\">**</bpt>localhost:9876<ept id=\"p37\">**</ept><ph id=\"ph40\"/> as a <bpt id=\"p38\">**</bpt>SOCKS v5<ept id=\"p38\">**</ept><ph id=\"ph41\"/> proxy. Here's what the Firefox settings look like. If you used a different port than 9876, change the port to the one you used:",
      "nodes": [
        {
          "content": "Configure the browser to use <bpt id=\"p37\">**</bpt>localhost:9876<ept id=\"p37\">**</ept><ph id=\"ph40\"/> as a <bpt id=\"p38\">**</bpt>SOCKS v5<ept id=\"p38\">**</ept><ph id=\"ph41\"/> proxy.",
          "pos": [
            0,
            182
          ]
        },
        {
          "content": "Here's what the Firefox settings look like.",
          "pos": [
            183,
            226
          ]
        },
        {
          "content": "If you used a different port than 9876, change the port to the one you used:",
          "pos": [
            227,
            303
          ]
        }
      ]
    },
    {
      "pos": [
        9460,
        9552
      ],
      "content": "<ph id=\"ph42\">![</ph>image of Firefox settings<ph id=\"ph43\">](./media/hdinsight-apache-spark-use-zeppelin-notebook/socks.png)</ph>"
    },
    {
      "pos": [
        9560,
        9729
      ],
      "content": "<ph id=\"ph44\">[AZURE.NOTE]</ph><ph id=\"ph45\"/> Selecting <bpt id=\"p39\">**</bpt>Remote DNS<ept id=\"p39\">**</ept><ph id=\"ph46\"/> will resolve Domain Name System (DNS) requests by using the HDInsight cluster. If this is unselected, DNS will be resolved locally.",
      "nodes": [
        {
          "content": "<ph id=\"ph44\">[AZURE.NOTE]</ph><ph id=\"ph45\"/> Selecting <bpt id=\"p39\">**</bpt>Remote DNS<ept id=\"p39\">**</ept><ph id=\"ph46\"/> will resolve Domain Name System (DNS) requests by using the HDInsight cluster.",
          "pos": [
            0,
            205
          ]
        },
        {
          "content": "If this is unselected, DNS will be resolved locally.",
          "pos": [
            206,
            258
          ]
        }
      ]
    },
    {
      "pos": [
        9734,
        10031
      ],
      "content": "Verify that traffic is being routed through the tunnel by vising a site such as <bpt id=\"p40\">[</bpt>http://www.whatismyip.com/<ept id=\"p40\">](http://www.whatismyip.com/)</ept><ph id=\"ph47\"/> with the proxy settings enabled and disabled in Firefox. While the settings are enabled, the IP address will be for a machine in the Microsoft Azure datacenter.",
      "nodes": [
        {
          "content": "Verify that traffic is being routed through the tunnel by vising a site such as <bpt id=\"p40\">[</bpt>http://www.whatismyip.com/<ept id=\"p40\">](http://www.whatismyip.com/)</ept><ph id=\"ph47\"/> with the proxy settings enabled and disabled in Firefox.",
          "pos": [
            0,
            248
          ]
        },
        {
          "content": "While the settings are enabled, the IP address will be for a machine in the Microsoft Azure datacenter.",
          "pos": [
            249,
            352
          ]
        }
      ]
    },
    {
      "pos": [
        10037,
        10055
      ],
      "content": "Browser extensions"
    },
    {
      "pos": [
        10057,
        10384
      ],
      "content": "While configuring the browser to use the tunnel works, you don't usually want to route all traffic over the tunnel. Browser extensions such as <bpt id=\"p41\">[</bpt>FoxyProxy<ept id=\"p41\">](http://getfoxyproxy.org/)</ept><ph id=\"ph48\"/> support pattern matching for URL requests (FoxyProxy Standard or Plus only), so that only requests for specific URLs will be sent over the tunnel.",
      "nodes": [
        {
          "content": "While configuring the browser to use the tunnel works, you don't usually want to route all traffic over the tunnel.",
          "pos": [
            0,
            115
          ]
        },
        {
          "content": "Browser extensions such as <bpt id=\"p41\">[</bpt>FoxyProxy<ept id=\"p41\">](http://getfoxyproxy.org/)</ept><ph id=\"ph48\"/> support pattern matching for URL requests (FoxyProxy Standard or Plus only), so that only requests for specific URLs will be sent over the tunnel.",
          "pos": [
            116,
            382
          ]
        }
      ]
    },
    {
      "pos": [
        10386,
        10522
      ],
      "content": "If you have installed FoxyProxy Standard, use the following steps to configure it to only forward traffic for HDInsight over the tunnel."
    },
    {
      "pos": [
        10527,
        10650
      ],
      "content": "Open the FoxyProxy extension in your browser. For example, in Firefox, select the FoxyProxy icon next to the address field.",
      "nodes": [
        {
          "content": "Open the FoxyProxy extension in your browser.",
          "pos": [
            0,
            45
          ]
        },
        {
          "content": "For example, in Firefox, select the FoxyProxy icon next to the address field.",
          "pos": [
            46,
            123
          ]
        }
      ]
    },
    {
      "pos": [
        10656,
        10741
      ],
      "content": "<ph id=\"ph49\">![</ph>foxyproxy icon<ph id=\"ph50\">](./media/hdinsight-apache-spark-use-zeppelin-notebook/foxyproxy.png)</ph>"
    },
    {
      "pos": [
        10746,
        10850
      ],
      "content": "Select <bpt id=\"p42\">**</bpt>Add New Proxy<ept id=\"p42\">**</ept>, select the <bpt id=\"p43\">**</bpt>General<ept id=\"p43\">**</ept><ph id=\"ph51\"/> tab, and then enter a proxy name of <bpt id=\"p44\">**</bpt>HDInsightProxy<ept id=\"p44\">**</ept>."
    },
    {
      "pos": [
        10856,
        10946
      ],
      "content": "<ph id=\"ph52\">![</ph>foxyproxy general<ph id=\"ph53\">](./media/hdinsight-apache-spark-use-zeppelin-notebook/foxygeneral.png)</ph>"
    },
    {
      "pos": [
        10951,
        11018
      ],
      "content": "Select the <bpt id=\"p45\">**</bpt>Proxy Details<ept id=\"p45\">**</ept><ph id=\"ph54\"/> tab and populate the following fields:"
    },
    {
      "pos": [
        11026,
        11124
      ],
      "content": "<bpt id=\"p46\">**</bpt>Host or IP Address<ept id=\"p46\">**</ept><ph id=\"ph55\"/> - This is localhost, since we are using an SSH tunnel on the local machine."
    },
    {
      "pos": [
        11132,
        11188
      ],
      "content": "<bpt id=\"p47\">**</bpt>Port<ept id=\"p47\">**</ept><ph id=\"ph56\"/> - This is the port you used for the SSH tunnel."
    },
    {
      "pos": [
        11196,
        11277
      ],
      "content": "<bpt id=\"p48\">**</bpt>SOCKS proxy<ept id=\"p48\">**</ept><ph id=\"ph57\"/> - Select this to enable the browser to use the tunnel as a proxy."
    },
    {
      "pos": [
        11285,
        11354
      ],
      "content": "<bpt id=\"p49\">**</bpt>SOCKS v5<ept id=\"p49\">**</ept><ph id=\"ph58\"/> - Select this to set the required version for the proxy."
    },
    {
      "pos": [
        11360,
        11451
      ],
      "content": "<ph id=\"ph59\">![</ph>foxyproxy proxy<ph id=\"ph60\">](./media/hdinsight-apache-spark-use-zeppelin-notebook/foxyproxyproxy.png)</ph>"
    },
    {
      "pos": [
        11456,
        11589
      ],
      "content": "Select the <bpt id=\"p50\">**</bpt>URL Patterns<ept id=\"p50\">**</ept><ph id=\"ph61\"/> tab, and then select <bpt id=\"p51\">**</bpt>Add New Pattern<ept id=\"p51\">**</ept>. Use the following to define the pattern, and then click <bpt id=\"p52\">**</bpt>OK<ept id=\"p52\">**</ept>:",
      "nodes": [
        {
          "content": "Select the <bpt id=\"p50\">**</bpt>URL Patterns<ept id=\"p50\">**</ept><ph id=\"ph61\"/> tab, and then select <bpt id=\"p51\">**</bpt>Add New Pattern<ept id=\"p51\">**</ept>.",
          "pos": [
            0,
            164
          ]
        },
        {
          "content": "Use the following to define the pattern, and then click <bpt id=\"p52\">**</bpt>OK<ept id=\"p52\">**</ept>:",
          "pos": [
            165,
            268
          ]
        }
      ]
    },
    {
      "pos": [
        11597,
        11684
      ],
      "content": "<bpt id=\"p53\">**</bpt>Pattern Name<ept id=\"p53\">**</ept><ph id=\"ph62\"/> - <bpt id=\"p54\">**</bpt>zeppelinnotebook<ept id=\"p54\">**</ept><ph id=\"ph63\"/> - This is just a friendly name for the pattern."
    },
    {
      "pos": [
        11692,
        12103
      ],
      "content": "<bpt id=\"p55\">**</bpt>URL pattern<ept id=\"p55\">**</ept><ph id=\"ph64\"/> - <bpt id=\"p56\">**</bpt>\\*hn0\\*<ept id=\"p56\">**</ept><ph id=\"ph65\"/> - This defines a pattern that matches the internal fully qualified domain name of endpoint where the Zeppelin notebooks are hosted. Because Zeppelin notebooks are available only on the headnode0 of the cluster, and the endpoint is typically <ph id=\"ph66\">`http://hn0-&lt;string&gt;.internal.cloudapp.net`</ph>, using the pattern <bpt id=\"p57\">**</bpt>hn0<ept id=\"p57\">**</ept><ph id=\"ph67\"/> would ensure that the request is redirected to the Zeppelin endpoint.",
      "nodes": [
        {
          "content": "<bpt id=\"p55\">**</bpt>URL pattern<ept id=\"p55\">**</ept><ph id=\"ph64\"/> - <bpt id=\"p56\">**</bpt>\\*hn0\\*<ept id=\"p56\">**</ept><ph id=\"ph65\"/> - This defines a pattern that matches the internal fully qualified domain name of endpoint where the Zeppelin notebooks are hosted.",
          "pos": [
            0,
            271
          ]
        },
        {
          "content": "Because Zeppelin notebooks are available only on the headnode0 of the cluster, and the endpoint is typically <ph id=\"ph66\">`http://hn0-&lt;string&gt;.internal.cloudapp.net`</ph>, using the pattern <bpt id=\"p57\">**</bpt>hn0<ept id=\"p57\">**</ept><ph id=\"ph67\"/> would ensure that the request is redirected to the Zeppelin endpoint.",
          "pos": [
            272,
            601
          ]
        }
      ]
    },
    {
      "pos": [
        12113,
        12203
      ],
      "content": "<ph id=\"ph68\">![</ph>foxyproxy pattern<ph id=\"ph69\">](./media/hdinsight-apache-spark-use-zeppelin-notebook/foxypattern.png)</ph>"
    },
    {
      "pos": [
        12208,
        12267
      ],
      "content": "Click <bpt id=\"p58\">**</bpt>OK<ept id=\"p58\">**</ept><ph id=\"ph70\"/> to add the proxy and close <bpt id=\"p59\">**</bpt>Proxy Settings<ept id=\"p59\">**</ept>."
    },
    {
      "pos": [
        12272,
        12427
      ],
      "content": "At the top of the FoxyProxy dialog, change <bpt id=\"p60\">**</bpt>Select Mode<ept id=\"p60\">**</ept><ph id=\"ph71\"/> to <bpt id=\"p61\">**</bpt>Use proxies based on their pre-defined patterns and priorities<ept id=\"p61\">**</ept>, and then click <bpt id=\"p62\">**</bpt>Close<ept id=\"p62\">**</ept>."
    },
    {
      "pos": [
        12433,
        12526
      ],
      "content": "<ph id=\"ph72\">![</ph>foxyproxy select mode<ph id=\"ph73\">](./media/hdinsight-apache-spark-use-zeppelin-notebook/selectmode.png)</ph>"
    },
    {
      "pos": [
        12528,
        12665
      ],
      "content": "After following these steps, only requests for URLs that contain the string <bpt id=\"p63\">__</bpt>internal.cloudapp.net<ept id=\"p63\">__</ept><ph id=\"ph74\"/> will be routed over the SSL tunnel."
    },
    {
      "pos": [
        12671,
        12699
      ],
      "content": "Access the Zeppelin notebook"
    },
    {
      "pos": [
        12701,
        12846
      ],
      "content": "Once you have SSH tunneling setup, you can use the following steps to access Zeppelin notebook on the Spark cluster by following the steps below."
    },
    {
      "pos": [
        12851,
        12901
      ],
      "content": "From the web browser, open the following endpoint:"
    },
    {
      "pos": [
        12941,
        12966
      ],
      "content": "<bpt id=\"p64\">**</bpt>hn0<ept id=\"p64\">**</ept><ph id=\"ph75\"/> denotes headnode0"
    },
    {
      "pos": [
        12973,
        13035
      ],
      "content": "<bpt id=\"p65\">**</bpt>myspar<ept id=\"p65\">**</ept><ph id=\"ph76\"/> is the first six letters of the Spark cluster name."
    },
    {
      "pos": [
        13042,
        13101
      ],
      "content": "<bpt id=\"p66\">**</bpt>9995<ept id=\"p66\">**</ept><ph id=\"ph77\"/> is the port where Zeppelin notebook is accessible."
    },
    {
      "pos": [
        13106,
        13206
      ],
      "content": "Create a new notebook. From the header pane, click <bpt id=\"p67\">**</bpt>Notebook<ept id=\"p67\">**</ept>, and then click <bpt id=\"p68\">**</bpt>Create New Note<ept id=\"p68\">**</ept>.",
      "nodes": [
        {
          "content": "Create a new notebook.",
          "pos": [
            0,
            22
          ]
        },
        {
          "content": "From the header pane, click <bpt id=\"p67\">**</bpt>Notebook<ept id=\"p67\">**</ept>, and then click <bpt id=\"p68\">**</bpt>Create New Note<ept id=\"p68\">**</ept>.",
          "pos": [
            23,
            180
          ]
        }
      ]
    },
    {
      "pos": [
        13212,
        13376
      ],
      "content": "<ph id=\"ph78\">![</ph>Create a new Zeppelin notebook<ph id=\"ph79\">](./media/hdinsight-apache-spark-zeppelin-notebook-jupyter-spark-sql-v1/hdispark.createnewnote.png \"Create a new Zeppelin notebook\")</ph>"
    },
    {
      "pos": [
        13382,
        13533
      ],
      "content": "On the same page, under the <bpt id=\"p69\">**</bpt>Notebook<ept id=\"p69\">**</ept><ph id=\"ph80\"/> heading, you should see a new notebook with the name starting with <bpt id=\"p70\">**</bpt>Note XXXXXXXXX<ept id=\"p70\">**</ept>. Click the new notebook.",
      "nodes": [
        {
          "content": "On the same page, under the <bpt id=\"p69\">**</bpt>Notebook<ept id=\"p69\">**</ept><ph id=\"ph80\"/> heading, you should see a new notebook with the name starting with <bpt id=\"p70\">**</bpt>Note XXXXXXXXX<ept id=\"p70\">**</ept>.",
          "pos": [
            0,
            222
          ]
        },
        {
          "content": "Click the new notebook.",
          "pos": [
            223,
            246
          ]
        }
      ]
    },
    {
      "pos": [
        13538,
        13773
      ],
      "content": "On the web page for the new notebook, click the heading, and change the name of the notebook if you want to. Press ENTER to save the name change. Also, make sure the notebook header shows a <bpt id=\"p71\">**</bpt>Connected<ept id=\"p71\">**</ept><ph id=\"ph81\"/> status in the top-right corner.",
      "nodes": [
        {
          "content": "On the web page for the new notebook, click the heading, and change the name of the notebook if you want to.",
          "pos": [
            0,
            108
          ]
        },
        {
          "content": "Press ENTER to save the name change.",
          "pos": [
            109,
            145
          ]
        },
        {
          "content": "Also, make sure the notebook header shows a <bpt id=\"p71\">**</bpt>Connected<ept id=\"p71\">**</ept><ph id=\"ph81\"/> status in the top-right corner.",
          "pos": [
            146,
            290
          ]
        }
      ]
    },
    {
      "pos": [
        13779,
        13935
      ],
      "content": "<ph id=\"ph82\">![</ph>Zeppelin notebook status<ph id=\"ph83\">](./media/hdinsight-apache-spark-zeppelin-notebook-jupyter-spark-sql-v1/hdispark.newnote.connected.png \"Zeppelin notebook status\")</ph>"
    },
    {
      "pos": [
        13940,
        14151
      ],
      "content": "Load sample data into a temporary table. When you create a Spark cluster in HDInsight, the sample data file, <bpt id=\"p72\">**</bpt>hvac.csv<ept id=\"p72\">**</ept>, is copied to the associated storage account under <bpt id=\"p73\">**</bpt>\\HdiSamples\\SensorSampleData\\hvac<ept id=\"p73\">**</ept>.",
      "nodes": [
        {
          "content": "Load sample data into a temporary table.",
          "pos": [
            0,
            40
          ]
        },
        {
          "content": "When you create a Spark cluster in HDInsight, the sample data file, <bpt id=\"p72\">**</bpt>hvac.csv<ept id=\"p72\">**</ept>, is copied to the associated storage account under <bpt id=\"p73\">**</bpt>\\HdiSamples\\SensorSampleData\\hvac<ept id=\"p73\">**</ept>.",
          "pos": [
            41,
            291
          ]
        }
      ]
    },
    {
      "pos": [
        14157,
        14256
      ],
      "content": "In the empty paragraph that is created by default in the new notebook, paste the following snippet."
    },
    {
      "pos": [
        15009,
        15303
      ],
      "content": "Press <bpt id=\"p74\">**</bpt>SHIFT + ENTER<ept id=\"p74\">**</ept><ph id=\"ph84\"/> or click the <bpt id=\"p75\">**</bpt>Play<ept id=\"p75\">**</ept><ph id=\"ph85\"/> button for the paragraph to run the snippet. The status on the right-corner of the paragraph should progress from READY, PENDING, RUNNING to FINISHED. The output shows up at the bottom of the same paragraph. The screenshot looks like the following:",
      "nodes": [
        {
          "content": "Press <bpt id=\"p74\">**</bpt>SHIFT + ENTER<ept id=\"p74\">**</ept><ph id=\"ph84\"/> or click the <bpt id=\"p75\">**</bpt>Play<ept id=\"p75\">**</ept><ph id=\"ph85\"/> button for the paragraph to run the snippet.",
          "pos": [
            0,
            200
          ]
        },
        {
          "content": "The status on the right-corner of the paragraph should progress from READY, PENDING, RUNNING to FINISHED.",
          "pos": [
            201,
            306
          ]
        },
        {
          "content": "The output shows up at the bottom of the same paragraph.",
          "pos": [
            307,
            363
          ]
        },
        {
          "content": "The screenshot looks like the following:",
          "pos": [
            364,
            404
          ]
        }
      ]
    },
    {
      "pos": [
        15309,
        15498
      ],
      "content": "<ph id=\"ph86\">![</ph>Create a temporary table from raw data<ph id=\"ph87\">](./media/hdinsight-apache-spark-zeppelin-notebook-jupyter-spark-sql-v1/hdispark.note.loaddataintotable.png \"Create a temporary table from raw data\")</ph>"
    },
    {
      "pos": [
        15504,
        15639
      ],
      "content": "You can also provide a title to each paragraph. From the right-hand corner, click the <bpt id=\"p76\">**</bpt>Settings<ept id=\"p76\">**</ept><ph id=\"ph88\"/> icon, and then click <bpt id=\"p77\">**</bpt>Show title<ept id=\"p77\">**</ept>.",
      "nodes": [
        {
          "content": "You can also provide a title to each paragraph.",
          "pos": [
            0,
            47
          ]
        },
        {
          "content": "From the right-hand corner, click the <bpt id=\"p76\">**</bpt>Settings<ept id=\"p76\">**</ept><ph id=\"ph88\"/> icon, and then click <bpt id=\"p77\">**</bpt>Show title<ept id=\"p77\">**</ept>.",
          "pos": [
            48,
            230
          ]
        }
      ]
    },
    {
      "pos": [
        15644,
        15907
      ],
      "content": "You can now run Spark SQL statements on the <bpt id=\"p78\">**</bpt>hvac<ept id=\"p78\">**</ept><ph id=\"ph89\"/> table. Paste the following query in a new paragraph. The query retrieves the building ID and the difference between the target and actual temperatures for each building on a given date. Press <bpt id=\"p79\">**</bpt>SHIFT + ENTER<ept id=\"p79\">**</ept>.",
      "nodes": [
        {
          "content": "You can now run Spark SQL statements on the <bpt id=\"p78\">**</bpt>hvac<ept id=\"p78\">**</ept><ph id=\"ph89\"/> table.",
          "pos": [
            0,
            114
          ]
        },
        {
          "content": "Paste the following query in a new paragraph.",
          "pos": [
            115,
            160
          ]
        },
        {
          "content": "The query retrieves the building ID and the difference between the target and actual temperatures for each building on a given date.",
          "pos": [
            161,
            293
          ]
        },
        {
          "content": "Press <bpt id=\"p79\">**</bpt>SHIFT + ENTER<ept id=\"p79\">**</ept>.",
          "pos": [
            294,
            358
          ]
        }
      ]
    },
    {
      "pos": [
        16049,
        16236
      ],
      "content": "The <bpt id=\"p80\">**</bpt>%sql<ept id=\"p80\">**</ept><ph id=\"ph90\"/> statement at the beginning tells the notebook to use the Spark  SQL interpreter. You can look at the defined interpreters from the <bpt id=\"p81\">**</bpt>Interpreter<ept id=\"p81\">**</ept><ph id=\"ph91\"/> tab in the notebook header.",
      "nodes": [
        {
          "content": "The <bpt id=\"p80\">**</bpt>%sql<ept id=\"p80\">**</ept><ph id=\"ph90\"/> statement at the beginning tells the notebook to use the Spark  SQL interpreter.",
          "pos": [
            0,
            148
          ]
        },
        {
          "content": "You can look at the defined interpreters from the <bpt id=\"p81\">**</bpt>Interpreter<ept id=\"p81\">**</ept><ph id=\"ph91\"/> tab in the notebook header.",
          "pos": [
            149,
            297
          ]
        }
      ]
    },
    {
      "pos": [
        16242,
        16284
      ],
      "content": "The following screenshot shows the output."
    },
    {
      "pos": [
        16290,
        16488
      ],
      "content": "<ph id=\"ph92\">![</ph>Run a Spark SQL statement using the notebook<ph id=\"ph93\">](./media/hdinsight-apache-spark-zeppelin-notebook-jupyter-spark-sql-v1/hdispark.note.sparksqlquery1.png \"Run a Spark SQL statement using the notebook\")</ph>"
    },
    {
      "pos": [
        16495,
        16794
      ],
      "content": "Click the display options (highlighted in rectangle) to switch between different representations for the same output. Click <bpt id=\"p82\">**</bpt>Settings<ept id=\"p82\">**</ept><ph id=\"ph94\"/> to choose what consitutes the key and values in the output. The screen capture above uses <bpt id=\"p83\">**</bpt>buildingID<ept id=\"p83\">**</ept><ph id=\"ph95\"/> as the key and the average of <bpt id=\"p84\">**</bpt>temp_diff<ept id=\"p84\">**</ept><ph id=\"ph96\"/> as the value.",
      "nodes": [
        {
          "content": "Click the display options (highlighted in rectangle) to switch between different representations for the same output.",
          "pos": [
            0,
            117
          ]
        },
        {
          "content": "Click <bpt id=\"p82\">**</bpt>Settings<ept id=\"p82\">**</ept><ph id=\"ph94\"/> to choose what consitutes the key and values in the output.",
          "pos": [
            118,
            251
          ]
        },
        {
          "content": "The screen capture above uses <bpt id=\"p83\">**</bpt>buildingID<ept id=\"p83\">**</ept><ph id=\"ph95\"/> as the key and the average of <bpt id=\"p84\">**</bpt>temp_diff<ept id=\"p84\">**</ept><ph id=\"ph96\"/> as the value.",
          "pos": [
            252,
            464
          ]
        }
      ]
    },
    {
      "pos": [
        16804,
        17109
      ],
      "content": "You can also run Spark SQL statements using variables in the query. The next snippet shows how to define a variable, <bpt id=\"p85\">**</bpt>Temp<ept id=\"p85\">**</ept>, in the query with the possible values you want to query with. When you first run the query, a drop-down is automatically populated with the values you specified for the variable.",
      "nodes": [
        {
          "content": "You can also run Spark SQL statements using variables in the query.",
          "pos": [
            0,
            67
          ]
        },
        {
          "content": "The next snippet shows how to define a variable, <bpt id=\"p85\">**</bpt>Temp<ept id=\"p85\">**</ept>, in the query with the possible values you want to query with.",
          "pos": [
            68,
            228
          ]
        },
        {
          "content": "When you first run the query, a drop-down is automatically populated with the values you specified for the variable.",
          "pos": [
            229,
            345
          ]
        }
      ]
    },
    {
      "pos": [
        17283,
        17392
      ],
      "content": "Paste this snippet in a new paragraph and press <bpt id=\"p86\">**</bpt>SHIFT + ENTER<ept id=\"p86\">**</ept>. The following screenshot shows the output.",
      "nodes": [
        {
          "content": "Paste this snippet in a new paragraph and press <bpt id=\"p86\">**</bpt>SHIFT + ENTER<ept id=\"p86\">**</ept>.",
          "pos": [
            0,
            106
          ]
        },
        {
          "content": "The following screenshot shows the output.",
          "pos": [
            107,
            149
          ]
        }
      ]
    },
    {
      "pos": [
        17398,
        17596
      ],
      "content": "<ph id=\"ph97\">![</ph>Run a Spark SQL statement using the notebook<ph id=\"ph98\">](./media/hdinsight-apache-spark-zeppelin-notebook-jupyter-spark-sql-v1/hdispark.note.sparksqlquery2.png \"Run a Spark SQL statement using the notebook\")</ph>"
    },
    {
      "pos": [
        17602,
        17908
      ],
      "content": "For subsequent queries, you can select a new value from the drop-down and run the query again. Click <bpt id=\"p87\">**</bpt>Settings<ept id=\"p87\">**</ept><ph id=\"ph99\"/> to choose what consitutes the key and values in the output. The screen capture above uses <bpt id=\"p88\">**</bpt>buildingID<ept id=\"p88\">**</ept><ph id=\"ph100\"/> as the key, the average of <bpt id=\"p89\">**</bpt>temp_diff<ept id=\"p89\">**</ept><ph id=\"ph101\"/> as the value, and <bpt id=\"p90\">**</bpt>targettemp<ept id=\"p90\">**</ept><ph id=\"ph102\"/> as the group.",
      "nodes": [
        {
          "content": "For subsequent queries, you can select a new value from the drop-down and run the query again.",
          "pos": [
            0,
            94
          ]
        },
        {
          "content": "Click <bpt id=\"p87\">**</bpt>Settings<ept id=\"p87\">**</ept><ph id=\"ph99\"/> to choose what consitutes the key and values in the output.",
          "pos": [
            95,
            228
          ]
        },
        {
          "content": "The screen capture above uses <bpt id=\"p88\">**</bpt>buildingID<ept id=\"p88\">**</ept><ph id=\"ph100\"/> as the key, the average of <bpt id=\"p89\">**</bpt>temp_diff<ept id=\"p89\">**</ept><ph id=\"ph101\"/> as the value, and <bpt id=\"p90\">**</bpt>targettemp<ept id=\"p90\">**</ept><ph id=\"ph102\"/> as the group.",
          "pos": [
            229,
            529
          ]
        }
      ]
    },
    {
      "pos": [
        17913,
        18063
      ],
      "content": "Restart the Spark SQL interpreter to exit the application. Click the <bpt id=\"p91\">**</bpt>Interpreter<ept id=\"p91\">**</ept><ph id=\"ph103\"/> tab at the top, and for the Spark interpreter, click <bpt id=\"p92\">**</bpt>Restart<ept id=\"p92\">**</ept>.",
      "nodes": [
        {
          "content": "Restart the Spark SQL interpreter to exit the application.",
          "pos": [
            0,
            58
          ]
        },
        {
          "content": "Click the <bpt id=\"p91\">**</bpt>Interpreter<ept id=\"p91\">**</ept><ph id=\"ph103\"/> tab at the top, and for the Spark interpreter, click <bpt id=\"p92\">**</bpt>Restart<ept id=\"p92\">**</ept>.",
          "pos": [
            59,
            246
          ]
        }
      ]
    },
    {
      "pos": [
        18069,
        18250
      ],
      "content": "<ph id=\"ph104\">![</ph>Restart the Zeppelin intepreter<ph id=\"ph105\">](./media/hdinsight-apache-spark-zeppelin-notebook-jupyter-spark-sql-v1/hdispark.zeppelin.restart.interpreter.png \"Restart the Zeppelin intepreter\")</ph>"
    },
    {
      "pos": [
        18278,
        18286
      ],
      "content": "See also"
    },
    {
      "pos": [
        18291,
        18370
      ],
      "content": "<bpt id=\"p93\">[</bpt>Overview: Apache Spark on Azure HDInsight<ept id=\"p93\">](hdinsight-apache-spark-overview.md)</ept>"
    },
    {
      "pos": [
        18376,
        18385
      ],
      "content": "Scenarios"
    },
    {
      "pos": [
        18389,
        18518
      ],
      "content": "<bpt id=\"p94\">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id=\"p94\">](hdinsight-apache-spark-use-bi-tools.md)</ept>"
    },
    {
      "pos": [
        18522,
        18687
      ],
      "content": "<bpt id=\"p95\">[</bpt>Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data<ept id=\"p95\">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept>"
    },
    {
      "pos": [
        18691,
        18837
      ],
      "content": "<bpt id=\"p96\">[</bpt>Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results<ept id=\"p96\">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept>"
    },
    {
      "pos": [
        18841,
        18974
      ],
      "content": "<bpt id=\"p97\">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id=\"p97\">](hdinsight-apache-spark-eventhub-streaming.md)</ept>"
    },
    {
      "pos": [
        18978,
        19088
      ],
      "content": "<bpt id=\"p98\">[</bpt>Website log analysis using Spark in HDInsight<ept id=\"p98\">](hdinsight-apache-spark-custom-library-website-log-analysis.md)</ept>"
    },
    {
      "pos": [
        19094,
        19121
      ],
      "content": "Create and run applications"
    },
    {
      "pos": [
        19125,
        19227
      ],
      "content": "<bpt id=\"p99\">[</bpt>Create a standalone application using Scala<ept id=\"p99\">](hdinsight-apache-spark-create-standalone-application.md)</ept>"
    },
    {
      "pos": [
        19231,
        19327
      ],
      "content": "<bpt id=\"p100\">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id=\"p100\">](hdinsight-apache-spark-livy-rest-interface.md)</ept>"
    },
    {
      "pos": [
        19333,
        19353
      ],
      "content": "Tools and extensions"
    },
    {
      "pos": [
        19357,
        19496
      ],
      "content": "<bpt id=\"p101\">[</bpt>Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons<ept id=\"p101\">](hdinsight-apache-spark-intellij-tool-plugin.md)</ept>"
    },
    {
      "pos": [
        19500,
        19623
      ],
      "content": "<bpt id=\"p102\">[</bpt>Kernels available for Jupyter notebook in Spark cluster for HDInsight<ept id=\"p102\">](hdinsight-apache-spark-jupyter-notebook-kernels.md)</ept>"
    },
    {
      "pos": [
        19629,
        19645
      ],
      "content": "Manage resources"
    },
    {
      "pos": [
        19649,
        19759
      ],
      "content": "<bpt id=\"p103\">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id=\"p103\">](hdinsight-apache-spark-resource-manager.md)</ept>"
    }
  ],
  "content": "<properties \n    pageTitle=\"Use Zeppelin notebooks with Spark cluster on HDInsight Linux | Azure\" \n    description=\"Step-by-step instructions on how to use Zeppelin notebooks with Spark clusters on HDInsight Linux.\" \n    services=\"hdinsight\" \n    documentationCenter=\"\" \n    authors=\"nitinme\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\"/>\n\n<tags \n    ms.service=\"hdinsight\" \n    ms.workload=\"big-data\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"02/05/2016\" \n    ms.author=\"nitinme\"/>\n\n\n# Use Zeppelin notebooks with Spark cluster on HDInsight (Linux)\n\nLearn how to install Zeppelin notebooks on Spark clusters and how to use the Zeppelin notebooks.\n\n> [AZURE.IMPORTANT] Zeppelin notebook for HDInsight Spark cluster is an offering just to showcase how to use Zeppelin in an Azure HDInsight Spark environment. If you want to use notebooks to work with HDInsight Spark, we recommend that you use Jupyter notebooks instead. Jupyter notebooks also provide different kernel options, such as Scala, and will continue to have feature improvements. For instructions on how to use Jupyter notebooks with HDInsight spark, see [Run Spark SQL queries using a Jupyter notebook](hdinsight-apache-spark-jupyter-spark-sql.md#jupyter). \n\n**Prerequisites:**\n\n* Before you begin this tutorial, you must have an Azure subscription. See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).\n* An Apache Spark cluster. For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-provision-clusters.md).\n* An SSH client. For Linux and Unix distributions or Macintosh OS X, the `ssh` command is provided with the operating system. For Windows, we recommend [PuTTY](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html)\n\n    > [AZURE.NOTE] If you want to use an SSH client other than `ssh` or PuTTY, please consult the documentation for your client on how to establish an SSH tunnel.\n\n* A web browser that can be configured to use a SOCKS proxy\n\n* __(optional)__: A plugin such as [FoxyProxy](http://getfoxyproxy.org/,) that can apply rules that only route specific requests through the tunnel.\n\n    > [AZURE.WARNING] Without a plugin such as FoxyProxy, all requests made through the browser may be routed through the tunnel. This can result in slower loading of web pages in your browser.\n\n## Install Zeppelin as part of cluster creation\n\nYou can install Zeppelin on a Spark cluster using script action. Script action uses custom scripts to install components on the cluster that are not available by default. The custom script to install Zeppelin on a Spark cluster is available at **https://hdiconfigactions.blob.core.windows.net/linuxincubatorzeppelinv01/install-zeppelin-spark151-v01.sh**.\n\n### Using the Azure Portal\n\nFor instructions on how to use HDInsight .NET SDK to run script action to install Zeppelin, see [Customize HDInsight clusters using Script Action](hdinsight-hadoop-customize-cluster-linux.md#use-a-script-action-from-the-azure-portal). You must make a couple of changes to the instructions in that article.\n\n* You must use the script for installing Zeppelin. The script to use is **https://hdiconfigactions.blob.core.windows.net/linuxincubatorzeppelinv01/install-zeppelin-spark151-v01.sh**.\n\n* You must run the script action only on the headnode.\n\n* The script does not need any parameters. \n\n### Using HDInsight .NET SDK\n\nFor instructions on how to use HDInsight .NET SDK to run script action to install Zeppelin, see [Customize HDInsight clusters using Script Action](hdinsight-hadoop-customize-cluster-linux.md#use-a-script-action-from-the-hdinsight-net-sdk). You must make a couple of changes to the instructions in that article.\n\n* You must use the script for installing Zeppelin. The script to use is **https://hdiconfigactions.blob.core.windows.net/linuxincubatorzeppelinv01/install-zeppelin-spark151-v01.sh**.\n\n* The script does not need any parameters. \n\n* Set the cluster type you are creating to Spark.\n\n### Using Azure PowerShell\n\nUse the following PowerShell snippet to create a Spark cluster on HDInsight Linux with Zeppelin installed. Make sure you have PowerShell installed before you proceed. See [Install and configure Azure PowerShell](../powershell-install-configure.md) for instructions.\n\n    Login-AzureRMAccount\n    \n    # PROVIDE VALUES FOR THE VARIABLES\n    $clusterAdminUsername=\"admin\"\n    $clusterAdminPassword=\"<<password>>\"\n    $clusterSshUsername=\"adminssh\"\n    $clusterSshPassword=\"<<password>>\"\n    $clusterName=\"<<clustername>>\"\n    $clusterContainerName=$clusterName\n    $resourceGroupName=\"<<resourceGroupName>>\"\n    $location=\"<<region>>\"\n    $storage1Name=\"<<storagename>>\"\n    $storage1Key=\"<<storagekey>>\"\n    $subscriptionId=\"<<subscriptionId>>\"\n    \n    Select-AzureRmSubscription -SubscriptionId $subscriptionId\n    \n    $passwordAsSecureString=ConvertTo-SecureString $clusterAdminPassword -AsPlainText -Force\n    $clusterCredential=New-Object System.Management.Automation.PSCredential ($clusterAdminUsername, $passwordAsSecureString)\n    $passwordAsSecureString=ConvertTo-SecureString $clusterSshPassword -AsPlainText -Force\n    $clusterSshCredential=New-Object System.Management.Automation.PSCredential ($clusterSshUsername, $passwordAsSecureString)\n    \n    $azureHDInsightConfigs= New-AzureRmHDInsightClusterConfig -ClusterType Spark\n    $azureHDInsightConfigs.DefaultStorageAccountKey = $storage1Key\n    $azureHDInsightConfigs.DefaultStorageAccountName = \"$storage1Name.blob.core.windows.net\"\n    \n    Add-AzureRMHDInsightScriptAction -Config $azureHDInsightConfigs -Name \"Install Zeppelin\" -NodeType HeadNode -Parameters \"void\" -Uri \"https://hdiconfigactions.blob.core.windows.net/linuxincubatorzeppelinv01/install-zeppelin-spark151-v01.sh\"\n    \n    New-AzureRMHDInsightCluster -Config $azureHDInsightConfigs -OSType Linux -HeadNodeSize \"Standard_D12\" -WorkerNodeSize \"Standard_D12\" -ClusterSizeInNodes 2 -Location $location -ResourceGroupName $resourceGroupName -ClusterName $clusterName -HttpCredential $clusterCredential -DefaultStorageContainer $clusterContainerName -SshCredential $clusterSshCredential -Version \"3.3\"\n \n## Set up SSH tunneling to access a Zeppelin notebook\n\nYou will use SSH tunnels to access the Zeppelin notebooks running on Spark cluster on HDInsight Linux. The steps below demonstrate how to create an SSH tunnel using ssh command line (Linux) and PuTTY (Windows).\n\n### Create a tunnel using the SSH command (Linux)\n\nUse the following command to create an SSH tunnel using the `ssh` command. Replace __USERNAME__ with an SSH user for your HDInsight cluster, and replace __CLUSTERNAME__ with the name of your HDInsight cluster\n\n    ssh -C2qTnNf -D 9876 USERNAME@CLUSTERNAME-ssh.azurehdinsight.net\n\nThis creates a connection that routes traffic to local port 9876 to the cluster over SSH. The options are:\n\n* **D 9876** - The local port that will route traffic through the tunnel.\n\n* **C** - Compress all data, because web traffic is mostly text.\n\n* **2** - Force SSH to try protocol version 2 only.\n\n* **q** - Quiet mode.\n\n* **T** - Disable pseudo-tty allocation, since we are just forwarding a port.\n\n* **n** - Prevent reading of STDIN, since we are just forwarding a port.\n\n* **N** - Do not execute a remote command, since we are just forwarding a port.\n\n* **f** - Run in the background.\n\nIf you configured the cluster with an SSH key, you may need use the `-i` parameter and specify the path to the private SSH key.\n\nOnce the command finishes, traffic sent to port 9876 on the local computer will be routed over Secure Sockets Layer (SSL) to the cluster head node and appear to originate there.\n\n### Create a tunnel using PuTTY (Windows)\n\nUse the following steps to create an SSH tunnel using PuTTY.\n\n1. Open PuTTY, and enter your connection information. If you are not familiar with PuTTY, see [Use SSH with Linux-based Hadoop on HDInsight from Windows](hdinsight-hadoop-linux-use-ssh-windows.md) for information on how to use it with HDInsight.\n\n2. In the **Category** section to the left of the dialog, expand **Connection**, expand **SSH**, and then select **Tunnels**.\n\n3. Provide the following information on the **Options controlling SSH port forwarding** form:\n\n    * **Source port** - The port on the client that you wish to forward. For example, **9876**.\n\n    * **Destination** - The SSH address for the Linux-based HDInsight cluster. For example, **mycluster-ssh.azurehdinsight.net**.\n\n    * **Dynamic** - Enables dynamic SOCKS proxy routing.\n\n    ![image of tunneling options](./media/hdinsight-apache-spark-use-zeppelin-notebook/puttytunnel.png)\n\n4. Click **Add** to add the settings, and then click **Open** to open an SSH connection.\n\n5. When prompted, log in to the server. This will establish an SSH session and enable the tunnel.\n\n### Use the tunnel from your browser\n\n> [AZURE.NOTE] The steps in this section use the FireFox browser, as it is freely available for Linux, Unix, Macintosh OS X and Windows systems. Other modern browsers such as Google Chrome, Microsoft Edge, or Apple Safari should work as well; however, the FoxyProxy plugin used in some steps may not be available for all browsers.\n\n1. Configure the browser to use **localhost:9876** as a **SOCKS v5** proxy. Here's what the Firefox settings look like. If you used a different port than 9876, change the port to the one you used:\n\n    ![image of Firefox settings](./media/hdinsight-apache-spark-use-zeppelin-notebook/socks.png)\n\n    > [AZURE.NOTE] Selecting **Remote DNS** will resolve Domain Name System (DNS) requests by using the HDInsight cluster. If this is unselected, DNS will be resolved locally.\n\n2. Verify that traffic is being routed through the tunnel by vising a site such as [http://www.whatismyip.com/](http://www.whatismyip.com/) with the proxy settings enabled and disabled in Firefox. While the settings are enabled, the IP address will be for a machine in the Microsoft Azure datacenter.\n\n### Browser extensions\n\nWhile configuring the browser to use the tunnel works, you don't usually want to route all traffic over the tunnel. Browser extensions such as [FoxyProxy](http://getfoxyproxy.org/) support pattern matching for URL requests (FoxyProxy Standard or Plus only), so that only requests for specific URLs will be sent over the tunnel.\n\nIf you have installed FoxyProxy Standard, use the following steps to configure it to only forward traffic for HDInsight over the tunnel.\n\n1. Open the FoxyProxy extension in your browser. For example, in Firefox, select the FoxyProxy icon next to the address field.\n\n    ![foxyproxy icon](./media/hdinsight-apache-spark-use-zeppelin-notebook/foxyproxy.png)\n\n2. Select **Add New Proxy**, select the **General** tab, and then enter a proxy name of **HDInsightProxy**.\n\n    ![foxyproxy general](./media/hdinsight-apache-spark-use-zeppelin-notebook/foxygeneral.png)\n\n3. Select the **Proxy Details** tab and populate the following fields:\n\n    * **Host or IP Address** - This is localhost, since we are using an SSH tunnel on the local machine.\n\n    * **Port** - This is the port you used for the SSH tunnel.\n\n    * **SOCKS proxy** - Select this to enable the browser to use the tunnel as a proxy.\n\n    * **SOCKS v5** - Select this to set the required version for the proxy.\n\n    ![foxyproxy proxy](./media/hdinsight-apache-spark-use-zeppelin-notebook/foxyproxyproxy.png)\n\n4. Select the **URL Patterns** tab, and then select **Add New Pattern**. Use the following to define the pattern, and then click **OK**:\n\n    * **Pattern Name** - **zeppelinnotebook** - This is just a friendly name for the pattern.\n\n    * **URL pattern** - **\\*hn0\\*** - This defines a pattern that matches the internal fully qualified domain name of endpoint where the Zeppelin notebooks are hosted. Because Zeppelin notebooks are available only on the headnode0 of the cluster, and the endpoint is typically `http://hn0-<string>.internal.cloudapp.net`, using the pattern **hn0** would ensure that the request is redirected to the Zeppelin endpoint.\n\n        ![foxyproxy pattern](./media/hdinsight-apache-spark-use-zeppelin-notebook/foxypattern.png)\n\n4. Click **OK** to add the proxy and close **Proxy Settings**.\n\n5. At the top of the FoxyProxy dialog, change **Select Mode** to **Use proxies based on their pre-defined patterns and priorities**, and then click **Close**.\n\n    ![foxyproxy select mode](./media/hdinsight-apache-spark-use-zeppelin-notebook/selectmode.png)\n\nAfter following these steps, only requests for URLs that contain the string __internal.cloudapp.net__ will be routed over the SSL tunnel. \n\n## Access the Zeppelin notebook\n\nOnce you have SSH tunneling setup, you can use the following steps to access Zeppelin notebook on the Spark cluster by following the steps below.\n\n1. From the web browser, open the following endpoint:\n\n        http://hn0-myspar:9995\n\n    * **hn0** denotes headnode0\n    * **myspar** is the first six letters of the Spark cluster name.\n    * **9995** is the port where Zeppelin notebook is accessible.\n\n2. Create a new notebook. From the header pane, click **Notebook**, and then click **Create New Note**.\n\n    ![Create a new Zeppelin notebook](./media/hdinsight-apache-spark-zeppelin-notebook-jupyter-spark-sql-v1/hdispark.createnewnote.png \"Create a new Zeppelin notebook\")\n\n    On the same page, under the **Notebook** heading, you should see a new notebook with the name starting with **Note XXXXXXXXX**. Click the new notebook.\n\n3. On the web page for the new notebook, click the heading, and change the name of the notebook if you want to. Press ENTER to save the name change. Also, make sure the notebook header shows a **Connected** status in the top-right corner.\n\n    ![Zeppelin notebook status](./media/hdinsight-apache-spark-zeppelin-notebook-jupyter-spark-sql-v1/hdispark.newnote.connected.png \"Zeppelin notebook status\")\n\n4. Load sample data into a temporary table. When you create a Spark cluster in HDInsight, the sample data file, **hvac.csv**, is copied to the associated storage account under **\\HdiSamples\\SensorSampleData\\hvac**.\n\n    In the empty paragraph that is created by default in the new notebook, paste the following snippet.\n\n        // Create an RDD using the default Spark context, sc\n        val hvacText = sc.textFile(\"wasb:///HdiSamples/HdiSamples/SensorSampleData/hvac/HVAC.csv\")\n        \n        // Define a schema\n        case class Hvac(date: String, time: String, targettemp: Integer, actualtemp: Integer, buildingID: String)\n        \n        // Map the values in the .csv file to the schema\n        val hvac = hvacText.map(s => s.split(\",\")).filter(s => s(0) != \"Date\").map(\n            s => Hvac(s(0), \n                    s(1),\n                    s(2).toInt,\n                    s(3).toInt,\n                    s(6)\n            )\n        ).toDF()\n        \n        // Register as a temporary table called \"hvac\"\n        hvac.registerTempTable(\"hvac\")\n        \n    Press **SHIFT + ENTER** or click the **Play** button for the paragraph to run the snippet. The status on the right-corner of the paragraph should progress from READY, PENDING, RUNNING to FINISHED. The output shows up at the bottom of the same paragraph. The screenshot looks like the following:\n\n    ![Create a temporary table from raw data](./media/hdinsight-apache-spark-zeppelin-notebook-jupyter-spark-sql-v1/hdispark.note.loaddataintotable.png \"Create a temporary table from raw data\")\n\n    You can also provide a title to each paragraph. From the right-hand corner, click the **Settings** icon, and then click **Show title**.\n\n5. You can now run Spark SQL statements on the **hvac** table. Paste the following query in a new paragraph. The query retrieves the building ID and the difference between the target and actual temperatures for each building on a given date. Press **SHIFT + ENTER**.\n\n        %sql\n        select buildingID, (targettemp - actualtemp) as temp_diff, date \n        from hvac\n        where date = \"6/1/13\" \n\n    The **%sql** statement at the beginning tells the notebook to use the Spark  SQL interpreter. You can look at the defined interpreters from the **Interpreter** tab in the notebook header.\n\n    The following screenshot shows the output.\n\n    ![Run a Spark SQL statement using the notebook](./media/hdinsight-apache-spark-zeppelin-notebook-jupyter-spark-sql-v1/hdispark.note.sparksqlquery1.png \"Run a Spark SQL statement using the notebook\")\n\n     Click the display options (highlighted in rectangle) to switch between different representations for the same output. Click **Settings** to choose what consitutes the key and values in the output. The screen capture above uses **buildingID** as the key and the average of **temp_diff** as the value.\n\n    \n6. You can also run Spark SQL statements using variables in the query. The next snippet shows how to define a variable, **Temp**, in the query with the possible values you want to query with. When you first run the query, a drop-down is automatically populated with the values you specified for the variable.\n\n        %sql\n        select buildingID, date, targettemp, (targettemp - actualtemp) as temp_diff\n        from hvac\n        where targettemp > \"${Temp = 65,65|75|85}\" \n\n    Paste this snippet in a new paragraph and press **SHIFT + ENTER**. The following screenshot shows the output.\n\n    ![Run a Spark SQL statement using the notebook](./media/hdinsight-apache-spark-zeppelin-notebook-jupyter-spark-sql-v1/hdispark.note.sparksqlquery2.png \"Run a Spark SQL statement using the notebook\")\n\n    For subsequent queries, you can select a new value from the drop-down and run the query again. Click **Settings** to choose what consitutes the key and values in the output. The screen capture above uses **buildingID** as the key, the average of **temp_diff** as the value, and **targettemp** as the group.\n\n7. Restart the Spark SQL interpreter to exit the application. Click the **Interpreter** tab at the top, and for the Spark interpreter, click **Restart**.\n\n    ![Restart the Zeppelin intepreter](./media/hdinsight-apache-spark-zeppelin-notebook-jupyter-spark-sql-v1/hdispark.zeppelin.restart.interpreter.png \"Restart the Zeppelin intepreter\")\n\n\n## <a name=\"seealso\"></a>See also\n\n\n* [Overview: Apache Spark on Azure HDInsight](hdinsight-apache-spark-overview.md)\n\n### Scenarios\n\n* [Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools](hdinsight-apache-spark-use-bi-tools.md)\n\n* [Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data](hdinsight-apache-spark-ipython-notebook-machine-learning.md)\n\n* [Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results](hdinsight-apache-spark-machine-learning-mllib-ipython.md)\n\n* [Spark Streaming: Use Spark in HDInsight for building real-time streaming applications](hdinsight-apache-spark-eventhub-streaming.md)\n\n* [Website log analysis using Spark in HDInsight](hdinsight-apache-spark-custom-library-website-log-analysis.md)\n\n### Create and run applications\n\n* [Create a standalone application using Scala](hdinsight-apache-spark-create-standalone-application.md)\n\n* [Run jobs remotely on a Spark cluster using Livy](hdinsight-apache-spark-livy-rest-interface.md)\n\n### Tools and extensions\n\n* [Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons](hdinsight-apache-spark-intellij-tool-plugin.md)\n\n* [Kernels available for Jupyter notebook in Spark cluster for HDInsight](hdinsight-apache-spark-jupyter-notebook-kernels.md)\n\n### Manage resources\n\n* [Manage resources for the Apache Spark cluster in Azure HDInsight](hdinsight-apache-spark-resource-manager.md)\n\n\n[hdinsight-versions]: hdinsight-component-versioning.md\n[hdinsight-upload-data]: hdinsight-upload-data.md\n[hdinsight-storage]: hdinsight-hadoop-use-blob-storage.md\n\n[azure-purchase-options]: http://azure.microsoft.com/pricing/purchase-options/\n[azure-member-offers]: http://azure.microsoft.com/pricing/member-offers/\n[azure-free-trial]: http://azure.microsoft.com/pricing/free-trial/\n[azure-management-portal]: https://manage.windowsazure.com/\n[azure-create-storageaccount]: storage-create-storage-account.md \n\n\n\n\n\n\n\n"
}