{
  "nodes": [
    {
      "pos": [
        1,
        376
      ],
      "content": "<ph id=\"ph1\">&lt;properties \n    pageTitle=\"</ph>Create Spark Scala applications using HDInsight plugin for IntelliJ IDEA | Microsoft Azure<ph id=\"ph2\">\" \n    description=\"</ph>Learn how to create a standalone Spark application to run on HDInsight Spark clusters.<ph id=\"ph3\">\" \n    services=\"hdinsight\" \n    documentationCenter=\"\" \n    authors=\"nitinme\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/&gt;</ph>"
    },
    {
      "pos": [
        566,
        664
      ],
      "content": "Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applications (Linux)"
    },
    {
      "pos": [
        666,
        897
      ],
      "content": "This article provides step-by-step guidance on developing Spark applications written in Scala and submitting it to an HDInsight Spark cluster using HDInsight plugin for IntelliJ IDEA. You can use the plugin in a few different ways:",
      "nodes": [
        {
          "content": "This article provides step-by-step guidance on developing Spark applications written in Scala and submitting it to an HDInsight Spark cluster using HDInsight plugin for IntelliJ IDEA.",
          "pos": [
            0,
            183
          ]
        },
        {
          "content": "You can use the plugin in a few different ways:",
          "pos": [
            184,
            231
          ]
        }
      ]
    },
    {
      "pos": [
        901,
        978
      ],
      "content": "To develop and submit a Scala Spark application on an HDInsight Spark cluster"
    },
    {
      "pos": [
        981,
        1035
      ],
      "content": "To access your Azure HDInsight Spark cluster resources"
    },
    {
      "pos": [
        1038,
        1090
      ],
      "content": "To develop and run a Scala Spark application locally"
    },
    {
      "pos": [
        1093,
        1212
      ],
      "content": "<ph id=\"ph5\">[AZURE.IMPORTANT]</ph><ph id=\"ph6\"/> This tool can be used to create and submit applications only for an HDInsight Spark cluster on Linux."
    },
    {
      "pos": [
        1215,
        1232
      ],
      "content": "<bpt id=\"p1\">**</bpt>Prerequisites<ept id=\"p1\">**</ept>"
    },
    {
      "pos": [
        1236,
        1390
      ],
      "content": "An Azure subscription. See <bpt id=\"p2\">[</bpt>Get Azure free trial<ept id=\"p2\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
      "nodes": [
        {
          "content": "An Azure subscription.",
          "pos": [
            0,
            22
          ]
        },
        {
          "content": "See <bpt id=\"p2\">[</bpt>Get Azure free trial<ept id=\"p2\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
          "pos": [
            23,
            192
          ]
        }
      ]
    },
    {
      "pos": [
        1393,
        1554
      ],
      "content": "An Apache Spark cluster on HDInsight Linux. For instructions, see <bpt id=\"p3\">[</bpt>Create Apache Spark clusters in Azure HDInsight<ept id=\"p3\">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.",
      "nodes": [
        {
          "content": "An Apache Spark cluster on HDInsight Linux.",
          "pos": [
            0,
            43
          ]
        },
        {
          "content": "For instructions, see <bpt id=\"p3\">[</bpt>Create Apache Spark clusters in Azure HDInsight<ept id=\"p3\">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.",
          "pos": [
            44,
            199
          ]
        }
      ]
    },
    {
      "pos": [
        1557,
        1702
      ],
      "content": "Oracle Java Development kit. You can install it from <bpt id=\"p4\">[</bpt>here<ept id=\"p4\">](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)</ept>.",
      "nodes": [
        {
          "content": "Oracle Java Development kit.",
          "pos": [
            0,
            28
          ]
        },
        {
          "content": "You can install it from <bpt id=\"p4\">[</bpt>here<ept id=\"p4\">](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)</ept>.",
          "pos": [
            29,
            183
          ]
        }
      ]
    },
    {
      "pos": [
        1705,
        1827
      ],
      "content": "IntelliJ IDEA. This article uses version 15.0.1. You can install it from <bpt id=\"p5\">[</bpt>here<ept id=\"p5\">](https://www.jetbrains.com/idea/download/)</ept>.",
      "nodes": [
        {
          "content": "IntelliJ IDEA.",
          "pos": [
            0,
            14
          ]
        },
        {
          "content": "This article uses version 15.0.1.",
          "pos": [
            15,
            48
          ]
        },
        {
          "content": "You can install it from <bpt id=\"p5\">[</bpt>here<ept id=\"p5\">](https://www.jetbrains.com/idea/download/)</ept>.",
          "pos": [
            49,
            160
          ]
        }
      ]
    },
    {
      "pos": [
        1834,
        1872
      ],
      "content": "Install Scala plugin for IntelliJ IDEA"
    },
    {
      "pos": [
        1874,
        2028
      ],
      "content": "If IntelliJ IDEA installation did not not prompt for enabling Scala plugin, launch IntelliJ IDEA and go through the following steps to install the plugin:"
    },
    {
      "pos": [
        2033,
        2124
      ],
      "content": "Start IntelliJ IDEA and from welcome screen click <bpt id=\"p6\">**</bpt>Configure<ept id=\"p6\">**</ept><ph id=\"ph7\"/> and then click <bpt id=\"p7\">**</bpt>Plugins<ept id=\"p7\">**</ept>."
    },
    {
      "pos": [
        2130,
        2229
      ],
      "content": "<ph id=\"ph8\">![</ph>Enable scala plugin<ph id=\"ph9\">](./media/hdinsight-apache-spark-intellij-tool-plugin/enable-scala-plugin.png)</ph>"
    },
    {
      "pos": [
        2234,
        2420
      ],
      "content": "In the next screen, click <bpt id=\"p8\">**</bpt>Install JetBrains plugin<ept id=\"p8\">**</ept><ph id=\"ph10\"/> from the lower left corner. In the <bpt id=\"p9\">**</bpt>Browse JetBrains Plugins<ept id=\"p9\">**</ept><ph id=\"ph11\"/> dialog box that opens, search for Scala and then click <bpt id=\"p10\">**</bpt>Install<ept id=\"p10\">**</ept>.",
      "nodes": [
        {
          "content": "In the next screen, click <bpt id=\"p8\">**</bpt>Install JetBrains plugin<ept id=\"p8\">**</ept><ph id=\"ph10\"/> from the lower left corner.",
          "pos": [
            0,
            135
          ]
        },
        {
          "content": "In the <bpt id=\"p9\">**</bpt>Browse JetBrains Plugins<ept id=\"p9\">**</ept><ph id=\"ph11\"/> dialog box that opens, search for Scala and then click <bpt id=\"p10\">**</bpt>Install<ept id=\"p10\">**</ept>.",
          "pos": [
            136,
            332
          ]
        }
      ]
    },
    {
      "pos": [
        2426,
        2527
      ],
      "content": "<ph id=\"ph12\">![</ph>Install scala plugin<ph id=\"ph13\">](./media/hdinsight-apache-spark-intellij-tool-plugin/install-scala-plugin.png)</ph>"
    },
    {
      "pos": [
        2532,
        2639
      ],
      "content": "After the plugin installs successfully, you will be prompted to restart the IDE. You can skip that for now.",
      "nodes": [
        {
          "content": "After the plugin installs successfully, you will be prompted to restart the IDE.",
          "pos": [
            0,
            80
          ]
        },
        {
          "content": "You can skip that for now.",
          "pos": [
            81,
            107
          ]
        }
      ]
    },
    {
      "pos": [
        2644,
        2692
      ],
      "content": "Install HDInsight Tools plugin for IntelliJ IDEA"
    },
    {
      "pos": [
        2697,
        2809
      ],
      "content": "If you are back on the IntelliJ IDEA welcome screen, click click <bpt id=\"p11\">**</bpt>Configure<ept id=\"p11\">**</ept><ph id=\"ph14\"/> and then click <bpt id=\"p12\">**</bpt>Plugins<ept id=\"p12\">**</ept><ph id=\"ph15\"/> again."
    },
    {
      "pos": [
        2814,
        3060
      ],
      "content": "In the next screen, click <bpt id=\"p13\">**</bpt>Browse Repositories<ept id=\"p13\">**</ept><ph id=\"ph16\"/> from the lower left corner. In the <bpt id=\"p14\">**</bpt>Browse Repositories<ept id=\"p14\">**</ept><ph id=\"ph17\"/> dialog box that opens, search for <bpt id=\"p15\">**</bpt>HDInsight<ept id=\"p15\">**</ept>, select the <bpt id=\"p16\">**</bpt>Microsoft Azure HDInsight Tools for IntelliJ<ept id=\"p16\">**</ept>, and then click <bpt id=\"p17\">**</bpt>Install<ept id=\"p17\">**</ept>.",
      "nodes": [
        {
          "content": "In the next screen, click <bpt id=\"p13\">**</bpt>Browse Repositories<ept id=\"p13\">**</ept><ph id=\"ph16\"/> from the lower left corner.",
          "pos": [
            0,
            132
          ]
        },
        {
          "content": "In the <bpt id=\"p14\">**</bpt>Browse Repositories<ept id=\"p14\">**</ept><ph id=\"ph17\"/> dialog box that opens, search for <bpt id=\"p15\">**</bpt>HDInsight<ept id=\"p15\">**</ept>, select the <bpt id=\"p16\">**</bpt>Microsoft Azure HDInsight Tools for IntelliJ<ept id=\"p16\">**</ept>, and then click <bpt id=\"p17\">**</bpt>Install<ept id=\"p17\">**</ept>.",
          "pos": [
            133,
            476
          ]
        }
      ]
    },
    {
      "pos": [
        3065,
        3142
      ],
      "content": "When prompted, click the <bpt id=\"p18\">**</bpt>Restart IntelliJ IDEA<ept id=\"p18\">**</ept><ph id=\"ph18\"/> button to restart the IDE."
    },
    {
      "pos": [
        3147,
        3206
      ],
      "content": "Run a Spark Scala application on an HDInsight Spark cluster"
    },
    {
      "pos": [
        3211,
        3341
      ],
      "content": "Launch IntelliJ IDEA and create a new project. In the new project dialog box, make the following choices, and then click <bpt id=\"p19\">**</bpt>Next<ept id=\"p19\">**</ept>.",
      "nodes": [
        {
          "content": "Launch IntelliJ IDEA and create a new project.",
          "pos": [
            0,
            46
          ]
        },
        {
          "content": "In the new project dialog box, make the following choices, and then click <bpt id=\"p19\">**</bpt>Next<ept id=\"p19\">**</ept>.",
          "pos": [
            47,
            170
          ]
        }
      ]
    },
    {
      "pos": [
        3347,
        3458
      ],
      "content": "<ph id=\"ph19\">![</ph>Create Spark Scala application<ph id=\"ph20\">](./media/hdinsight-apache-spark-intellij-tool-plugin/create-hdi-scala-app.png)</ph>"
    },
    {
      "pos": [
        3466,
        3507
      ],
      "content": "From the left pane, select <bpt id=\"p20\">**</bpt>HDInsight<ept id=\"p20\">**</ept>."
    },
    {
      "pos": [
        3514,
        3573
      ],
      "content": "From the right pane, select <bpt id=\"p21\">**</bpt>Spark on HDInsight (Scala)<ept id=\"p21\">**</ept>."
    },
    {
      "pos": [
        3580,
        3595
      ],
      "content": "Click <bpt id=\"p22\">**</bpt>Next<ept id=\"p22\">**</ept>."
    },
    {
      "pos": [
        3600,
        3648
      ],
      "content": "In the next window, provide the project details."
    },
    {
      "pos": [
        3654,
        3770
      ],
      "content": "<ph id=\"ph21\">![</ph>Create Spark Scala application<ph id=\"ph22\">](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-scala-project-details.png)</ph>"
    },
    {
      "pos": [
        3778,
        3822
      ],
      "content": "Provide a project name and project location."
    },
    {
      "pos": [
        3829,
        3902
      ],
      "content": "For <bpt id=\"p23\">**</bpt>Project SDK<ept id=\"p23\">**</ept>, make sure you provide a Java version greater than 7."
    },
    {
      "pos": [
        3909,
        4092
      ],
      "content": "For <bpt id=\"p24\">**</bpt>Scala SDK<ept id=\"p24\">**</ept>, click <bpt id=\"p25\">**</bpt>Create<ept id=\"p25\">**</ept>, click <bpt id=\"p26\">**</bpt>Download<ept id=\"p26\">**</ept>, and then select the version of Scala to use. <bpt id=\"p27\">**</bpt>Make sure you do not use version 2.11.x<ept id=\"p27\">**</ept>. This sample uses version <bpt id=\"p28\">**</bpt>2.10.6<ept id=\"p28\">**</ept>.",
      "nodes": [
        {
          "content": "For <bpt id=\"p24\">**</bpt>Scala SDK<ept id=\"p24\">**</ept>, click <bpt id=\"p25\">**</bpt>Create<ept id=\"p25\">**</ept>, click <bpt id=\"p26\">**</bpt>Download<ept id=\"p26\">**</ept>, and then select the version of Scala to use.",
          "pos": [
            0,
            221
          ]
        },
        {
          "content": "<bpt id=\"p27\">**</bpt>Make sure you do not use version 2.11.x<ept id=\"p27\">**</ept>.",
          "pos": [
            222,
            306
          ]
        },
        {
          "content": "This sample uses version <bpt id=\"p28\">**</bpt>2.10.6<ept id=\"p28\">**</ept>.",
          "pos": [
            307,
            383
          ]
        }
      ]
    },
    {
      "pos": [
        4106,
        4214
      ],
      "content": "<ph id=\"ph23\">![</ph>Create Spark Scala application<ph id=\"ph24\">](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-scala-version.png)</ph>"
    },
    {
      "pos": [
        4222,
        4337
      ],
      "content": "For <bpt id=\"p29\">**</bpt>Spark SDK<ept id=\"p29\">**</ept>, download and use the SDK from <bpt id=\"p30\">[</bpt>here<ept id=\"p30\">](http://go.microsoft.com/fwlink/?LinkID=723585&amp;clcid=0x409)</ept>."
    },
    {
      "pos": [
        4344,
        4361
      ],
      "content": "Click <bpt id=\"p31\">**</bpt>Finish<ept id=\"p31\">**</ept>."
    },
    {
      "pos": [
        4366,
        4495
      ],
      "content": "Define the project structure to create an artifact (packaged jar) that will eventually contain the code that runs on the cluster."
    },
    {
      "pos": [
        4505,
        4557
      ],
      "content": "From the <bpt id=\"p32\">**</bpt>File<ept id=\"p32\">**</ept><ph id=\"ph25\"/> menu, click <bpt id=\"p33\">**</bpt>Project Structure<ept id=\"p33\">**</ept>."
    },
    {
      "pos": [
        4565,
        4726
      ],
      "content": "In the <bpt id=\"p34\">**</bpt>Project Structure<ept id=\"p34\">**</ept><ph id=\"ph26\"/> dialog box, click <bpt id=\"p35\">**</bpt>Artifacts<ept id=\"p35\">**</ept><ph id=\"ph27\"/> and then click the plus symbol. From the pop-up dialog box, click <bpt id=\"p36\">**</bpt>JAR<ept id=\"p36\">**</ept>, and then click <bpt id=\"p37\">**</bpt>Empty<ept id=\"p37\">**</ept>.",
      "nodes": [
        {
          "content": "In the <bpt id=\"p34\">**</bpt>Project Structure<ept id=\"p34\">**</ept><ph id=\"ph26\"/> dialog box, click <bpt id=\"p35\">**</bpt>Artifacts<ept id=\"p35\">**</ept><ph id=\"ph27\"/> and then click the plus symbol.",
          "pos": [
            0,
            202
          ]
        },
        {
          "content": "From the pop-up dialog box, click <bpt id=\"p36\">**</bpt>JAR<ept id=\"p36\">**</ept>, and then click <bpt id=\"p37\">**</bpt>Empty<ept id=\"p37\">**</ept>.",
          "pos": [
            203,
            351
          ]
        }
      ]
    },
    {
      "pos": [
        4736,
        4819
      ],
      "content": "<ph id=\"ph28\">![</ph>Create JAR<ph id=\"ph29\">](./media/hdinsight-apache-spark-intellij-tool-plugin/create-jar-1.png)</ph>"
    },
    {
      "pos": [
        4828,
        5004
      ],
      "content": "Enter a name for the JAR file (e.g. <bpt id=\"p38\">**</bpt>MyClusterApp<ept id=\"p38\">**</ept>). From the Available Elements pane, right-click <bpt id=\"p39\">**</bpt>'MyClusterApp' compile output<ept id=\"p39\">**</ept>, and then click <bpt id=\"p40\">**</bpt>Put into Output Root<ept id=\"p40\">**</ept>.",
      "nodes": [
        {
          "content": "Enter a name for the JAR file (e.g. <bpt id=\"p38\">**</bpt>MyClusterApp<ept id=\"p38\">**</ept>).",
          "pos": [
            0,
            94
          ]
        },
        {
          "content": "From the Available Elements pane, right-click <bpt id=\"p39\">**</bpt>'MyClusterApp' compile output<ept id=\"p39\">**</ept>, and then click <bpt id=\"p40\">**</bpt>Put into Output Root<ept id=\"p40\">**</ept>.",
          "pos": [
            95,
            296
          ]
        }
      ]
    },
    {
      "pos": [
        5014,
        5097
      ],
      "content": "<ph id=\"ph30\">![</ph>Create JAR<ph id=\"ph31\">](./media/hdinsight-apache-spark-intellij-tool-plugin/create-jar-2.png)</ph>"
    },
    {
      "pos": [
        5111,
        5149
      ],
      "content": "Click <bpt id=\"p41\">**</bpt>Apply<ept id=\"p41\">**</ept><ph id=\"ph32\"/> and then click <bpt id=\"p42\">**</bpt>OK<ept id=\"p42\">**</ept>."
    },
    {
      "pos": [
        5154,
        5187
      ],
      "content": "Add your application source code."
    },
    {
      "pos": [
        5196,
        5297
      ],
      "content": "From the <bpt id=\"p43\">**</bpt>Project Explorer<ept id=\"p43\">**</ept>, right-click <bpt id=\"p44\">**</bpt>src<ept id=\"p44\">**</ept>, point to <bpt id=\"p45\">**</bpt>New<ept id=\"p45\">**</ept>, and then click <bpt id=\"p46\">**</bpt>Scala class<ept id=\"p46\">**</ept>."
    },
    {
      "pos": [
        5307,
        5403
      ],
      "content": "<ph id=\"ph33\">![</ph>Add source code<ph id=\"ph34\">](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-spark-scala-code.png)</ph>"
    },
    {
      "pos": [
        5412,
        5528
      ],
      "content": "In the <bpt id=\"p47\">**</bpt>Create New Scala Class<ept id=\"p47\">**</ept><ph id=\"ph35\"/> dialog box, provide a name, for <bpt id=\"p48\">**</bpt>Kind<ept id=\"p48\">**</ept><ph id=\"ph36\"/> select <bpt id=\"p49\">**</bpt>Object<ept id=\"p49\">**</ept>, and then click <bpt id=\"p50\">**</bpt>OK<ept id=\"p50\">**</ept>."
    },
    {
      "pos": [
        5538,
        5641
      ],
      "content": "<ph id=\"ph37\">![</ph>Add source code<ph id=\"ph38\">](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-spark-scala-code-object.png)</ph>"
    },
    {
      "pos": [
        5650,
        5968
      ],
      "content": "In the <bpt id=\"p51\">**</bpt>MyClusterApp.scala<ept id=\"p51\">**</ept><ph id=\"ph39\"/> file, paste the following code. This code reads the data from the HVAC.csv (available on all HDInsight Spark clusters), retrieves the rows that only have one digit in the seventh column in the CSV, and writes the output to <bpt id=\"p52\">**</bpt>/HVACOut<ept id=\"p52\">**</ept><ph id=\"ph40\"/> under the default storage container for the cluster.",
      "nodes": [
        {
          "content": "In the <bpt id=\"p51\">**</bpt>MyClusterApp.scala<ept id=\"p51\">**</ept><ph id=\"ph39\"/> file, paste the following code.",
          "pos": [
            0,
            116
          ]
        },
        {
          "content": "This code reads the data from the HVAC.csv (available on all HDInsight Spark clusters), retrieves the rows that only have one digit in the seventh column in the CSV, and writes the output to <bpt id=\"p52\">**</bpt>/HVACOut<ept id=\"p52\">**</ept><ph id=\"ph40\"/> under the default storage container for the cluster.",
          "pos": [
            117,
            428
          ]
        }
      ]
    },
    {
      "pos": [
        6689,
        6739
      ],
      "content": "Run the application on an HDInsight Spark cluster."
    },
    {
      "pos": [
        6748,
        6867
      ],
      "content": "From the <bpt id=\"p53\">**</bpt>Project Explorer<ept id=\"p53\">**</ept>, right-click the project name, and then select <bpt id=\"p54\">**</bpt>Submit Spark Application to HDInsight<ept id=\"p54\">**</ept>."
    },
    {
      "pos": [
        6877,
        6984
      ],
      "content": "<ph id=\"ph41\">![</ph>Submit Spark application<ph id=\"ph42\">](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-submit-spark-app-1.png)</ph>"
    },
    {
      "pos": [
        6993,
        7129
      ],
      "content": "You will be prompted to enter your Azure subscription credentials. In the <bpt id=\"p55\">**</bpt>Spark Submission<ept id=\"p55\">**</ept><ph id=\"ph43\"/> dialog box, provide the following values.",
      "nodes": [
        {
          "content": "You will be prompted to enter your Azure subscription credentials.",
          "pos": [
            0,
            66
          ]
        },
        {
          "content": "In the <bpt id=\"p55\">**</bpt>Spark Submission<ept id=\"p55\">**</ept><ph id=\"ph43\"/> dialog box, provide the following values.",
          "pos": [
            67,
            191
          ]
        }
      ]
    },
    {
      "pos": [
        7139,
        7246
      ],
      "content": "<ph id=\"ph44\">![</ph>Submit Spark application<ph id=\"ph45\">](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-submit-spark-app-2.png)</ph>"
    },
    {
      "pos": [
        7258,
        7372
      ],
      "content": "For <bpt id=\"p56\">**</bpt>Spark clusters (Linux only)<ept id=\"p56\">**</ept>, select the HDInsight Spark cluster on which you want to run your application."
    },
    {
      "pos": [
        7384,
        7479
      ],
      "content": "The <bpt id=\"p57\">**</bpt>Build Artifacts<ept id=\"p57\">**</ept><ph id=\"ph46\"/> drop-down should list the JAR name you specified in the previous steps."
    },
    {
      "pos": [
        7491,
        7711
      ],
      "content": "Against the <bpt id=\"p58\">**</bpt>Main class name<ept id=\"p58\">**</ept><ph id=\"ph47\"/> text box, click the ellipsis (<ph id=\"ph48\">![</ph>ellipsis<ph id=\"ph49\">](./media/hdinsight-apache-spark-intellij-tool-plugin/ellipsis.png)</ph> ), select the main class in your applicaiton source code, and then click <bpt id=\"p59\">**</bpt>OK<ept id=\"p59\">**</ept>."
    },
    {
      "pos": [
        7725,
        7832
      ],
      "content": "<ph id=\"ph50\">![</ph>Submit Spark application<ph id=\"ph51\">](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-submit-spark-app-3.png)</ph>"
    },
    {
      "pos": [
        7848,
        8010
      ],
      "content": "Because the application code in this example does not require any command line arguments or reference JARs or files, you can leave the remaining text boxes empty."
    },
    {
      "pos": [
        8026,
        8043
      ],
      "content": "Click <bpt id=\"p60\">**</bpt>Submit<ept id=\"p60\">**</ept>."
    },
    {
      "pos": [
        8052,
        8146
      ],
      "content": "The <bpt id=\"p61\">**</bpt>Spark Submission<ept id=\"p61\">**</ept><ph id=\"ph52\"/> tab at the bottom of the window should start displaying the progress."
    },
    {
      "pos": [
        8152,
        8257
      ],
      "content": "In the next section, you learn how to access the job output using the HDInsight plugin for IntelliJ IDEA."
    },
    {
      "pos": [
        8263,
        8345
      ],
      "content": "Access and manage HDInsight Spark clusters using the HDInsight plugin for IntelliJ"
    },
    {
      "pos": [
        8347,
        8414
      ],
      "content": "You can perform a variety of operations using the HDInsight plugin."
    },
    {
      "pos": [
        8420,
        8464
      ],
      "content": "Access the storage container for the cluster"
    },
    {
      "pos": [
        8469,
        8628
      ],
      "content": "From the <bpt id=\"p62\">**</bpt>View<ept id=\"p62\">**</ept><ph id=\"ph53\"/> menu, point to <bpt id=\"p63\">**</bpt>Tool Windows<ept id=\"p63\">**</ept>, and then click <bpt id=\"p64\">**</bpt>HDInsight Explorer<ept id=\"p64\">**</ept>. If prompted, enter the credentials to access your Azure subscription.",
      "nodes": [
        {
          "content": "From the <bpt id=\"p62\">**</bpt>View<ept id=\"p62\">**</ept><ph id=\"ph53\"/> menu, point to <bpt id=\"p63\">**</bpt>Tool Windows<ept id=\"p63\">**</ept>, and then click <bpt id=\"p64\">**</bpt>HDInsight Explorer<ept id=\"p64\">**</ept>.",
          "pos": [
            0,
            224
          ]
        },
        {
          "content": "If prompted, enter the credentials to access your Azure subscription.",
          "pos": [
            225,
            294
          ]
        }
      ]
    },
    {
      "pos": [
        8633,
        8725
      ],
      "content": "Expand <bpt id=\"p65\">**</bpt>HDInsight<ept id=\"p65\">**</ept><ph id=\"ph54\"/> root node to see a list of HDInsight Spark clusters that are available."
    },
    {
      "pos": [
        8730,
        8831
      ],
      "content": "Expand the cluster name to see the storage account and the default storage container for the cluster."
    },
    {
      "pos": [
        8837,
        8944
      ],
      "content": "<ph id=\"ph55\">![</ph>Access cluster storage<ph id=\"ph56\">](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-spark-access-storage.png)</ph>"
    },
    {
      "pos": [
        8949,
        9202
      ],
      "content": "Click the storage container name associated with the cluster. In the right-pane, you should see a folder called <bpt id=\"p66\">**</bpt>HVACOut<ept id=\"p66\">**</ept>. Double-click to open the folder and you will see <bpt id=\"p67\">**</bpt>part-<ept id=\"p67\">**</ept>* files. Open one of those files to see the output of the application.",
      "nodes": [
        {
          "content": "Click the storage container name associated with the cluster.",
          "pos": [
            0,
            61
          ]
        },
        {
          "content": "In the right-pane, you should see a folder called <bpt id=\"p66\">**</bpt>HVACOut<ept id=\"p66\">**</ept>.",
          "pos": [
            62,
            164
          ]
        },
        {
          "content": "Double-click to open the folder and you will see <bpt id=\"p67\">**</bpt>part-<ept id=\"p67\">**</ept>* files.",
          "pos": [
            165,
            271
          ]
        },
        {
          "content": "Open one of those files to see the output of the application.",
          "pos": [
            272,
            333
          ]
        }
      ]
    },
    {
      "pos": [
        9208,
        9239
      ],
      "content": "Access the Spark History Server"
    },
    {
      "pos": [
        9244,
        9477
      ],
      "content": "From the <bpt id=\"p68\">**</bpt>HDInsight Explorer<ept id=\"p68\">**</ept>, right-click your Spark cluster name and then select <bpt id=\"p69\">**</bpt>Open Spark History UI<ept id=\"p69\">**</ept>. When prompted, enter the admin credentials for the cluster. You must have specified these while provisioning the cluster.",
      "nodes": [
        {
          "content": "From the <bpt id=\"p68\">**</bpt>HDInsight Explorer<ept id=\"p68\">**</ept>, right-click your Spark cluster name and then select <bpt id=\"p69\">**</bpt>Open Spark History UI<ept id=\"p69\">**</ept>.",
          "pos": [
            0,
            191
          ]
        },
        {
          "content": "When prompted, enter the admin credentials for the cluster.",
          "pos": [
            192,
            251
          ]
        },
        {
          "content": "You must have specified these while provisioning the cluster.",
          "pos": [
            252,
            313
          ]
        }
      ]
    },
    {
      "pos": [
        9482,
        9778
      ],
      "content": "In the Spark History Server dashboard, you can look for the application you just finished running by using the application name. In the code above, you set the application name using <ph id=\"ph57\">`val conf = new SparkConf().setAppName(\"MyClusterApp\")`</ph>. Hence, your Spark application name was <bpt id=\"p70\">**</bpt>MyClusterApp<ept id=\"p70\">**</ept>.",
      "nodes": [
        {
          "content": "In the Spark History Server dashboard, you can look for the application you just finished running by using the application name.",
          "pos": [
            0,
            128
          ]
        },
        {
          "content": "In the code above, you set the application name using <ph id=\"ph57\">`val conf = new SparkConf().setAppName(\"MyClusterApp\")`</ph>.",
          "pos": [
            129,
            258
          ]
        },
        {
          "content": "Hence, your Spark application name was <bpt id=\"p70\">**</bpt>MyClusterApp<ept id=\"p70\">**</ept>.",
          "pos": [
            259,
            355
          ]
        }
      ]
    },
    {
      "pos": [
        9784,
        9808
      ],
      "content": "Launch the Ambari portal"
    },
    {
      "pos": [
        9810,
        10061
      ],
      "content": "From the <bpt id=\"p71\">**</bpt>HDInsight Explorer<ept id=\"p71\">**</ept>, right-click your Spark cluster name and then select <bpt id=\"p72\">**</bpt>Open Cluster Management Portal (Ambari)<ept id=\"p72\">**</ept>. When prompted, enter the admin credentials for the cluster. You must have specified these while provisioning the cluster.",
      "nodes": [
        {
          "content": "From the <bpt id=\"p71\">**</bpt>HDInsight Explorer<ept id=\"p71\">**</ept>, right-click your Spark cluster name and then select <bpt id=\"p72\">**</bpt>Open Cluster Management Portal (Ambari)<ept id=\"p72\">**</ept>.",
          "pos": [
            0,
            209
          ]
        },
        {
          "content": "When prompted, enter the admin credentials for the cluster.",
          "pos": [
            210,
            269
          ]
        },
        {
          "content": "You must have specified these while provisioning the cluster.",
          "pos": [
            270,
            331
          ]
        }
      ]
    },
    {
      "pos": [
        10067,
        10093
      ],
      "content": "Manage Azure subscriptions"
    },
    {
      "pos": [
        10095,
        10601
      ],
      "content": "By default, the HDInsight plugin lists the Spark clusters from all your Azure subscriptions. If required, you can specify the subscriptions for which you want to access the cluster. From the <bpt id=\"p73\">**</bpt>HDInsight Explorer<ept id=\"p73\">**</ept>, right-click the <bpt id=\"p74\">**</bpt>HDInsight<ept id=\"p74\">**</ept><ph id=\"ph58\"/> root node, and then click <bpt id=\"p75\">**</bpt>Manage Subscriptions<ept id=\"p75\">**</ept>. From the dialog box, clear the check boxes against the subscription that you do not want to access and then click <bpt id=\"p76\">**</bpt>Close<ept id=\"p76\">**</ept>. You can also click <bpt id=\"p77\">**</bpt>Sign Out<ept id=\"p77\">**</ept><ph id=\"ph59\"/> if you want to log off from your Azure subscription.",
      "nodes": [
        {
          "content": "By default, the HDInsight plugin lists the Spark clusters from all your Azure subscriptions.",
          "pos": [
            0,
            92
          ]
        },
        {
          "content": "If required, you can specify the subscriptions for which you want to access the cluster.",
          "pos": [
            93,
            181
          ]
        },
        {
          "content": "From the <bpt id=\"p73\">**</bpt>HDInsight Explorer<ept id=\"p73\">**</ept>, right-click the <bpt id=\"p74\">**</bpt>HDInsight<ept id=\"p74\">**</ept><ph id=\"ph58\"/> root node, and then click <bpt id=\"p75\">**</bpt>Manage Subscriptions<ept id=\"p75\">**</ept>.",
          "pos": [
            182,
            431
          ]
        },
        {
          "content": "From the dialog box, clear the check boxes against the subscription that you do not want to access and then click <bpt id=\"p76\">**</bpt>Close<ept id=\"p76\">**</ept>.",
          "pos": [
            432,
            596
          ]
        },
        {
          "content": "You can also click <bpt id=\"p77\">**</bpt>Sign Out<ept id=\"p77\">**</ept><ph id=\"ph59\"/> if you want to log off from your Azure subscription.",
          "pos": [
            597,
            736
          ]
        }
      ]
    },
    {
      "pos": [
        10607,
        10644
      ],
      "content": "Run a Spark Scala application locally"
    },
    {
      "pos": [
        10646,
        10893
      ],
      "content": "You can use the HDInsight Tools plugin for IntelliJ IDEA to run Spark Scala applications locally on your workstation. Typically, such applications do not need access to cluster resources such as storage container and can be run and tested locally.",
      "nodes": [
        {
          "content": "You can use the HDInsight Tools plugin for IntelliJ IDEA to run Spark Scala applications locally on your workstation.",
          "pos": [
            0,
            117
          ]
        },
        {
          "content": "Typically, such applications do not need access to cluster resources such as storage container and can be run and tested locally.",
          "pos": [
            118,
            247
          ]
        }
      ]
    },
    {
      "pos": [
        10899,
        10911
      ],
      "content": "Prerequisite"
    },
    {
      "pos": [
        10913,
        11431
      ],
      "content": "While running the local Spark Scala application on a Windows computer, you might get an exception as explained in <bpt id=\"p78\">[</bpt>SPARK-2356<ept id=\"p78\">](https://issues.apache.org/jira/browse/SPARK-2356)</ept><ph id=\"ph60\"/> that occurs due to a missing WinUtils.exe on Windows. To work around this error, you must <bpt id=\"p79\">[</bpt>download the executable from here<ept id=\"p79\">](http://public-repo-1.hortonworks.com/hdp-win-alpha/winutils.exe)</ept><ph id=\"ph61\"/> to a location like <bpt id=\"p80\">**</bpt>C:\\WinUtils\\bin<ept id=\"p80\">**</ept>. You must then add an environment variable <bpt id=\"p81\">**</bpt>HADOOP_HOME<ept id=\"p81\">**</ept><ph id=\"ph62\"/> and set the value of the variable to <bpt id=\"p82\">**</bpt>C\\WinUtils<ept id=\"p82\">**</ept>.",
      "nodes": [
        {
          "content": "While running the local Spark Scala application on a Windows computer, you might get an exception as explained in <bpt id=\"p78\">[</bpt>SPARK-2356<ept id=\"p78\">](https://issues.apache.org/jira/browse/SPARK-2356)</ept><ph id=\"ph60\"/> that occurs due to a missing WinUtils.exe on Windows.",
          "pos": [
            0,
            285
          ]
        },
        {
          "content": "To work around this error, you must <bpt id=\"p79\">[</bpt>download the executable from here<ept id=\"p79\">](http://public-repo-1.hortonworks.com/hdp-win-alpha/winutils.exe)</ept><ph id=\"ph61\"/> to a location like <bpt id=\"p80\">**</bpt>C:\\WinUtils\\bin<ept id=\"p80\">**</ept>.",
          "pos": [
            286,
            557
          ]
        },
        {
          "content": "You must then add an environment variable <bpt id=\"p81\">**</bpt>HADOOP_HOME<ept id=\"p81\">**</ept><ph id=\"ph62\"/> and set the value of the variable to <bpt id=\"p82\">**</bpt>C\\WinUtils<ept id=\"p82\">**</ept>.",
          "pos": [
            558,
            763
          ]
        }
      ]
    },
    {
      "pos": [
        11437,
        11472
      ],
      "content": "Run a local Spark Scala application"
    },
    {
      "pos": [
        11479,
        11609
      ],
      "content": "Launch IntelliJ IDEA and create a new project. In the new project dialog box, make the following choices, and then click <bpt id=\"p83\">**</bpt>Next<ept id=\"p83\">**</ept>.",
      "nodes": [
        {
          "content": "Launch IntelliJ IDEA and create a new project.",
          "pos": [
            0,
            46
          ]
        },
        {
          "content": "In the new project dialog box, make the following choices, and then click <bpt id=\"p83\">**</bpt>Next<ept id=\"p83\">**</ept>.",
          "pos": [
            47,
            170
          ]
        }
      ]
    },
    {
      "pos": [
        11615,
        11726
      ],
      "content": "<ph id=\"ph63\">![</ph>Create Spark Scala application<ph id=\"ph64\">](./media/hdinsight-apache-spark-intellij-tool-plugin/create-hdi-scala-app.png)</ph>"
    },
    {
      "pos": [
        11734,
        11775
      ],
      "content": "From the left pane, select <bpt id=\"p84\">**</bpt>HDInsight<ept id=\"p84\">**</ept>."
    },
    {
      "pos": [
        11782,
        11841
      ],
      "content": "From the right pane, select <bpt id=\"p85\">**</bpt>Spark on HDInsight (Scala)<ept id=\"p85\">**</ept>."
    },
    {
      "pos": [
        11848,
        11863
      ],
      "content": "Click <bpt id=\"p86\">**</bpt>Next<ept id=\"p86\">**</ept>."
    },
    {
      "pos": [
        11868,
        11916
      ],
      "content": "In the next window, provide the project details."
    },
    {
      "pos": [
        11922,
        12044
      ],
      "content": "<ph id=\"ph65\">![</ph>Create Spark Scala application<ph id=\"ph66\">](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-scala-local-project-details.png)</ph>"
    },
    {
      "pos": [
        12052,
        12096
      ],
      "content": "Provide a project name and project location."
    },
    {
      "pos": [
        12103,
        12176
      ],
      "content": "For <bpt id=\"p87\">**</bpt>Project SDK<ept id=\"p87\">**</ept>, make sure you provide a Java version greater than 7."
    },
    {
      "pos": [
        12183,
        12366
      ],
      "content": "For <bpt id=\"p88\">**</bpt>Scala SDK<ept id=\"p88\">**</ept>, click <bpt id=\"p89\">**</bpt>Create<ept id=\"p89\">**</ept>, click <bpt id=\"p90\">**</bpt>Download<ept id=\"p90\">**</ept>, and then select the version of Scala to use. <bpt id=\"p91\">**</bpt>Make sure you do not use version 2.11.x<ept id=\"p91\">**</ept>. This sample uses version <bpt id=\"p92\">**</bpt>2.10.6<ept id=\"p92\">**</ept>.",
      "nodes": [
        {
          "content": "For <bpt id=\"p88\">**</bpt>Scala SDK<ept id=\"p88\">**</ept>, click <bpt id=\"p89\">**</bpt>Create<ept id=\"p89\">**</ept>, click <bpt id=\"p90\">**</bpt>Download<ept id=\"p90\">**</ept>, and then select the version of Scala to use.",
          "pos": [
            0,
            221
          ]
        },
        {
          "content": "<bpt id=\"p91\">**</bpt>Make sure you do not use version 2.11.x<ept id=\"p91\">**</ept>.",
          "pos": [
            222,
            306
          ]
        },
        {
          "content": "This sample uses version <bpt id=\"p92\">**</bpt>2.10.6<ept id=\"p92\">**</ept>.",
          "pos": [
            307,
            383
          ]
        }
      ]
    },
    {
      "pos": [
        12380,
        12488
      ],
      "content": "<ph id=\"ph67\">![</ph>Create Spark Scala application<ph id=\"ph68\">](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-scala-version.png)</ph>"
    },
    {
      "pos": [
        12496,
        12611
      ],
      "content": "For <bpt id=\"p93\">**</bpt>Spark SDK<ept id=\"p93\">**</ept>, download and use the SDK from <bpt id=\"p94\">[</bpt>here<ept id=\"p94\">](http://go.microsoft.com/fwlink/?LinkID=723585&amp;clcid=0x409)</ept>."
    },
    {
      "pos": [
        12618,
        12635
      ],
      "content": "Click <bpt id=\"p95\">**</bpt>Finish<ept id=\"p95\">**</ept>."
    },
    {
      "pos": [
        12640,
        12769
      ],
      "content": "Define the project structure to create an artifact (packaged jar) that will eventually contain the code that runs on the cluster."
    },
    {
      "pos": [
        12779,
        12831
      ],
      "content": "From the <bpt id=\"p96\">**</bpt>File<ept id=\"p96\">**</ept><ph id=\"ph69\"/> menu, click <bpt id=\"p97\">**</bpt>Project Structure<ept id=\"p97\">**</ept>."
    },
    {
      "pos": [
        12839,
        13000
      ],
      "content": "In the <bpt id=\"p98\">**</bpt>Project Structure<ept id=\"p98\">**</ept><ph id=\"ph70\"/> dialog box, click <bpt id=\"p99\">**</bpt>Artifacts<ept id=\"p99\">**</ept><ph id=\"ph71\"/> and then click the plus symbol. From the pop-up dialog box, click <bpt id=\"p100\">**</bpt>JAR<ept id=\"p100\">**</ept>, and then click <bpt id=\"p101\">**</bpt>Empty<ept id=\"p101\">**</ept>.",
      "nodes": [
        {
          "content": "In the <bpt id=\"p98\">**</bpt>Project Structure<ept id=\"p98\">**</ept><ph id=\"ph70\"/> dialog box, click <bpt id=\"p99\">**</bpt>Artifacts<ept id=\"p99\">**</ept><ph id=\"ph71\"/> and then click the plus symbol.",
          "pos": [
            0,
            202
          ]
        },
        {
          "content": "From the pop-up dialog box, click <bpt id=\"p100\">**</bpt>JAR<ept id=\"p100\">**</ept>, and then click <bpt id=\"p101\">**</bpt>Empty<ept id=\"p101\">**</ept>.",
          "pos": [
            203,
            355
          ]
        }
      ]
    },
    {
      "pos": [
        13010,
        13093
      ],
      "content": "<ph id=\"ph72\">![</ph>Create JAR<ph id=\"ph73\">](./media/hdinsight-apache-spark-intellij-tool-plugin/create-jar-1.png)</ph>"
    },
    {
      "pos": [
        13102,
        13274
      ],
      "content": "Enter a name for the JAR file (e.g. <bpt id=\"p102\">**</bpt>MyLocalApp<ept id=\"p102\">**</ept>). From the Available Elements pane, right-click <bpt id=\"p103\">**</bpt>'MyLocalApp' compile output<ept id=\"p103\">**</ept>, and then click <bpt id=\"p104\">**</bpt>Put into Output Root<ept id=\"p104\">**</ept>.",
      "nodes": [
        {
          "content": "Enter a name for the JAR file (e.g. <bpt id=\"p102\">**</bpt>MyLocalApp<ept id=\"p102\">**</ept>).",
          "pos": [
            0,
            94
          ]
        },
        {
          "content": "From the Available Elements pane, right-click <bpt id=\"p103\">**</bpt>'MyLocalApp' compile output<ept id=\"p103\">**</ept>, and then click <bpt id=\"p104\">**</bpt>Put into Output Root<ept id=\"p104\">**</ept>.",
          "pos": [
            95,
            298
          ]
        }
      ]
    },
    {
      "pos": [
        13284,
        13373
      ],
      "content": "<ph id=\"ph74\">![</ph>Create JAR<ph id=\"ph75\">](./media/hdinsight-apache-spark-intellij-tool-plugin/create-local-jar-2.png)</ph>"
    },
    {
      "pos": [
        13389,
        13427
      ],
      "content": "Click <bpt id=\"p105\">**</bpt>Apply<ept id=\"p105\">**</ept><ph id=\"ph76\"/> and then click <bpt id=\"p106\">**</bpt>OK<ept id=\"p106\">**</ept>."
    },
    {
      "pos": [
        13432,
        13465
      ],
      "content": "Add your application source code."
    },
    {
      "pos": [
        13474,
        13575
      ],
      "content": "From the <bpt id=\"p107\">**</bpt>Project Explorer<ept id=\"p107\">**</ept>, right-click <bpt id=\"p108\">**</bpt>src<ept id=\"p108\">**</ept>, point to <bpt id=\"p109\">**</bpt>New<ept id=\"p109\">**</ept>, and then click <bpt id=\"p110\">**</bpt>Scala class<ept id=\"p110\">**</ept>."
    },
    {
      "pos": [
        13585,
        13687
      ],
      "content": "<ph id=\"ph77\">![</ph>Add source code<ph id=\"ph78\">](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-spark-local-scala-code.png)</ph>"
    },
    {
      "pos": [
        13696,
        13812
      ],
      "content": "In the <bpt id=\"p111\">**</bpt>Create New Scala Class<ept id=\"p111\">**</ept><ph id=\"ph79\"/> dialog box, provide a name, for <bpt id=\"p112\">**</bpt>Kind<ept id=\"p112\">**</ept><ph id=\"ph80\"/> select <bpt id=\"p113\">**</bpt>Object<ept id=\"p113\">**</ept>, and then click <bpt id=\"p114\">**</bpt>OK<ept id=\"p114\">**</ept>."
    },
    {
      "pos": [
        13822,
        13931
      ],
      "content": "<ph id=\"ph81\">![</ph>Add source code<ph id=\"ph82\">](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-spark-local-scala-code-object.png)</ph>"
    },
    {
      "pos": [
        13940,
        14151
      ],
      "content": "In the <bpt id=\"p115\">**</bpt>MyLocalApp.scala<ept id=\"p115\">**</ept><ph id=\"ph83\"/> file, paste the following code. This code reads a sample input text file on your computer and prints out the number of lines in that text file that contain the characters \"a\" and \"b\".",
      "nodes": [
        {
          "content": "In the <bpt id=\"p115\">**</bpt>MyLocalApp.scala<ept id=\"p115\">**</ept><ph id=\"ph83\"/> file, paste the following code.",
          "pos": [
            0,
            116
          ]
        },
        {
          "content": "This code reads a sample input text file on your computer and prints out the number of lines in that text file that contain the characters \"a\" and \"b\".",
          "pos": [
            117,
            268
          ]
        }
      ]
    },
    {
      "pos": [
        14974,
        15140
      ],
      "content": "Run the application locally on your workstation. From the <bpt id=\"p116\">**</bpt>Run<ept id=\"p116\">**</ept><ph id=\"ph84\"/> menu, click <bpt id=\"p117\">**</bpt>Run 'MyLocalApp'<ept id=\"p117\">**</ept>. You will see an output like this in the <bpt id=\"p118\">**</bpt>Run<ept id=\"p118\">**</ept><ph id=\"ph85\"/> tab at the bottom.",
      "nodes": [
        {
          "content": "Run the application locally on your workstation.",
          "pos": [
            0,
            48
          ]
        },
        {
          "content": "From the <bpt id=\"p116\">**</bpt>Run<ept id=\"p116\">**</ept><ph id=\"ph84\"/> menu, click <bpt id=\"p117\">**</bpt>Run 'MyLocalApp'<ept id=\"p117\">**</ept>.",
          "pos": [
            49,
            198
          ]
        },
        {
          "content": "You will see an output like this in the <bpt id=\"p118\">**</bpt>Run<ept id=\"p118\">**</ept><ph id=\"ph85\"/> tab at the bottom.",
          "pos": [
            199,
            322
          ]
        }
      ]
    },
    {
      "pos": [
        15589,
        15665
      ],
      "content": "Convert existing IntelliJ IDEA applications to use the HDInsight tool plugin"
    },
    {
      "pos": [
        15667,
        15944
      ],
      "content": "You can also convert your existing Spark Scala applications created in IntelliJ IDEA to be compatible with the HDInsight tool plugin. This will enable you to use the tool to submit the applications to an HDInsight Spark cluster. You can do so by performing the following steps:",
      "nodes": [
        {
          "content": "You can also convert your existing Spark Scala applications created in IntelliJ IDEA to be compatible with the HDInsight tool plugin.",
          "pos": [
            0,
            133
          ]
        },
        {
          "content": "This will enable you to use the tool to submit the applications to an HDInsight Spark cluster.",
          "pos": [
            134,
            228
          ]
        },
        {
          "content": "You can do so by performing the following steps:",
          "pos": [
            229,
            277
          ]
        }
      ]
    },
    {
      "pos": [
        15949,
        16047
      ],
      "content": "For an existing Spark Scala appliction created using IntelliJ IDEA, open the associated .iml file."
    },
    {
      "pos": [
        16051,
        16114
      ],
      "content": "At the root level, you will see a <bpt id=\"p119\">**</bpt>module<ept id=\"p119\">**</ept><ph id=\"ph86\"/> element like this:"
    },
    {
      "pos": [
        16243,
        16351
      ],
      "content": "Edit the element to add <ph id=\"ph87\">`UniqueKey=\"HDInsightTool\"`</ph><ph id=\"ph88\"/> so that the <bpt id=\"p120\">**</bpt>module<ept id=\"p120\">**</ept><ph id=\"ph89\"/> element looks like the following:"
    },
    {
      "pos": [
        16506,
        16767
      ],
      "content": "Save the changes. Your application should now be compatible with the HDInsight tool plugin. You can test this by right-clicking on the project name in the Project Explorer. The pop-up menu should now have the option to <bpt id=\"p121\">**</bpt>Submit Spark Application to HDInsight<ept id=\"p121\">**</ept>.",
      "nodes": [
        {
          "content": "Save the changes.",
          "pos": [
            0,
            17
          ]
        },
        {
          "content": "Your application should now be compatible with the HDInsight tool plugin.",
          "pos": [
            18,
            91
          ]
        },
        {
          "content": "You can test this by right-clicking on the project name in the Project Explorer.",
          "pos": [
            92,
            172
          ]
        },
        {
          "content": "The pop-up menu should now have the option to <bpt id=\"p121\">**</bpt>Submit Spark Application to HDInsight<ept id=\"p121\">**</ept>.",
          "pos": [
            173,
            303
          ]
        }
      ]
    },
    {
      "pos": [
        16794,
        16802
      ],
      "content": "See also"
    },
    {
      "pos": [
        16807,
        16886
      ],
      "content": "<bpt id=\"p122\">[</bpt>Overview: Apache Spark on Azure HDInsight<ept id=\"p122\">](hdinsight-apache-spark-overview.md)</ept>"
    },
    {
      "pos": [
        16892,
        16901
      ],
      "content": "Scenarios"
    },
    {
      "pos": [
        16905,
        17034
      ],
      "content": "<bpt id=\"p123\">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id=\"p123\">](hdinsight-apache-spark-use-bi-tools.md)</ept>"
    },
    {
      "pos": [
        17038,
        17203
      ],
      "content": "<bpt id=\"p124\">[</bpt>Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data<ept id=\"p124\">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept>"
    },
    {
      "pos": [
        17207,
        17353
      ],
      "content": "<bpt id=\"p125\">[</bpt>Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results<ept id=\"p125\">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept>"
    },
    {
      "pos": [
        17357,
        17490
      ],
      "content": "<bpt id=\"p126\">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id=\"p126\">](hdinsight-apache-spark-eventhub-streaming.md)</ept>"
    },
    {
      "pos": [
        17494,
        17604
      ],
      "content": "<bpt id=\"p127\">[</bpt>Website log analysis using Spark in HDInsight<ept id=\"p127\">](hdinsight-apache-spark-custom-library-website-log-analysis.md)</ept>"
    },
    {
      "pos": [
        17610,
        17637
      ],
      "content": "Create and run applications"
    },
    {
      "pos": [
        17641,
        17737
      ],
      "content": "<bpt id=\"p128\">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id=\"p128\">](hdinsight-apache-spark-livy-rest-interface.md)</ept>"
    },
    {
      "pos": [
        17743,
        17763
      ],
      "content": "Tools and extensions"
    },
    {
      "pos": [
        17767,
        17874
      ],
      "content": "<bpt id=\"p129\">[</bpt>Use Zeppelin notebooks with a Spark cluster on HDInsight<ept id=\"p129\">](hdinsight-apache-spark-use-zeppelin-notebook.md)</ept>"
    },
    {
      "pos": [
        17878,
        18001
      ],
      "content": "<bpt id=\"p130\">[</bpt>Kernels available for Jupyter notebook in Spark cluster for HDInsight<ept id=\"p130\">](hdinsight-apache-spark-jupyter-notebook-kernels.md)</ept>"
    },
    {
      "pos": [
        18007,
        18023
      ],
      "content": "Manage resources"
    },
    {
      "pos": [
        18027,
        18137
      ],
      "content": "<bpt id=\"p131\">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id=\"p131\">](hdinsight-apache-spark-resource-manager.md)</ept>"
    }
  ],
  "content": " <properties \n    pageTitle=\"Create Spark Scala applications using HDInsight plugin for IntelliJ IDEA | Microsoft Azure\" \n    description=\"Learn how to create a standalone Spark application to run on HDInsight Spark clusters.\" \n    services=\"hdinsight\" \n    documentationCenter=\"\" \n    authors=\"nitinme\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags \n    ms.service=\"hdinsight\" \n    ms.workload=\"big-data\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"02/05/2016\" \n    ms.author=\"nitinme\"/>\n\n\n# Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applications (Linux)\n\nThis article provides step-by-step guidance on developing Spark applications written in Scala and submitting it to an HDInsight Spark cluster using HDInsight plugin for IntelliJ IDEA. You can use the plugin in a few different ways:\n\n* To develop and submit a Scala Spark application on an HDInsight Spark cluster\n* To access your Azure HDInsight Spark cluster resources\n* To develop and run a Scala Spark application locally\n\n>[AZURE.IMPORTANT] This tool can be used to create and submit applications only for an HDInsight Spark cluster on Linux.\n\n\n**Prerequisites**\n\n* An Azure subscription. See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).\n* An Apache Spark cluster on HDInsight Linux. For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).\n* Oracle Java Development kit. You can install it from [here](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html).\n* IntelliJ IDEA. This article uses version 15.0.1. You can install it from [here](https://www.jetbrains.com/idea/download/). \n\n\n## Install Scala plugin for IntelliJ IDEA\n\nIf IntelliJ IDEA installation did not not prompt for enabling Scala plugin, launch IntelliJ IDEA and go through the following steps to install the plugin:\n\n1. Start IntelliJ IDEA and from welcome screen click **Configure** and then click **Plugins**.\n\n    ![Enable scala plugin](./media/hdinsight-apache-spark-intellij-tool-plugin/enable-scala-plugin.png)\n\n2. In the next screen, click **Install JetBrains plugin** from the lower left corner. In the **Browse JetBrains Plugins** dialog box that opens, search for Scala and then click **Install**.\n\n    ![Install scala plugin](./media/hdinsight-apache-spark-intellij-tool-plugin/install-scala-plugin.png)\n\n3. After the plugin installs successfully, you will be prompted to restart the IDE. You can skip that for now.\n\n## Install HDInsight Tools plugin for IntelliJ IDEA\n\n1. If you are back on the IntelliJ IDEA welcome screen, click click **Configure** and then click **Plugins** again.\n\n2. In the next screen, click **Browse Repositories** from the lower left corner. In the **Browse Repositories** dialog box that opens, search for **HDInsight**, select the **Microsoft Azure HDInsight Tools for IntelliJ**, and then click **Install**.\n\n3. When prompted, click the **Restart IntelliJ IDEA** button to restart the IDE.\n\n## Run a Spark Scala application on an HDInsight Spark cluster\n\n1. Launch IntelliJ IDEA and create a new project. In the new project dialog box, make the following choices, and then click **Next**.\n\n    ![Create Spark Scala application](./media/hdinsight-apache-spark-intellij-tool-plugin/create-hdi-scala-app.png)\n\n    * From the left pane, select **HDInsight**.\n    * From the right pane, select **Spark on HDInsight (Scala)**.\n    * Click **Next**.\n\n2. In the next window, provide the project details.\n\n    ![Create Spark Scala application](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-scala-project-details.png)\n\n    * Provide a project name and project location.\n    * For **Project SDK**, make sure you provide a Java version greater than 7.\n    * For **Scala SDK**, click **Create**, click **Download**, and then select the version of Scala to use. **Make sure you do not use version 2.11.x**. This sample uses version **2.10.6**.\n    \n        ![Create Spark Scala application](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-scala-version.png)\n\n    * For **Spark SDK**, download and use the SDK from [here](http://go.microsoft.com/fwlink/?LinkID=723585&clcid=0x409).\n    * Click **Finish**.\n\n3. Define the project structure to create an artifact (packaged jar) that will eventually contain the code that runs on the cluster. \n\n    1. From the **File** menu, click **Project Structure**.\n    2. In the **Project Structure** dialog box, click **Artifacts** and then click the plus symbol. From the pop-up dialog box, click **JAR**, and then click **Empty**.\n\n        ![Create JAR](./media/hdinsight-apache-spark-intellij-tool-plugin/create-jar-1.png)\n\n    3. Enter a name for the JAR file (e.g. **MyClusterApp**). From the Available Elements pane, right-click **'MyClusterApp' compile output**, and then click **Put into Output Root**.\n\n        ![Create JAR](./media/hdinsight-apache-spark-intellij-tool-plugin/create-jar-2.png) \n    \n    4. Click **Apply** and then click **OK**.\n\n4. Add your application source code.\n\n    1. From the **Project Explorer**, right-click **src**, point to **New**, and then click **Scala class**.\n\n        ![Add source code](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-spark-scala-code.png)\n\n    2. In the **Create New Scala Class** dialog box, provide a name, for **Kind** select **Object**, and then click **OK**.\n\n        ![Add source code](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-spark-scala-code-object.png)\n\n    3. In the **MyClusterApp.scala** file, paste the following code. This code reads the data from the HVAC.csv (available on all HDInsight Spark clusters), retrieves the rows that only have one digit in the seventh column in the CSV, and writes the output to **/HVACOut** under the default storage container for the cluster.\n\n\n            import org.apache.spark.SparkConf\n            import org.apache.spark.SparkContext\n            \n            object MyClusterApp{\n              def main (arg: Array[String]): Unit = {\n                val conf = new SparkConf().setAppName(\"MyClusterApp\")\n                val sc = new SparkContext(conf)\n            \n                val rdd = sc.textFile(\"wasb:///HdiSamples/HdiSamples/SensorSampleData/hvac/HVAC.csv\")\n            \n                //find the rows which have only one digit in the 7th column in the CSV\n                val rdd1 =  rdd.filter(s => s.split(\",\")(6).length() == 1)\n            \n                rdd1.saveAsTextFile(\"wasb:///HVACOut\")\n              }\n            \n            }\n\n5. Run the application on an HDInsight Spark cluster.\n\n    1. From the **Project Explorer**, right-click the project name, and then select **Submit Spark Application to HDInsight**.\n\n        ![Submit Spark application](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-submit-spark-app-1.png)\n\n    2. You will be prompted to enter your Azure subscription credentials. In the **Spark Submission** dialog box, provide the following values.\n\n        ![Submit Spark application](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-submit-spark-app-2.png)\n\n        * For **Spark clusters (Linux only)**, select the HDInsight Spark cluster on which you want to run your application.\n\n        * The **Build Artifacts** drop-down should list the JAR name you specified in the previous steps.\n\n        * Against the **Main class name** text box, click the ellipsis (![ellipsis](./media/hdinsight-apache-spark-intellij-tool-plugin/ellipsis.png) ), select the main class in your applicaiton source code, and then click **OK**.\n\n            ![Submit Spark application](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-submit-spark-app-3.png)\n    \n        * Because the application code in this example does not require any command line arguments or reference JARs or files, you can leave the remaining text boxes empty.\n    \n        * Click **Submit**.\n\n    3. The **Spark Submission** tab at the bottom of the window should start displaying the progress.\n\n    In the next section, you learn how to access the job output using the HDInsight plugin for IntelliJ IDEA.\n\n\n## Access and manage HDInsight Spark clusters using the HDInsight plugin for IntelliJ\n\nYou can perform a variety of operations using the HDInsight plugin.\n\n### Access the storage container for the cluster\n\n1. From the **View** menu, point to **Tool Windows**, and then click **HDInsight Explorer**. If prompted, enter the credentials to access your Azure subscription.\n\n2. Expand **HDInsight** root node to see a list of HDInsight Spark clusters that are available.\n\n3. Expand the cluster name to see the storage account and the default storage container for the cluster.\n\n    ![Access cluster storage](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-spark-access-storage.png)\n\n4. Click the storage container name associated with the cluster. In the right-pane, you should see a folder called **HVACOut**. Double-click to open the folder and you will see **part-*** files. Open one of those files to see the output of the application.\n\n### Access the Spark History Server\n\n1. From the **HDInsight Explorer**, right-click your Spark cluster name and then select **Open Spark History UI**. When prompted, enter the admin credentials for the cluster. You must have specified these while provisioning the cluster.\n\n2. In the Spark History Server dashboard, you can look for the application you just finished running by using the application name. In the code above, you set the application name using `val conf = new SparkConf().setAppName(\"MyClusterApp\")`. Hence, your Spark application name was **MyClusterApp**.\n\n### Launch the Ambari portal\n\nFrom the **HDInsight Explorer**, right-click your Spark cluster name and then select **Open Cluster Management Portal (Ambari)**. When prompted, enter the admin credentials for the cluster. You must have specified these while provisioning the cluster.\n\n### Manage Azure subscriptions\n\nBy default, the HDInsight plugin lists the Spark clusters from all your Azure subscriptions. If required, you can specify the subscriptions for which you want to access the cluster. From the **HDInsight Explorer**, right-click the **HDInsight** root node, and then click **Manage Subscriptions**. From the dialog box, clear the check boxes against the subscription that you do not want to access and then click **Close**. You can also click **Sign Out** if you want to log off from your Azure subscription.\n\n\n## Run a Spark Scala application locally\n\nYou can use the HDInsight Tools plugin for IntelliJ IDEA to run Spark Scala applications locally on your workstation. Typically, such applications do not need access to cluster resources such as storage container and can be run and tested locally.\n\n### Prerequisite\n\nWhile running the local Spark Scala application on a Windows computer, you might get an exception as explained in [SPARK-2356](https://issues.apache.org/jira/browse/SPARK-2356) that occurs due to a missing WinUtils.exe on Windows. To work around this error, you must [download the executable from here](http://public-repo-1.hortonworks.com/hdp-win-alpha/winutils.exe) to a location like **C:\\WinUtils\\bin**. You must then add an environment variable **HADOOP_HOME** and set the value of the variable to **C\\WinUtils**.\n\n### Run a local Spark Scala application  \n\n1. Launch IntelliJ IDEA and create a new project. In the new project dialog box, make the following choices, and then click **Next**.\n\n    ![Create Spark Scala application](./media/hdinsight-apache-spark-intellij-tool-plugin/create-hdi-scala-app.png)\n\n    * From the left pane, select **HDInsight**.\n    * From the right pane, select **Spark on HDInsight (Scala)**.\n    * Click **Next**.\n\n2. In the next window, provide the project details.\n\n    ![Create Spark Scala application](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-scala-local-project-details.png)\n\n    * Provide a project name and project location.\n    * For **Project SDK**, make sure you provide a Java version greater than 7.\n    * For **Scala SDK**, click **Create**, click **Download**, and then select the version of Scala to use. **Make sure you do not use version 2.11.x**. This sample uses version **2.10.6**.\n    \n        ![Create Spark Scala application](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-scala-version.png)\n\n    * For **Spark SDK**, download and use the SDK from [here](http://go.microsoft.com/fwlink/?LinkID=723585&clcid=0x409).\n    * Click **Finish**.\n\n3. Define the project structure to create an artifact (packaged jar) that will eventually contain the code that runs on the cluster. \n\n    1. From the **File** menu, click **Project Structure**.\n    2. In the **Project Structure** dialog box, click **Artifacts** and then click the plus symbol. From the pop-up dialog box, click **JAR**, and then click **Empty**.\n\n        ![Create JAR](./media/hdinsight-apache-spark-intellij-tool-plugin/create-jar-1.png)\n\n    3. Enter a name for the JAR file (e.g. **MyLocalApp**). From the Available Elements pane, right-click **'MyLocalApp' compile output**, and then click **Put into Output Root**.\n\n        ![Create JAR](./media/hdinsight-apache-spark-intellij-tool-plugin/create-local-jar-2.png)   \n    \n    4. Click **Apply** and then click **OK**.\n\n4. Add your application source code.\n\n    1. From the **Project Explorer**, right-click **src**, point to **New**, and then click **Scala class**.\n\n        ![Add source code](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-spark-local-scala-code.png)\n\n    2. In the **Create New Scala Class** dialog box, provide a name, for **Kind** select **Object**, and then click **OK**.\n\n        ![Add source code](./media/hdinsight-apache-spark-intellij-tool-plugin/hdi-spark-local-scala-code-object.png)\n\n    3. In the **MyLocalApp.scala** file, paste the following code. This code reads a sample input text file on your computer and prints out the number of lines in that text file that contain the characters \"a\" and \"b\".\n\n\n            import org.apache.spark.SparkContext\n            import org.apache.spark.SparkContext._\n            import org.apache.spark.SparkConf\n            \n            object MyLocalApp {\n              def main(args: Array[String]) {\n                val logFile = \"C:/users/nitinme/Desktop/commands.txt\" // Should be some file on your system\n                val conf = new SparkConf().setAppName(\"MyLocalApp\").setMaster(\"local[2]\")\n                val sc = new SparkContext(conf)\n                val logData = sc.textFile(logFile, 2).cache()\n                val numAs = logData.filter(line => line.contains(\"a\")).count()\n                val numBs = logData.filter(line => line.contains(\"b\")).count()\n                println(\"Lines with a: %s, Lines with b: %s\".format(numAs, numBs))\n              }\n            }\n\n5. Run the application locally on your workstation. From the **Run** menu, click **Run 'MyLocalApp'**. You will see an output like this in the **Run** tab at the bottom.\n\n        ...\n        ...\n        Lines with a: 4, Lines with b: 4\n        ...\n        ...\n        16/02/01 15:04:05 INFO SparkContext: Successfully stopped SparkContext\n        16/02/01 15:04:05 INFO ShutdownHookManager: Shutdown hook called\n        16/02/01 15:04:05 INFO ShutdownHookManager: Deleting directory C:\\Users\\nitinme\\AppData\\Local\\Temp\\spark-618dee33-45a3-4bce-a8fc-bf85663133b3\n        \n        Process finished with exit code 0\n\n\n## Convert existing IntelliJ IDEA applications to use the HDInsight tool plugin\n\nYou can also convert your existing Spark Scala applications created in IntelliJ IDEA to be compatible with the HDInsight tool plugin. This will enable you to use the tool to submit the applications to an HDInsight Spark cluster. You can do so by performing the following steps:\n\n1. For an existing Spark Scala appliction created using IntelliJ IDEA, open the associated .iml file.\n2. At the root level, you will see a **module** element like this:\n\n        <module org.jetbrains.idea.maven.project.MavenProjectsManager.isMavenModule=\"true\" type=\"JAVA_MODULE\" version=\"4\">\n\n3. Edit the element to add `UniqueKey=\"HDInsightTool\"` so that the **module** element looks like the following:\n\n        <module org.jetbrains.idea.maven.project.MavenProjectsManager.isMavenModule=\"true\" type=\"JAVA_MODULE\" version=\"4\" UniqueKey=\"HDInsightTool\">\n\n4. Save the changes. Your application should now be compatible with the HDInsight tool plugin. You can test this by right-clicking on the project name in the Project Explorer. The pop-up menu should now have the option to **Submit Spark Application to HDInsight**.\n\n## <a name=\"seealso\"></a>See also\n\n\n* [Overview: Apache Spark on Azure HDInsight](hdinsight-apache-spark-overview.md)\n\n### Scenarios\n\n* [Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools](hdinsight-apache-spark-use-bi-tools.md)\n\n* [Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data](hdinsight-apache-spark-ipython-notebook-machine-learning.md)\n\n* [Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results](hdinsight-apache-spark-machine-learning-mllib-ipython.md)\n\n* [Spark Streaming: Use Spark in HDInsight for building real-time streaming applications](hdinsight-apache-spark-eventhub-streaming.md)\n\n* [Website log analysis using Spark in HDInsight](hdinsight-apache-spark-custom-library-website-log-analysis.md)\n\n### Create and run applications\n\n* [Run jobs remotely on a Spark cluster using Livy](hdinsight-apache-spark-livy-rest-interface.md)\n\n### Tools and extensions\n\n* [Use Zeppelin notebooks with a Spark cluster on HDInsight](hdinsight-apache-spark-use-zeppelin-notebook.md)\n\n* [Kernels available for Jupyter notebook in Spark cluster for HDInsight](hdinsight-apache-spark-jupyter-notebook-kernels.md)\n\n### Manage resources\n\n* [Manage resources for the Apache Spark cluster in Azure HDInsight](hdinsight-apache-spark-resource-manager.md)\n"
}