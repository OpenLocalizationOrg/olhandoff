{
  "nodes": [
    {
      "pos": [
        26,
        97
      ],
      "content": "MapReduce and Remote Desktop with Hadoop in HDInsight | Microsoft Azure"
    },
    {
      "pos": [
        115,
        204
      ],
      "content": "Learn how to use Remote Desktop to connect to Hadoop on HDInsight and run MapReduce jobs."
    },
    {
      "pos": [
        522,
        578
      ],
      "content": "Use MapReduce in Hadoop on HDInsight with Remote Desktop"
    },
    {
      "pos": [
        670,
        830
      ],
      "content": "In this article, you will learn how to connect to a Hadoop on HDInsight cluster by using Remote Desktop and then run MapReduce jobs by using the Hadoop command."
    },
    {
      "pos": [
        832,
        834
      ],
      "content": "##"
    },
    {
      "pos": [
        853,
        866
      ],
      "content": "Prerequisites"
    },
    {
      "pos": [
        868,
        935
      ],
      "content": "To complete the steps in this article, you will need the following:"
    },
    {
      "pos": [
        939,
        994
      ],
      "content": "A Windows-based HDInsight (Hadoop on HDInsight) cluster"
    },
    {
      "pos": [
        998,
        1059
      ],
      "content": "A client computer running Windows 10, Windows 8, or Windows 7"
    },
    {
      "pos": [
        1061,
        1063
      ],
      "content": "##"
    },
    {
      "pos": [
        1083,
        1110
      ],
      "content": "Connect with Remote Desktop"
    },
    {
      "pos": [
        1112,
        1306
      ],
      "content": "Enable Remote Desktop for the HDInsight cluster, then connect to it by following the instructions at <bpt id=\"p1\">[</bpt>Connect to HDInsight clusters using RDP<ept id=\"p1\">](hdinsight-administer-use-management-portal.md#rdp)</ept>."
    },
    {
      "pos": [
        1308,
        1310
      ],
      "content": "##"
    },
    {
      "pos": [
        1329,
        1351
      ],
      "content": "Use the Hadoop command"
    },
    {
      "pos": [
        1353,
        1493
      ],
      "content": "When you are connected to the desktop for the HDInsight cluster, use the following steps to run a MapReduce job by using the Hadoop command:"
    },
    {
      "pos": [
        1498,
        1654
      ],
      "content": "From the HDInsight desktop, start the <bpt id=\"p2\">**</bpt>Hadoop Command Line<ept id=\"p2\">**</ept>. This opens a new command prompt in the <bpt id=\"p3\">**</bpt>c:\\apps\\dist\\hadoop-&amp;lt;version number&gt;<ept id=\"p3\">**</ept><ph id=\"ph3\"/> directory.",
      "nodes": [
        {
          "content": "From the HDInsight desktop, start the <bpt id=\"p2\">**</bpt>Hadoop Command Line<ept id=\"p2\">**</ept>.",
          "pos": [
            0,
            100
          ]
        },
        {
          "content": "This opens a new command prompt in the <bpt id=\"p3\">**</bpt>c:\\apps\\dist\\hadoop-&amp;lt;version number&gt;<ept id=\"p3\">**</ept><ph id=\"ph3\"/> directory.",
          "pos": [
            101,
            253
          ]
        }
      ]
    },
    {
      "pos": [
        1662,
        1921
      ],
      "content": "<ph id=\"ph4\">[AZURE.NOTE]</ph><ph id=\"ph5\"/> The version number changes as Hadoop is updated. The <bpt id=\"p4\">**</bpt>HADOOP_HOME<ept id=\"p4\">**</ept><ph id=\"ph6\"/> environment variable can be used to find the path. For example, <ph id=\"ph7\">`cd %HADOOP_HOME%`</ph><ph id=\"ph8\"/> changes directories to the Hadoop directory, without requiring you to know the version number.",
      "nodes": [
        {
          "content": "<ph id=\"ph4\">[AZURE.NOTE]</ph><ph id=\"ph5\"/> The version number changes as Hadoop is updated.",
          "pos": [
            0,
            93
          ]
        },
        {
          "content": "The <bpt id=\"p4\">**</bpt>HADOOP_HOME<ept id=\"p4\">**</ept><ph id=\"ph6\"/> environment variable can be used to find the path.",
          "pos": [
            94,
            216
          ]
        },
        {
          "content": "For example, <ph id=\"ph7\">`cd %HADOOP_HOME%`</ph><ph id=\"ph8\"/> changes directories to the Hadoop directory, without requiring you to know the version number.",
          "pos": [
            217,
            375
          ]
        }
      ]
    },
    {
      "pos": [
        1926,
        2015
      ],
      "content": "To use the <bpt id=\"p5\">**</bpt>Hadoop<ept id=\"p5\">**</ept><ph id=\"ph9\"/> command to run an example MapReduce job, use the following command:"
    },
    {
      "pos": [
        2161,
        2433
      ],
      "content": "This starts the <bpt id=\"p6\">**</bpt>wordcount<ept id=\"p6\">**</ept><ph id=\"ph10\"/> class, which is contained in the <bpt id=\"p7\">**</bpt>hadoop-mapreduce-examples.jar<ept id=\"p7\">**</ept><ph id=\"ph11\"/> file in the current directory. As input, it uses the <bpt id=\"p8\">**</bpt>wasb://example/data/gutenberg/davinci.txt<ept id=\"p8\">**</ept><ph id=\"ph12\"/> document, and output is stored at: <bpt id=\"p9\">**</bpt>wasb:///example/data/WordCountOutput<ept id=\"p9\">**</ept>.",
      "nodes": [
        {
          "content": "This starts the <bpt id=\"p6\">**</bpt>wordcount<ept id=\"p6\">**</ept><ph id=\"ph10\"/> class, which is contained in the <bpt id=\"p7\">**</bpt>hadoop-mapreduce-examples.jar<ept id=\"p7\">**</ept><ph id=\"ph11\"/> file in the current directory.",
          "pos": [
            0,
            233
          ]
        },
        {
          "content": "As input, it uses the <bpt id=\"p8\">**</bpt>wasb://example/data/gutenberg/davinci.txt<ept id=\"p8\">**</ept><ph id=\"ph12\"/> document, and output is stored at: <bpt id=\"p9\">**</bpt>wasb:///example/data/WordCountOutput<ept id=\"p9\">**</ept>.",
          "pos": [
            234,
            469
          ]
        }
      ]
    },
    {
      "pos": [
        2441,
        2601
      ],
      "content": "<ph id=\"ph13\">[AZURE.NOTE]</ph><ph id=\"ph14\"/> for more information about this MapReduce job and the example data, see <ph id=\"ph15\">&lt;a href=\"hdinsight-use-mapreduce.md\"&gt;</ph>Use MapReduce in HDInsight Hadoop<ph id=\"ph16\">&lt;/a&gt;</ph>."
    },
    {
      "pos": [
        2606,
        2725
      ],
      "content": "The job emits details as it is processed, and it returns information similar to the following when the job is complete:"
    },
    {
      "pos": [
        2858,
        2985
      ],
      "content": "When the job is complete, use the following command to list the output files stored at <bpt id=\"p10\">**</bpt>wasb://example/data/WordCountOutput<ept id=\"p10\">**</ept>:"
    },
    {
      "pos": [
        3051,
        3176
      ],
      "content": "This should display two files, <bpt id=\"p11\">**</bpt>_SUCCESS<ept id=\"p11\">**</ept><ph id=\"ph17\"/> and <bpt id=\"p12\">**</bpt>part-r-00000<ept id=\"p12\">**</ept>. The <bpt id=\"p13\">**</bpt>part-r-00000<ept id=\"p13\">**</ept><ph id=\"ph18\"/> file contains the output for this job.",
      "nodes": [
        {
          "content": "This should display two files, <bpt id=\"p11\">**</bpt>_SUCCESS<ept id=\"p11\">**</ept><ph id=\"ph17\"/> and <bpt id=\"p12\">**</bpt>part-r-00000<ept id=\"p12\">**</ept>.",
          "pos": [
            0,
            160
          ]
        },
        {
          "content": "The <bpt id=\"p13\">**</bpt>part-r-00000<ept id=\"p13\">**</ept><ph id=\"ph18\"/> file contains the output for this job.",
          "pos": [
            161,
            275
          ]
        }
      ]
    },
    {
      "pos": [
        3184,
        3342
      ],
      "content": "<ph id=\"ph19\">[AZURE.NOTE]</ph><ph id=\"ph20\"/> Some MapReduce jobs may split the results across multiple <bpt id=\"p14\">**</bpt>part-r-#####<ept id=\"p14\">**</ept><ph id=\"ph21\"/> files. If so, use the ##### suffix to indicate the order of the files.",
      "nodes": [
        {
          "content": "<ph id=\"ph19\">[AZURE.NOTE]</ph><ph id=\"ph20\"/> Some MapReduce jobs may split the results across multiple <bpt id=\"p14\">**</bpt>part-r-#####<ept id=\"p14\">**</ept><ph id=\"ph21\"/> files.",
          "pos": [
            0,
            183
          ]
        },
        {
          "content": "If so, use the ##### suffix to indicate the order of the files.",
          "pos": [
            184,
            247
          ]
        }
      ]
    },
    {
      "pos": [
        3347,
        3393
      ],
      "content": "To view the output, use the following command:"
    },
    {
      "pos": [
        3473,
        3710
      ],
      "content": "This displays a list of the words that are contained in the <bpt id=\"p15\">**</bpt>wasb://example/data/gutenberg/davinci.txt<ept id=\"p15\">**</ept><ph id=\"ph22\"/> file, along with the number of times each word occured. The following is an example of the data that will be contained in the file:",
      "nodes": [
        {
          "content": "This displays a list of the words that are contained in the <bpt id=\"p15\">**</bpt>wasb://example/data/gutenberg/davinci.txt<ept id=\"p15\">**</ept><ph id=\"ph22\"/> file, along with the number of times each word occured.",
          "pos": [
            0,
            216
          ]
        },
        {
          "content": "The following is an example of the data that will be contained in the file:",
          "pos": [
            217,
            292
          ]
        }
      ]
    },
    {
      "pos": [
        3895,
        3897
      ],
      "content": "##"
    },
    {
      "pos": [
        3917,
        3924
      ],
      "content": "Summary"
    },
    {
      "pos": [
        3926,
        4057
      ],
      "content": "As you can see, the Hadoop command provides an easy way to run MapReduce jobs on an HDInsight cluster and then view the job output."
    },
    {
      "pos": [
        4059,
        4061
      ],
      "content": "##"
    },
    {
      "pos": [
        4083,
        4093
      ],
      "content": "Next steps"
    },
    {
      "pos": [
        4095,
        4153
      ],
      "content": "For general information about MapReduce jobs in HDInsight:"
    },
    {
      "pos": [
        4157,
        4220
      ],
      "content": "<bpt id=\"p16\">[</bpt>Use MapReduce on HDInsight Hadoop<ept id=\"p16\">](hdinsight-use-mapreduce.md)</ept>"
    },
    {
      "pos": [
        4222,
        4293
      ],
      "content": "For information about other ways you can work with Hadoop on HDInsight:"
    },
    {
      "pos": [
        4297,
        4355
      ],
      "content": "<bpt id=\"p17\">[</bpt>Use Hive with Hadoop on HDInsight<ept id=\"p17\">](hdinsight-use-hive.md)</ept>"
    },
    {
      "pos": [
        4359,
        4415
      ],
      "content": "<bpt id=\"p18\">[</bpt>Use Pig with Hadoop on HDInsight<ept id=\"p18\">](hdinsight-use-pig.md)</ept>"
    }
  ],
  "content": "<properties\n   pageTitle=\"MapReduce and Remote Desktop with Hadoop in HDInsight | Microsoft Azure\"\n   description=\"Learn how to use Remote Desktop to connect to Hadoop on HDInsight and run MapReduce jobs.\"\n   services=\"hdinsight\"\n   documentationCenter=\"\"\n   authors=\"Blackmist\"\n   manager=\"paulettm\"\n   editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags\n   ms.service=\"hdinsight\"\n   ms.devlang=\"na\"\n   ms.topic=\"article\"\n   ms.tgt_pltfrm=\"na\"\n   ms.workload=\"big-data\"\n   ms.date=\"02/05/2016\"\n   ms.author=\"larryfr\"/>\n\n# Use MapReduce in Hadoop on HDInsight with Remote Desktop\n\n[AZURE.INCLUDE [mapreduce-selector](../../includes/hdinsight-selector-use-mapreduce.md)]\n\nIn this article, you will learn how to connect to a Hadoop on HDInsight cluster by using Remote Desktop and then run MapReduce jobs by using the Hadoop command.\n\n##<a id=\"prereq\"></a>Prerequisites\n\nTo complete the steps in this article, you will need the following:\n\n* A Windows-based HDInsight (Hadoop on HDInsight) cluster\n\n* A client computer running Windows 10, Windows 8, or Windows 7\n\n##<a id=\"connect\"></a>Connect with Remote Desktop\n\nEnable Remote Desktop for the HDInsight cluster, then connect to it by following the instructions at [Connect to HDInsight clusters using RDP](hdinsight-administer-use-management-portal.md#rdp).\n\n##<a id=\"hadoop\"></a>Use the Hadoop command\n\nWhen you are connected to the desktop for the HDInsight cluster, use the following steps to run a MapReduce job by using the Hadoop command:\n\n1. From the HDInsight desktop, start the **Hadoop Command Line**. This opens a new command prompt in the **c:\\apps\\dist\\hadoop-&lt;version number>** directory.\n\n    > [AZURE.NOTE] The version number changes as Hadoop is updated. The **HADOOP_HOME** environment variable can be used to find the path. For example, `cd %HADOOP_HOME%` changes directories to the Hadoop directory, without requiring you to know the version number.\n\n2. To use the **Hadoop** command to run an example MapReduce job, use the following command:\n\n        hadoop jar hadoop-mapreduce-examples.jar wordcount wasb:///example/data/gutenberg/davinci.txt wasb:///example/data/WordCountOutput\n\n    This starts the **wordcount** class, which is contained in the **hadoop-mapreduce-examples.jar** file in the current directory. As input, it uses the **wasb://example/data/gutenberg/davinci.txt** document, and output is stored at: **wasb:///example/data/WordCountOutput**.\n\n    > [AZURE.NOTE] for more information about this MapReduce job and the example data, see <a href=\"hdinsight-use-mapreduce.md\">Use MapReduce in HDInsight Hadoop</a>.\n\n2. The job emits details as it is processed, and it returns information similar to the following when the job is complete:\n\n        File Input Format Counters\n        Bytes Read=1395666\n        File Output Format Counters\n        Bytes Written=337623\n\n3. When the job is complete, use the following command to list the output files stored at **wasb://example/data/WordCountOutput**:\n\n        hadoop fs -ls wasb:///example/data/WordCountOutput\n\n    This should display two files, **_SUCCESS** and **part-r-00000**. The **part-r-00000** file contains the output for this job.\n\n    > [AZURE.NOTE] Some MapReduce jobs may split the results across multiple **part-r-#####** files. If so, use the ##### suffix to indicate the order of the files.\n\n4. To view the output, use the following command:\n\n        hadoop fs -cat wasb:///example/data/WordCountOutput/part-r-00000\n\n    This displays a list of the words that are contained in the **wasb://example/data/gutenberg/davinci.txt** file, along with the number of times each word occured. The following is an example of the data that will be contained in the file:\n\n        wreathed        3\n        wreathing       1\n        wreaths         1\n        wrecked         3\n        wrenching       1\n        wretched        6\n        wriggling       1\n\n##<a id=\"summary\"></a>Summary\n\nAs you can see, the Hadoop command provides an easy way to run MapReduce jobs on an HDInsight cluster and then view the job output.\n\n##<a id=\"nextsteps\"></a>Next steps\n\nFor general information about MapReduce jobs in HDInsight:\n\n* [Use MapReduce on HDInsight Hadoop](hdinsight-use-mapreduce.md)\n\nFor information about other ways you can work with Hadoop on HDInsight:\n\n* [Use Hive with Hadoop on HDInsight](hdinsight-use-hive.md)\n\n* [Use Pig with Hadoop on HDInsight](hdinsight-use-pig.md)\n"
}