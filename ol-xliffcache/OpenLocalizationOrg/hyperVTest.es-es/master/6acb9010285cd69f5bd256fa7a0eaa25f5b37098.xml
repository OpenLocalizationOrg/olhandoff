{
  "nodes": [
    {
      "pos": [
        27,
        83
      ],
      "content": "Consume a Machine Learning web service | Microsoft Azure"
    },
    {
      "pos": [
        102,
        277
      ],
      "content": "Once a machine learning service is deployed, the RESTFul web service that is made available can be consumed either as request-response service or as a batch execution service."
    },
    {
      "pos": [
        595,
        705
      ],
      "content": "How to consume an Azure Machine Learning web service that has been deployed from a Machine Learning experiment"
    },
    {
      "pos": [
        710,
        722
      ],
      "content": "Introduction"
    },
    {
      "pos": [
        724,
        1184
      ],
      "content": "When deployed as a web service, Azure Machine Learning experiments provide a REST API that can be consumed by a wide range of devices and platforms. This is because the simple REST API accepts and responds with JSON formatted messages. The Azure Machine Learning portal provides code that can be used to call the web service in R, C#, and Python. But these services can be called with any programming language and from any device that satisfies three criteria:",
      "nodes": [
        {
          "content": "When deployed as a web service, Azure Machine Learning experiments provide a REST API that can be consumed by a wide range of devices and platforms.",
          "pos": [
            0,
            148
          ]
        },
        {
          "content": "This is because the simple REST API accepts and responds with JSON formatted messages.",
          "pos": [
            149,
            235
          ]
        },
        {
          "content": "The Azure Machine Learning portal provides code that can be used to call the web service in R, C#, and Python.",
          "pos": [
            236,
            346
          ]
        },
        {
          "content": "But these services can be called with any programming language and from any device that satisfies three criteria:",
          "pos": [
            347,
            460
          ]
        }
      ]
    },
    {
      "pos": [
        1188,
        1212
      ],
      "content": "Has a network connection"
    },
    {
      "pos": [
        1215,
        1261
      ],
      "content": "Has SSL capabilities to perform HTTPS requests"
    },
    {
      "pos": [
        1264,
        1324
      ],
      "content": "Has the ability to parse JSON (by hand or support libraries)"
    },
    {
      "pos": [
        1326,
        1465
      ],
      "content": "This means the services can be consumed from web applications, mobile applications, custom desktop applications and even from within Excel."
    },
    {
      "pos": [
        1563,
        2075
      ],
      "content": "An Azure Machine Learning web service can be consumed in two different ways, either as a request-response service or as a batch execution service. In each scenario the functionality is provided through the RESTFul web service that is made available for consumption once the experiment has been deployed. Deploying a Machine Learning web service in Azure with an Azure web service end-point, where the service is automatically scaled based on usage, you can avoid upfront and ongoing costs for hardware resources.",
      "nodes": [
        {
          "content": "An Azure Machine Learning web service can be consumed in two different ways, either as a request-response service or as a batch execution service.",
          "pos": [
            0,
            146
          ]
        },
        {
          "content": "In each scenario the functionality is provided through the RESTFul web service that is made available for consumption once the experiment has been deployed.",
          "pos": [
            147,
            303
          ]
        },
        {
          "content": "Deploying a Machine Learning web service in Azure with an Azure web service end-point, where the service is automatically scaled based on usage, you can avoid upfront and ongoing costs for hardware resources.",
          "pos": [
            304,
            512
          ]
        }
      ]
    },
    {
      "pos": [
        2079,
        2306
      ],
      "content": "<ph id=\"ph3\">[AZURE.TIP]</ph><ph id=\"ph4\"/> For a simple way to create a web app to access your predictive web service, see <bpt id=\"p1\">[</bpt>Consume an Azure Machine Learning web service with a web app template<ept id=\"p1\">](machine-learning-consume-web-service-with-web-app-template.md)</ept>."
    },
    {
      "pos": [
        2536,
        2855
      ],
      "content": "For information about how to create and deploy an Azure Machine Learning web service, see <bpt id=\"p2\">[</bpt>Deploy an Azure Machine Learning web service<ept id=\"p2\">][publish]</ept>. For a step-by-step walkthrough of creating a Machine Learning experiment and deploying it, see <bpt id=\"p3\">[</bpt>Develop a predictive solution by using Azure Machine Learning<ept id=\"p3\">][walkthrough]</ept>.",
      "nodes": [
        {
          "content": "For information about how to create and deploy an Azure Machine Learning web service, see <bpt id=\"p2\">[</bpt>Deploy an Azure Machine Learning web service<ept id=\"p2\">][publish]</ept>.",
          "pos": [
            0,
            184
          ]
        },
        {
          "content": "For a step-by-step walkthrough of creating a Machine Learning experiment and deploying it, see <bpt id=\"p3\">[</bpt>Develop a predictive solution by using Azure Machine Learning<ept id=\"p3\">][walkthrough]</ept>.",
          "pos": [
            185,
            395
          ]
        }
      ]
    },
    {
      "pos": [
        3007,
        3037
      ],
      "content": "Request-Response Service (RRS)"
    },
    {
      "pos": [
        3039,
        3342
      ],
      "content": "A Request-Response Service (RRS) is a low-latency, highly scalable web service used to provide an interface to the stateless models that have been created and deployed from an Azure Machine Learning Studio experiment. It enables scenarios where the consuming application expects a response in real-time.",
      "nodes": [
        {
          "content": "A Request-Response Service (RRS) is a low-latency, highly scalable web service used to provide an interface to the stateless models that have been created and deployed from an Azure Machine Learning Studio experiment.",
          "pos": [
            0,
            217
          ]
        },
        {
          "content": "It enables scenarios where the consuming application expects a response in real-time.",
          "pos": [
            218,
            303
          ]
        }
      ]
    },
    {
      "pos": [
        3344,
        3515
      ],
      "content": "RRS accepts a single row, or multiple rows, of input parameters and can generate a single row, or multiple rows, as output. The output row(s) can contain multiple columns.",
      "nodes": [
        {
          "content": "RRS accepts a single row, or multiple rows, of input parameters and can generate a single row, or multiple rows, as output.",
          "pos": [
            0,
            123
          ]
        },
        {
          "content": "The output row(s) can contain multiple columns.",
          "pos": [
            124,
            171
          ]
        }
      ]
    },
    {
      "pos": [
        3517,
        3894
      ],
      "content": "An example for RRS is validating the authenticity of an application. Hundreds to millions of installations of an application can be expected in this case. When the application starts up, it makes a call to the RRS service with the relevant input. The application then receives a validation response from the service that either allows or blocks the application from performing.",
      "nodes": [
        {
          "content": "An example for RRS is validating the authenticity of an application.",
          "pos": [
            0,
            68
          ]
        },
        {
          "content": "Hundreds to millions of installations of an application can be expected in this case.",
          "pos": [
            69,
            154
          ]
        },
        {
          "content": "When the application starts up, it makes a call to the RRS service with the relevant input.",
          "pos": [
            155,
            246
          ]
        },
        {
          "content": "The application then receives a validation response from the service that either allows or blocks the application from performing.",
          "pos": [
            247,
            377
          ]
        }
      ]
    },
    {
      "pos": [
        3900,
        3929
      ],
      "content": "Batch Execution Service (BES)"
    },
    {
      "pos": [
        3931,
        4414
      ],
      "content": "A Batch Execution Service (BES) is a service that handles high volume, asynchronous, scoring of a batch of data records. The input for the BES contains a batch of records from a variety of sources, such as blobs, tables in Azure, SQL Azure, HDInsight (results of a Hive Query, for example), and HTTP sources. The output for the BES contains the results of the scoring. Results are output to a file in Azure blob storage and data from the storage endpoint is returned in the response.",
      "nodes": [
        {
          "content": "A Batch Execution Service (BES) is a service that handles high volume, asynchronous, scoring of a batch of data records.",
          "pos": [
            0,
            120
          ]
        },
        {
          "content": "The input for the BES contains a batch of records from a variety of sources, such as blobs, tables in Azure, SQL Azure, HDInsight (results of a Hive Query, for example), and HTTP sources.",
          "pos": [
            121,
            308
          ]
        },
        {
          "content": "The output for the BES contains the results of the scoring.",
          "pos": [
            309,
            368
          ]
        },
        {
          "content": "Results are output to a file in Azure blob storage and data from the storage endpoint is returned in the response.",
          "pos": [
            369,
            483
          ]
        }
      ]
    },
    {
      "pos": [
        4416,
        4573
      ],
      "content": "A BES would be useful when responses are not needed immediately, such as for regularly scheduled scoring for individuals or internet of things (IOT) devices."
    },
    {
      "pos": [
        4578,
        4586
      ],
      "content": "Examples"
    },
    {
      "pos": [
        4587,
        4825
      ],
      "content": "To show how both RRS and BES work, we use an example Azure web service. This service would be used in an IOT (Internet Of Things) scenario. To keep it simple, our device only sends up one value, <ph id=\"ph6\">`cog_speed`</ph>, and gets a single answer back.",
      "nodes": [
        {
          "content": "To show how both RRS and BES work, we use an example Azure web service.",
          "pos": [
            0,
            71
          ]
        },
        {
          "content": "This service would be used in an IOT (Internet Of Things) scenario.",
          "pos": [
            72,
            139
          ]
        },
        {
          "content": "To keep it simple, our device only sends up one value, <ph id=\"ph6\">`cog_speed`</ph>, and gets a single answer back.",
          "pos": [
            140,
            256
          ]
        }
      ]
    },
    {
      "pos": [
        4827,
        5259
      ],
      "content": "There are four pieces of information that are needed to call either the RRS or BES service. This information is readily available from the service pages in <bpt id=\"p4\">[</bpt>Azure Machine Learning Studio<ept id=\"p4\">](https://studio.azureml.net)</ept><ph id=\"ph7\"/> once the experiment has been deployed. Click on the WEB SERVICES tab at the left of the screen and you will see the deployed services. Click a service to find the following links and information for both RRS and BES:",
      "nodes": [
        {
          "content": "There are four pieces of information that are needed to call either the RRS or BES service.",
          "pos": [
            0,
            91
          ]
        },
        {
          "content": "This information is readily available from the service pages in <bpt id=\"p4\">[</bpt>Azure Machine Learning Studio<ept id=\"p4\">](https://studio.azureml.net)</ept><ph id=\"ph7\"/> once the experiment has been deployed.",
          "pos": [
            92,
            306
          ]
        },
        {
          "content": "Click on the WEB SERVICES tab at the left of the screen and you will see the deployed services.",
          "pos": [
            307,
            402
          ]
        },
        {
          "content": "Click a service to find the following links and information for both RRS and BES:",
          "pos": [
            403,
            484
          ]
        }
      ]
    },
    {
      "pos": [
        5265,
        5325
      ],
      "content": "The service <bpt id=\"p5\">**</bpt>API key<ept id=\"p5\">**</ept>, available on the services Dashboard"
    },
    {
      "pos": [
        5330,
        5412
      ],
      "content": "The service <bpt id=\"p6\">**</bpt>request URI<ept id=\"p6\">**</ept>, available on the API help page for the chosen service"
    },
    {
      "pos": [
        5417,
        5521
      ],
      "content": "The expected API <bpt id=\"p7\">**</bpt>request headers<ept id=\"p7\">**</ept><ph id=\"ph8\"/> and <bpt id=\"p8\">**</bpt>body<ept id=\"p8\">**</ept>, available on the API help page for the chosen service"
    },
    {
      "pos": [
        5526,
        5631
      ],
      "content": "The expected API <bpt id=\"p9\">**</bpt>response headers<ept id=\"p9\">**</ept><ph id=\"ph9\"/> and <bpt id=\"p10\">**</bpt>body<ept id=\"p10\">**</ept>, available on the API help page for the chosen service"
    },
    {
      "pos": [
        5633,
        5763
      ],
      "content": "In the two examples below, the C# language is used to illustrate the code needed and the targeted platform is a Windows 8 desktop."
    },
    {
      "pos": [
        5769,
        5780
      ],
      "content": "RRS Example"
    },
    {
      "pos": [
        5781,
        6075
      ],
      "content": "Click <bpt id=\"p11\">**</bpt>REQUEST/RESPONSE<ept id=\"p11\">**</ept><ph id=\"ph10\"/> under <bpt id=\"p12\">**</bpt>API HELP PAGE<ept id=\"p12\">**</ept><ph id=\"ph11\"/> on the service Dashboard to view the API help page. On this page, aside from the URI, you will find input and output definitions and code samples. The API input, for this service specifically, is shown below and is the payload of the API call.",
      "nodes": [
        {
          "content": "Click <bpt id=\"p11\">**</bpt>REQUEST/RESPONSE<ept id=\"p11\">**</ept><ph id=\"ph10\"/> under <bpt id=\"p12\">**</bpt>API HELP PAGE<ept id=\"p12\">**</ept><ph id=\"ph11\"/> on the service Dashboard to view the API help page.",
          "pos": [
            0,
            212
          ]
        },
        {
          "content": "On this page, aside from the URI, you will find input and output definitions and code samples.",
          "pos": [
            213,
            307
          ]
        },
        {
          "content": "The API input, for this service specifically, is shown below and is the payload of the API call.",
          "pos": [
            308,
            404
          ]
        }
      ]
    },
    {
      "pos": [
        6077,
        6095
      ],
      "content": "<bpt id=\"p13\">**</bpt>Sample Request<ept id=\"p13\">**</ept>"
    },
    {
      "pos": [
        6388,
        6453
      ],
      "content": "Similarly, the API response for this service is also shown below."
    },
    {
      "pos": [
        6455,
        6474
      ],
      "content": "<bpt id=\"p14\">**</bpt>Sample Response<ept id=\"p14\">**</ept>"
    },
    {
      "pos": [
        6894,
        7014
      ],
      "content": "Towards the bottom of the help page you will find the code examples. Below is the code sample for the C# implementation.",
      "nodes": [
        {
          "content": "Towards the bottom of the help page you will find the code examples.",
          "pos": [
            0,
            68
          ]
        },
        {
          "content": "Below is the code sample for the C# implementation.",
          "pos": [
            69,
            120
          ]
        }
      ]
    },
    {
      "pos": [
        7016,
        7031
      ],
      "content": "<bpt id=\"p15\">**</bpt>Sample Code<ept id=\"p15\">**</ept>"
    },
    {
      "pos": [
        9930,
        9941
      ],
      "content": "BES Example"
    },
    {
      "pos": [
        9942,
        10197
      ],
      "content": "Unlike the RRS service, the BES service is asynchronous. This means that the BES API is simply queuing up a job to be executed, and the caller polls the job's status to see when it has completed. Here are the operations currently supported for batch jobs:",
      "nodes": [
        {
          "content": "Unlike the RRS service, the BES service is asynchronous.",
          "pos": [
            0,
            56
          ]
        },
        {
          "content": "This means that the BES API is simply queuing up a job to be executed, and the caller polls the job's status to see when it has completed.",
          "pos": [
            57,
            195
          ]
        },
        {
          "content": "Here are the operations currently supported for batch jobs:",
          "pos": [
            196,
            255
          ]
        }
      ]
    },
    {
      "pos": [
        10202,
        10229
      ],
      "content": "Create (submit) a batch job"
    },
    {
      "pos": [
        10233,
        10253
      ],
      "content": "Start this batch job"
    },
    {
      "pos": [
        10257,
        10298
      ],
      "content": "Get the status or result of the batch job"
    },
    {
      "pos": [
        10302,
        10328
      ],
      "content": "Cancel a running batch job"
    },
    {
      "pos": [
        10330,
        10365
      ],
      "content": "<bpt id=\"p16\">**</bpt>1. Create a Batch Execution Job<ept id=\"p16\">**</ept>"
    },
    {
      "pos": [
        10367,
        10516
      ],
      "content": "When creating a batch job for your Azure Machine Learning service endpoint, you can specify several parameters that will define this batch execution:"
    },
    {
      "pos": [
        10520,
        10597
      ],
      "content": "<bpt id=\"p17\">**</bpt>Input<ept id=\"p17\">**</ept>: represents a blob reference where the batch job's input is stored."
    },
    {
      "pos": [
        10600,
        10967
      ],
      "content": "<bpt id=\"p18\">**</bpt>GlobalParameters<ept id=\"p18\">**</ept>: represents the set of global parameters you can define for their experiment. An Azure Machine Learning experiment can have both required and optional parameters that customize the service's execution, and the caller is expected to provide all required parameters, if applicable. These parameters are specified as a collection of key-value pairs.",
      "nodes": [
        {
          "content": "<bpt id=\"p18\">**</bpt>GlobalParameters<ept id=\"p18\">**</ept>: represents the set of global parameters you can define for their experiment.",
          "pos": [
            0,
            138
          ]
        },
        {
          "content": "An Azure Machine Learning experiment can have both required and optional parameters that customize the service's execution, and the caller is expected to provide all required parameters, if applicable.",
          "pos": [
            139,
            340
          ]
        },
        {
          "content": "These parameters are specified as a collection of key-value pairs.",
          "pos": [
            341,
            407
          ]
        }
      ]
    },
    {
      "pos": [
        10970,
        11249
      ],
      "content": "<bpt id=\"p19\">**</bpt>Outputs<ept id=\"p19\">**</ept>: if the service has defined one or more outputs, the caller can redirect any of them to an Azure blob location. This allows you to save the service's output(s) in a preferred location and under a predictable name, otherwise the output blob name is randomly generated.",
      "nodes": [
        {
          "content": "<bpt id=\"p19\">**</bpt>Outputs<ept id=\"p19\">**</ept>: if the service has defined one or more outputs, the caller can redirect any of them to an Azure blob location.",
          "pos": [
            0,
            163
          ]
        },
        {
          "content": "This allows you to save the service's output(s) in a preferred location and under a predictable name, otherwise the output blob name is randomly generated.",
          "pos": [
            164,
            319
          ]
        }
      ]
    },
    {
      "pos": [
        11256,
        11358
      ],
      "content": "Note that the service expects the output content, based on its type, to be saved as supported formats:"
    },
    {
      "pos": [
        11363,
        11417
      ],
      "content": "dataset outputs: can be saved as <bpt id=\"p20\">**</bpt>.csv, .tsv, .arff<ept id=\"p20\">**</ept>"
    },
    {
      "pos": [
        11422,
        11474
      ],
      "content": "trained model outputs: can be saved as <bpt id=\"p21\">**</bpt>.ilearner<ept id=\"p21\">**</ept>"
    },
    {
      "pos": [
        11478,
        11799
      ],
      "content": "Output location overrides are specified as a collection of <bpt id=\"p22\">*</bpt>&lt;output name, blob reference&gt;<ept id=\"p22\">*</ept><ph id=\"ph12\"/> pairs, where the <bpt id=\"p23\">*</bpt>output name<ept id=\"p23\">*</ept><ph id=\"ph13\"/> is the user defined name for a specific output node (also shown on the service's API help page), and <bpt id=\"p24\">*</bpt>blob reference<ept id=\"p24\">*</ept><ph id=\"ph14\"/> is a reference to an Azure blob location to which the output is to be redirected."
    },
    {
      "pos": [
        11801,
        12313
      ],
      "content": "All these job creation parameters can be optional depending on the nature of your service. For example, services with no input node defined do not require passing in an <bpt id=\"p25\">*</bpt>Input<ept id=\"p25\">*</ept><ph id=\"ph15\"/> parameter. Likewise, the output location override feature is completely optional, as outputs will otherwise be stored in the default storage account that was set up for your Azure Machine Learning workspace. Below, we show a sample request payload, as passed to the REST API, for a service where only the input information is provided:",
      "nodes": [
        {
          "content": "All these job creation parameters can be optional depending on the nature of your service.",
          "pos": [
            0,
            90
          ]
        },
        {
          "content": "For example, services with no input node defined do not require passing in an <bpt id=\"p25\">*</bpt>Input<ept id=\"p25\">*</ept><ph id=\"ph15\"/> parameter.",
          "pos": [
            91,
            242
          ]
        },
        {
          "content": "Likewise, the output location override feature is completely optional, as outputs will otherwise be stored in the default storage account that was set up for your Azure Machine Learning workspace.",
          "pos": [
            243,
            439
          ]
        },
        {
          "content": "Below, we show a sample request payload, as passed to the REST API, for a service where only the input information is provided:",
          "pos": [
            440,
            567
          ]
        }
      ]
    },
    {
      "pos": [
        12315,
        12333
      ],
      "content": "<bpt id=\"p26\">**</bpt>Sample Request<ept id=\"p26\">**</ept>"
    },
    {
      "pos": [
        12675,
        12898
      ],
      "content": "The response to the batch job creation API is the unique job ID that was associated to your job. This ID is very important because it provides the only means for you to reference this job in the system for other operations.",
      "nodes": [
        {
          "content": "The response to the batch job creation API is the unique job ID that was associated to your job.",
          "pos": [
            0,
            96
          ]
        },
        {
          "content": "This ID is very important because it provides the only means for you to reference this job in the system for other operations.",
          "pos": [
            97,
            223
          ]
        }
      ]
    },
    {
      "pos": [
        12902,
        12921
      ],
      "content": "<bpt id=\"p27\">**</bpt>Sample Response<ept id=\"p27\">**</ept>"
    },
    {
      "pos": [
        12977,
        13011
      ],
      "content": "<bpt id=\"p28\">**</bpt>2. Start a Batch Execution Job<ept id=\"p28\">**</ept>"
    },
    {
      "pos": [
        13013,
        13283
      ],
      "content": "Creating a batch job registers it within the system and places it in a <bpt id=\"p29\">*</bpt>Not started<ept id=\"p29\">*</ept><ph id=\"ph16\"/> state. To actually schedule the job for execution, you call the <bpt id=\"p30\">**</bpt>start<ept id=\"p30\">**</ept><ph id=\"ph17\"/> API described on the service endpoint's API help page and provide the job ID obtained when the job was created.",
      "nodes": [
        {
          "content": "Creating a batch job registers it within the system and places it in a <bpt id=\"p29\">*</bpt>Not started<ept id=\"p29\">*</ept><ph id=\"ph16\"/> state.",
          "pos": [
            0,
            146
          ]
        },
        {
          "content": "To actually schedule the job for execution, you call the <bpt id=\"p30\">**</bpt>start<ept id=\"p30\">**</ept><ph id=\"ph17\"/> API described on the service endpoint's API help page and provide the job ID obtained when the job was created.",
          "pos": [
            147,
            380
          ]
        }
      ]
    },
    {
      "pos": [
        13285,
        13331
      ],
      "content": "<bpt id=\"p31\">**</bpt>3. Get the Status of a Batch Execution Job<ept id=\"p31\">**</ept>"
    },
    {
      "pos": [
        13333,
        13741
      ],
      "content": "You can poll the status of your asynchronous batch job at any time by passing the job's ID to the GetJobStatus API. The API response will contain an indicator of the job's current state, as well as the actual results of the batch job if it has completed successfully. In the case of an error, more information about the actual reasons behind the failure are returned in the <bpt id=\"p32\">*</bpt>Details<ept id=\"p32\">*</ept><ph id=\"ph18\"/> property, as shown here:",
      "nodes": [
        {
          "content": "You can poll the status of your asynchronous batch job at any time by passing the job's ID to the GetJobStatus API.",
          "pos": [
            0,
            115
          ]
        },
        {
          "content": "The API response will contain an indicator of the job's current state, as well as the actual results of the batch job if it has completed successfully.",
          "pos": [
            116,
            267
          ]
        },
        {
          "content": "In the case of an error, more information about the actual reasons behind the failure are returned in the <bpt id=\"p32\">*</bpt>Details<ept id=\"p32\">*</ept><ph id=\"ph18\"/> property, as shown here:",
          "pos": [
            268,
            463
          ]
        }
      ]
    },
    {
      "pos": [
        13743,
        13763
      ],
      "content": "<bpt id=\"p33\">**</bpt>Response Payload<ept id=\"p33\">**</ept>"
    },
    {
      "pos": [
        13868,
        13909
      ],
      "content": "<bpt id=\"p34\">*</bpt>StatusCode<ept id=\"p34\">*</ept><ph id=\"ph19\"/> can be one of the following:"
    },
    {
      "pos": [
        13913,
        13924
      ],
      "content": "Not started"
    },
    {
      "pos": [
        13927,
        13934
      ],
      "content": "Running"
    },
    {
      "pos": [
        13937,
        13943
      ],
      "content": "Failed"
    },
    {
      "pos": [
        13946,
        13955
      ],
      "content": "Cancelled"
    },
    {
      "pos": [
        13958,
        13966
      ],
      "content": "Finished"
    },
    {
      "pos": [
        13968,
        14342
      ],
      "content": "The <bpt id=\"p35\">*</bpt>Results<ept id=\"p35\">*</ept><ph id=\"ph20\"/> property is populated only if the job has completed successfully (it is <bpt id=\"p36\">**</bpt>null<ept id=\"p36\">**</ept><ph id=\"ph21\"/> otherwise). Upon the job has completed, and if the service has at least one output node defined, the results will be returned as a collection of <bpt id=\"p37\">*</bpt>[output name, blob reference]<ept id=\"p37\">*</ept><ph id=\"ph22\"/> pairs, where the blob reference is a SAS read-only reference to the blob containing the actual result.",
      "nodes": [
        {
          "content": "The <bpt id=\"p35\">*</bpt>Results<ept id=\"p35\">*</ept><ph id=\"ph20\"/> property is populated only if the job has completed successfully (it is <bpt id=\"p36\">**</bpt>null<ept id=\"p36\">**</ept><ph id=\"ph21\"/> otherwise).",
          "pos": [
            0,
            216
          ]
        },
        {
          "content": "Upon the job has completed, and if the service has at least one output node defined, the results will be returned as a collection of <bpt id=\"p37\">*</bpt>[output name, blob reference]<ept id=\"p37\">*</ept><ph id=\"ph22\"/> pairs, where the blob reference is a SAS read-only reference to the blob containing the actual result.",
          "pos": [
            217,
            539
          ]
        }
      ]
    },
    {
      "pos": [
        14344,
        14363
      ],
      "content": "<bpt id=\"p38\">**</bpt>Sample Response<ept id=\"p38\">**</ept>"
    },
    {
      "pos": [
        15293,
        15328
      ],
      "content": "<bpt id=\"p39\">**</bpt>4. Cancel a Batch Execution Job<ept id=\"p39\">**</ept>"
    },
    {
      "pos": [
        15330,
        15539
      ],
      "content": "A running batch job can be cancelled at any time by calling the designated CancelJob API and passing in the job's id. This would be done for various reasons such as that the job is taking too long to complete.",
      "nodes": [
        {
          "content": "A running batch job can be cancelled at any time by calling the designated CancelJob API and passing in the job's id.",
          "pos": [
            0,
            117
          ]
        },
        {
          "content": "This would be done for various reasons such as that the job is taking too long to complete.",
          "pos": [
            118,
            209
          ]
        }
      ]
    },
    {
      "pos": [
        15548,
        15565
      ],
      "content": "Using the BES SDK"
    },
    {
      "pos": [
        15567,
        15870
      ],
      "content": "The <bpt id=\"p40\">[</bpt>BES SDK Nugget package<ept id=\"p40\">](http://www.nuget.org/packages/Microsoft.Azure.MachineLearning/)</ept><ph id=\"ph23\"/> provides functions that simplify calling BES to score in batch mode. To install the Nuget package, in Visual Studio in the <bpt id=\"p41\">**</bpt>Tools<ept id=\"p41\">**</ept><ph id=\"ph24\"/> menu, select <bpt id=\"p42\">**</bpt>Nuget Package Manager<ept id=\"p42\">**</ept><ph id=\"ph25\"/> and click <bpt id=\"p43\">**</bpt>Package Manager Console<ept id=\"p43\">**</ept>.",
      "nodes": [
        {
          "content": "The <bpt id=\"p40\">[</bpt>BES SDK Nugget package<ept id=\"p40\">](http://www.nuget.org/packages/Microsoft.Azure.MachineLearning/)</ept><ph id=\"ph23\"/> provides functions that simplify calling BES to score in batch mode.",
          "pos": [
            0,
            216
          ]
        },
        {
          "content": "To install the Nuget package, in Visual Studio in the <bpt id=\"p41\">**</bpt>Tools<ept id=\"p41\">**</ept><ph id=\"ph24\"/> menu, select <bpt id=\"p42\">**</bpt>Nuget Package Manager<ept id=\"p42\">**</ept><ph id=\"ph25\"/> and click <bpt id=\"p43\">**</bpt>Package Manager Console<ept id=\"p43\">**</ept>.",
          "pos": [
            217,
            508
          ]
        }
      ]
    },
    {
      "pos": [
        15872,
        16456
      ],
      "content": "Azure Machine Learning experiments that are deployed as web services can include web service input modules. This means that they expect the input to be provided through the web service call in the form of a reference to a blob location. There is also the option of not using a web service input module and using a <bpt id=\"p44\">**</bpt>Reader<ept id=\"p44\">**</ept><ph id=\"ph26\"/> module instead. In this case, the <bpt id=\"p45\">**</bpt>Reader<ept id=\"p45\">**</ept><ph id=\"ph27\"/> module typically would read from a SQL DB using a query at run time to get the data. Web service parameters can be used to dynamically point to other servers or tables, etc. The SDK supports both of these patterns.",
      "nodes": [
        {
          "content": "Azure Machine Learning experiments that are deployed as web services can include web service input modules.",
          "pos": [
            0,
            107
          ]
        },
        {
          "content": "This means that they expect the input to be provided through the web service call in the form of a reference to a blob location.",
          "pos": [
            108,
            236
          ]
        },
        {
          "content": "There is also the option of not using a web service input module and using a <bpt id=\"p44\">**</bpt>Reader<ept id=\"p44\">**</ept><ph id=\"ph26\"/> module instead.",
          "pos": [
            237,
            395
          ]
        },
        {
          "content": "In this case, the <bpt id=\"p45\">**</bpt>Reader<ept id=\"p45\">**</ept><ph id=\"ph27\"/> module typically would read from a SQL DB using a query at run time to get the data.",
          "pos": [
            396,
            564
          ]
        },
        {
          "content": "Web service parameters can be used to dynamically point to other servers or tables, etc. The SDK supports both of these patterns.",
          "pos": [
            565,
            694
          ]
        }
      ]
    },
    {
      "pos": [
        16458,
        16662
      ],
      "content": "The code sample below demonstrates how you can submit and monitor a batch job against an Azure Machine Learning service endpoint using the BES SDK. Note the comments for details on the settings and calls.",
      "nodes": [
        {
          "content": "The code sample below demonstrates how you can submit and monitor a batch job against an Azure Machine Learning service endpoint using the BES SDK.",
          "pos": [
            0,
            147
          ]
        },
        {
          "content": "Note the comments for details on the settings and calls.",
          "pos": [
            148,
            204
          ]
        }
      ]
    },
    {
      "pos": [
        16669,
        16684
      ],
      "content": "<bpt id=\"p46\">**</bpt>Sample Code<ept id=\"p46\">**</ept>"
    }
  ],
  "content": "<properties\n    pageTitle=\"Consume a Machine Learning web service | Microsoft Azure\"\n    description=\"Once a machine learning service is deployed, the RESTFul web service that is made available can be consumed either as request-response service or as a batch execution service.\"\n    services=\"machine-learning\"\n    documentationCenter=\"\"\n    authors=\"garyericson\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\" />\n\n<tags\n    ms.service=\"machine-learning\"\n    ms.devlang=\"na\"\n    ms.topic=\"article\"\n    ms.tgt_pltfrm=\"na\"\n    ms.workload=\"tbd\"\n    ms.date=\"02/10/2016\"\n    ms.author=\"garye\" />\n\n\n# How to consume an Azure Machine Learning web service that has been deployed from a Machine Learning experiment\n\n## Introduction\n\nWhen deployed as a web service, Azure Machine Learning experiments provide a REST API that can be consumed by a wide range of devices and platforms. This is because the simple REST API accepts and responds with JSON formatted messages. The Azure Machine Learning portal provides code that can be used to call the web service in R, C#, and Python. But these services can be called with any programming language and from any device that satisfies three criteria:\n\n* Has a network connection\n* Has SSL capabilities to perform HTTPS requests\n* Has the ability to parse JSON (by hand or support libraries)\n\nThis means the services can be consumed from web applications, mobile applications, custom desktop applications and even from within Excel.\n\n[AZURE.INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]  \n\nAn Azure Machine Learning web service can be consumed in two different ways, either as a request-response service or as a batch execution service. In each scenario the functionality is provided through the RESTFul web service that is made available for consumption once the experiment has been deployed. Deploying a Machine Learning web service in Azure with an Azure web service end-point, where the service is automatically scaled based on usage, you can avoid upfront and ongoing costs for hardware resources.\n\n> [AZURE.TIP] For a simple way to create a web app to access your predictive web service, see [Consume an Azure Machine Learning web service with a web app template](machine-learning-consume-web-service-with-web-app-template.md).\n\n<!-- When this article gets published, fix the link and uncomment\nFor more information on how to manage Azure Machine Learning web service endpoints using the REST API, see **Azure machine learning web service endpoints**.\n-->\n\nFor information about how to create and deploy an Azure Machine Learning web service, see [Deploy an Azure Machine Learning web service][publish]. For a step-by-step walkthrough of creating a Machine Learning experiment and deploying it, see [Develop a predictive solution by using Azure Machine Learning][walkthrough].\n\n[publish]: machine-learning-publish-a-machine-learning-web-service.md\n[walkthrough]: machine-learning-walkthrough-develop-predictive-solution.md\n\n\n## Request-Response Service (RRS)\n\nA Request-Response Service (RRS) is a low-latency, highly scalable web service used to provide an interface to the stateless models that have been created and deployed from an Azure Machine Learning Studio experiment. It enables scenarios where the consuming application expects a response in real-time.\n\nRRS accepts a single row, or multiple rows, of input parameters and can generate a single row, or multiple rows, as output. The output row(s) can contain multiple columns.\n\nAn example for RRS is validating the authenticity of an application. Hundreds to millions of installations of an application can be expected in this case. When the application starts up, it makes a call to the RRS service with the relevant input. The application then receives a validation response from the service that either allows or blocks the application from performing.\n\n\n## Batch Execution Service (BES)\n\nA Batch Execution Service (BES) is a service that handles high volume, asynchronous, scoring of a batch of data records. The input for the BES contains a batch of records from a variety of sources, such as blobs, tables in Azure, SQL Azure, HDInsight (results of a Hive Query, for example), and HTTP sources. The output for the BES contains the results of the scoring. Results are output to a file in Azure blob storage and data from the storage endpoint is returned in the response.\n\nA BES would be useful when responses are not needed immediately, such as for regularly scheduled scoring for individuals or internet of things (IOT) devices.\n\n## Examples\nTo show how both RRS and BES work, we use an example Azure web service. This service would be used in an IOT (Internet Of Things) scenario. To keep it simple, our device only sends up one value, `cog_speed`, and gets a single answer back.\n\nThere are four pieces of information that are needed to call either the RRS or BES service. This information is readily available from the service pages in [Azure Machine Learning Studio](https://studio.azureml.net) once the experiment has been deployed. Click on the WEB SERVICES tab at the left of the screen and you will see the deployed services. Click a service to find the following links and information for both RRS and BES:\n\n1.  The service **API key**, available on the services Dashboard\n2.  The service **request URI**, available on the API help page for the chosen service\n3.  The expected API **request headers** and **body**, available on the API help page for the chosen service\n4.  The expected API **response headers** and **body**, available on the API help page for the chosen service\n\nIn the two examples below, the C# language is used to illustrate the code needed and the targeted platform is a Windows 8 desktop.\n\n### RRS Example\nClick **REQUEST/RESPONSE** under **API HELP PAGE** on the service Dashboard to view the API help page. On this page, aside from the URI, you will find input and output definitions and code samples. The API input, for this service specifically, is shown below and is the payload of the API call.\n\n**Sample Request**\n\n    {\n      \"Inputs\": {\n        \"input1\": {\n          \"ColumnNames\": [\n            \"cog_speed\"\n          ],\n          \"Values\": [\n            [\n              \"0\"\n            ],\n            [\n              \"1\"\n            ]\n          ]\n        }\n      },\n      \"GlobalParameters\": {}\n    }\n\n\nSimilarly, the API response for this service is also shown below.\n\n**Sample Response**\n\n    {\n      \"Results\": {\n        \"output1\": {\n          \"type\": \"DataTable\",\n          \"value\": {\n            \"ColumnNames\": [\n              \"cog_speed\"\n            ],\n            \"ColumnTypes\": [\n              \"Numeric\"\n            ].\n          \"Values\": [\n            [\n              \"0\"\n            ],\n            [\n              \"1\"\n            ]\n          ]\n        }\n      },\n      \"GlobalParameters\": {}\n    }\n\nTowards the bottom of the help page you will find the code examples. Below is the code sample for the C# implementation.\n\n**Sample Code**\n\n    using System;\n    using System.Collections.Generic;\n    using System.IO;\n    using System.Net.Http;\n    using System.Net.Http.Formatting;\n    using System.Net.Http.Headers;\n    using System.Text;\n    using System.Threading.Tasks;\n\n    namespace CallRequestResponseService\n    {\n        public class StringTable\n        {\n            public string[] ColumnNames { get; set; }\n            public string[,] Values { get; set; }\n        }\n\n        class Program\n        {\n            static void Main(string[] args)\n            {\n                InvokeRequestResponseService().Wait();\n            }\n\n            static async Task InvokeRequestResponseService()\n            {\n                using (var client = new HttpClient())\n                {\n                    var scoreRequest = new\n                    {\n                        Inputs = new Dictionary<string, StringTable> () {\n                            {\n                                \"input1\",\n                                new StringTable()\n                                {\n                                    ColumnNames = new string[] {\"cog_speed\"},\n                                    Values = new string[,] {  { \"0\"},  { \"1\"}  }\n                                }\n                            },\n                        GlobalParameters = new Dictionary<string, string>() { }\n                    };\n\n                    const string apiKey = \"abc123\"; // Replace this with the API key for the web service\n                    client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue( \"Bearer\", apiKey);\n\n                    client.BaseAddress = new Uri(\"https://ussouthcentral.services.azureml.net/workspaces/<workspace id>/services/<service id>/execute?api-version=2.0&details=true\");\n\n                    // WARNING: The 'await' statement below can result in a deadlock if you are calling this code from the UI thread of an ASP.Net application.\n                    // One way to address this would be to call ConfigureAwait(false) so that the execution does not attempt to resume on the original context.\n                    // For instance, replace code such as:\n                    //      result = await DoSomeTask()\n                    // with the following:\n                    //      result = await DoSomeTask().ConfigureAwait(false)\n\n                    HttpResponseMessage response = await client.PostAsJsonAsync(\"\", scoreRequest);\n\n                    if (response.IsSuccessStatusCode)\n                    {\n                        string result = await response.Content.ReadAsStringAsync();\n                        Console.WriteLine(\"Result: {0}\", result);\n                    }\n                    else\n                    {\n                        Console.WriteLine(\"Failed with status code: {0}\", response.StatusCode);\n                    }\n                }\n            }\n        }\n    }\n\n### BES Example\nUnlike the RRS service, the BES service is asynchronous. This means that the BES API is simply queuing up a job to be executed, and the caller polls the job's status to see when it has completed. Here are the operations currently supported for batch jobs:\n\n1. Create (submit) a batch job\n1. Start this batch job\n1. Get the status or result of the batch job\n1. Cancel a running batch job\n\n**1. Create a Batch Execution Job**\n\nWhen creating a batch job for your Azure Machine Learning service endpoint, you can specify several parameters that will define this batch execution:\n\n* **Input**: represents a blob reference where the batch job's input is stored.\n* **GlobalParameters**: represents the set of global parameters you can define for their experiment. An Azure Machine Learning experiment can have both required and optional parameters that customize the service's execution, and the caller is expected to provide all required parameters, if applicable. These parameters are specified as a collection of key-value pairs.\n* **Outputs**: if the service has defined one or more outputs, the caller can redirect any of them to an Azure blob location. This allows you to save the service's output(s) in a preferred location and under a predictable name, otherwise the output blob name is randomly generated. \n\n    Note that the service expects the output content, based on its type, to be saved as supported formats:\n  - dataset outputs: can be saved as **.csv, .tsv, .arff**\n  - trained model outputs: can be saved as **.ilearner**\n\n  Output location overrides are specified as a collection of *<output name, blob reference>* pairs, where the *output name* is the user defined name for a specific output node (also shown on the service's API help page), and *blob reference* is a reference to an Azure blob location to which the output is to be redirected.\n\nAll these job creation parameters can be optional depending on the nature of your service. For example, services with no input node defined do not require passing in an *Input* parameter. Likewise, the output location override feature is completely optional, as outputs will otherwise be stored in the default storage account that was set up for your Azure Machine Learning workspace. Below, we show a sample request payload, as passed to the REST API, for a service where only the input information is provided:\n\n**Sample Request**\n\n    {\n      \"Input\": {\n        \"ConnectionString\":     \n        \"DefaultEndpointsProtocol=https;AccountName=mystorageacct;AccountKey=mystorageacctKey\",\n        \"RelativeLocation\": \"/mycontainer/mydatablob.csv\",\n        \"BaseLocation\": null,\n        \"SasBlobToken\": null\n      },\n      \"Outputs\": null,\n      \"GlobalParameters\": null\n    }\n\nThe response to the batch job creation API is the unique job ID that was associated to your job. This ID is very important because it provides the only means for you to reference this job in the system for other operations.  \n\n**Sample Response**\n\n    \"539d0bc2fde945b6ac986b851d0000f0\" // The JOB_ID\n\n**2. Start a Batch Execution Job**\n\nCreating a batch job registers it within the system and places it in a *Not started* state. To actually schedule the job for execution, you call the **start** API described on the service endpoint's API help page and provide the job ID obtained when the job was created.\n\n**3. Get the Status of a Batch Execution Job**\n\nYou can poll the status of your asynchronous batch job at any time by passing the job's ID to the GetJobStatus API. The API response will contain an indicator of the job's current state, as well as the actual results of the batch job if it has completed successfully. In the case of an error, more information about the actual reasons behind the failure are returned in the *Details* property, as shown here:\n\n**Response Payload**\n\n    {\n        \"StatusCode\": STATUS_CODE,\n        \"Results\": RESULTS,\n        \"Details\": DETAILS\n    }\n\n*StatusCode* can be one of the following:\n\n* Not started\n* Running\n* Failed\n* Cancelled\n* Finished\n\nThe *Results* property is populated only if the job has completed successfully (it is **null** otherwise). Upon the job has completed, and if the service has at least one output node defined, the results will be returned as a collection of *[output name, blob reference]* pairs, where the blob reference is a SAS read-only reference to the blob containing the actual result.\n\n**Sample Response**\n\n    {\n        \"Status Code\": \"Finished\",\n        \"Results\":\n        {\n            \"dataOutput\":\n            {              \n                \"ConnectionString\": null,\n                \"RelativeLocation\": \"outputs/dataOutput.csv\",\n                \"BaseLocation\": \"https://mystorageaccount.blob.core.windows.net/\",\n                \"SasBlobToken\": \"?sv=2013-08-15&sr=b&sig=ABCD&st=2015-04-04T05%3A39%3A55Z&se=2015-04-05T05%3A44%3A55Z&sp=r\"              \n            },\n            \"trainedModelOutput\":\n            {              \n                \"ConnectionString\": null,\n                \"RelativeLocation\": \"models/trainedModel.ilearner\",\n                \"BaseLocation\": \"https://mystorageaccount.blob.core.windows.net/\",\n                \"SasBlobToken\": \"?sv=2013-08-15&sr=b&sig=EFGH%3D&st=2015-04-04T05%3A39%3A55Z&se=2015-04-05T05%3A44%3A55Z&sp=r\"              \n            },           \n        },\n        \"Details\": null\n    }\n\n**4. Cancel a Batch Execution Job**\n\nA running batch job can be cancelled at any time by calling the designated CancelJob API and passing in the job's id. This would be done for various reasons such as that the job is taking too long to complete.\n\n\n\n#### Using the BES SDK\n\nThe [BES SDK Nugget package](http://www.nuget.org/packages/Microsoft.Azure.MachineLearning/) provides functions that simplify calling BES to score in batch mode. To install the Nuget package, in Visual Studio in the **Tools** menu, select **Nuget Package Manager** and click **Package Manager Console**.\n\nAzure Machine Learning experiments that are deployed as web services can include web service input modules. This means that they expect the input to be provided through the web service call in the form of a reference to a blob location. There is also the option of not using a web service input module and using a **Reader** module instead. In this case, the **Reader** module typically would read from a SQL DB using a query at run time to get the data. Web service parameters can be used to dynamically point to other servers or tables, etc. The SDK supports both of these patterns.\n\nThe code sample below demonstrates how you can submit and monitor a batch job against an Azure Machine Learning service endpoint using the BES SDK. Note the comments for details on the settings and calls.\n\n#### **Sample Code**\n\n    // This code requires the Nuget package Microsoft.Azure.MachineLearning to be installed.\n    // Instructions for doing this in Visual Studio:\n    // Tools -> Nuget Package Manager -> Package Manager Console\n    // Install-Package Microsoft.Azure.MachineLearning\n\n      using System;\n      using System.Collections.Generic;\n      using System.Threading.Tasks;\n\n      using Microsoft.Azure.MachineLearning;\n      using Microsoft.Azure.MachineLearning.Contracts;\n      using Microsoft.Azure.MachineLearning.Exceptions;\n\n    namespace CallBatchExecutionService\n    {\n        class Program\n        {\n            static void Main(string[] args)\n            {               \n                InvokeBatchExecutionService().Wait();\n            }\n\n            static async Task InvokeBatchExecutionService()\n            {\n                // First collect and fill in the URI and access key for your web service endpoint.\n                // These are available on your service's API help page.\n                var endpointUri = \"https://ussouthcentral.services.azureml.net/workspaces/YOUR_WORKSPACE_ID/services/YOUR_SERVICE_ENDPOINT_ID/\";\n                string accessKey = \"YOUR_SERVICE_ENDPOINT_ACCESS_KEY\";\n\n                // Create an Azure Machine Learning runtime client for this endpoint\n                var runtimeClient = new RuntimeClient(endpointUri, accessKey);\n\n                // Define the request information for your batch job. This information can contain:\n                // -- A reference to the AzureBlob containing the input for your job run\n                // -- A set of values for global parameters defined as part of your experiment and service\n                // -- A set of output blob locations that allow you to redirect the job's results\n\n                // NOTE: This sample is applicable, as is, for a service with explicit input port and\n                // potential global parameters. Also, we choose to also demo how you could override the\n                // location of one of the output blobs that could be generated by your service. You might\n                // need to tweak these features to adjust the sample to your service.\n                //\n                // All of these properties of a BatchJobRequest shown below can be optional, depending on\n                // your service, so it is not required to specify all with any request.  If you do not want to\n                // use any of the parameters, a null value should be passed in its place.\n\n                // Define the reference to the blob containing your input data. You can refer to this blob by its\n                    // connection string / container / blob name values; alternatively, we also support references\n                    // based on a blob SAS URI\n\n                    BlobReference inputBlob = BlobReference.CreateFromConnectionStringData(connectionString:                                         \"DefaultEndpointsProtocol=https;AccountName=YOUR_ACCOUNT_NAME;AccountKey=YOUR_ACCOUNT_KEY\",\n                        containerName: \"YOUR_CONTAINER_NAME\",\n                        blobName: \"YOUR_INPUT_BLOB_NAME\");\n\n                    // If desired, one can override the location where the job outputs are to be stored, by passing in\n                    // the storage account details and name of the blob where we want the output to be redirected to.\n\n                    var outputLocations = new Dictionary<string, BlobReference>\n                        {\n                          {\n                           \"YOUR_OUTPUT_NODE_NAME\",\n                           BlobReference.CreateFromConnectionStringData(                                     connectionString: \"DefaultEndpointsProtocol=https;AccountName=YOUR_ACCOUNT_NAME;AccountKey=YOUR_ACCOUNT_KEY\",\n                                containerName: \"YOUR_CONTAINER_NAME\",\n                                blobName: \"YOUR_DESIRED_OUTPUT_BLOB_NAME\")\n                           }\n                        };\n\n                // If applicable, you can also set the global parameters for your service\n                var globalParameters = new Dictionary<string, string>\n                {\n                    { \"YOUR_GLOBAL_PARAMETER\", \"PARAMETER_VALUE\" }\n                };\n\n                var jobRequest = new BatchJobRequest\n                {\n                    Input = inputBlob,\n                    GlobalParameters = globalParameters,\n                    Outputs = outputLocations\n                };\n\n                try\n                {\n                    // Register the batch job with the system, which will grant you access to a job object\n                    BatchJob job = await runtimeClient.RegisterBatchJobAsync(jobRequest);\n\n                    // Start the job to allow it to be scheduled in the running queue\n                    await job.StartAsync();\n\n                    // Wait for the job's completion and handle the output\n                    BatchJobStatus jobStatus = await job.WaitForCompletionAsync();\n                    if (jobStatus.JobState == JobState.Finished)\n                    {\n                        // Process job outputs\n                        Console.WriteLine(@\"Job {0} has completed successfully and returned {1} outputs\", job.Id, jobStatus.Results.Count);\n                        foreach (var output in jobStatus.Results)\n                        {\n                            Console.WriteLine(@\"\\t{0}: {1}\", output.Key, output.Value.AbsoluteUri);\n                        }\n                    }\n                    else if (jobStatus.JobState == JobState.Failed)\n                    {\n                        // Handle job failure\n                        Console.WriteLine(@\"Job {0} has failed with this error: {1}\", job.Id, jobStatus.Details);\n                    }\n                }\n                catch (ArgumentException aex)\n                {\n                    Console.WriteLine(\"Argument {0} is invalid: {1}\", aex.ParamName, aex.Message);\n                }\n                catch (RuntimeException runtimeError)\n                {\n                    Console.WriteLine(\"Runtime error occurred: {0} - {1}\", runtimeError.ErrorCode, runtimeError.Message);\n                    Console.WriteLine(\"Error details:\");\n                    foreach (var errorDetails in runtimeError.Details)\n                    {\n                        Console.WriteLine(\"\\t{0} - {1}\", errorDetails.Code, errorDetails.Message);\n                    }\n                }\n                catch (Exception ex)\n                {\n                    Console.WriteLine(\"Unexpected error occurred: {0} - {1}\", ex.GetType().Name, ex.Message);\n                }\n            }\n        }\n    }\n"
}