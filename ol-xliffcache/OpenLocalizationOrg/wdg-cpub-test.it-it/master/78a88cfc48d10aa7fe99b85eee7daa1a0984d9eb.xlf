<?xml version="1.0" encoding="utf-8"?>
<xliff srcLang="en-US" trgLang="it-it" version="2.0" xmlns="urn:oasis:names:tc:xliff:document:2.0" xmlns:mda="urn:oasis:names:tc:xliff:metadata:2.0">
  <file id="1">
    <mda:metadata>
      <mda:metaGroup>
        <mda:meta type="olfilehash">78a88cfc48d10aa7fe99b85eee7daa1a0984d9eb</mda:meta>
      </mda:metaGroup>
    </mda:metadata>
    <group id="content">
      <unit id="101">
        <segment state="initial">
          <source xml:space="preserve">ms.assetid: CB924E17-C726-48E7-A445-364781F4CCA1</source>
          <target xml:space="preserve">ms.assetid: CB924E17-C726-48E7-A445-364781F4CCA1</target>
        </segment>
      </unit>
      <unit id="102">
        <segment state="initial">
          <source xml:space="preserve">description: This article shows how to use the APIs in the Windows.Media.Audio namespace to create audio graphs for audio routing, mixing, and processing scenarios.</source>
          <target xml:space="preserve">description: This article shows how to use the APIs in the Windows.Media.Audio namespace to create audio graphs for audio routing, mixing, and processing scenarios.</target>
        </segment>
      </unit>
      <unit id="103">
        <segment state="initial">
          <source xml:space="preserve">title: Audio Graphs</source>
          <target xml:space="preserve">title: Audio Graphs</target>
        </segment>
      </unit>
      <unit id="104">
        <segment state="initial">
          <source xml:space="preserve">Audio Graphs</source>
          <target xml:space="preserve">Audio Graphs</target>
        </segment>
      </unit>
      <unit id="105">
        <segment state="initial">
          <source xml:space="preserve">\[ Updated for UWP apps on Windows 10.</source>
          <target xml:space="preserve">\[ Updated for UWP apps on Windows 10.</target>
        </segment>
      </unit>
      <unit id="106">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](http://go.microsoft.com/fwlink/p/?linkid=619132)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">For Windows 8.x articles, see the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">archive</pc> \]</source>
          <target xml:space="preserve">For Windows 8.x articles, see the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">archive</pc> \]</target>
        </segment>
      </unit>
      <unit id="107">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914341)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">This article shows how to use the APIs in the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Windows.Media.Audio</pc></pc> namespace to create audio graphs for audio routing, mixing, and processing scenarios.</source>
          <target xml:space="preserve">This article shows how to use the APIs in the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Windows.Media.Audio</pc></pc> namespace to create audio graphs for audio routing, mixing, and processing scenarios.</target>
        </segment>
      </unit>
      <unit id="108">
        <segment state="initial">
          <source xml:space="preserve">An audio graph is a set of interconnected audio nodes through which audio data flows.</source>
          <target xml:space="preserve">An audio graph is a set of interconnected audio nodes through which audio data flows.</target>
        </segment>
      </unit>
      <unit id="109">
        <segment state="initial">
          <source xml:space="preserve">Audio input nodes supply audio data to the graph from audio input devices, audio files, or from custom code.</source>
          <target xml:space="preserve">Audio input nodes supply audio data to the graph from audio input devices, audio files, or from custom code.</target>
        </segment>
      </unit>
      <unit id="110">
        <segment state="initial">
          <source xml:space="preserve">Audio output nodes are the destination for audio processed by the graph.</source>
          <target xml:space="preserve">Audio output nodes are the destination for audio processed by the graph.</target>
        </segment>
      </unit>
      <unit id="111">
        <segment state="initial">
          <source xml:space="preserve">Audio can be routed out of the graph to audio output devices, audio files, or custom code.</source>
          <target xml:space="preserve">Audio can be routed out of the graph to audio output devices, audio files, or custom code.</target>
        </segment>
      </unit>
      <unit id="112">
        <segment state="initial">
          <source xml:space="preserve">The last type of node is a submix node which takes audio from one or more nodes and combines them into a single output that can be routed to other nodes in the graph.</source>
          <target xml:space="preserve">The last type of node is a submix node which takes audio from one or more nodes and combines them into a single output that can be routed to other nodes in the graph.</target>
        </segment>
      </unit>
      <unit id="113">
        <segment state="initial">
          <source xml:space="preserve">After all of the nodes have been created and the connections between them set up, you simply start the audio graph and the audio data flows from the input nodes, through any submix nodes, to the output nodes.</source>
          <target xml:space="preserve">After all of the nodes have been created and the connections between them set up, you simply start the audio graph and the audio data flows from the input nodes, through any submix nodes, to the output nodes.</target>
        </segment>
      </unit>
      <unit id="114">
        <segment state="initial">
          <source xml:space="preserve">This model makes scenarios like recording from a device's microphone to an audio file, playing audio from a file to a device's speaker, or mixing audio from multiple sources quick and easy to implement.</source>
          <target xml:space="preserve">This model makes scenarios like recording from a device's microphone to an audio file, playing audio from a file to a device's speaker, or mixing audio from multiple sources quick and easy to implement.</target>
        </segment>
      </unit>
      <unit id="115">
        <segment state="initial">
          <source xml:space="preserve">Additional scenarios are enabled with the addition of audio effects to the audio graph.</source>
          <target xml:space="preserve">Additional scenarios are enabled with the addition of audio effects to the audio graph.</target>
        </segment>
      </unit>
      <unit id="116">
        <segment state="initial">
          <source xml:space="preserve">Every node in an audio graph can be populated with zero or more audio effects that perform audio processing on the audio passing through the node.</source>
          <target xml:space="preserve">Every node in an audio graph can be populated with zero or more audio effects that perform audio processing on the audio passing through the node.</target>
        </segment>
      </unit>
      <unit id="117">
        <segment state="initial">
          <source xml:space="preserve">There are several built-in effects such as echo, equalizer, limiting, and reverb that can be attached to an audio node with just a few lines of code.</source>
          <target xml:space="preserve">There are several built-in effects such as echo, equalizer, limiting, and reverb that can be attached to an audio node with just a few lines of code.</target>
        </segment>
      </unit>
      <unit id="118">
        <segment state="initial">
          <source xml:space="preserve">You can also create your own custom audio effects that work exactly the same as the built-in effects.</source>
          <target xml:space="preserve">You can also create your own custom audio effects that work exactly the same as the built-in effects.</target>
        </segment>
      </unit>
      <unit id="119">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">
						<pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>
					</source>
          <target xml:space="preserve">
						<pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>
					</target>
        </segment>
      </unit>
      <unit id="120">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](http://go.microsoft.com/fwlink/?LinkId=619481)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioGraph UWP sample</pc> implements the code discussed in this overview.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioGraph UWP sample</pc> implements the code discussed in this overview.</target>
        </segment>
      </unit>
      <unit id="121">
        <segment state="initial">
          <source xml:space="preserve">You can download the sample to see the code in context or to use as a starting point for your own app.</source>
          <target xml:space="preserve">You can download the sample to see the code in context or to use as a starting point for your own app.</target>
        </segment>
      </unit>
      <unit id="122">
        <segment state="initial">
          <source xml:space="preserve">Choosing Windows Runtime AudioGraph or XAudio2</source>
          <target xml:space="preserve">Choosing Windows Runtime AudioGraph or XAudio2</target>
        </segment>
      </unit>
      <unit id="123">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/desktop/hh405049)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The Windows Runtime audio graph APIs offer functionality that can also be implemented using the COM-based <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAudio2 APIs</pc>.</source>
          <target xml:space="preserve">The Windows Runtime audio graph APIs offer functionality that can also be implemented using the COM-based <pc dataRefEnd="id2" dataRefStart="id1" id="p1">XAudio2 APIs</pc>.</target>
        </segment>
      </unit>
      <unit id="124">
        <segment state="initial">
          <source xml:space="preserve">The following are features of the Windows Runtime audio graph framework that differ from XAudio2.</source>
          <target xml:space="preserve">The following are features of the Windows Runtime audio graph framework that differ from XAudio2.</target>
        </segment>
      </unit>
      <unit id="125">
        <segment state="initial">
          <source xml:space="preserve">The Windows Runtime audio graph APIs are significantly easier to use than XAudio2.</source>
          <target xml:space="preserve">The Windows Runtime audio graph APIs are significantly easier to use than XAudio2.</target>
        </segment>
      </unit>
      <unit id="126">
        <segment state="initial">
          <source xml:space="preserve">The Windows Runtime audio graph APIs can be used from C# - in addition to being supported for C++.</source>
          <target xml:space="preserve">The Windows Runtime audio graph APIs can be used from C# - in addition to being supported for C++.</target>
        </segment>
      </unit>
      <unit id="127">
        <segment state="initial">
          <source xml:space="preserve">The Windows Runtime audio graph APIs can use audio files, including compressed file formats, directly.</source>
          <target xml:space="preserve">The Windows Runtime audio graph APIs can use audio files, including compressed file formats, directly.</target>
        </segment>
      </unit>
      <unit id="128">
        <segment state="initial">
          <source xml:space="preserve">XAudio2 only operates on audio buffers and does not provide any file I/O capabilities.</source>
          <target xml:space="preserve">XAudio2 only operates on audio buffers and does not provide any file I/O capabilities.</target>
        </segment>
      </unit>
      <unit id="129">
        <segment state="initial">
          <source xml:space="preserve">The Windows Runtime audio graph APIs can use the low-latency audio pipeline in Windows 10.</source>
          <target xml:space="preserve">The Windows Runtime audio graph APIs can use the low-latency audio pipeline in Windows 10.</target>
        </segment>
      </unit>
      <unit id="130">
        <segment state="initial">
          <source xml:space="preserve">The Windows Runtime audio graph APIs supports automatic endpoint switching when default endpoint parameters are used.</source>
          <target xml:space="preserve">The Windows Runtime audio graph APIs supports automatic endpoint switching when default endpoint parameters are used.</target>
        </segment>
      </unit>
      <unit id="131">
        <segment state="initial">
          <source xml:space="preserve">For example, if the user switches from a device's speaker to a headset, the audio is automatically redirected to the new input.</source>
          <target xml:space="preserve">For example, if the user switches from a device's speaker to a headset, the audio is automatically redirected to the new input.</target>
        </segment>
      </unit>
      <unit id="132">
        <segment state="initial">
          <source xml:space="preserve">AudioGraph class</source>
          <target xml:space="preserve">AudioGraph class</target>
        </segment>
      </unit>
      <unit id="133">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914176)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph</pc></pc> class is the parent of all nodes that make up the graph.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph</pc></pc> class is the parent of all nodes that make up the graph.</target>
        </segment>
      </unit>
      <unit id="134">
        <segment state="initial">
          <source xml:space="preserve">Use this object to create instances of all of the audio node types.</source>
          <target xml:space="preserve">Use this object to create instances of all of the audio node types.</target>
        </segment>
      </unit>
      <unit id="135">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
          <data id="id3">[</data>
          <data id="id4">](https://msdn.microsoft.com/library/windows/apps/dn914185)</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
          <data id="id7">[</data>
          <data id="id8">](https://msdn.microsoft.com/library/windows/apps/dn914216)</data>
          <data id="id9">**</data>
          <data id="id10">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Create an instance of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioGraph</pc> class by initializing an <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">AudioGraphSettings</pc></pc> object, containing configuration settings for the graph, and then calling <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">AudioGraph.CreateAsync</pc></pc>.</source>
          <target xml:space="preserve">Create an instance of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioGraph</pc> class by initializing an <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">AudioGraphSettings</pc></pc> object, containing configuration settings for the graph, and then calling <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">AudioGraph.CreateAsync</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="136">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914273)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The returned <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">CreateAudioGraphResult</pc></pc> gives access to the created audio graph or provides an error value if audio graph creation fails.</source>
          <target xml:space="preserve">The returned <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">CreateAudioGraphResult</pc></pc> gives access to the created audio graph or provides an error value if audio graph creation fails.</target>
        </segment>
      </unit>
      <unit id="137">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetDeclareAudioGraph)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareAudioGraph</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareAudioGraph</pc>]</target>
        </segment>
      </unit>
      <unit id="138">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetInitAudioGraph)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">InitAudioGraph</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">InitAudioGraph</pc>]</target>
        </segment>
      </unit>
      <unit id="139">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">All audio node types are created by using the Create\* methods of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioGraph</pc> class.</source>
          <target xml:space="preserve">All audio node types are created by using the Create\* methods of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AudioGraph</pc> class.</target>
        </segment>
      </unit>
      <unit id="140">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914244)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph.Start</pc></pc> method causes the audio graph to start processing audio data.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph.Start</pc></pc> method causes the audio graph to start processing audio data.</target>
        </segment>
      </unit>
      <unit id="141">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914245)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph.Stop</pc></pc> method stops audio processing.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph.Stop</pc></pc> method stops audio processing.</target>
        </segment>
      </unit>
      <unit id="142">
        <segment state="initial">
          <source xml:space="preserve">Each node in the graph can be started and stopped independently while the graph is running, but no nodes are active when the graph is stopped.</source>
          <target xml:space="preserve">Each node in the graph can be started and stopped independently while the graph is running, but no nodes are active when the graph is stopped.</target>
        </segment>
      </unit>
      <unit id="143">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914242)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">
						<pc dataRefEnd="id2" dataRefStart="id1" id="p1">
							<pc dataRefEnd="id4" dataRefStart="id3" id="p2">ResetAllNodes</pc>
						</pc> causes all nodes in the graph to discard any data currently in their audio buffers.</source>
          <target xml:space="preserve">
						<pc dataRefEnd="id2" dataRefStart="id1" id="p1">
							<pc dataRefEnd="id4" dataRefStart="id3" id="p2">ResetAllNodes</pc>
						</pc> causes all nodes in the graph to discard any data currently in their audio buffers.</target>
        </segment>
      </unit>
      <unit id="144">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914241)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">QuantumStarted</pc></pc> event occurs when the graph is starting the processing of a new quantum of audio data.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">QuantumStarted</pc></pc> event occurs when the graph is starting the processing of a new quantum of audio data.</target>
        </segment>
      </unit>
      <unit id="145">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914240)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">QuantumProcessed</pc></pc> event occurs when the processing of a quantum is completed.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">QuantumProcessed</pc></pc> event occurs when the processing of a quantum is completed.</target>
        </segment>
      </unit>
      <unit id="146">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914185)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn297724)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The only <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraphSettings</pc></pc> property that is required is <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AudioRenderCategory</pc></pc>.</source>
          <target xml:space="preserve">The only <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraphSettings</pc></pc> property that is required is <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AudioRenderCategory</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="147">
        <segment state="initial">
          <source xml:space="preserve">Specifying this value allows the system to optimize the audio pipeline for the specified category.</source>
          <target xml:space="preserve">Specifying this value allows the system to optimize the audio pipeline for the specified category.</target>
        </segment>
      </unit>
      <unit id="148">
        <segment state="initial">
          <source xml:space="preserve">The quantum size of the audio graph determines the number of samples that are processed at one time.</source>
          <target xml:space="preserve">The quantum size of the audio graph determines the number of samples that are processed at one time.</target>
        </segment>
      </unit>
      <unit id="149">
        <segment state="initial">
          <source xml:space="preserve">By default, the quantum size is 10 ms based at the default sample rate.</source>
          <target xml:space="preserve">By default, the quantum size is 10 ms based at the default sample rate.</target>
        </segment>
      </unit>
      <unit id="150">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914205)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn914208)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
          <data id="id9">**</data>
          <data id="id10">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">If you specify a custom quantum size by setting the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">DesiredSamplesPerQuantum</pc></pc> property, you must also set the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">QuantumSizeSelectionMode</pc></pc> property to <pc dataRefEnd="id10" dataRefStart="id9" id="p5">ClosestToDesired</pc> or the supplied value is ignored.</source>
          <target xml:space="preserve">If you specify a custom quantum size by setting the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">DesiredSamplesPerQuantum</pc></pc> property, you must also set the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">QuantumSizeSelectionMode</pc></pc> property to <pc dataRefEnd="id10" dataRefStart="id9" id="p5">ClosestToDesired</pc> or the supplied value is ignored.</target>
        </segment>
      </unit>
      <unit id="151">
        <segment state="initial">
          <source xml:space="preserve">If this value is used, the system will choose a quantum size as close as possible to the one you specify.</source>
          <target xml:space="preserve">If this value is used, the system will choose a quantum size as close as possible to the one you specify.</target>
        </segment>
      </unit>
      <unit id="152">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914243)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">To determine the actual quantum size, check the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SamplesPerQuantum</pc></pc> of the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">AudioGraph</pc> after it has been created.</source>
          <target xml:space="preserve">To determine the actual quantum size, check the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SamplesPerQuantum</pc></pc> of the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">AudioGraph</pc> after it has been created.</target>
        </segment>
      </unit>
      <unit id="153">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914205)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">If you only plan to use the audio graph with files and don't plan to output to an audio device, it is recommended that you use the default quantum size by not setting the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">DesiredSamplesPerQuantum</pc></pc> property.</source>
          <target xml:space="preserve">If you only plan to use the audio graph with files and don't plan to output to an audio device, it is recommended that you use the default quantum size by not setting the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">DesiredSamplesPerQuantum</pc></pc> property.</target>
        </segment>
      </unit>
      <unit id="154">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn958522)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">DesiredRenderDeviceAudioProcessing</pc></pc> property determines the amount of processing the primary render device performs on the output of the audio graph.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">DesiredRenderDeviceAudioProcessing</pc></pc> property determines the amount of processing the primary render device performs on the output of the audio graph.</target>
        </segment>
      </unit>
      <unit id="155">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Default</pc> setting allows the system to use the default audio processing for the specified audio render category.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Default</pc> setting allows the system to use the default audio processing for the specified audio render category.</target>
        </segment>
      </unit>
      <unit id="156">
        <segment state="initial">
          <source xml:space="preserve">This processing can significantly improve the sound of audio on some devices, particularly mobile devices with small speakers.</source>
          <target xml:space="preserve">This processing can significantly improve the sound of audio on some devices, particularly mobile devices with small speakers.</target>
        </segment>
      </unit>
      <unit id="157">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Raw</pc> setting can improve performance by minimizing the amount of signal processing performed, but can result in inferior sound quality on some devices.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Raw</pc> setting can improve performance by minimizing the amount of signal processing performed, but can result in inferior sound quality on some devices.</target>
        </segment>
      </unit>
      <unit id="158">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914208)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
          <data id="id9">[</data>
          <data id="id10">](https://msdn.microsoft.com/library/windows/apps/dn958522)</data>
          <data id="id11">**</data>
          <data id="id12">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">If the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">QuantumSizeSelectionMode</pc></pc> is set to <pc dataRefEnd="id6" dataRefStart="id5" id="p3">LowestLatency</pc>, the audio graph will automatically use <pc dataRefEnd="id8" dataRefStart="id7" id="p4">Raw</pc> for <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">DesiredRenderDeviceAudioProcessing</pc></pc>.</source>
          <target xml:space="preserve">If the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">QuantumSizeSelectionMode</pc></pc> is set to <pc dataRefEnd="id6" dataRefStart="id5" id="p3">LowestLatency</pc>, the audio graph will automatically use <pc dataRefEnd="id8" dataRefStart="id7" id="p4">Raw</pc> for <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">DesiredRenderDeviceAudioProcessing</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="159">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn958523)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">EncodingProperties</pc></pc> determines the audio format used by the graph.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">EncodingProperties</pc></pc> determines the audio format used by the graph.</target>
        </segment>
      </unit>
      <unit id="160">
        <segment state="initial">
          <source xml:space="preserve">Only 32-bit float formats are supported.</source>
          <target xml:space="preserve">Only 32-bit float formats are supported.</target>
        </segment>
      </unit>
      <unit id="161">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn958524)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">PrimaryRenderDevice</pc></pc> sets the primary render device for the audio graph.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">PrimaryRenderDevice</pc></pc> sets the primary render device for the audio graph.</target>
        </segment>
      </unit>
      <unit id="162">
        <segment state="initial">
          <source xml:space="preserve">If you don't set this, the default system device is used.</source>
          <target xml:space="preserve">If you don't set this, the default system device is used.</target>
        </segment>
      </unit>
      <unit id="163">
        <segment state="initial">
          <source xml:space="preserve">The primary render device is used to calculate the quantum sizes for other nodes in the graph.</source>
          <target xml:space="preserve">The primary render device is used to calculate the quantum sizes for other nodes in the graph.</target>
        </segment>
      </unit>
      <unit id="164">
        <segment state="initial">
          <source xml:space="preserve">If there are no audio render devices present on the system, audio graph creation will fail.</source>
          <target xml:space="preserve">If there are no audio render devices present on the system, audio graph creation will fail.</target>
        </segment>
      </unit>
      <unit id="165">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/br225393)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/br225432)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
          <data id="id9">[</data>
          <data id="id10">](https://msdn.microsoft.com/library/windows/apps/br226817)</data>
          <data id="id11">**</data>
          <data id="id12">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">You can let the audio graph use the default audio render device or use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Windows.Devices.Enumeration.DeviceInformation</pc></pc> class to get a list of the system's available audio render devices by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">FindAllAsync</pc></pc> and passing in the audio render device selector returned by <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">Windows.Media.Devices.MediaDevice.GetAudioRenderSelector</pc></pc>.</source>
          <target xml:space="preserve">You can let the audio graph use the default audio render device or use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Windows.Devices.Enumeration.DeviceInformation</pc></pc> class to get a list of the system's available audio render devices by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">FindAllAsync</pc></pc> and passing in the audio render device selector returned by <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">Windows.Media.Devices.MediaDevice.GetAudioRenderSelector</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="166">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
          <data id="id3">[</data>
          <data id="id4">](https://msdn.microsoft.com/library/windows/apps/dn958524)</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">You can choose one of the returned <pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeviceInformation</pc> objects programatically or show UI to allow the user to select a device and then use it to set the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">PrimaryRenderDevice</pc></pc> property.</source>
          <target xml:space="preserve">You can choose one of the returned <pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeviceInformation</pc> objects programatically or show UI to allow the user to select a device and then use it to set the <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">PrimaryRenderDevice</pc></pc> property.</target>
        </segment>
      </unit>
      <unit id="167">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetEnumerateAudioRenderDevices)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">EnumerateAudioRenderDevices</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">EnumerateAudioRenderDevices</pc>]</target>
        </segment>
      </unit>
      <unit id="168">
        <segment state="initial">
          <source xml:space="preserve">Device input node</source>
          <target xml:space="preserve">Device input node</target>
        </segment>
      </unit>
      <unit id="169">
        <segment state="initial">
          <source xml:space="preserve">A device input node feeds audio into the graph from an audio capture device connected to the system, such as a microphone.</source>
          <target xml:space="preserve">A device input node feeds audio into the graph from an audio capture device connected to the system, such as a microphone.</target>
        </segment>
      </unit>
      <unit id="170">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914082)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn914218)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Create a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">DeviceInputNode</pc></pc> object that uses the system's default audio capture device by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CreateDeviceInputNodeAsync</pc></pc>.</source>
          <target xml:space="preserve">Create a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">DeviceInputNode</pc></pc> object that uses the system's default audio capture device by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CreateDeviceInputNodeAsync</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="171">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn297724)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Provide an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioRenderCategory</pc></pc> to allow the system to optimize the audio pipeline for the specified category.</source>
          <target xml:space="preserve">Provide an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioRenderCategory</pc></pc> to allow the system to optimize the audio pipeline for the specified category.</target>
        </segment>
      </unit>
      <unit id="172">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetDeclareDeviceInputNode)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareDeviceInputNode</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareDeviceInputNode</pc>]</target>
        </segment>
      </unit>
      <unit id="173">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetCreateDeviceInputNode)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateDeviceInputNode</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateDeviceInputNode</pc>]</target>
        </segment>
      </unit>
      <unit id="174">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/br225393)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/br225432)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
          <data id="id9">[</data>
          <data id="id10">](https://msdn.microsoft.com/library/windows/apps/br226817)</data>
          <data id="id11">**</data>
          <data id="id12">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">If you want to specify a specific audio capture device for the device input node, you can use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Windows.Devices.Enumeration.DeviceInformation</pc></pc> class to get a list of the system's available audio capture devices by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">FindAllAsync</pc></pc> and passing in the audio render device selector returned by <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">Windows.Media.Devices.MediaDevice.GetAudioRenderSelector</pc></pc>.</source>
          <target xml:space="preserve">If you want to specify a specific audio capture device for the device input node, you can use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Windows.Devices.Enumeration.DeviceInformation</pc></pc> class to get a list of the system's available audio capture devices by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">FindAllAsync</pc></pc> and passing in the audio render device selector returned by <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">Windows.Media.Devices.MediaDevice.GetAudioRenderSelector</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="175">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
          <data id="id3">[</data>
          <data id="id4">](https://msdn.microsoft.com/library/windows/apps/dn914218)</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">You can choose one of the returned <pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeviceInformation</pc> objects programmatically or show UI to allow the user to select a device and then pass it into <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">CreateDeviceInputNodeAsync</pc></pc>.</source>
          <target xml:space="preserve">You can choose one of the returned <pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeviceInformation</pc> objects programmatically or show UI to allow the user to select a device and then pass it into <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">CreateDeviceInputNodeAsync</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="176">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetEnumerateAudioCaptureDevices)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">EnumerateAudioCaptureDevices</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">EnumerateAudioCaptureDevices</pc>]</target>
        </segment>
      </unit>
      <unit id="177">
        <segment state="initial">
          <source xml:space="preserve">Device output node</source>
          <target xml:space="preserve">Device output node</target>
        </segment>
      </unit>
      <unit id="178">
        <segment state="initial">
          <source xml:space="preserve">A device output node pushes audio from the graph to an audio render device, such as speakers or a headset.</source>
          <target xml:space="preserve">A device output node pushes audio from the graph to an audio render device, such as speakers or a headset.</target>
        </segment>
      </unit>
      <unit id="179">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914098)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn958525)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Create a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">DeviceOutputNode</pc></pc> by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CreateDeviceOutputNodeAsync</pc></pc>.</source>
          <target xml:space="preserve">Create a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">DeviceOutputNode</pc></pc> by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CreateDeviceOutputNodeAsync</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="180">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn958524)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The output node uses the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">PrimaryRenderDevice</pc></pc> of the audio graph.</source>
          <target xml:space="preserve">The output node uses the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">PrimaryRenderDevice</pc></pc> of the audio graph.</target>
        </segment>
      </unit>
      <unit id="181">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetDeclareDeviceOutputNode)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareDeviceOutputNode</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareDeviceOutputNode</pc>]</target>
        </segment>
      </unit>
      <unit id="182">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetCreateDeviceOutputNode)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateDeviceOutputNode</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateDeviceOutputNode</pc>]</target>
        </segment>
      </unit>
      <unit id="183">
        <segment state="initial">
          <source xml:space="preserve">File input node</source>
          <target xml:space="preserve">File input node</target>
        </segment>
      </unit>
      <unit id="184">
        <segment state="initial">
          <source xml:space="preserve">A file input node allows you to feed data from an audio file into the graph.</source>
          <target xml:space="preserve">A file input node allows you to feed data from an audio file into the graph.</target>
        </segment>
      </unit>
      <unit id="185">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914108)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn914226)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Create an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFileInputNode</pc></pc> by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CreateFileInputNodeAsync</pc></pc>.</source>
          <target xml:space="preserve">Create an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFileInputNode</pc></pc> by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CreateFileInputNodeAsync</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="186">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetDeclareFileInputNode)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareFileInputNode</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareFileInputNode</pc>]</target>
        </segment>
      </unit>
      <unit id="187">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetCreateFileInputNode)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateFileInputNode</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateFileInputNode</pc>]</target>
        </segment>
      </unit>
      <unit id="188">
        <segment state="initial">
          <source xml:space="preserve">File input nodes support the following file formats: mp3, wav, wma, m4a</source>
          <target xml:space="preserve">File input nodes support the following file formats: mp3, wav, wma, m4a</target>
        </segment>
      </unit>
      <unit id="189">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914130)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Set the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">StartTime</pc></pc> property to specify the time offset into the file where playback should begin.</source>
          <target xml:space="preserve">Set the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">StartTime</pc></pc> property to specify the time offset into the file where playback should begin.</target>
        </segment>
      </unit>
      <unit id="190">
        <segment state="initial">
          <source xml:space="preserve">If this property is null, the beginning of the file is used.</source>
          <target xml:space="preserve">If this property is null, the beginning of the file is used.</target>
        </segment>
      </unit>
      <unit id="191">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914118)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Set the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">EndTime</pc></pc> property to specify the time offset into the file where playback should end.</source>
          <target xml:space="preserve">Set the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">EndTime</pc></pc> property to specify the time offset into the file where playback should end.</target>
        </segment>
      </unit>
      <unit id="192">
        <segment state="initial">
          <source xml:space="preserve">If this property is null, the end of the file is used.</source>
          <target xml:space="preserve">If this property is null, the end of the file is used.</target>
        </segment>
      </unit>
      <unit id="193">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914116)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The start time value must be lower than the end time value, and the end time value must be less than or equal to the duration of the audio file, which can be determined by checking the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Duration</pc></pc> property value.</source>
          <target xml:space="preserve">The start time value must be lower than the end time value, and the end time value must be less than or equal to the duration of the audio file, which can be determined by checking the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Duration</pc></pc> property value.</target>
        </segment>
      </unit>
      <unit id="194">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914127)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Seek to a position in the audio file by calling <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Seek</pc></pc> and specifying the time offset into the file to which the playback position should be moved.</source>
          <target xml:space="preserve">Seek to a position in the audio file by calling <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Seek</pc></pc> and specifying the time offset into the file to which the playback position should be moved.</target>
        </segment>
      </unit>
      <unit id="195">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914130)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn914118)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The specified value must be within the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">StartTime</pc></pc> and <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">EndTime</pc></pc> range.</source>
          <target xml:space="preserve">The specified value must be within the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">StartTime</pc></pc> and <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">EndTime</pc></pc> range.</target>
        </segment>
      </unit>
      <unit id="196">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914124)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Get the current playback position of the node with the read-only <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Position</pc></pc> property.</source>
          <target xml:space="preserve">Get the current playback position of the node with the read-only <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Position</pc></pc> property.</target>
        </segment>
      </unit>
      <unit id="197">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914120)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Enable looping of the audio file by setting the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">LoopCount</pc></pc> property.</source>
          <target xml:space="preserve">Enable looping of the audio file by setting the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">LoopCount</pc></pc> property.</target>
        </segment>
      </unit>
      <unit id="198">
        <segment state="initial">
          <source xml:space="preserve">When non-null, this value indicates the number of times the file will be played in after the initial playback.</source>
          <target xml:space="preserve">When non-null, this value indicates the number of times the file will be played in after the initial playback.</target>
        </segment>
      </unit>
      <unit id="199">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">So, for example, setting <pc dataRefEnd="id2" dataRefStart="id1" id="p1">LoopCount</pc> to 1 will cause the file to be played 2 times in total, and setting it to 5 will cause the file to be played 6 times in total.</source>
          <target xml:space="preserve">So, for example, setting <pc dataRefEnd="id2" dataRefStart="id1" id="p1">LoopCount</pc> to 1 will cause the file to be played 2 times in total, and setting it to 5 will cause the file to be played 6 times in total.</target>
        </segment>
      </unit>
      <unit id="200">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Setting <pc dataRefEnd="id2" dataRefStart="id1" id="p1">LoopCount</pc> to null causes the file to be looped indefinitely.</source>
          <target xml:space="preserve">Setting <pc dataRefEnd="id2" dataRefStart="id1" id="p1">LoopCount</pc> to null causes the file to be looped indefinitely.</target>
        </segment>
      </unit>
      <unit id="201">
        <segment state="initial">
          <source xml:space="preserve">To stop looping, set the value to 0.</source>
          <target xml:space="preserve">To stop looping, set the value to 0.</target>
        </segment>
      </unit>
      <unit id="202">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914123)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Adjust the speed at which the audio file is played back by setting the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">PlaybackSpeedFactor</pc></pc>.</source>
          <target xml:space="preserve">Adjust the speed at which the audio file is played back by setting the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">PlaybackSpeedFactor</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="203">
        <segment state="initial">
          <source xml:space="preserve">A value of 1 indicates the original speed of the file, .5 is half-speed, and 2 is double speed.</source>
          <target xml:space="preserve">A value of 1 indicates the original speed of the file, .5 is half-speed, and 2 is double speed.</target>
        </segment>
      </unit>
      <unit id="204">
        <segment state="initial">
          <source xml:space="preserve">File output node</source>
          <target xml:space="preserve">File output node</target>
        </segment>
      </unit>
      <unit id="205">
        <segment state="initial">
          <source xml:space="preserve">A file output node lets you direct audio data from the graph into an audio file.</source>
          <target xml:space="preserve">A file output node lets you direct audio data from the graph into an audio file.</target>
        </segment>
      </unit>
      <unit id="206">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914133)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn914227)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Create an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFileOutputNode</pc></pc> by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CreateFileOutputNodeAsync</pc></pc>.</source>
          <target xml:space="preserve">Create an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFileOutputNode</pc></pc> by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CreateFileOutputNodeAsync</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="207">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetDeclareFileOutputNode)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareFileOutputNode</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareFileOutputNode</pc>]</target>
        </segment>
      </unit>
      <unit id="208">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetCreateFileOutputNode)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateFileOutputNode</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateFileOutputNode</pc>]</target>
        </segment>
      </unit>
      <unit id="209">
        <segment state="initial">
          <source xml:space="preserve">File output nodes support the following file formats: mp3, wav, wma, m4a</source>
          <target xml:space="preserve">File output nodes support the following file formats: mp3, wav, wma, m4a</target>
        </segment>
      </unit>
      <unit id="210">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914144)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn914140)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">You must call <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFileOutputNode.Stop</pc></pc> to stop the node's processing before calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AudioFileOutputNode.FinalizeAsync</pc></pc> or an exception will be thrown.</source>
          <target xml:space="preserve">You must call <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFileOutputNode.Stop</pc></pc> to stop the node's processing before calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AudioFileOutputNode.FinalizeAsync</pc></pc> or an exception will be thrown.</target>
        </segment>
      </unit>
      <unit id="211">
        <segment state="initial">
          <source xml:space="preserve">Audio frame input node</source>
          <target xml:space="preserve">Audio frame input node</target>
        </segment>
      </unit>
      <unit id="212">
        <segment state="initial">
          <source xml:space="preserve">An audio frame input node allows you to push audio data that you generate in your own code into the audio graph.</source>
          <target xml:space="preserve">An audio frame input node allows you to push audio data that you generate in your own code into the audio graph.</target>
        </segment>
      </unit>
      <unit id="213">
        <segment state="initial">
          <source xml:space="preserve">This enables scenarios like creating a custom software synthesizer.</source>
          <target xml:space="preserve">This enables scenarios like creating a custom software synthesizer.</target>
        </segment>
      </unit>
      <unit id="214">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914147)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn914230)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Create an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFrameInputNode</pc></pc> by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CreateFrameInputNode</pc></pc>.</source>
          <target xml:space="preserve">Create an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFrameInputNode</pc></pc> by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CreateFrameInputNode</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="215">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetDeclareFrameInputNode)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareFrameInputNode</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareFrameInputNode</pc>]</target>
        </segment>
      </unit>
      <unit id="216">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetCreateFrameInputNode)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateFrameInputNode</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateFrameInputNode</pc>]</target>
        </segment>
      </unit>
      <unit id="217">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn958507)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FrameInputNode.QuantumStarted</pc></pc> event is raised when the audio graph is ready to begin processing the next quantum of audio data.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FrameInputNode.QuantumStarted</pc></pc> event is raised when the audio graph is ready to begin processing the next quantum of audio data.</target>
        </segment>
      </unit>
      <unit id="218">
        <segment state="initial">
          <source xml:space="preserve">You supply your custom generated audio data from within the handler to this event.</source>
          <target xml:space="preserve">You supply your custom generated audio data from within the handler to this event.</target>
        </segment>
      </unit>
      <unit id="219">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetQuantumStarted)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">QuantumStarted</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">QuantumStarted</pc>]</target>
        </segment>
      </unit>
      <unit id="220">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn958533)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
          <data id="id7">[</data>
          <data id="id8">](https://msdn.microsoft.com/library/windows/apps/dn958534)</data>
          <data id="id9">**</data>
          <data id="id10">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FrameInputNodeQuantumStartedEventArgs</pc></pc> object passed into the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">QuantumStarted</pc> event handler exposes the <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">RequiredSamples</pc></pc> property that indicates how many samples the audio graph needs to fill up the quantum to be processed.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">FrameInputNodeQuantumStartedEventArgs</pc></pc> object passed into the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">QuantumStarted</pc> event handler exposes the <pc dataRefEnd="id8" dataRefStart="id7" id="p4"><pc dataRefEnd="id10" dataRefStart="id9" id="p5">RequiredSamples</pc></pc> property that indicates how many samples the audio graph needs to fill up the quantum to be processed.</target>
        </segment>
      </unit>
      <unit id="221">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914148)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn930871)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Call <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFrameInputNode.AddFrame</pc></pc> to pass an <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AudioFrame</pc></pc> object filled with audio data into the graph.</source>
          <target xml:space="preserve">Call <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFrameInputNode.AddFrame</pc></pc> to pass an <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AudioFrame</pc></pc> object filled with audio data into the graph.</target>
        </segment>
      </unit>
      <unit id="222">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">An example implementation of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">GenerateAudioData</pc> helper method is shown below.</source>
          <target xml:space="preserve">An example implementation of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">GenerateAudioData</pc> helper method is shown below.</target>
        </segment>
      </unit>
      <unit id="223">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn930871)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">To populate an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFrame</pc></pc> with audio data, you must get access to the underlying memory buffer of the audio frame.</source>
          <target xml:space="preserve">To populate an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFrame</pc></pc> with audio data, you must get access to the underlying memory buffer of the audio frame.</target>
        </segment>
      </unit>
      <unit id="224">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">To do this you must initialize the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IMemoryBufferByteAccess</pc> COM interface by adding the following code within your namespace.</source>
          <target xml:space="preserve">To do this you must initialize the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IMemoryBufferByteAccess</pc> COM interface by adding the following code within your namespace.</target>
        </segment>
      </unit>
      <unit id="225">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetComImportIMemoryBufferByteAccess)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">ComImportIMemoryBufferByteAccess</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">ComImportIMemoryBufferByteAccess</pc>]</target>
        </segment>
      </unit>
      <unit id="226">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
          <data id="id3">[</data>
          <data id="id4">](https://msdn.microsoft.com/library/windows/apps/dn930871)</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The following code shows an example implementation of a <pc dataRefEnd="id2" dataRefStart="id1" id="p1">GenerateAudioData</pc> helper method that creates an <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">AudioFrame</pc></pc> and populates it with audio data.</source>
          <target xml:space="preserve">The following code shows an example implementation of a <pc dataRefEnd="id2" dataRefStart="id1" id="p1">GenerateAudioData</pc> helper method that creates an <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">AudioFrame</pc></pc> and populates it with audio data.</target>
        </segment>
      </unit>
      <unit id="227">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetGenerateAudioData)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">GenerateAudioData</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">GenerateAudioData</pc>]</target>
        </segment>
      </unit>
      <unit id="228">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Because this method accesses the raw buffer underlying the Windows Runtime types, it must be declared using the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">unsafe</pc> keyword.</source>
          <target xml:space="preserve">Because this method accesses the raw buffer underlying the Windows Runtime types, it must be declared using the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">unsafe</pc> keyword.</target>
        </segment>
      </unit>
      <unit id="229">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">You must also configure your project in Microsoft Visual Studio to allow the compilation of unsafe code by opening the project's <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Properties</pc> page, clicking the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Build</pc> property page, and selecting the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">Allow Unsafe Code</pc> checkbox.</source>
          <target xml:space="preserve">You must also configure your project in Microsoft Visual Studio to allow the compilation of unsafe code by opening the project's <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Properties</pc> page, clicking the <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Build</pc> property page, and selecting the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">Allow Unsafe Code</pc> checkbox.</target>
        </segment>
      </unit>
      <unit id="230">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn930871)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Initialize a new instance of <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFrame</pc></pc>, in the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">Windows.Media</pc> namespace, by passing in the desired buffer size to the constructor.</source>
          <target xml:space="preserve">Initialize a new instance of <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFrame</pc></pc>, in the <pc dataRefEnd="id6" dataRefStart="id5" id="p3">Windows.Media</pc> namespace, by passing in the desired buffer size to the constructor.</target>
        </segment>
      </unit>
      <unit id="231">
        <segment state="initial">
          <source xml:space="preserve">The buffer size is the number of samples multiplied by the size of each sample.</source>
          <target xml:space="preserve">The buffer size is the number of samples multiplied by the size of each sample.</target>
        </segment>
      </unit>
      <unit id="232">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn958454)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn930878)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Get the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioBuffer</pc></pc> of the audio frame by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">LockBuffer</pc></pc>.</source>
          <target xml:space="preserve">Get the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioBuffer</pc></pc> of the audio frame by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">LockBuffer</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="233">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/desktop/mt297505)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn958457)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Get an instance of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IMemoryBufferByteAccess</pc></pc> COM interface from the audio buffer by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CreateReference</pc></pc>.</source>
          <target xml:space="preserve">Get an instance of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IMemoryBufferByteAccess</pc></pc> COM interface from the audio buffer by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CreateReference</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="234">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/desktop/mt297506)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Get a pointer to raw audio buffer data by calling <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IMemoryBufferByteAccess.GetBuffer</pc></pc> and cast it to the sample data type of the audio data.</source>
          <target xml:space="preserve">Get a pointer to raw audio buffer data by calling <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IMemoryBufferByteAccess.GetBuffer</pc></pc> and cast it to the sample data type of the audio data.</target>
        </segment>
      </unit>
      <unit id="235">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn930871)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Fill the buffer with data and return the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFrame</pc></pc> for submission into the audio graph.</source>
          <target xml:space="preserve">Fill the buffer with data and return the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFrame</pc></pc> for submission into the audio graph.</target>
        </segment>
      </unit>
      <unit id="236">
        <segment state="initial">
          <source xml:space="preserve">Audio frame output node</source>
          <target xml:space="preserve">Audio frame output node</target>
        </segment>
      </unit>
      <unit id="237">
        <segment state="initial">
          <source xml:space="preserve">An audio frame output node allows you to receive and process audio data output from the audio graph with custom code that you create.</source>
          <target xml:space="preserve">An audio frame output node allows you to receive and process audio data output from the audio graph with custom code that you create.</target>
        </segment>
      </unit>
      <unit id="238">
        <segment state="initial">
          <source xml:space="preserve">An example scenario for this is performing signal analysis on the audio output.</source>
          <target xml:space="preserve">An example scenario for this is performing signal analysis on the audio output.</target>
        </segment>
      </unit>
      <unit id="239">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914166)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn914233)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Create an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFrameOutputNode</pc></pc> by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CreateFrameOutputNode</pc></pc>.</source>
          <target xml:space="preserve">Create an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFrameOutputNode</pc></pc> by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">CreateFrameOutputNode</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="240">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetDeclareFrameOutputNode)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareFrameOutputNode</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">DeclareFrameOutputNode</pc>]</target>
        </segment>
      </unit>
      <unit id="241">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetCreateFrameOutputNode)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateFrameOutputNode</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateFrameOutputNode</pc>]</target>
        </segment>
      </unit>
      <unit id="242">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914240)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph.QuantumProcessed</pc></pc> event is raised when the audio graph has completed processing a quantum of audio data.</source>
          <target xml:space="preserve">The <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph.QuantumProcessed</pc></pc> event is raised when the audio graph has completed processing a quantum of audio data.</target>
        </segment>
      </unit>
      <unit id="243">
        <segment state="initial">
          <source xml:space="preserve">You can access the audio data from within the handler for this event.</source>
          <target xml:space="preserve">You can access the audio data from within the handler for this event.</target>
        </segment>
      </unit>
      <unit id="244">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetQuantumProcessed)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">QuantumProcessed</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">QuantumProcessed</pc>]</target>
        </segment>
      </unit>
      <unit id="245">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914171)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn930871)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Call <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">GetFrame</pc></pc> to get an <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AudioFrame</pc></pc> object filled with audio data from the graph.</source>
          <target xml:space="preserve">Call <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">GetFrame</pc></pc> to get an <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AudioFrame</pc></pc> object filled with audio data from the graph.</target>
        </segment>
      </unit>
      <unit id="246">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">An example implementation of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">ProcessFrameOutput</pc> helper method is shown below.</source>
          <target xml:space="preserve">An example implementation of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">ProcessFrameOutput</pc> helper method is shown below.</target>
        </segment>
      </unit>
      <unit id="247">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetProcessFrameOutput)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">ProcessFrameOutput</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">ProcessFrameOutput</pc>]</target>
        </segment>
      </unit>
      <unit id="248">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Like the audio frame input node example above, you will need to declare the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IMemoryBufferByteAccess</pc> COM interface and configure your project to allow unsafe code in order to access the underlying audio buffer.</source>
          <target xml:space="preserve">Like the audio frame input node example above, you will need to declare the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IMemoryBufferByteAccess</pc> COM interface and configure your project to allow unsafe code in order to access the underlying audio buffer.</target>
        </segment>
      </unit>
      <unit id="249">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn958454)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn930878)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Get the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioBuffer</pc></pc> of the audio frame by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">LockBuffer</pc></pc>.</source>
          <target xml:space="preserve">Get the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioBuffer</pc></pc> of the audio frame by calling <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">LockBuffer</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="250">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
          <data id="id3">[</data>
          <data id="id4">](https://msdn.microsoft.com/library/windows/apps/dn958457)</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Get an instance of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IMemoryBufferByteAccess</pc> COM interface from the audio buffer by calling <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">CreateReference</pc></pc>.</source>
          <target xml:space="preserve">Get an instance of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IMemoryBufferByteAccess</pc> COM interface from the audio buffer by calling <pc dataRefEnd="id4" dataRefStart="id3" id="p2"><pc dataRefEnd="id6" dataRefStart="id5" id="p3">CreateReference</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="251">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Get a pointer to raw audio buffer data by calling <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IMemoryBufferByteAccess.GetBuffer</pc> and cast it to the sample data type of the audio data.</source>
          <target xml:space="preserve">Get a pointer to raw audio buffer data by calling <pc dataRefEnd="id2" dataRefStart="id1" id="p1">IMemoryBufferByteAccess.GetBuffer</pc> and cast it to the sample data type of the audio data.</target>
        </segment>
      </unit>
      <unit id="252">
        <segment state="initial">
          <source xml:space="preserve">Node connections and submix nodes</source>
          <target xml:space="preserve">Node connections and submix nodes</target>
        </segment>
      </unit>
      <unit id="253">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">All input nodes types expose the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddOutgoingConnection</pc> method that routes the audio produced by the node to the node that is passed into the method.</source>
          <target xml:space="preserve">All input nodes types expose the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddOutgoingConnection</pc> method that routes the audio produced by the node to the node that is passed into the method.</target>
        </segment>
      </unit>
      <unit id="254">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914108)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn914098)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The following example connects an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFileInputNode</pc></pc> to an <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AudioDeviceOutputNode</pc></pc>, which is a simple setup for playing an audio file on the device's speaker.</source>
          <target xml:space="preserve">The following example connects an <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFileInputNode</pc></pc> to an <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AudioDeviceOutputNode</pc></pc>, which is a simple setup for playing an audio file on the device's speaker.</target>
        </segment>
      </unit>
      <unit id="255">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetAddOutgoingConnection1)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddOutgoingConnection1</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddOutgoingConnection1</pc>]</target>
        </segment>
      </unit>
      <unit id="256">
        <segment state="initial">
          <source xml:space="preserve">You can create more than one connection from an input node to other nodes.</source>
          <target xml:space="preserve">You can create more than one connection from an input node to other nodes.</target>
        </segment>
      </unit>
      <unit id="257">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914108)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn914133)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">The following example adds another connection from the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFileInputNode</pc></pc> to an <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AudioFileOutputNode</pc></pc>.</source>
          <target xml:space="preserve">The following example adds another connection from the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioFileInputNode</pc></pc> to an <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AudioFileOutputNode</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="258">
        <segment state="initial">
          <source xml:space="preserve">Now, the audio from the audio file is played to the device's speaker and is also written out to an audio file.</source>
          <target xml:space="preserve">Now, the audio from the audio file is played to the device's speaker and is also written out to an audio file.</target>
        </segment>
      </unit>
      <unit id="259">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetAddOutgoingConnection2)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddOutgoingConnection2</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddOutgoingConnection2</pc>]</target>
        </segment>
      </unit>
      <unit id="260">
        <segment state="initial">
          <source xml:space="preserve">Output nodes can also receive more than one connection from other nodes.</source>
          <target xml:space="preserve">Output nodes can also receive more than one connection from other nodes.</target>
        </segment>
      </unit>
      <unit id="261">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914082)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn914098)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">In the following example a connection is made from a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioDeviceInputNode</pc></pc> to the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AudioDeviceOutput</pc></pc> node.</source>
          <target xml:space="preserve">In the following example a connection is made from a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioDeviceInputNode</pc></pc> to the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">AudioDeviceOutput</pc></pc> node.</target>
        </segment>
      </unit>
      <unit id="262">
        <segment state="initial">
          <source xml:space="preserve">Because the output node has connections from the file input node and the device input node, the output will contain a mix of audio from both sources.</source>
          <target xml:space="preserve">Because the output node has connections from the file input node and the device input node, the output will contain a mix of audio from both sources.</target>
        </segment>
      </unit>
      <unit id="263">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">
						<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddOutgoingConnection</pc> provides an overload that lets you specify a gain value for the signal passing through the connection.</source>
          <target xml:space="preserve">
						<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddOutgoingConnection</pc> provides an overload that lets you specify a gain value for the signal passing through the connection.</target>
        </segment>
      </unit>
      <unit id="264">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetAddOutgoingConnection3)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddOutgoingConnection3</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddOutgoingConnection3</pc>]</target>
        </segment>
      </unit>
      <unit id="265">
        <segment state="initial">
          <source xml:space="preserve">Although output nodes can accept connections from multiple nodes, you may want to create an intermediate mix of signals from one or more nodes before passing the mix to an output.</source>
          <target xml:space="preserve">Although output nodes can accept connections from multiple nodes, you may want to create an intermediate mix of signals from one or more nodes before passing the mix to an output.</target>
        </segment>
      </unit>
      <unit id="266">
        <segment state="initial">
          <source xml:space="preserve">For example, you may want to set the level or apply effects to a subset of the audio signals in a graph.</source>
          <target xml:space="preserve">For example, you may want to set the level or apply effects to a subset of the audio signals in a graph.</target>
        </segment>
      </unit>
      <unit id="267">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914247)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">To do this, use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioSubmixNode</pc></pc>.</source>
          <target xml:space="preserve">To do this, use the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioSubmixNode</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="268">
        <segment state="initial">
          <source xml:space="preserve">You can connect to a submix node from one or more input nodes or other submix nodes.</source>
          <target xml:space="preserve">You can connect to a submix node from one or more input nodes or other submix nodes.</target>
        </segment>
      </unit>
      <unit id="269">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914236)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">In the following example, a new submix node is created with <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph.CreateSubmixNode</pc></pc>.</source>
          <target xml:space="preserve">In the following example, a new submix node is created with <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph.CreateSubmixNode</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="270">
        <segment state="initial">
          <source xml:space="preserve">Then, connections are added from a file input node and a frame output node to the submix node.</source>
          <target xml:space="preserve">Then, connections are added from a file input node and a frame output node to the submix node.</target>
        </segment>
      </unit>
      <unit id="271">
        <segment state="initial">
          <source xml:space="preserve">Finally, the submix node is connected to a file output node.</source>
          <target xml:space="preserve">Finally, the submix node is connected to a file output node.</target>
        </segment>
      </unit>
      <unit id="272">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetCreateSubmixNode)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateSubmixNode</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">CreateSubmixNode</pc>]</target>
        </segment>
      </unit>
      <unit id="273">
        <segment state="initial">
          <source xml:space="preserve">Starting and stopping audio graph nodes</source>
          <target xml:space="preserve">Starting and stopping audio graph nodes</target>
        </segment>
      </unit>
      <unit id="274">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914244)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">When <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph.Start</pc></pc> is called, the audio graph begins processing audio data.</source>
          <target xml:space="preserve">When <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph.Start</pc></pc> is called, the audio graph begins processing audio data.</target>
        </segment>
      </unit>
      <unit id="275">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Every node type provides <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Start</pc> and <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Stop</pc> methods that cause the individual node to start or stop processing data.</source>
          <target xml:space="preserve">Every node type provides <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Start</pc> and <pc dataRefEnd="id4" dataRefStart="id3" id="p2">Stop</pc> methods that cause the individual node to start or stop processing data.</target>
        </segment>
      </unit>
      <unit id="276">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn914245)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">When <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph.Stop</pc></pc> is called, all audio processing in the all nodes is stopped regardless of the state of individual nodes, but the state of each node can be set while the audio graph is stopped.</source>
          <target xml:space="preserve">When <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph.Stop</pc></pc> is called, all audio processing in the all nodes is stopped regardless of the state of individual nodes, but the state of each node can be set while the audio graph is stopped.</target>
        </segment>
      </unit>
      <unit id="277">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">For example, you could call <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Stop</pc> on an individual node while the graph is stopped and then call <pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph.Start</pc>, and the individual node will remain in the stopped state.</source>
          <target xml:space="preserve">For example, you could call <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Stop</pc> on an individual node while the graph is stopped and then call <pc dataRefEnd="id4" dataRefStart="id3" id="p2">AudioGraph.Start</pc>, and the individual node will remain in the stopped state.</target>
        </segment>
      </unit>
      <unit id="278">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">All node types expose the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">ConsumeInput</pc> property that, when set to false, allows the node to continue audio processing but stops it from consuming any audio data being input from other nodes.</source>
          <target xml:space="preserve">All node types expose the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">ConsumeInput</pc> property that, when set to false, allows the node to continue audio processing but stops it from consuming any audio data being input from other nodes.</target>
        </segment>
      </unit>
      <unit id="279">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">All node types expose the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Reset</pc> method that causes the node to discard any audio data currently in its buffer.</source>
          <target xml:space="preserve">All node types expose the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Reset</pc> method that causes the node to discard any audio data currently in its buffer.</target>
        </segment>
      </unit>
      <unit id="280">
        <segment state="initial">
          <source xml:space="preserve">Adding audio effects</source>
          <target xml:space="preserve">Adding audio effects</target>
        </segment>
      </unit>
      <unit id="281">
        <segment state="initial">
          <source xml:space="preserve">The audio graph API allows you to add audio effects to every type of node in a graph.</source>
          <target xml:space="preserve">The audio graph API allows you to add audio effects to every type of node in a graph.</target>
        </segment>
      </unit>
      <unit id="282">
        <segment state="initial">
          <source xml:space="preserve">Output nodes, input nodes, and submix nodes can each have an unlimited number of audio effects, limited only by the capabilities of the hardware.The following example demonstrates adding the built-in echo effect to a submix node.</source>
          <target xml:space="preserve">Output nodes, input nodes, and submix nodes can each have an unlimited number of audio effects, limited only by the capabilities of the hardware.The following example demonstrates adding the built-in echo effect to a submix node.</target>
        </segment>
      </unit>
      <unit id="283">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](./code/AudioGraph/cs/MainPage.xaml.cs#SnippetAddEffect)</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddEffect</pc>]</source>
          <target xml:space="preserve">[!code-cs<pc dataRefEnd="id2" dataRefStart="id1" id="p1">AddEffect</pc>]</target>
        </segment>
      </unit>
      <unit id="284">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn608044)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">All audio effects implement <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IAudioEffectDefinition</pc></pc>.</source>
          <target xml:space="preserve">All audio effects implement <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IAudioEffectDefinition</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="285">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Every node exposes an <pc dataRefEnd="id2" dataRefStart="id1" id="p1">EffectDefinitions</pc> property representing the list of effects applied to that node.</source>
          <target xml:space="preserve">Every node exposes an <pc dataRefEnd="id2" dataRefStart="id1" id="p1">EffectDefinitions</pc> property representing the list of effects applied to that node.</target>
        </segment>
      </unit>
      <unit id="286">
        <segment state="initial">
          <source xml:space="preserve">Add an effect by adding it's definition object to the list.</source>
          <target xml:space="preserve">Add an effect by adding it's definition object to the list.</target>
        </segment>
      </unit>
      <unit id="287">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">There are several effect definition classes that are provided in the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Windows.Media.Audio</pc> namespace.</source>
          <target xml:space="preserve">There are several effect definition classes that are provided in the <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Windows.Media.Audio</pc> namespace.</target>
        </segment>
      </unit>
      <unit id="288">
        <segment state="initial">
          <source xml:space="preserve">These include:</source>
          <target xml:space="preserve">These include:</target>
        </segment>
      </unit>
      <unit id="289">
        <segment state="initial">
          <source xml:space="preserve">EchoEffectDefinition</source>
          <target xml:space="preserve">EchoEffectDefinition</target>
        </segment>
      </unit>
      <unit id="290">
        <segment state="initial">
          <source xml:space="preserve">EqualizerEffectDefinition</source>
          <target xml:space="preserve">EqualizerEffectDefinition</target>
        </segment>
      </unit>
      <unit id="291">
        <segment state="initial">
          <source xml:space="preserve">LimiterEffectDefinition</source>
          <target xml:space="preserve">LimiterEffectDefinition</target>
        </segment>
      </unit>
      <unit id="292">
        <segment state="initial">
          <source xml:space="preserve">ReverbEffectDefinition</source>
          <target xml:space="preserve">ReverbEffectDefinition</target>
        </segment>
      </unit>
      <unit id="293">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn608044)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">You can create your own audio effects that implement <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IAudioEffectDefinition</pc></pc> and apply them to any node in an audio graph.</source>
          <target xml:space="preserve">You can create your own audio effects that implement <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">IAudioEffectDefinition</pc></pc> and apply them to any node in an audio graph.</target>
        </segment>
      </unit>
      <unit id="294">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">Every node type exposes a <pc dataRefEnd="id2" dataRefStart="id1" id="p1">DisableEffectsByDefinition</pc> method that disables all effects in the node's <pc dataRefEnd="id4" dataRefStart="id3" id="p2">EffectDefinitions</pc> list that were added using the specified definition.</source>
          <target xml:space="preserve">Every node type exposes a <pc dataRefEnd="id2" dataRefStart="id1" id="p1">DisableEffectsByDefinition</pc> method that disables all effects in the node's <pc dataRefEnd="id4" dataRefStart="id3" id="p2">EffectDefinitions</pc> list that were added using the specified definition.</target>
        </segment>
      </unit>
      <unit id="295">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source xml:space="preserve">
						<pc dataRefEnd="id2" dataRefStart="id1" id="p1">EnableEffectsByDefinition</pc> enables the effects with the specified definition.</source>
          <target xml:space="preserve">
						<pc dataRefEnd="id2" dataRefStart="id1" id="p1">EnableEffectsByDefinition</pc> enables the effects with the specified definition.</target>
        </segment>
      </unit>
    </group>
  </file>
</xliff>