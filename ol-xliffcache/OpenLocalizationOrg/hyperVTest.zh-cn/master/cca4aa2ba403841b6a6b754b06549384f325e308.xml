{
  "nodes": [
    {
      "pos": [
        27,
        90
      ],
      "content": "Analyze Twitter data with Hadoop in HDInsight | Microsoft Azure"
    },
    {
      "pos": [
        109,
        227
      ],
      "content": "Learn how to use Hive to analyze Twitter data on Hadoop in HDInsight to find the usage frequency of a particular word."
    },
    {
      "pos": [
        527,
        571
      ],
      "content": "Analyze Twitter data using Hive in HDInsight"
    },
    {
      "pos": [
        573,
        669
      ],
      "content": "Social websites are one of the major driving forces for big-data adoption. Public APIs provided ",
      "nodes": [
        {
          "content": "Social websites are one of the major driving forces for big-data adoption.",
          "pos": [
            0,
            74
          ]
        },
        {
          "content": "Public APIs provided",
          "pos": [
            75,
            95
          ]
        }
      ]
    },
    {
      "pos": [
        670,
        768
      ],
      "content": "by sites like Twitter are a useful source of data for analyzing and understanding popular trends. ",
      "nodes": [
        {
          "content": "by sites like Twitter are a useful source of data for analyzing and understanding popular trends.",
          "pos": [
            0,
            97
          ]
        },
        {
          "content": " ",
          "pos": [
            97,
            98
          ]
        }
      ]
    },
    {
      "pos": [
        769,
        865
      ],
      "content": "In this tutorial, you will get tweets by using a Twitter streaming API, and then use Apache Hive"
    },
    {
      "pos": [
        867,
        972
      ],
      "content": "on Azure HDInsight to get a list of Twitter users who sent the most tweets that contained a certain word."
    },
    {
      "pos": [
        976,
        1205
      ],
      "content": "<ph id=\"ph2\">[AZURE.NOTE]</ph><ph id=\"ph3\"/> The steps in this document require a Windows-based HDInsight cluster. For steps specific \n<ph id=\"ph4\"/>to a Linux-based cluster, see <bpt id=\"p1\">[</bpt>Analyze Twitter data using Hive in HDInsight (Linux)<ept id=\"p1\">](hdinsight-analyze-twitter-data-linux.md)</ept>.",
      "nodes": [
        {
          "content": "<ph id=\"ph2\">[AZURE.NOTE]</ph><ph id=\"ph3\"/> The steps in this document require a Windows-based HDInsight cluster.",
          "pos": [
            0,
            114
          ]
        },
        {
          "content": "For steps specific \n<ph id=\"ph4\"/>to a Linux-based cluster, see <bpt id=\"p1\">[</bpt>Analyze Twitter data using Hive in HDInsight (Linux)<ept id=\"p1\">](hdinsight-analyze-twitter-data-linux.md)</ept>.",
          "pos": [
            115,
            313
          ]
        }
      ]
    },
    {
      "pos": [
        1211,
        1525
      ],
      "content": "<ph id=\"ph5\">[AZURE.TIP]</ph><ph id=\"ph6\"/> A similar sample is in the HDInsight Sample Gallery. Watch the Channel 9 video: <ph id=\"ph7\">&lt;a href=\"http://channel9.msdn.com/Series/Getting-started-with-Windows-Azure-HDInsight-Service/Analyze-Twitter-trend-using-Apache-Hive-in-HDInsight\" target=\"_blank\"&gt;</ph>Analyze Twitter trends using Apache Hive in HDInsight<ph id=\"ph8\">&lt;/a&gt;</ph>.",
      "nodes": [
        {
          "content": "<ph id=\"ph5\">[AZURE.TIP]</ph><ph id=\"ph6\"/> A similar sample is in the HDInsight Sample Gallery.",
          "pos": [
            0,
            96
          ]
        },
        {
          "content": "Watch the Channel 9 video: <ph id=\"ph7\">&lt;a href=\"http://channel9.msdn.com/Series/Getting-started-with-Windows-Azure-HDInsight-Service/Analyze-Twitter-trend-using-Apache-Hive-in-HDInsight\" target=\"_blank\"&gt;</ph>Analyze Twitter trends using Apache Hive in HDInsight<ph id=\"ph8\">&lt;/a&gt;</ph>.",
          "pos": [
            97,
            394
          ]
        }
      ]
    },
    {
      "pos": [
        1530,
        1543
      ],
      "content": "Prerequisites"
    },
    {
      "pos": [
        1545,
        1605
      ],
      "content": "Before you begin this tutorial, you must have the following:"
    },
    {
      "pos": [
        1609,
        1989
      ],
      "content": "<bpt id=\"p2\">**</bpt>A workstation<ept id=\"p2\">**</ept><ph id=\"ph9\"/> with Azure PowerShell installed and configured. See <bpt id=\"p3\">[</bpt>Install and use Azure PowerShell<ept id=\"p3\">](https://azure.microsoft.com/documentation/videos/install-and-use-azure-powershell/)</ept>. To execute Windows PowerShell scripts, you must run Azure PowerShell as administrator and set the execution policy to <bpt id=\"p4\">*</bpt>RemoteSigned<ept id=\"p4\">*</ept>. See <bpt id=\"p5\">[</bpt>Run Windows PowerShell scripts<ept id=\"p5\">][powershell-script]</ept>.",
      "nodes": [
        {
          "content": "<bpt id=\"p2\">**</bpt>A workstation<ept id=\"p2\">**</ept><ph id=\"ph9\"/> with Azure PowerShell installed and configured.",
          "pos": [
            0,
            117
          ]
        },
        {
          "content": "See <bpt id=\"p3\">[</bpt>Install and use Azure PowerShell<ept id=\"p3\">](https://azure.microsoft.com/documentation/videos/install-and-use-azure-powershell/)</ept>.",
          "pos": [
            118,
            279
          ]
        },
        {
          "content": "To execute Windows PowerShell scripts, you must run Azure PowerShell as administrator and set the execution policy to <bpt id=\"p4\">*</bpt>RemoteSigned<ept id=\"p4\">*</ept>.",
          "pos": [
            280,
            451
          ]
        },
        {
          "content": "See <bpt id=\"p5\">[</bpt>Run Windows PowerShell scripts<ept id=\"p5\">][powershell-script]</ept>.",
          "pos": [
            452,
            546
          ]
        }
      ]
    },
    {
      "pos": [
        1995,
        2123
      ],
      "content": "Before running Windows PowerShell scripts, make sure you are connected to your Azure subscription by using the following cmdlet:"
    },
    {
      "pos": [
        2159,
        2258
      ],
      "content": "If you have multiple Azure subscriptions, use the following cmdlet to set the current subscription:"
    },
    {
      "pos": [
        2339,
        2580
      ],
      "content": "<bpt id=\"p6\">**</bpt>An Azure HDInsight cluster<ept id=\"p6\">**</ept>. For instructions on cluster provisioning, see <bpt id=\"p7\">[</bpt>Get started using HDInsight<ept id=\"p7\">][hdinsight-get-started]</ept><ph id=\"ph10\"/> or <bpt id=\"p8\">[</bpt>Provision HDInsight clusters<ept id=\"p8\">] [hdinsight-provision]</ept>. You will need the cluster name later in the tutorial.",
      "nodes": [
        {
          "content": "<bpt id=\"p6\">**</bpt>An Azure HDInsight cluster<ept id=\"p6\">**</ept>.",
          "pos": [
            0,
            69
          ]
        },
        {
          "content": "For instructions on cluster provisioning, see <bpt id=\"p7\">[</bpt>Get started using HDInsight<ept id=\"p7\">][hdinsight-get-started]</ept><ph id=\"ph10\"/> or <bpt id=\"p8\">[</bpt>Provision HDInsight clusters<ept id=\"p8\">] [hdinsight-provision]</ept>.",
          "pos": [
            70,
            316
          ]
        },
        {
          "content": "You will need the cluster name later in the tutorial.",
          "pos": [
            317,
            370
          ]
        }
      ]
    },
    {
      "pos": [
        2582,
        2640
      ],
      "content": "The following table lists the files used in this tutorial:"
    },
    {
      "pos": [
        2642,
        2647
      ],
      "content": "Files"
    },
    {
      "pos": [
        2648,
        2659
      ],
      "content": "Description"
    },
    {
      "pos": [
        2668,
        2702
      ],
      "content": "/tutorials/twitter/data/tweets.txt"
    },
    {
      "pos": [
        2703,
        2736
      ],
      "content": "The source data for the Hive job."
    },
    {
      "pos": [
        2737,
        2762
      ],
      "content": "/tutorials/twitter/output"
    },
    {
      "pos": [
        2763,
        2853
      ],
      "content": "The output folder for the Hive job. The default Hive job output file name is <bpt id=\"p9\">**</bpt>000000_0<ept id=\"p9\">**</ept>.",
      "nodes": [
        {
          "content": "The output folder for the Hive job.",
          "pos": [
            0,
            35
          ]
        },
        {
          "content": "The default Hive job output file name is <bpt id=\"p9\">**</bpt>000000_0<ept id=\"p9\">**</ept>.",
          "pos": [
            36,
            128
          ]
        }
      ]
    },
    {
      "pos": [
        2854,
        2883
      ],
      "content": "tutorials/twitter/twitter.hql"
    },
    {
      "pos": [
        2884,
        2907
      ],
      "content": "The HiveQL script file."
    },
    {
      "pos": [
        2908,
        2936
      ],
      "content": "/tutorials/twitter/jobstatus"
    },
    {
      "pos": [
        2937,
        2959
      ],
      "content": "The Hadoop job status."
    },
    {
      "pos": [
        2964,
        2980
      ],
      "content": "Get Twitter feed"
    },
    {
      "pos": [
        2982,
        3160
      ],
      "content": "In this tutorial, you will use the <bpt id=\"p10\">[</bpt>Twitter streaming APIs<ept id=\"p10\">][twitter-streaming-api]</ept>. The specific Twitter streaming API you will use is <bpt id=\"p11\">[</bpt>statuses/filter<ept id=\"p11\">][twitter-statuses-filter]</ept>.",
      "nodes": [
        {
          "content": "In this tutorial, you will use the <bpt id=\"p10\">[</bpt>Twitter streaming APIs<ept id=\"p10\">][twitter-streaming-api]</ept>.",
          "pos": [
            0,
            123
          ]
        },
        {
          "content": "The specific Twitter streaming API you will use is <bpt id=\"p11\">[</bpt>statuses/filter<ept id=\"p11\">][twitter-statuses-filter]</ept>.",
          "pos": [
            124,
            258
          ]
        }
      ]
    },
    {
      "pos": [
        3163,
        3374
      ],
      "content": "<ph id=\"ph11\">[AZURE.NOTE]</ph><ph id=\"ph12\"/> A file containing 10,000 tweets and the Hive script file (covered in the next section) have been uploaded in a public Blob container. You can skip this section if you want to use the uploaded files.",
      "nodes": [
        {
          "content": "<ph id=\"ph11\">[AZURE.NOTE]</ph><ph id=\"ph12\"/> A file containing 10,000 tweets and the Hive script file (covered in the next section) have been uploaded in a public Blob container.",
          "pos": [
            0,
            180
          ]
        },
        {
          "content": "You can skip this section if you want to use the uploaded files.",
          "pos": [
            181,
            245
          ]
        }
      ]
    },
    {
      "pos": [
        3376,
        3778
      ],
      "content": "<bpt id=\"p12\">[</bpt>Tweets data<ept id=\"p12\">](https://dev.twitter.com/docs/platform-objects/tweets)</ept><ph id=\"ph13\"/> is stored in the JavaScript Object Notation (JSON) format that contains a complex nested structure. Instead of writing many lines of code by using a conventional programming language, you can transform this nested structure into a Hive table, so that it can be queried by a Structured Query Language (SQL)-like language called HiveQL.",
      "nodes": [
        {
          "content": "<bpt id=\"p12\">[</bpt>Tweets data<ept id=\"p12\">](https://dev.twitter.com/docs/platform-objects/tweets)</ept><ph id=\"ph13\"/> is stored in the JavaScript Object Notation (JSON) format that contains a complex nested structure.",
          "pos": [
            0,
            222
          ]
        },
        {
          "content": "Instead of writing many lines of code by using a conventional programming language, you can transform this nested structure into a Hive table, so that it can be queried by a Structured Query Language (SQL)-like language called HiveQL.",
          "pos": [
            223,
            457
          ]
        }
      ]
    },
    {
      "pos": [
        3780,
        4131
      ],
      "content": "Twitter uses OAuth to provide authorized access to its API. OAuth is an authentication protocol that allows users to approve applications to act on their behalf without sharing their password. More information can be found at <bpt id=\"p13\">[</bpt>oauth.net<ept id=\"p13\">](http://oauth.net/)</ept><ph id=\"ph14\"/> or in the excellent <bpt id=\"p14\">[</bpt>Beginner's Guide to OAuth<ept id=\"p14\">](http://hueniverse.com/oauth/)</ept><ph id=\"ph15\"/> from Hueniverse.",
      "nodes": [
        {
          "content": "Twitter uses OAuth to provide authorized access to its API.",
          "pos": [
            0,
            59
          ]
        },
        {
          "content": "OAuth is an authentication protocol that allows users to approve applications to act on their behalf without sharing their password.",
          "pos": [
            60,
            192
          ]
        },
        {
          "content": "More information can be found at <bpt id=\"p13\">[</bpt>oauth.net<ept id=\"p13\">](http://oauth.net/)</ept><ph id=\"ph14\"/> or in the excellent <bpt id=\"p14\">[</bpt>Beginner's Guide to OAuth<ept id=\"p14\">](http://hueniverse.com/oauth/)</ept><ph id=\"ph15\"/> from Hueniverse.",
          "pos": [
            193,
            461
          ]
        }
      ]
    },
    {
      "pos": [
        4133,
        4222
      ],
      "content": "The first step to use OAuth is to create a new application on the Twitter Developer site."
    },
    {
      "pos": [
        4224,
        4259
      ],
      "content": "<bpt id=\"p15\">**</bpt>To create a Twitter application<ept id=\"p15\">**</ept>"
    },
    {
      "pos": [
        4264,
        4398
      ],
      "content": "Sign in to <bpt id=\"p16\">[</bpt>https://apps.twitter.com/<ept id=\"p16\">](https://apps.twitter.com/)</ept>. Click the <bpt id=\"p17\">**</bpt>Sign up now<ept id=\"p17\">**</ept><ph id=\"ph16\"/> link if you don't have a Twitter account.",
      "nodes": [
        {
          "content": "Sign in to <bpt id=\"p16\">[</bpt>https://apps.twitter.com/<ept id=\"p16\">](https://apps.twitter.com/)</ept>.",
          "pos": [
            0,
            106
          ]
        },
        {
          "content": "Click the <bpt id=\"p17\">**</bpt>Sign up now<ept id=\"p17\">**</ept><ph id=\"ph16\"/> link if you don't have a Twitter account.",
          "pos": [
            107,
            229
          ]
        }
      ]
    },
    {
      "pos": [
        4402,
        4427
      ],
      "content": "Click <bpt id=\"p18\">**</bpt>Create New App<ept id=\"p18\">**</ept>."
    },
    {
      "pos": [
        4431,
        4578
      ],
      "content": "Enter <bpt id=\"p19\">**</bpt>Name<ept id=\"p19\">**</ept>, <bpt id=\"p20\">**</bpt>Description<ept id=\"p20\">**</ept>, <bpt id=\"p21\">**</bpt>Website<ept id=\"p21\">**</ept>. You can make up a URL for the <bpt id=\"p22\">**</bpt>Website<ept id=\"p22\">**</ept><ph id=\"ph17\"/> field. The following table shows some sample values to use:",
      "nodes": [
        {
          "content": "Enter <bpt id=\"p19\">**</bpt>Name<ept id=\"p19\">**</ept>, <bpt id=\"p20\">**</bpt>Description<ept id=\"p20\">**</ept>, <bpt id=\"p21\">**</bpt>Website<ept id=\"p21\">**</ept>.",
          "pos": [
            0,
            165
          ]
        },
        {
          "content": "You can make up a URL for the <bpt id=\"p22\">**</bpt>Website<ept id=\"p22\">**</ept><ph id=\"ph17\"/> field.",
          "pos": [
            166,
            269
          ]
        },
        {
          "content": "The following table shows some sample values to use:",
          "pos": [
            270,
            322
          ]
        }
      ]
    },
    {
      "pos": [
        4580,
        4585
      ],
      "content": "Field"
    },
    {
      "pos": [
        4586,
        4591
      ],
      "content": "Value"
    },
    {
      "pos": [
        4600,
        4604
      ],
      "content": "Name"
    },
    {
      "pos": [
        4605,
        4619
      ],
      "content": "MyHDInsightApp"
    },
    {
      "pos": [
        4620,
        4631
      ],
      "content": "Description"
    },
    {
      "pos": [
        4632,
        4646
      ],
      "content": "MyHDInsightApp"
    },
    {
      "pos": [
        4647,
        4654
      ],
      "content": "Website"
    },
    {
      "pos": [
        4655,
        4684
      ],
      "content": "http://www.myhdinsightapp.com"
    },
    {
      "pos": [
        4689,
        4764
      ],
      "content": "Check <bpt id=\"p23\">**</bpt>Yes, I agree<ept id=\"p23\">**</ept>, and then click <bpt id=\"p24\">**</bpt>Create your Twitter application<ept id=\"p24\">**</ept>."
    },
    {
      "pos": [
        4768,
        4877
      ],
      "content": "Click the <bpt id=\"p25\">**</bpt>Permissions<ept id=\"p25\">**</ept><ph id=\"ph18\"/> tab. The default permission is <bpt id=\"p26\">**</bpt>Read only<ept id=\"p26\">**</ept>. This is sufficient for this tutorial.",
      "nodes": [
        {
          "content": "Click the <bpt id=\"p25\">**</bpt>Permissions<ept id=\"p25\">**</ept><ph id=\"ph18\"/> tab.",
          "pos": [
            0,
            85
          ]
        },
        {
          "content": "The default permission is <bpt id=\"p26\">**</bpt>Read only<ept id=\"p26\">**</ept>.",
          "pos": [
            86,
            166
          ]
        },
        {
          "content": "This is sufficient for this tutorial.",
          "pos": [
            167,
            204
          ]
        }
      ]
    },
    {
      "pos": [
        4881,
        4922
      ],
      "content": "Click the <bpt id=\"p27\">**</bpt>Keys and Access Tokens<ept id=\"p27\">**</ept><ph id=\"ph19\"/> tab."
    },
    {
      "pos": [
        4926,
        4959
      ],
      "content": "Click <bpt id=\"p28\">**</bpt>Create my access token<ept id=\"p28\">**</ept>."
    },
    {
      "pos": [
        4963,
        5022
      ],
      "content": "Click <bpt id=\"p29\">**</bpt>Test OAuth<ept id=\"p29\">**</ept><ph id=\"ph20\"/> in the upper-right corner of the page."
    },
    {
      "pos": [
        5026,
        5170
      ],
      "content": "Write down <bpt id=\"p30\">**</bpt>consumer key<ept id=\"p30\">**</ept>, <bpt id=\"p31\">**</bpt>Consumer secret<ept id=\"p31\">**</ept>, <bpt id=\"p32\">**</bpt>Access token<ept id=\"p32\">**</ept>, and <bpt id=\"p33\">**</bpt>Access token secret<ept id=\"p33\">**</ept>. You will need the values later in the tutorial.",
      "nodes": [
        {
          "content": "Write down <bpt id=\"p30\">**</bpt>consumer key<ept id=\"p30\">**</ept>, <bpt id=\"p31\">**</bpt>Consumer secret<ept id=\"p31\">**</ept>, <bpt id=\"p32\">**</bpt>Access token<ept id=\"p32\">**</ept>, and <bpt id=\"p33\">**</bpt>Access token secret<ept id=\"p33\">**</ept>.",
          "pos": [
            0,
            256
          ]
        },
        {
          "content": "You will need the values later in the tutorial.",
          "pos": [
            257,
            304
          ]
        }
      ]
    },
    {
      "pos": [
        5172,
        5494
      ],
      "content": "In this tutorial, you will use Windows PowerShell to make the web service call. For a .NET C# sample, see <bpt id=\"p34\">[</bpt>Analyze real-time Twitter sentiment with HBase in HDInsight<ept id=\"p34\">][hdinsight-hbase-twitter-sentiment]</ept>. The other popular tool to make web service calls is <bpt id=\"p35\">[</bpt><bpt id=\"p36\">*</bpt>Curl<ept id=\"p36\">*</ept><ept id=\"p35\">][curl]</ept>. Curl can be downloaded from <bpt id=\"p37\">[</bpt>here<ept id=\"p37\">][curl-download]</ept>.",
      "nodes": [
        {
          "content": "In this tutorial, you will use Windows PowerShell to make the web service call.",
          "pos": [
            0,
            79
          ]
        },
        {
          "content": "For a .NET C# sample, see <bpt id=\"p34\">[</bpt>Analyze real-time Twitter sentiment with HBase in HDInsight<ept id=\"p34\">][hdinsight-hbase-twitter-sentiment]</ept>.",
          "pos": [
            80,
            243
          ]
        },
        {
          "content": "The other popular tool to make web service calls is <bpt id=\"p35\">[</bpt><bpt id=\"p36\">*</bpt>Curl<ept id=\"p36\">*</ept><ept id=\"p35\">][curl]</ept>.",
          "pos": [
            244,
            391
          ]
        },
        {
          "content": "Curl can be downloaded from <bpt id=\"p37\">[</bpt>here<ept id=\"p37\">][curl-download]</ept>.",
          "pos": [
            392,
            482
          ]
        }
      ]
    },
    {
      "pos": [
        5497,
        5617
      ],
      "content": "<ph id=\"ph21\">[AZURE.NOTE]</ph><ph id=\"ph22\"/> When you use the curl command in Windows, use double quotes instead of single quotes for the option values."
    },
    {
      "pos": [
        5619,
        5636
      ],
      "content": "<bpt id=\"p38\">**</bpt>To get tweets<ept id=\"p38\">**</ept>"
    },
    {
      "pos": [
        5641,
        5883
      ],
      "content": "Open the Windows PowerShell Integrated Scripting Environment (ISE). (On the Windows 8 Start screen, type <bpt id=\"p39\">**</bpt>PowerShell_ISE<ept id=\"p39\">**</ept><ph id=\"ph23\"/> and then click <bpt id=\"p40\">**</bpt>Windows PowerShell ISE<ept id=\"p40\">**</ept>. See <bpt id=\"p41\">[</bpt>Start Windows PowerShell on Windows 8 and Windows<ept id=\"p41\">][powershell-start]</ept>.)",
      "nodes": [
        {
          "content": "Open the Windows PowerShell Integrated Scripting Environment (ISE).",
          "pos": [
            0,
            67
          ]
        },
        {
          "content": "(On the Windows 8 Start screen, type <bpt id=\"p39\">**</bpt>PowerShell_ISE<ept id=\"p39\">**</ept><ph id=\"ph23\"/> and then click <bpt id=\"p40\">**</bpt>Windows PowerShell ISE<ept id=\"p40\">**</ept>.",
          "pos": [
            68,
            261
          ]
        },
        {
          "content": "See <bpt id=\"p41\">[</bpt>Start Windows PowerShell on Windows 8 and Windows<ept id=\"p41\">][powershell-start]</ept>.)",
          "pos": [
            262,
            377
          ]
        }
      ]
    },
    {
      "pos": [
        5888,
        5935
      ],
      "content": "Copy the following script into the script pane:"
    },
    {
      "pos": [
        12708,
        12760
      ],
      "content": "Set the first five to eight variables in the script:"
    },
    {
      "pos": [
        12763,
        12771
      ],
      "content": "Variable"
    },
    {
      "pos": [
        12772,
        12783
      ],
      "content": "Description"
    },
    {
      "pos": [
        12792,
        12804
      ],
      "content": "$clusterName"
    },
    {
      "pos": [
        12805,
        12885
      ],
      "content": "This is the name of the HDInsight cluster where you want to run the application."
    },
    {
      "pos": [
        12886,
        12905
      ],
      "content": "$oauth_consumer_key"
    },
    {
      "pos": [
        12906,
        13019
      ],
      "content": "This is the Twitter application <bpt id=\"p42\">**</bpt>consumer key<ept id=\"p42\">**</ept><ph id=\"ph24\"/> you wrote down earlier when you created the Twitter application."
    },
    {
      "pos": [
        13020,
        13042
      ],
      "content": "$oauth_consumer_secret"
    },
    {
      "pos": [
        13043,
        13118
      ],
      "content": "This is the Twitter application <bpt id=\"p43\">**</bpt>consumer secret<ept id=\"p43\">**</ept><ph id=\"ph25\"/> you wrote down earlier."
    },
    {
      "pos": [
        13119,
        13131
      ],
      "content": "$oauth_token"
    },
    {
      "pos": [
        13132,
        13204
      ],
      "content": "This is the Twitter application <bpt id=\"p44\">**</bpt>access token<ept id=\"p44\">**</ept><ph id=\"ph26\"/> you wrote down earlier."
    },
    {
      "pos": [
        13205,
        13224
      ],
      "content": "$oauth_token_secret"
    },
    {
      "pos": [
        13225,
        13304
      ],
      "content": "This is the Twitter application <bpt id=\"p45\">**</bpt>access token secret<ept id=\"p45\">**</ept><ph id=\"ph27\"/> you wrote down earlier."
    },
    {
      "pos": [
        13305,
        13318
      ],
      "content": "$destBlobName"
    },
    {
      "pos": [
        13319,
        13509
      ],
      "content": "This is the output blob name. The default value is <bpt id=\"p46\">**</bpt>tutorials/twitter/data/tweets.txt<ept id=\"p46\">**</ept>. If you change the default value, you will need to update the Windows PowerShell scripts accordingly.",
      "nodes": [
        {
          "content": "This is the output blob name.",
          "pos": [
            0,
            29
          ]
        },
        {
          "content": "The default value is <bpt id=\"p46\">**</bpt>tutorials/twitter/data/tweets.txt<ept id=\"p46\">**</ept>.",
          "pos": [
            30,
            129
          ]
        },
        {
          "content": "If you change the default value, you will need to update the Windows PowerShell scripts accordingly.",
          "pos": [
            130,
            230
          ]
        }
      ]
    },
    {
      "pos": [
        13510,
        13522
      ],
      "content": "$trackString"
    },
    {
      "pos": [
        13523,
        13727
      ],
      "content": "The web service will return tweets related to these keywords. The default value is <bpt id=\"p47\">**</bpt>Azure, Cloud, HDInsight<ept id=\"p47\">**</ept>. If you change the default value, you will update the Windows PowerShell scripts accordingly.",
      "nodes": [
        {
          "content": "The web service will return tweets related to these keywords.",
          "pos": [
            0,
            61
          ]
        },
        {
          "content": "The default value is <bpt id=\"p47\">**</bpt>Azure, Cloud, HDInsight<ept id=\"p47\">**</ept>.",
          "pos": [
            62,
            151
          ]
        },
        {
          "content": "If you change the default value, you will update the Windows PowerShell scripts accordingly.",
          "pos": [
            152,
            244
          ]
        }
      ]
    },
    {
      "pos": [
        13728,
        13736
      ],
      "content": "$lineMax"
    },
    {
      "pos": [
        13737,
        13913
      ],
      "content": "The value determines how many tweets the script will read. It takes about three minutes to read 100 tweets. You can set a larger number, but it will take more time to download.",
      "nodes": [
        {
          "content": "The value determines how many tweets the script will read.",
          "pos": [
            0,
            58
          ]
        },
        {
          "content": "It takes about three minutes to read 100 tweets.",
          "pos": [
            59,
            107
          ]
        },
        {
          "content": "You can set a larger number, but it will take more time to download.",
          "pos": [
            108,
            176
          ]
        }
      ]
    },
    {
      "pos": [
        13918,
        14037
      ],
      "content": "Press <bpt id=\"p48\">**</bpt>F5<ept id=\"p48\">**</ept><ph id=\"ph28\"/> to run the script. If you run into problems, as a workaround, select all the lines, and then press <bpt id=\"p49\">**</bpt>F8<ept id=\"p49\">**</ept>.",
      "nodes": [
        {
          "content": "Press <bpt id=\"p48\">**</bpt>F5<ept id=\"p48\">**</ept><ph id=\"ph28\"/> to run the script.",
          "pos": [
            0,
            86
          ]
        },
        {
          "content": "If you run into problems, as a workaround, select all the lines, and then press <bpt id=\"p49\">**</bpt>F8<ept id=\"p49\">**</ept>.",
          "pos": [
            87,
            214
          ]
        }
      ]
    },
    {
      "pos": [
        14041,
        14137
      ],
      "content": "You shall see \"Complete!\" at the end of the output. Any error messages will be displayed in red.",
      "nodes": [
        {
          "content": "You shall see \"Complete!\"",
          "pos": [
            0,
            25
          ]
        },
        {
          "content": "at the end of the output.",
          "pos": [
            26,
            51
          ]
        },
        {
          "content": "Any error messages will be displayed in red.",
          "pos": [
            52,
            96
          ]
        }
      ]
    },
    {
      "pos": [
        14139,
        14446
      ],
      "content": "As a validation procedure, you can check the output file, <bpt id=\"p50\">**</bpt>/tutorials/twitter/data/tweets.txt<ept id=\"p50\">**</ept>, on your Azure Blob storage by using an Azure storage explorer or Azure PowerShell. For a sample Windows PowerShell script for listing files, see <bpt id=\"p51\">[</bpt>Use Blob storage with HDInsight<ept id=\"p51\">][hdinsight-storage-powershell]</ept>.",
      "nodes": [
        {
          "content": "As a validation procedure, you can check the output file, <bpt id=\"p50\">**</bpt>/tutorials/twitter/data/tweets.txt<ept id=\"p50\">**</ept>, on your Azure Blob storage by using an Azure storage explorer or Azure PowerShell.",
          "pos": [
            0,
            220
          ]
        },
        {
          "content": "For a sample Windows PowerShell script for listing files, see <bpt id=\"p51\">[</bpt>Use Blob storage with HDInsight<ept id=\"p51\">][hdinsight-storage-powershell]</ept>.",
          "pos": [
            221,
            387
          ]
        }
      ]
    },
    {
      "pos": [
        14452,
        14472
      ],
      "content": "Create HiveQL script"
    },
    {
      "pos": [
        14474,
        14787
      ],
      "content": "Using Azure PowerShell, you can run multiple HiveQL statements one at a time, or package the HiveQL statement into a script file. In this tutorial, you will create a HiveQL script. The script file must be uploaded to Azure Blob storage. In the next section, you will run the script file by using Azure PowerShell.",
      "nodes": [
        {
          "content": "Using Azure PowerShell, you can run multiple HiveQL statements one at a time, or package the HiveQL statement into a script file.",
          "pos": [
            0,
            129
          ]
        },
        {
          "content": "In this tutorial, you will create a HiveQL script.",
          "pos": [
            130,
            180
          ]
        },
        {
          "content": "The script file must be uploaded to Azure Blob storage.",
          "pos": [
            181,
            236
          ]
        },
        {
          "content": "In the next section, you will run the script file by using Azure PowerShell.",
          "pos": [
            237,
            313
          ]
        }
      ]
    },
    {
      "pos": [
        14790,
        14971
      ],
      "content": "<ph id=\"ph29\">[AZURE.NOTE]</ph><ph id=\"ph30\"/> The Hive script file and a file containing 10,000 tweets have been uploaded in a public Blob container. You can skip this section if you want to use the uploaded files.",
      "nodes": [
        {
          "content": "<ph id=\"ph29\">[AZURE.NOTE]</ph><ph id=\"ph30\"/> The Hive script file and a file containing 10,000 tweets have been uploaded in a public Blob container.",
          "pos": [
            0,
            150
          ]
        },
        {
          "content": "You can skip this section if you want to use the uploaded files.",
          "pos": [
            151,
            215
          ]
        }
      ]
    },
    {
      "pos": [
        14973,
        15018
      ],
      "content": "The HiveQL script will perform the following:"
    },
    {
      "pos": [
        15023,
        15086
      ],
      "content": "<bpt id=\"p52\">**</bpt>Drop the tweets_raw table<ept id=\"p52\">**</ept><ph id=\"ph31\"/> in case the table already exists."
    },
    {
      "pos": [
        15090,
        15312
      ],
      "content": "<bpt id=\"p53\">**</bpt>Create the tweets_raw Hive table<ept id=\"p53\">**</ept>. This temporary Hive structured table holds the data for further extract, transform, and load (ETL) processing. For information on partitions, see <bpt id=\"p54\">[</bpt>Hive tutorial<ept id=\"p54\">][apache-hive-tutorial]</ept>.",
      "nodes": [
        {
          "content": "<bpt id=\"p53\">**</bpt>Create the tweets_raw Hive table<ept id=\"p53\">**</ept>.",
          "pos": [
            0,
            77
          ]
        },
        {
          "content": "This temporary Hive structured table holds the data for further extract, transform, and load (ETL) processing.",
          "pos": [
            78,
            188
          ]
        },
        {
          "content": "For information on partitions, see <bpt id=\"p54\">[</bpt>Hive tutorial<ept id=\"p54\">][apache-hive-tutorial]</ept>.",
          "pos": [
            189,
            302
          ]
        }
      ]
    },
    {
      "pos": [
        15318,
        15491
      ],
      "content": "<bpt id=\"p55\">**</bpt>Load data<ept id=\"p55\">**</ept><ph id=\"ph32\"/> from the source folder, /tutorials/twitter/data. The large tweets dataset in nested JSON format has now been transformed into a temporary Hive table structure.",
      "nodes": [
        {
          "content": "<bpt id=\"p55\">**</bpt>Load data<ept id=\"p55\">**</ept><ph id=\"ph32\"/> from the source folder, /tutorials/twitter/data.",
          "pos": [
            0,
            117
          ]
        },
        {
          "content": "The large tweets dataset in nested JSON format has now been transformed into a temporary Hive table structure.",
          "pos": [
            118,
            228
          ]
        }
      ]
    },
    {
      "pos": [
        15495,
        15554
      ],
      "content": "<bpt id=\"p56\">**</bpt>Drop the tweets table<ept id=\"p56\">**</ept><ph id=\"ph33\"/> in case the table already exists."
    },
    {
      "pos": [
        15558,
        15802
      ],
      "content": "<bpt id=\"p57\">**</bpt>Create the tweets table<ept id=\"p57\">**</ept>. Before you can query against the tweets dataset by using Hive, you need to run another ETL process. This ETL process defines a more detailed table schema for the data that you have stored in the \"twitter_raw\" table.",
      "nodes": [
        {
          "content": "<bpt id=\"p57\">**</bpt>Create the tweets table<ept id=\"p57\">**</ept>.",
          "pos": [
            0,
            68
          ]
        },
        {
          "content": "Before you can query against the tweets dataset by using Hive, you need to run another ETL process.",
          "pos": [
            69,
            168
          ]
        },
        {
          "content": "This ETL process defines a more detailed table schema for the data that you have stored in the \"twitter_raw\" table.",
          "pos": [
            169,
            284
          ]
        }
      ]
    },
    {
      "pos": [
        15808,
        16016
      ],
      "content": "<bpt id=\"p58\">**</bpt>Insert overwrite table<ept id=\"p58\">**</ept>. This complex Hive script will kick off a set of long MapReduce jobs by the Hadoop cluster. Depending on your dataset and the size of your cluster, this could take about 10 minutes.",
      "nodes": [
        {
          "content": "<bpt id=\"p58\">**</bpt>Insert overwrite table<ept id=\"p58\">**</ept>.",
          "pos": [
            0,
            67
          ]
        },
        {
          "content": "This complex Hive script will kick off a set of long MapReduce jobs by the Hadoop cluster.",
          "pos": [
            68,
            158
          ]
        },
        {
          "content": "Depending on your dataset and the size of your cluster, this could take about 10 minutes.",
          "pos": [
            159,
            248
          ]
        }
      ]
    },
    {
      "pos": [
        16020,
        16198
      ],
      "content": "<bpt id=\"p59\">**</bpt>Insert overwrite directory<ept id=\"p59\">**</ept>. Run a query and output the dataset to a file. This query will return a list of Twitter users who sent most tweets that contained the word \"Azure\".",
      "nodes": [
        {
          "content": "<bpt id=\"p59\">**</bpt>Insert overwrite directory<ept id=\"p59\">**</ept>.",
          "pos": [
            0,
            71
          ]
        },
        {
          "content": "Run a query and output the dataset to a file.",
          "pos": [
            72,
            117
          ]
        },
        {
          "content": "This query will return a list of Twitter users who sent most tweets that contained the word \"Azure\".",
          "pos": [
            118,
            218
          ]
        }
      ]
    },
    {
      "pos": [
        16200,
        16250
      ],
      "content": "<bpt id=\"p60\">**</bpt>To create a Hive script and upload it to Azure<ept id=\"p60\">**</ept>"
    },
    {
      "pos": [
        16255,
        16283
      ],
      "content": "Open Windows PowerShell ISE."
    },
    {
      "pos": [
        16287,
        16334
      ],
      "content": "Copy the following script into the script pane:"
    },
    {
      "pos": [
        24562,
        24604
      ],
      "content": "Set the first two variables in the script:"
    },
    {
      "pos": [
        24606,
        24614
      ],
      "content": "Variable"
    },
    {
      "pos": [
        24615,
        24626
      ],
      "content": "Description"
    },
    {
      "pos": [
        24635,
        24647
      ],
      "content": "$clusterName"
    },
    {
      "pos": [
        24648,
        24719
      ],
      "content": "Enter the HDInsight cluster name where you want to run the application."
    },
    {
      "pos": [
        24720,
        24735
      ],
      "content": "$subscriptionID"
    },
    {
      "pos": [
        24736,
        24769
      ],
      "content": "Enter your Azure subscription ID."
    },
    {
      "pos": [
        24770,
        24785
      ],
      "content": "$sourceDataPath"
    },
    {
      "pos": [
        24786,
        24905
      ],
      "content": "The Azure Blob storage location where the Hive queries will read the data from. You don't need to change this variable.",
      "nodes": [
        {
          "content": "The Azure Blob storage location where the Hive queries will read the data from.",
          "pos": [
            0,
            79
          ]
        },
        {
          "content": "You don't need to change this variable.",
          "pos": [
            80,
            119
          ]
        }
      ]
    },
    {
      "pos": [
        24906,
        24917
      ],
      "content": "$outputPath"
    },
    {
      "pos": [
        24918,
        25037
      ],
      "content": "The Azure Blob storage location where the Hive queries will output the results. You don't need to change this variable.",
      "nodes": [
        {
          "content": "The Azure Blob storage location where the Hive queries will output the results.",
          "pos": [
            0,
            79
          ]
        },
        {
          "content": "You don't need to change this variable.",
          "pos": [
            80,
            119
          ]
        }
      ]
    },
    {
      "pos": [
        25038,
        25052
      ],
      "content": "$hqlScriptFile"
    },
    {
      "pos": [
        25053,
        25150
      ],
      "content": "The location and the file name of the HiveQL script file. You don't need to change this variable.",
      "nodes": [
        {
          "content": "The location and the file name of the HiveQL script file.",
          "pos": [
            0,
            57
          ]
        },
        {
          "content": "You don't need to change this variable.",
          "pos": [
            58,
            97
          ]
        }
      ]
    },
    {
      "pos": [
        25155,
        25274
      ],
      "content": "Press <bpt id=\"p61\">**</bpt>F5<ept id=\"p61\">**</ept><ph id=\"ph34\"/> to run the script. If you run into problems, as a workaround, select all the lines, and then press <bpt id=\"p62\">**</bpt>F8<ept id=\"p62\">**</ept>.",
      "nodes": [
        {
          "content": "Press <bpt id=\"p61\">**</bpt>F5<ept id=\"p61\">**</ept><ph id=\"ph34\"/> to run the script.",
          "pos": [
            0,
            86
          ]
        },
        {
          "content": "If you run into problems, as a workaround, select all the lines, and then press <bpt id=\"p62\">**</bpt>F8<ept id=\"p62\">**</ept>.",
          "pos": [
            87,
            214
          ]
        }
      ]
    },
    {
      "pos": [
        25278,
        25374
      ],
      "content": "You shall see \"Complete!\" at the end of the output. Any error messages will be displayed in red.",
      "nodes": [
        {
          "content": "You shall see \"Complete!\"",
          "pos": [
            0,
            25
          ]
        },
        {
          "content": "at the end of the output.",
          "pos": [
            26,
            51
          ]
        },
        {
          "content": "Any error messages will be displayed in red.",
          "pos": [
            52,
            96
          ]
        }
      ]
    },
    {
      "pos": [
        25376,
        25679
      ],
      "content": "As a validation procedure, you can check the output file, <bpt id=\"p63\">**</bpt>/tutorials/twitter/twitter.hql<ept id=\"p63\">**</ept>, on your Azure Blob storage by using an Azure storage explorer or Azure PowerShell. For a sample Windows PowerShell script for listing files, see <bpt id=\"p64\">[</bpt>Use Blob storage with HDInsight<ept id=\"p64\">][hdinsight-storage-powershell]</ept>.",
      "nodes": [
        {
          "content": "As a validation procedure, you can check the output file, <bpt id=\"p63\">**</bpt>/tutorials/twitter/twitter.hql<ept id=\"p63\">**</ept>, on your Azure Blob storage by using an Azure storage explorer or Azure PowerShell.",
          "pos": [
            0,
            216
          ]
        },
        {
          "content": "For a sample Windows PowerShell script for listing files, see <bpt id=\"p64\">[</bpt>Use Blob storage with HDInsight<ept id=\"p64\">][hdinsight-storage-powershell]</ept>.",
          "pos": [
            217,
            383
          ]
        }
      ]
    },
    {
      "pos": [
        25686,
        25720
      ],
      "content": "Process Twitter data by using Hive"
    },
    {
      "pos": [
        25722,
        25824
      ],
      "content": "You have finished all the preparation work. Now, you can invoke the Hive script and check the results.",
      "nodes": [
        {
          "content": "You have finished all the preparation work.",
          "pos": [
            0,
            43
          ]
        },
        {
          "content": "Now, you can invoke the Hive script and check the results.",
          "pos": [
            44,
            102
          ]
        }
      ]
    },
    {
      "pos": [
        25830,
        25847
      ],
      "content": "Submit a Hive job"
    },
    {
      "pos": [
        25849,
        25957
      ],
      "content": "Use the following Windows PowerShell script to run the Hive script. You will need to set the first variable.",
      "nodes": [
        {
          "content": "Use the following Windows PowerShell script to run the Hive script.",
          "pos": [
            0,
            67
          ]
        },
        {
          "content": "You will need to set the first variable.",
          "pos": [
            68,
            108
          ]
        }
      ]
    },
    {
      "pos": [
        25960,
        26268
      ],
      "content": "<ph id=\"ph35\">[AZURE.NOTE]</ph><ph id=\"ph36\"/> To use the tweets and the HiveQL script you uploaded in the last two sections, set $hqlScriptFile to \"/tutorials/twitter/twitter.hql\". To use the ones that have been uploaded to a public blob for you, set $hqlScriptFile to \"wasb://twittertrend@hditutorialdata.blob.core.windows.net/twitter.hql\".",
      "nodes": [
        {
          "content": "<ph id=\"ph35\">[AZURE.NOTE]</ph><ph id=\"ph36\"/> To use the tweets and the HiveQL script you uploaded in the last two sections, set $hqlScriptFile to \"/tutorials/twitter/twitter.hql\".",
          "pos": [
            0,
            181
          ]
        },
        {
          "content": "To use the ones that have been uploaded to a public blob for you, set $hqlScriptFile to \"wasb://twittertrend@hditutorialdata.blob.core.windows.net/twitter.hql\".",
          "pos": [
            182,
            342
          ]
        }
      ]
    },
    {
      "pos": [
        28170,
        28187
      ],
      "content": "Check the results"
    },
    {
      "pos": [
        28189,
        28308
      ],
      "content": "Use the following Windows PowerShell script to check the Hive job output. You will need to set the first two variables.",
      "nodes": [
        {
          "content": "Use the following Windows PowerShell script to check the Hive job output.",
          "pos": [
            0,
            73
          ]
        },
        {
          "content": "You will need to set the first two variables.",
          "pos": [
            74,
            119
          ]
        }
      ]
    },
    {
      "pos": [
        30056,
        30161
      ],
      "content": "<ph id=\"ph37\">[AZURE.NOTE]</ph><ph id=\"ph38\"/> The Hive table uses \\001 as the field delimiter. The delimiter is not visible in the output.",
      "nodes": [
        {
          "content": "<ph id=\"ph37\">[AZURE.NOTE]</ph><ph id=\"ph38\"/> The Hive table uses \\001 as the field delimiter.",
          "pos": [
            0,
            95
          ]
        },
        {
          "content": "The delimiter is not visible in the output.",
          "pos": [
            96,
            139
          ]
        }
      ]
    },
    {
      "pos": [
        30163,
        30726
      ],
      "content": "After the analysis results have been placed in Azure Blob storage, you can export the data to an Azure SQL database/SQL server, export the data to Excel by using Power Query, or connect your application to the data by using the Hive ODBC Driver. For more information, see <bpt id=\"p65\">[</bpt>Use Sqoop with HDInsight<ept id=\"p65\">][hdinsight-use-sqoop]</ept>, <bpt id=\"p66\">[</bpt>Analyze flight delay data using HDInsight<ept id=\"p66\">][hdinsight-analyze-flight-delay-data]</ept>, <bpt id=\"p67\">[</bpt>Connect Excel to HDInsight with Power Query<ept id=\"p67\">][hdinsight-power-query]</ept>, and <bpt id=\"p68\">[</bpt>Connect Excel to HDInsight with the Microsoft Hive ODBC Driver<ept id=\"p68\">][hdinsight-hive-odbc]</ept>.",
      "nodes": [
        {
          "content": "After the analysis results have been placed in Azure Blob storage, you can export the data to an Azure SQL database/SQL server, export the data to Excel by using Power Query, or connect your application to the data by using the Hive ODBC Driver.",
          "pos": [
            0,
            245
          ]
        },
        {
          "content": "For more information, see <bpt id=\"p65\">[</bpt>Use Sqoop with HDInsight<ept id=\"p65\">][hdinsight-use-sqoop]</ept>, <bpt id=\"p66\">[</bpt>Analyze flight delay data using HDInsight<ept id=\"p66\">][hdinsight-analyze-flight-delay-data]</ept>, <bpt id=\"p67\">[</bpt>Connect Excel to HDInsight with Power Query<ept id=\"p67\">][hdinsight-power-query]</ept>, and <bpt id=\"p68\">[</bpt>Connect Excel to HDInsight with the Microsoft Hive ODBC Driver<ept id=\"p68\">][hdinsight-hive-odbc]</ept>.",
          "pos": [
            246,
            723
          ]
        }
      ]
    },
    {
      "pos": [
        30730,
        30740
      ],
      "content": "Next steps"
    },
    {
      "pos": [
        30742,
        30944
      ],
      "content": "In this tutorial we have seen how to transform an unstructured JSON dataset into a structured Hive table to query, explore, and analyze data from Twitter by using HDInsight on Azure. To learn more, see:",
      "nodes": [
        {
          "content": "In this tutorial we have seen how to transform an unstructured JSON dataset into a structured Hive table to query, explore, and analyze data from Twitter by using HDInsight on Azure.",
          "pos": [
            0,
            182
          ]
        },
        {
          "content": "To learn more, see:",
          "pos": [
            183,
            202
          ]
        }
      ]
    },
    {
      "pos": [
        30948,
        30999
      ],
      "content": "<bpt id=\"p69\">[</bpt>Get started with HDInsight<ept id=\"p69\">][hdinsight-get-started]</ept>"
    },
    {
      "pos": [
        31002,
        31098
      ],
      "content": "<bpt id=\"p70\">[</bpt>Analyze real-time Twitter sentiment with HBase in HDInsight<ept id=\"p70\">][hdinsight-hbase-twitter-sentiment]</ept>"
    },
    {
      "pos": [
        31101,
        31181
      ],
      "content": "<bpt id=\"p71\">[</bpt>Analyze flight delay data using HDInsight<ept id=\"p71\">][hdinsight-analyze-flight-delay-data]</ept>"
    },
    {
      "pos": [
        31184,
        31252
      ],
      "content": "<bpt id=\"p72\">[</bpt>Connect Excel to HDInsight with Power Query<ept id=\"p72\">][hdinsight-power-query]</ept>"
    },
    {
      "pos": [
        31255,
        31340
      ],
      "content": "<bpt id=\"p73\">[</bpt>Connect Excel to HDInsight with the Microsoft Hive ODBC Driver<ept id=\"p73\">][hdinsight-hive-odbc]</ept>"
    },
    {
      "pos": [
        31343,
        31390
      ],
      "content": "<bpt id=\"p74\">[</bpt>Use Sqoop with HDInsight<ept id=\"p74\">][hdinsight-use-sqoop]</ept>"
    }
  ],
  "content": "<properties\n    pageTitle=\"Analyze Twitter data with Hadoop in HDInsight | Microsoft Azure\"\n    description=\"Learn how to use Hive to analyze Twitter data on Hadoop in HDInsight to find the usage frequency of a particular word.\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    authors=\"mumian\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.workload=\"big-data\"\n    ms.tgt_pltfrm=\"na\"\n    ms.devlang=\"na\"\n    ms.topic=\"article\"\n    ms.date=\"12/02/2015\"\n    ms.author=\"jgao\"/>\n\n# Analyze Twitter data using Hive in HDInsight\n\nSocial websites are one of the major driving forces for big-data adoption. Public APIs provided \nby sites like Twitter are a useful source of data for analyzing and understanding popular trends. \nIn this tutorial, you will get tweets by using a Twitter streaming API, and then use Apache Hive \non Azure HDInsight to get a list of Twitter users who sent the most tweets that contained a certain word.\n\n> [AZURE.NOTE] The steps in this document require a Windows-based HDInsight cluster. For steps specific \nto a Linux-based cluster, see [Analyze Twitter data using Hive in HDInsight (Linux)](hdinsight-analyze-twitter-data-linux.md).\n\n\n\n> [AZURE.TIP] A similar sample is in the HDInsight Sample Gallery. Watch the Channel 9 video: <a href=\"http://channel9.msdn.com/Series/Getting-started-with-Windows-Azure-HDInsight-Service/Analyze-Twitter-trend-using-Apache-Hive-in-HDInsight\" target=\"_blank\">Analyze Twitter trends using Apache Hive in HDInsight</a>.\n\n###Prerequisites\n\nBefore you begin this tutorial, you must have the following:\n\n- **A workstation** with Azure PowerShell installed and configured. See [Install and use Azure PowerShell](https://azure.microsoft.com/documentation/videos/install-and-use-azure-powershell/). To execute Windows PowerShell scripts, you must run Azure PowerShell as administrator and set the execution policy to *RemoteSigned*. See [Run Windows PowerShell scripts][powershell-script].\n\n    Before running Windows PowerShell scripts, make sure you are connected to your Azure subscription by using the following cmdlet:\n\n        Login-AzureRmAccount\n\n    If you have multiple Azure subscriptions, use the following cmdlet to set the current subscription:\n\n        Select-AzureRmSubscription -SubscriptionID <Azure Subscription ID>\n\n\n- **An Azure HDInsight cluster**. For instructions on cluster provisioning, see [Get started using HDInsight][hdinsight-get-started] or [Provision HDInsight clusters] [hdinsight-provision]. You will need the cluster name later in the tutorial.\n\nThe following table lists the files used in this tutorial:\n\nFiles|Description\n---|---\n/tutorials/twitter/data/tweets.txt|The source data for the Hive job.\n/tutorials/twitter/output|The output folder for the Hive job. The default Hive job output file name is **000000_0**.\ntutorials/twitter/twitter.hql|The HiveQL script file.\n/tutorials/twitter/jobstatus|The Hadoop job status.\n\n\n##Get Twitter feed\n\nIn this tutorial, you will use the [Twitter streaming APIs][twitter-streaming-api]. The specific Twitter streaming API you will use is [statuses/filter][twitter-statuses-filter].\n\n>[AZURE.NOTE] A file containing 10,000 tweets and the Hive script file (covered in the next section) have been uploaded in a public Blob container. You can skip this section if you want to use the uploaded files.\n\n[Tweets data](https://dev.twitter.com/docs/platform-objects/tweets) is stored in the JavaScript Object Notation (JSON) format that contains a complex nested structure. Instead of writing many lines of code by using a conventional programming language, you can transform this nested structure into a Hive table, so that it can be queried by a Structured Query Language (SQL)-like language called HiveQL.\n\nTwitter uses OAuth to provide authorized access to its API. OAuth is an authentication protocol that allows users to approve applications to act on their behalf without sharing their password. More information can be found at [oauth.net](http://oauth.net/) or in the excellent [Beginner's Guide to OAuth](http://hueniverse.com/oauth/) from Hueniverse.\n\nThe first step to use OAuth is to create a new application on the Twitter Developer site.\n\n**To create a Twitter application**\n\n1. Sign in to [https://apps.twitter.com/](https://apps.twitter.com/). Click the **Sign up now** link if you don't have a Twitter account.\n2. Click **Create New App**.\n3. Enter **Name**, **Description**, **Website**. You can make up a URL for the **Website** field. The following table shows some sample values to use:\n\nField|Value\n---|---\nName|MyHDInsightApp\nDescription|MyHDInsightApp\nWebsite|http://www.myhdinsightapp.com\n\n4. Check **Yes, I agree**, and then click **Create your Twitter application**.\n5. Click the **Permissions** tab. The default permission is **Read only**. This is sufficient for this tutorial.\n6. Click the **Keys and Access Tokens** tab.\n7. Click **Create my access token**.\n8. Click **Test OAuth** in the upper-right corner of the page.\n9. Write down **consumer key**, **Consumer secret**, **Access token**, and **Access token secret**. You will need the values later in the tutorial.\n\nIn this tutorial, you will use Windows PowerShell to make the web service call. For a .NET C# sample, see [Analyze real-time Twitter sentiment with HBase in HDInsight][hdinsight-hbase-twitter-sentiment]. The other popular tool to make web service calls is [*Curl*][curl]. Curl can be downloaded from [here][curl-download].\n\n>[AZURE.NOTE] When you use the curl command in Windows, use double quotes instead of single quotes for the option values.\n\n**To get tweets**\n\n1. Open the Windows PowerShell Integrated Scripting Environment (ISE). (On the Windows 8 Start screen, type **PowerShell_ISE** and then click **Windows PowerShell ISE**. See [Start Windows PowerShell on Windows 8 and Windows][powershell-start].)\n\n2. Copy the following script into the script pane:\n\n        #region - variables and constants\n        $clusterName = \"<HDInsightClusterName>\" # Enter the HDInsight cluster name\n\n        # Enter the OAuth information for your Twitter application\n        $oauth_consumer_key = \"<TwitterAppConsumerKey>\";\n        $oauth_consumer_secret = \"<TwitterAppConsumerSecret>\";\n        $oauth_token = \"<TwitterAppAccessToken>\";\n        $oauth_token_secret = \"<TwitterAppAccessTokenSecret>\";\n\n        $destBlobName = \"tutorials/twitter/data/tweets.txt\" # This script saves the tweets into this blob.\n\n        $trackString = \"Azure, Cloud, HDInsight\" # This script gets the tweets containing these keywords.\n        $track = [System.Uri]::EscapeDataString($trackString);\n        $lineMax = 10000  # The script will get this number of tweets. It is about 3 minutes every 100 lines.\n        #endregion\n\n        #region - Connect to Azure subscription\n        Write-Host \"`nConnecting to your Azure subscription ...\" -ForegroundColor Green\n        Add-AzureAccount\n        #endregion\n\n        #region - Create a block blob object for writing tweets into Blob storage\n        Write-Host \"Get the default storage account name and Blob container name using the cluster name ...\" -ForegroundColor Green\n        $myCluster = Get-AzureRmHDInsightCluster -Name $clusterName\n        $resourceGroupName = $myCluster.ResourceGroup\n        $storageAccountName = $myCluster.DefaultStorageAccount.Replace(\".blob.core.windows.net\", \"\")\n        $containerName = $myCluster.DefaultStorageContainer\n        Write-Host \"`tThe storage account name is $storageAccountName.\" -ForegroundColor Yellow\n        Write-Host \"`tThe blob container name is $containerName.\" -ForegroundColor Yellow\n\n        Write-Host \"Define the Azure storage connection string ...\" -ForegroundColor Green\n        $storageAccountKey = Get-AzureRmStorageAccountKey -ResourceGroupName $resourceGroupName -Name $storageAccountName |  %{ $_.Key1 }\n        $storageConnectionString = \"DefaultEndpointsProtocol=https;AccountName=$storageAccountName;AccountKey=$storageAccountKey\"\n        Write-Host \"`tThe connection string is $storageConnectionString.\" -ForegroundColor Yellow\n\n        Write-Host \"Create block blob object ...\" -ForegroundColor Green\n        $storageAccount = [Microsoft.WindowsAzure.Storage.CloudStorageAccount]::Parse($storageConnectionString)\n        $storageClient = $storageAccount.CreateCloudBlobClient();\n        $storageContainer = $storageClient.GetContainerReference($containerName)\n        $destBlob = $storageContainer.GetBlockBlobReference($destBlobName)\n        #end region\n\n        # region - Format OAuth strings\n        Write-Host \"Format oauth strings ...\" -ForegroundColor Green\n        $oauth_nonce = [System.Convert]::ToBase64String([System.Text.Encoding]::ASCII.GetBytes([System.DateTime]::Now.Ticks.ToString()));\n        $ts = [System.DateTime]::UtcNow - [System.DateTime]::ParseExact(\"01/01/1970\", \"dd/MM/yyyy\", $null)\n        $oauth_timestamp = [System.Convert]::ToInt64($ts.TotalSeconds).ToString();\n\n        $signature = \"POST&\";\n        $signature += [System.Uri]::EscapeDataString(\"https://stream.twitter.com/1.1/statuses/filter.json\") + \"&\";\n        $signature += [System.Uri]::EscapeDataString(\"oauth_consumer_key=\" + $oauth_consumer_key + \"&\");\n        $signature += [System.Uri]::EscapeDataString(\"oauth_nonce=\" + $oauth_nonce + \"&\");\n        $signature += [System.Uri]::EscapeDataString(\"oauth_signature_method=HMAC-SHA1&\");\n        $signature += [System.Uri]::EscapeDataString(\"oauth_timestamp=\" + $oauth_timestamp + \"&\");\n        $signature += [System.Uri]::EscapeDataString(\"oauth_token=\" + $oauth_token + \"&\");\n        $signature += [System.Uri]::EscapeDataString(\"oauth_version=1.0&\");\n        $signature += [System.Uri]::EscapeDataString(\"track=\" + $track);\n\n        $signature_key = [System.Uri]::EscapeDataString($oauth_consumer_secret) + \"&\" + [System.Uri]::EscapeDataString($oauth_token_secret);\n\n        $hmacsha1 = new-object System.Security.Cryptography.HMACSHA1;\n        $hmacsha1.Key = [System.Text.Encoding]::ASCII.GetBytes($signature_key);\n        $oauth_signature = [System.Convert]::ToBase64String($hmacsha1.ComputeHash([System.Text.Encoding]::ASCII.GetBytes($signature)));\n\n        $oauth_authorization = 'OAuth ';\n        $oauth_authorization += 'oauth_consumer_key=\"' + [System.Uri]::EscapeDataString($oauth_consumer_key) + '\",';\n        $oauth_authorization += 'oauth_nonce=\"' + [System.Uri]::EscapeDataString($oauth_nonce) + '\",';\n        $oauth_authorization += 'oauth_signature=\"' + [System.Uri]::EscapeDataString($oauth_signature) + '\",';\n        $oauth_authorization += 'oauth_signature_method=\"HMAC-SHA1\",'\n        $oauth_authorization += 'oauth_timestamp=\"' + [System.Uri]::EscapeDataString($oauth_timestamp) + '\",'\n        $oauth_authorization += 'oauth_token=\"' + [System.Uri]::EscapeDataString($oauth_token) + '\",';\n        $oauth_authorization += 'oauth_version=\"1.0\"';\n\n        $post_body = [System.Text.Encoding]::ASCII.GetBytes(\"track=\" + $track);\n        #endregion\n\n        #region - Read tweets\n        Write-Host \"Create HTTP web request ...\" -ForegroundColor Green\n        [System.Net.HttpWebRequest] $request = [System.Net.WebRequest]::Create(\"https://stream.twitter.com/1.1/statuses/filter.json\");\n        $request.Method = \"POST\";\n        $request.Headers.Add(\"Authorization\", $oauth_authorization);\n        $request.ContentType = \"application/x-www-form-urlencoded\";\n        $body = $request.GetRequestStream();\n\n        $body.write($post_body, 0, $post_body.length);\n        $body.flush();\n        $body.close();\n        $response = $request.GetResponse() ;\n\n        Write-Host \"Start stream reading ...\" -ForegroundColor Green\n\n        Write-Host \"Define a MemoryStream and a StreamWriter for writing ...\" -ForegroundColor Green\n        $memStream = New-Object System.IO.MemoryStream\n        $writeStream = New-Object System.IO.StreamWriter $memStream\n\n        $sReader = New-Object System.IO.StreamReader($response.GetResponseStream())\n\n        $inrec = $sReader.ReadLine()\n        $count = 0\n        while (($inrec -ne $null) -and ($count -le $lineMax))\n        {\n            if ($inrec -ne \"\")\n            {\n                Write-Host \"`n`t $count tweets received.\" -ForegroundColor Yellow\n\n                $writeStream.WriteLine($inrec)\n                $count ++\n            }\n\n            $inrec=$sReader.ReadLine()\n        }\n        #endregion\n\n        #region - Write tweets to Blob storage\n        Write-Host \"Write to the destination blob ...\" -ForegroundColor Green\n        $writeStream.Flush()\n        $memStream.Seek(0, \"Begin\")\n        $destBlob.UploadFromStream($memStream)\n\n        $sReader.close()\n        #endregion\n\n        Write-Host \"Completed!\" -ForegroundColor Green\n\n3. Set the first five to eight variables in the script:\n\n\nVariable|Description\n---|---\n$clusterName|This is the name of the HDInsight cluster where you want to run the application.\n$oauth_consumer_key|This is the Twitter application **consumer key** you wrote down earlier when you created the Twitter application.\n$oauth_consumer_secret|This is the Twitter application **consumer secret** you wrote down earlier.\n$oauth_token|This is the Twitter application **access token** you wrote down earlier.\n$oauth_token_secret|This is the Twitter application **access token secret** you wrote down earlier.\n$destBlobName|This is the output blob name. The default value is **tutorials/twitter/data/tweets.txt**. If you change the default value, you will need to update the Windows PowerShell scripts accordingly.\n$trackString|The web service will return tweets related to these keywords. The default value is **Azure, Cloud, HDInsight**. If you change the default value, you will update the Windows PowerShell scripts accordingly.\n$lineMax|The value determines how many tweets the script will read. It takes about three minutes to read 100 tweets. You can set a larger number, but it will take more time to download.\n\n5. Press **F5** to run the script. If you run into problems, as a workaround, select all the lines, and then press **F8**.\n6. You shall see \"Complete!\" at the end of the output. Any error messages will be displayed in red.\n\nAs a validation procedure, you can check the output file, **/tutorials/twitter/data/tweets.txt**, on your Azure Blob storage by using an Azure storage explorer or Azure PowerShell. For a sample Windows PowerShell script for listing files, see [Use Blob storage with HDInsight][hdinsight-storage-powershell].\n\n\n\n##Create HiveQL script\n\nUsing Azure PowerShell, you can run multiple HiveQL statements one at a time, or package the HiveQL statement into a script file. In this tutorial, you will create a HiveQL script. The script file must be uploaded to Azure Blob storage. In the next section, you will run the script file by using Azure PowerShell.\n\n>[AZURE.NOTE] The Hive script file and a file containing 10,000 tweets have been uploaded in a public Blob container. You can skip this section if you want to use the uploaded files.\n\nThe HiveQL script will perform the following:\n\n1. **Drop the tweets_raw table** in case the table already exists.\n2. **Create the tweets_raw Hive table**. This temporary Hive structured table holds the data for further extract, transform, and load (ETL) processing. For information on partitions, see [Hive tutorial][apache-hive-tutorial].  \n3. **Load data** from the source folder, /tutorials/twitter/data. The large tweets dataset in nested JSON format has now been transformed into a temporary Hive table structure.\n3. **Drop the tweets table** in case the table already exists.\n4. **Create the tweets table**. Before you can query against the tweets dataset by using Hive, you need to run another ETL process. This ETL process defines a more detailed table schema for the data that you have stored in the \"twitter_raw\" table.  \n5. **Insert overwrite table**. This complex Hive script will kick off a set of long MapReduce jobs by the Hadoop cluster. Depending on your dataset and the size of your cluster, this could take about 10 minutes.\n6. **Insert overwrite directory**. Run a query and output the dataset to a file. This query will return a list of Twitter users who sent most tweets that contained the word \"Azure\".\n\n**To create a Hive script and upload it to Azure**\n\n1. Open Windows PowerShell ISE.\n2. Copy the following script into the script pane:\n\n        #region - variables and constants\n        $clusterName = \"<Existing HDInsight Cluster Name>\" # Enter your HDInsight cluster name\n        $subscriptionID = \"<Azure Subscription ID>\"\n        \n        $sourceDataPath = \"/tutorials/twitter/data\"\n        $outputPath = \"/tutorials/twitter/output\"\n        $hqlScriptFile = \"tutorials/twitter/twitter.hql\"\n        \n        $hqlStatements = @\"\n        set hive.exec.dynamic.partition = true;\n        set hive.exec.dynamic.partition.mode = nonstrict;\n        \n        DROP TABLE tweets_raw;\n        CREATE EXTERNAL TABLE tweets_raw (\n            json_response STRING\n        )\n        STORED AS TEXTFILE LOCATION '$sourceDataPath';\n        \n        DROP TABLE tweets;\n        CREATE TABLE tweets\n        (\n            id BIGINT,\n            created_at STRING,\n            created_at_date STRING,\n            created_at_year STRING,\n            created_at_month STRING,\n            created_at_day STRING,\n            created_at_time STRING,\n            in_reply_to_user_id_str STRING,\n            text STRING,\n            contributors STRING,\n            retweeted STRING,\n            truncated STRING,\n            coordinates STRING,\n            source STRING,\n            retweet_count INT,\n            url STRING,\n            hashtags array<STRING>,\n            user_mentions array<STRING>,\n            first_hashtag STRING,\n            first_user_mention STRING,\n            screen_name STRING,\n            name STRING,\n            followers_count INT,\n            listed_count INT,\n            friends_count INT,\n            lang STRING,\n            user_location STRING,\n            time_zone STRING,\n            profile_image_url STRING,\n            json_response STRING\n        );\n        \n        FROM tweets_raw\n        INSERT OVERWRITE TABLE tweets\n        SELECT\n            cast(get_json_object(json_response, '$.id_str') as BIGINT),\n            get_json_object(json_response, '$.created_at'),\n            concat(substr (get_json_object(json_response, '$.created_at'),1,10),' ',\n            substr (get_json_object(json_response, '$.created_at'),27,4)),\n            substr (get_json_object(json_response, '$.created_at'),27,4),\n            case substr (get_json_object(json_response, '$.created_at'),5,3)\n                when \"Jan\" then \"01\"\n                when \"Feb\" then \"02\"\n                when \"Mar\" then \"03\"\n                when \"Apr\" then \"04\"\n                when \"May\" then \"05\"\n                when \"Jun\" then \"06\"\n                when \"Jul\" then \"07\"\n                when \"Aug\" then \"08\"\n                when \"Sep\" then \"09\"\n                when \"Oct\" then \"10\"\n                when \"Nov\" then \"11\"\n                when \"Dec\" then \"12\" end,\n            substr (get_json_object(json_response, '$.created_at'),9,2),\n            substr (get_json_object(json_response, '$.created_at'),12,8),\n            get_json_object(json_response, '$.in_reply_to_user_id_str'),\n            get_json_object(json_response, '$.text'),\n            get_json_object(json_response, '$.contributors'),\n            get_json_object(json_response, '$.retweeted'),\n            get_json_object(json_response, '$.truncated'),\n            get_json_object(json_response, '$.coordinates'),\n            get_json_object(json_response, '$.source'),\n            cast (get_json_object(json_response, '$.retweet_count') as INT),\n            get_json_object(json_response, '$.entities.display_url'),\n            array(\n                trim(lower(get_json_object(json_response, '$.entities.hashtags[0].text'))),\n                trim(lower(get_json_object(json_response, '$.entities.hashtags[1].text'))),\n                trim(lower(get_json_object(json_response, '$.entities.hashtags[2].text'))),\n                trim(lower(get_json_object(json_response, '$.entities.hashtags[3].text'))),\n                trim(lower(get_json_object(json_response, '$.entities.hashtags[4].text')))),\n            array(\n                trim(lower(get_json_object(json_response, '$.entities.user_mentions[0].screen_name'))),\n                trim(lower(get_json_object(json_response, '$.entities.user_mentions[1].screen_name'))),\n                trim(lower(get_json_object(json_response, '$.entities.user_mentions[2].screen_name'))),\n                trim(lower(get_json_object(json_response, '$.entities.user_mentions[3].screen_name'))),\n                trim(lower(get_json_object(json_response, '$.entities.user_mentions[4].screen_name')))),\n            trim(lower(get_json_object(json_response, '$.entities.hashtags[0].text'))),\n            trim(lower(get_json_object(json_response, '$.entities.user_mentions[0].screen_name'))),\n            get_json_object(json_response, '$.user.screen_name'),\n            get_json_object(json_response, '$.user.name'),\n            cast (get_json_object(json_response, '$.user.followers_count') as INT),\n            cast (get_json_object(json_response, '$.user.listed_count') as INT),\n            cast (get_json_object(json_response, '$.user.friends_count') as INT),\n            get_json_object(json_response, '$.user.lang'),\n            get_json_object(json_response, '$.user.location'),\n            get_json_object(json_response, '$.user.time_zone'),\n            get_json_object(json_response, '$.user.profile_image_url'),\n            json_response\n        WHERE (length(json_response) > 500);\n        \n        INSERT OVERWRITE DIRECTORY '$outputPath'\n        SELECT name, screen_name, count(1) as cc\n            FROM tweets\n            WHERE text like \"%Azure%\"\n            GROUP BY name,screen_name\n            ORDER BY cc DESC LIMIT 10;\n        \"@\n        #endregion\n        \n        #region - Connect to Azure subscription\n        Write-Host \"`nConnecting to your Azure subscription ...\" -ForegroundColor Green\n        \n        Try{\n            Get-AzureRmSubscription\n        }\n        Catch{\n            Login-AzureRmAccount\n        }\n        \n        Select-AzureRmSubscription -SubscriptionId $subscriptionID\n        \n        #endregion\n        \n        #region - Create a block blob object for writing the Hive script file\n        Write-Host \"Get the default storage account name and container name based on the cluster name ...\" -ForegroundColor Green\n        $myCluster = Get-AzureRmHDInsightCluster -ClusterName $clusterName\n        $resourceGroupName = $myCluster.ResourceGroup\n        $defaultStorageAccountName = $myCluster.DefaultStorageAccount.Replace(\".blob.core.windows.net\", \"\")\n        $defaultBlobContainerName = $myCluster.DefaultStorageContainer\n        Write-Host \"`tThe storage account name is $defaultStorageAccountName.\" -ForegroundColor Yellow\n        Write-Host \"`tThe blob container name is $defaultBlobContainerName.\" -ForegroundColor Yellow\n        \n        Write-Host \"Define the connection string ...\" -ForegroundColor Green\n        $defaultStorageAccountKey = Get-AzureRmStorageAccountKey -ResourceGroupName $resourceGroupName -Name $defaultStorageAccountName | %{$_.key1}\n        $storageConnectionString = \"DefaultEndpointsProtocol=https;AccountName=$defaultStorageAccountName;AccountKey=$defaultStorageAccountKey\"\n        \n        Write-Host \"Create block blob objects referencing the hql script file\" -ForegroundColor Green\n        $storageAccount = [Microsoft.WindowsAzure.Storage.CloudStorageAccount]::Parse($storageConnectionString)\n        $storageClient = $storageAccount.CreateCloudBlobClient();\n        $storageContainer = $storageClient.GetContainerReference($defaultBlobContainerName)\n        $hqlScriptBlob = $storageContainer.GetBlockBlobReference($hqlScriptFile)\n        \n        Write-Host \"Define a MemoryStream and a StreamWriter for writing ... \" -ForegroundColor Green\n        $memStream = New-Object System.IO.MemoryStream\n        $writeStream = New-Object System.IO.StreamWriter $memStream\n        $writeStream.Writeline($hqlStatements)\n        #endregion\n        \n        #region - Write the Hive script file to Blob storage\n        Write-Host \"Write to the destination blob ... \" -ForegroundColor Green\n        $writeStream.Flush()\n        $memStream.Seek(0, \"Begin\")\n        $hqlScriptBlob.UploadFromStream($memStream)\n        #endregion\n        \n        Write-Host \"Completed!\" -ForegroundColor Green\n\n        \n\n4. Set the first two variables in the script:\n\nVariable|Description\n---|---\n$clusterName|Enter the HDInsight cluster name where you want to run the application.\n$subscriptionID|Enter your Azure subscription ID.\n$sourceDataPath|The Azure Blob storage location where the Hive queries will read the data from. You don't need to change this variable.\n$outputPath|The Azure Blob storage location where the Hive queries will output the results. You don't need to change this variable.\n$hqlScriptFile|The location and the file name of the HiveQL script file. You don't need to change this variable.\n\n5. Press **F5** to run the script. If you run into problems, as a workaround, select all the lines, and then press **F8**.\n6. You shall see \"Complete!\" at the end of the output. Any error messages will be displayed in red.\n\nAs a validation procedure, you can check the output file, **/tutorials/twitter/twitter.hql**, on your Azure Blob storage by using an Azure storage explorer or Azure PowerShell. For a sample Windows PowerShell script for listing files, see [Use Blob storage with HDInsight][hdinsight-storage-powershell].  \n\n\n##Process Twitter data by using Hive\n\nYou have finished all the preparation work. Now, you can invoke the Hive script and check the results.\n\n### Submit a Hive job\n\nUse the following Windows PowerShell script to run the Hive script. You will need to set the first variable.\n\n>[AZURE.NOTE] To use the tweets and the HiveQL script you uploaded in the last two sections, set $hqlScriptFile to \"/tutorials/twitter/twitter.hql\". To use the ones that have been uploaded to a public blob for you, set $hqlScriptFile to \"wasb://twittertrend@hditutorialdata.blob.core.windows.net/twitter.hql\".\n\n    #region variables and constants\n    $clusterName = \"<Existing Azure HDInsight Cluster Name>\"\n    $httpUserName = \"admin\"\n    $httpUserPassword = \"<HDInsight Cluster HTTP User Password>\"\n    \n    #use one of the following\n    $hqlScriptFile = \"wasbs://twittertrend@hditutorialdata.blob.core.windows.net/twitter.hql\"\n    $hqlScriptFile = \"/tutorials/twitter/twitter.hql\"\n    \n    $statusFolder = \"/tutorials/twitter/jobstatus\"\n    #endregion\n    \n    $myCluster = Get-AzureRmHDInsightCluster -ClusterName $clusterName\n    $resourceGroupName = $myCluster.ResourceGroup\n    $defaultStorageAccountName = $myCluster.DefaultStorageAccount.Replace(\".blob.core.windows.net\", \"\")\n    $defaultStorageAccountKey = Get-AzureRmStorageAccountKey -ResourceGroupName $resourceGroupName -Name $defaultStorageAccountName |  %{ $_.Key1 }\n    \n    $defaultBlobContainerName = $myCluster.DefaultStorageContainer\n    \n    \n    #region - Invoke Hive\n    Write-Host \"Invoke Hive ... \" -ForegroundColor Green\n    \n    # Create the HDInsight cluster\n    $pw = ConvertTo-SecureString -String $httpUserPassword -AsPlainText -Force\n    $httpCredential = New-Object System.Management.Automation.PSCredential($httpUserName,$pw)\n    \n    Use-AzureRmHDInsightCluster -ResourceGroupName $resourceGroupName -ClusterName $clusterName -HttpCredential $httpCredential \n    $response = Invoke-AzureRmHDInsightHiveJob -DefaultStorageAccountName $defaultStorageAccountName -DefaultStorageAccountKey $defaultStorageAccountKey -DefaultContainer $defaultBlobContainerName -file $hqlScriptFile -StatusFolder $statusFolder #-OutVariable $outVariable\n    \n    Write-Host \"Display the standard error log ... \" -ForegroundColor Green\n    $jobID = ($response | Select-String job_ | Select-Object -First 1) -replace \\s*$ -replace .*\\s\n    Get-AzureRmHDInsightJobOutput -ClusterName $clusterName -JobId $jobID -StandardError\n    #endregion\n\n### Check the results\n\nUse the following Windows PowerShell script to check the Hive job output. You will need to set the first two variables.\n\n    #region variables and constants\n    $clusterName = \"<Existing Azure HDInsight Cluster Name>\"\n    \n    $blob = \"tutorials/twitter/output/000000_0\" # The name of the blob to be downloaded.\n    #engregion\n    \n    #region - Create an Azure storage context object\n    Write-Host \"Get the default storage account name and container name based on the cluster name ...\" -ForegroundColor Green\n    $myCluster = Get-AzureRmHDInsightCluster -ClusterName $clusterName\n    $resourceGroupName = $myCluster.ResourceGroup\n    $defaultStorageAccountName = $myCluster.DefaultStorageAccount.Replace(\".blob.core.windows.net\", \"\")\n    $defaultStorageAccountKey = Get-AzureRmStorageAccountKey -ResourceGroupName $resourceGroupName -Name $defaultStorageAccountName |  %{ $_.Key1 }\n    $defaultBlobContainerName = $myCluster.DefaultStorageContainer\n    \n    Write-Host \"`tThe storage account name is $defaultStorageAccountName.\" -ForegroundColor Yellow\n    Write-Host \"`tThe blob container name is $defaultBlobContainerName.\" -ForegroundColor Yellow\n    \n    Write-Host \"Create a context object ... \" -ForegroundColor Green\n    $storageContext = New-AzureStorageContext -StorageAccountName $defaultStorageAccountName -StorageAccountKey $storageAccountKey  \n    #endregion\n    \n    #region - Download blob and display blob\n    Write-Host \"Download the blob ...\" -ForegroundColor Green\n    cd $HOME\n    Get-AzureStorageBlobContent -Container $defaultBlobContainerName -Blob $blob -Context $storageContext -Force\n    \n    Write-Host \"Display the output ...\" -ForegroundColor Green\n    Write-Host \"==================================\" -ForegroundColor Green\n    cat \"./$blob\"\n    Write-Host \"==================================\" -ForegroundColor Green\n    #end region\n\n> [AZURE.NOTE] The Hive table uses \\001 as the field delimiter. The delimiter is not visible in the output.\n\nAfter the analysis results have been placed in Azure Blob storage, you can export the data to an Azure SQL database/SQL server, export the data to Excel by using Power Query, or connect your application to the data by using the Hive ODBC Driver. For more information, see [Use Sqoop with HDInsight][hdinsight-use-sqoop], [Analyze flight delay data using HDInsight][hdinsight-analyze-flight-delay-data], [Connect Excel to HDInsight with Power Query][hdinsight-power-query], and [Connect Excel to HDInsight with the Microsoft Hive ODBC Driver][hdinsight-hive-odbc].\n\n##Next steps\n\nIn this tutorial we have seen how to transform an unstructured JSON dataset into a structured Hive table to query, explore, and analyze data from Twitter by using HDInsight on Azure. To learn more, see:\n\n- [Get started with HDInsight][hdinsight-get-started]\n- [Analyze real-time Twitter sentiment with HBase in HDInsight][hdinsight-hbase-twitter-sentiment]\n- [Analyze flight delay data using HDInsight][hdinsight-analyze-flight-delay-data]\n- [Connect Excel to HDInsight with Power Query][hdinsight-power-query]\n- [Connect Excel to HDInsight with the Microsoft Hive ODBC Driver][hdinsight-hive-odbc]\n- [Use Sqoop with HDInsight][hdinsight-use-sqoop]\n\n[curl]: http://curl.haxx.se\n[curl-download]: http://curl.haxx.se/download.html\n\n[apache-hive-tutorial]: https://cwiki.apache.org/confluence/display/Hive/Tutorial\n\n[twitter-streaming-api]: https://dev.twitter.com/docs/streaming-apis\n[twitter-statuses-filter]: https://dev.twitter.com/docs/api/1.1/post/statuses/filter\n\n[powershell-start]: http://technet.microsoft.com/library/hh847889.aspx\n[powershell-install]: powershell-install-configure.md\n[powershell-script]: http://technet.microsoft.com/library/ee176961.aspx\n\n\n[hdinsight-provision]: hdinsight-provision-clusters.md\n[hdinsight-get-started]: hdinsight-hadoop-linux-tutorial-get-started.md\n[hdinsight-storage-powershell]: ../hdinsight-hadoop-use-blob-storage.md#powershell\n[hdinsight-analyze-flight-delay-data]: hdinsight-analyze-flight-delay-data.md\n[hdinsight-storage]: ../hdinsight-hadoop-use-blob-storage.md\n[hdinsight-use-sqoop]: hdinsight-use-sqoop.md\n[hdinsight-power-query]: hdinsight-connect-excel-power-query.md\n[hdinsight-hive-odbc]: hdinsight-connect-excel-hive-ODBC-driver.md\n[hdinsight-hbase-twitter-sentiment]: hdinsight-hbase-analyze-twitter-sentiment.md\n"
}