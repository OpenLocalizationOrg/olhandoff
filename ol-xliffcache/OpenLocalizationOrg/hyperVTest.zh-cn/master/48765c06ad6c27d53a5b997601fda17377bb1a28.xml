{
  "nodes": [
    {
      "pos": [
        28,
        86
      ],
      "content": "An overview of Apache Spark in HDInsight | Microsoft Azure"
    },
    {
      "pos": [
        106,
        221
      ],
      "content": "An introduction to Apache Spark in HDInsight and scenarios in which to use Spark on HDInsight in your applications."
    },
    {
      "pos": [
        561,
        610
      ],
      "content": "Overview: Apache Spark on Azure HDInsight (Linux)"
    },
    {
      "pos": [
        664,
        676
      ],
      "content": "Apache Spark"
    },
    {
      "pos": [
        681,
        1172
      ],
      "content": "is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications. Spark processing engine is built for speed, ease of use, and sophisticated analytics. Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations. Spark is also compatible with Azure Blob storage (WASB) so your existing data stored in Azure can easily be processed via Spark.",
      "nodes": [
        {
          "content": "is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.",
          "pos": [
            0,
            142
          ]
        },
        {
          "content": "Spark processing engine is built for speed, ease of use, and sophisticated analytics.",
          "pos": [
            143,
            228
          ]
        },
        {
          "content": "Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations.",
          "pos": [
            229,
            362
          ]
        },
        {
          "content": "Spark is also compatible with Azure Blob storage (WASB) so your existing data stored in Azure can easily be processed via Spark.",
          "pos": [
            363,
            491
          ]
        }
      ]
    },
    {
      "pos": [
        1174,
        1485
      ],
      "content": "When you create a Spark cluster in HDInsight, you create Azure compute resources with Spark installed and configured. It only takes about ten minutes to create a Spark cluster in HDInsight. The data to be processed is stored in Azure Blob storage. See <bpt id=\"p1\">[</bpt>Use Azure Blob Storage with HDInsight<ept id=\"p1\">][hdinsight-storage]</ept>.",
      "nodes": [
        {
          "content": "When you create a Spark cluster in HDInsight, you create Azure compute resources with Spark installed and configured.",
          "pos": [
            0,
            117
          ]
        },
        {
          "content": "It only takes about ten minutes to create a Spark cluster in HDInsight.",
          "pos": [
            118,
            189
          ]
        },
        {
          "content": "The data to be processed is stored in Azure Blob storage.",
          "pos": [
            190,
            247
          ]
        },
        {
          "content": "See <bpt id=\"p1\">[</bpt>Use Azure Blob Storage with HDInsight<ept id=\"p1\">][hdinsight-storage]</ept>.",
          "pos": [
            248,
            349
          ]
        }
      ]
    },
    {
      "pos": [
        1487,
        1623
      ],
      "content": "<ph id=\"ph2\">![</ph>Apache Spark on Azure HDInsight<ph id=\"ph3\">](./media/hdinsight-apache-spark-overview/hdispark.architecture.png  \"Apache Spark on Azure HDInsight\")</ph>"
    },
    {
      "pos": [
        1626,
        1835
      ],
      "content": "<bpt id=\"p2\">**</bpt>Want to get started with Apache Spark on Azure HDInsight?<ept id=\"p2\">**</ept><ph id=\"ph4\"/> See <bpt id=\"p3\">[</bpt>QuickStart: create a Spark cluster on HDInsight Linux and run sample applications using Jupyter<ept id=\"p3\">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>."
    },
    {
      "pos": [
        1838,
        2027
      ],
      "content": "<ph id=\"ph5\">[AZURE.NOTE]</ph><ph id=\"ph6\"/> For a list of known issues and limitations with the current release, see <bpt id=\"p4\">[</bpt>Known issues of Apache Spark in Azure HDInsight (Linux)<ept id=\"p4\">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>."
    },
    {
      "pos": [
        2033,
        2066
      ],
      "content": "Why use Spark on Azure HDInsight?"
    },
    {
      "pos": [
        2069,
        2164
      ],
      "content": "Azure HDInsight offers a fully managed Spark service. Benefits of using Spark on HDInsight are:",
      "nodes": [
        {
          "content": "Azure HDInsight offers a fully managed Spark service.",
          "pos": [
            0,
            53
          ]
        },
        {
          "content": "Benefits of using Spark on HDInsight are:",
          "pos": [
            54,
            95
          ]
        }
      ]
    },
    {
      "pos": [
        2168,
        2175
      ],
      "content": "Feature"
    },
    {
      "pos": [
        2206,
        2217
      ],
      "content": "Description"
    },
    {
      "pos": [
        2288,
        2304
      ],
      "content": "Ease of creating"
    },
    {
      "pos": [
        2318,
        2551
      ],
      "content": "You can create a new Spark cluster on HDInsight in minutes using the Azure Management Portal, Azure PowerShell, or the HDInsight .NET SDK. See <bpt id=\"p5\">[</bpt>Get started with Spark cluster in HDInsight<ept id=\"p5\">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>",
      "nodes": [
        {
          "content": "You can create a new Spark cluster on HDInsight in minutes using the Azure Management Portal, Azure PowerShell, or the HDInsight .NET SDK.",
          "pos": [
            0,
            138
          ]
        },
        {
          "content": "See <bpt id=\"p5\">[</bpt>Get started with Spark cluster in HDInsight<ept id=\"p5\">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>",
          "pos": [
            139,
            271
          ]
        }
      ]
    },
    {
      "pos": [
        2556,
        2567
      ],
      "content": "Ease of use"
    },
    {
      "pos": [
        2590,
        2868
      ],
      "content": "Spark in HDInsight clusters includes Jupyter notebooks pre-configured. You can use these for interactive data processing and visualization. The URLs for the is https://CLUSTERNAME.azurehdinsight.net/jupyter. Replace <bpt id=\"p6\">__</bpt>CLUSTERNAME<ept id=\"p6\">__</ept><ph id=\"ph7\"/> with the name of your Spark HDInsight cluster.",
      "nodes": [
        {
          "content": "Spark in HDInsight clusters includes Jupyter notebooks pre-configured.",
          "pos": [
            0,
            70
          ]
        },
        {
          "content": "You can use these for interactive data processing and visualization.",
          "pos": [
            71,
            139
          ]
        },
        {
          "content": "The URLs for the is https://CLUSTERNAME.azurehdinsight.net/jupyter.",
          "pos": [
            140,
            207
          ]
        },
        {
          "content": "Replace <bpt id=\"p6\">__</bpt>CLUSTERNAME<ept id=\"p6\">__</ept><ph id=\"ph7\"/> with the name of your Spark HDInsight cluster.",
          "pos": [
            208,
            330
          ]
        }
      ]
    },
    {
      "pos": [
        2872,
        2881
      ],
      "content": "REST APIs"
    },
    {
      "pos": [
        2906,
        3119
      ],
      "content": "Spark in HDInsight includes <bpt id=\"p7\">[</bpt>Livy<ept id=\"p7\">](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)</ept>, a REST-API based Spark job server to remotely submit and monitor running jobs."
    },
    {
      "pos": [
        3124,
        3142
      ],
      "content": "Concurrent Queries"
    },
    {
      "pos": [
        3158,
        3342
      ],
      "content": "Spark in HDInsight supports concurrent queries. This enables multiple queries from one user or multiple queries from various users and applications to share the same cluster resources.",
      "nodes": [
        {
          "content": "Spark in HDInsight supports concurrent queries.",
          "pos": [
            0,
            47
          ]
        },
        {
          "content": "This enables multiple queries from one user or multiple queries from various users and applications to share the same cluster resources.",
          "pos": [
            48,
            184
          ]
        }
      ]
    },
    {
      "pos": [
        3347,
        3362
      ],
      "content": "Caching on SSDs"
    },
    {
      "pos": [
        3381,
        3719
      ],
      "content": "You can choose to cache data either in memory or in SSDs attached to the cluster nodes. Caching in memory provides the best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without the need to create a cluster of a size that is required to fit the entire dataset in memory.",
      "nodes": [
        {
          "content": "You can choose to cache data either in memory or in SSDs attached to the cluster nodes.",
          "pos": [
            0,
            87
          ]
        },
        {
          "content": "Caching in memory provides the best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without the need to create a cluster of a size that is required to fit the entire dataset in memory.",
          "pos": [
            88,
            338
          ]
        }
      ]
    },
    {
      "pos": [
        3723,
        3754
      ],
      "content": "Integration with Azure services"
    },
    {
      "pos": [
        3757,
        3979
      ],
      "content": "Spark on HDInsight comes with a connector to Azure Event Hubs. Customers can build streaming applications using the Event Hubs, in addition to <bpt id=\"p8\">[</bpt>Kafka<ept id=\"p8\">](http://kafka.apache.org/)</ept>, which is already available as part of Spark.",
      "nodes": [
        {
          "content": "Spark on HDInsight comes with a connector to Azure Event Hubs.",
          "pos": [
            0,
            62
          ]
        },
        {
          "content": "Customers can build streaming applications using the Event Hubs, in addition to <bpt id=\"p8\">[</bpt>Kafka<ept id=\"p8\">](http://kafka.apache.org/)</ept>, which is already available as part of Spark.",
          "pos": [
            63,
            260
          ]
        }
      ]
    },
    {
      "pos": [
        3984,
        4009
      ],
      "content": "Integration with BI Tools"
    },
    {
      "pos": [
        4018,
        4197
      ],
      "content": "Spark for HDInsight provides connectors for popular BI tools such as <bpt id=\"p9\">[</bpt>Power BI<ept id=\"p9\">](http://www.powerbi.com/)</ept><ph id=\"ph8\"/> and <bpt id=\"p10\">[</bpt>Tableau<ept id=\"p10\">](http://www.tableau.com/products/desktop)</ept><ph id=\"ph9\"/> for data analytics."
    },
    {
      "pos": [
        4201,
        4230
      ],
      "content": "Pre-loaded Anaconda libraries"
    },
    {
      "pos": [
        4240,
        4447
      ],
      "content": "Spark clusters on HDInsight come with Anaconda libraries pre-installed. <bpt id=\"p11\">[</bpt>Anaconda<ept id=\"p11\">](http://docs.continuum.io/anaconda/)</ept><ph id=\"ph10\"/> provides close to 200 libraries for machine learning, data analysis, visualization, etc.",
      "nodes": [
        {
          "content": "Spark clusters on HDInsight come with Anaconda libraries pre-installed.",
          "pos": [
            0,
            71
          ]
        },
        {
          "content": "<bpt id=\"p11\">[</bpt>Anaconda<ept id=\"p11\">](http://docs.continuum.io/anaconda/)</ept><ph id=\"ph10\"/> provides close to 200 libraries for machine learning, data analysis, visualization, etc.",
          "pos": [
            72,
            262
          ]
        }
      ]
    },
    {
      "pos": [
        4451,
        4462
      ],
      "content": "Scalability"
    },
    {
      "pos": [
        4485,
        4812
      ],
      "content": "Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match workload. All HDInsight clusters allow you to change the number of nodes in the cluster. Also, Spark clusters can be dropped with no loss of data since all the data is stored in Azure Blob Storage.",
      "nodes": [
        {
          "content": "Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match workload.",
          "pos": [
            0,
            139
          ]
        },
        {
          "content": "All HDInsight clusters allow you to change the number of nodes in the cluster.",
          "pos": [
            140,
            218
          ]
        },
        {
          "content": "Also, Spark clusters can be dropped with no loss of data since all the data is stored in Azure Blob Storage.",
          "pos": [
            219,
            327
          ]
        }
      ]
    },
    {
      "pos": [
        4817,
        4829
      ],
      "content": "24/7 Support"
    },
    {
      "pos": [
        4851,
        4940
      ],
      "content": "Spark on HDInsight comes with  enterprise-level 24/7 support and an SLA of 99.9% up-time."
    },
    {
      "pos": [
        4948,
        4994
      ],
      "content": "What are the use cases for Spark on HDInsight?"
    },
    {
      "pos": [
        4996,
        5058
      ],
      "content": "Apache Spark in HDInsight enables the following key scenarios."
    },
    {
      "pos": [
        5064,
        5096
      ],
      "content": "Interactive data analysis and BI"
    },
    {
      "pos": [
        5098,
        5158
      ],
      "content": "<bpt id=\"p12\">[</bpt>Look at a tutorial<ept id=\"p12\">](hdinsight-apache-spark-use-bi-tools.md)</ept>"
    },
    {
      "pos": [
        5160,
        5751
      ],
      "content": "Apache Spark in HDInsight stores data in Azure Blobs. Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI to build interactive reports from the analyzed data. Analysts can start from unstructured/semi structured data in Azure storage, define a schema for the data using notebooks and then build data models using Microsoft Power BI. Spark in HDInsight also supports a number of third party BI tools such as Tableau, Qlikview, and SAP Lumira making it an ideal platform for data analysts, business experts, and key decision makers.",
      "nodes": [
        {
          "content": "Apache Spark in HDInsight stores data in Azure Blobs.",
          "pos": [
            0,
            53
          ]
        },
        {
          "content": "Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI to build interactive reports from the analyzed data.",
          "pos": [
            54,
            219
          ]
        },
        {
          "content": "Analysts can start from unstructured/semi structured data in Azure storage, define a schema for the data using notebooks and then build data models using Microsoft Power BI.",
          "pos": [
            220,
            393
          ]
        },
        {
          "content": "Spark in HDInsight also supports a number of third party BI tools such as Tableau, Qlikview, and SAP Lumira making it an ideal platform for data analysts, business experts, and key decision makers.",
          "pos": [
            394,
            591
          ]
        }
      ]
    },
    {
      "pos": [
        5757,
        5783
      ],
      "content": "Iterative Machine Learning"
    },
    {
      "pos": [
        5785,
        5913
      ],
      "content": "<bpt id=\"p13\">[</bpt>Look at a tutorial: Predict building temperatures uisng HVAC data<ept id=\"p13\">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept>"
    },
    {
      "pos": [
        5915,
        6026
      ],
      "content": "<bpt id=\"p14\">[</bpt>Look at a tutorial: Predict food inspection results<ept id=\"p14\">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept>"
    },
    {
      "pos": [
        6028,
        6423
      ],
      "content": "Apache Spark comes with <bpt id=\"p15\">[</bpt>MLlib<ept id=\"p15\">](http://spark.apache.org/mllib/)</ept>, a machine learning library built on top of Spark. In addition to this, Spark on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning. Couple this with a built-in support for Jupyter notebooks, and you have a top-of-the-line environment for creating machine learning applications.",
      "nodes": [
        {
          "content": "Apache Spark comes with <bpt id=\"p15\">[</bpt>MLlib<ept id=\"p15\">](http://spark.apache.org/mllib/)</ept>, a machine learning library built on top of Spark.",
          "pos": [
            0,
            154
          ]
        },
        {
          "content": "In addition to this, Spark on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.",
          "pos": [
            155,
            289
          ]
        },
        {
          "content": "Couple this with a built-in support for Jupyter notebooks, and you have a top-of-the-line environment for creating machine learning applications.",
          "pos": [
            290,
            435
          ]
        }
      ]
    },
    {
      "pos": [
        6431,
        6468
      ],
      "content": "Streaming and real-time data analysis"
    },
    {
      "pos": [
        6470,
        6536
      ],
      "content": "<bpt id=\"p16\">[</bpt>Look at a tutorial<ept id=\"p16\">](hdinsight-apache-spark-eventhub-streaming.md)</ept>"
    },
    {
      "pos": [
        6538,
        7184
      ],
      "content": "Real-time data analysis is used for scenarios ranging from reducing time to data insight by processing data as it lands, to building a true streaming solution. Spark in HDInsight offers a rich support for building real-time analytics solutions. While Spark already has connectors to ingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs. Event Hubs are the most widely used queuing service on Azure. Having an out-of-the-box support for Event Hubs makes Spark in HDInsight an ideal platform for building real time analytics pipeline.",
      "nodes": [
        {
          "content": "Real-time data analysis is used for scenarios ranging from reducing time to data insight by processing data as it lands, to building a true streaming solution.",
          "pos": [
            0,
            159
          ]
        },
        {
          "content": "Spark in HDInsight offers a rich support for building real-time analytics solutions.",
          "pos": [
            160,
            244
          ]
        },
        {
          "content": "While Spark already has connectors to ingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.",
          "pos": [
            245,
            450
          ]
        },
        {
          "content": "Event Hubs are the most widely used queuing service on Azure.",
          "pos": [
            451,
            512
          ]
        },
        {
          "content": "Having an out-of-the-box support for Event Hubs makes Spark in HDInsight an ideal platform for building real time analytics pipeline.",
          "pos": [
            513,
            646
          ]
        }
      ]
    },
    {
      "pos": [
        7186,
        7188
      ],
      "content": "##"
    },
    {
      "pos": [
        7213,
        7269
      ],
      "content": "What components are included as part of a Spark cluster?"
    },
    {
      "pos": [
        7271,
        7370
      ],
      "content": "Spark in HDInsight includes the following components that are available on the clusters by default."
    },
    {
      "pos": [
        7374,
        7498
      ],
      "content": "<bpt id=\"p17\">[</bpt>Spark Core<ept id=\"p17\">](https://spark.apache.org/docs/1.5.1/)</ept>. Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.",
      "nodes": [
        {
          "content": "<bpt id=\"p17\">[</bpt>Spark Core<ept id=\"p17\">](https://spark.apache.org/docs/1.5.1/)</ept>.",
          "pos": [
            0,
            91
          ]
        },
        {
          "content": "Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.",
          "pos": [
            92,
            164
          ]
        }
      ]
    },
    {
      "pos": [
        7501,
        7547
      ],
      "content": "<bpt id=\"p18\">[</bpt>Anaconda<ept id=\"p18\">](http://docs.continuum.io/anaconda/)</ept>"
    },
    {
      "pos": [
        7550,
        7655
      ],
      "content": "<bpt id=\"p19\">[</bpt>Livy<ept id=\"p19\">](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)</ept>"
    },
    {
      "pos": [
        7658,
        7697
      ],
      "content": "<bpt id=\"p20\">[</bpt>Jupyter Notebook<ept id=\"p20\">](https://jupyter.org)</ept>"
    },
    {
      "pos": [
        7699,
        7897
      ],
      "content": "Spark in HDInsight also provides an <bpt id=\"p21\">[</bpt>ODBC driver<ept id=\"p21\">](http://go.microsoft.com/fwlink/?LinkId=616229)</ept><ph id=\"ph11\"/> for connectivity to Spark clusters in HDInsight from BI tools such as Microsoft Power BI and Tableau."
    },
    {
      "pos": [
        7902,
        7919
      ],
      "content": "Where do I start?"
    },
    {
      "pos": [
        7921,
        8124
      ],
      "content": "Start with creating a Spark cluster on HDInsight Linux. See <bpt id=\"p22\">[</bpt>QuickStart: create a Spark cluster on HDInsight Linux and run sample applications using Jupyter<ept id=\"p22\">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.",
      "nodes": [
        {
          "content": "Start with creating a Spark cluster on HDInsight Linux.",
          "pos": [
            0,
            55
          ]
        },
        {
          "content": "See <bpt id=\"p22\">[</bpt>QuickStart: create a Spark cluster on HDInsight Linux and run sample applications using Jupyter<ept id=\"p22\">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.",
          "pos": [
            56,
            243
          ]
        }
      ]
    },
    {
      "pos": [
        8130,
        8140
      ],
      "content": "Next Steps"
    },
    {
      "pos": [
        8146,
        8155
      ],
      "content": "Scenarios"
    },
    {
      "pos": [
        8159,
        8288
      ],
      "content": "<bpt id=\"p23\">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id=\"p23\">](hdinsight-apache-spark-use-bi-tools.md)</ept>"
    },
    {
      "pos": [
        8292,
        8457
      ],
      "content": "<bpt id=\"p24\">[</bpt>Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data<ept id=\"p24\">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept>"
    },
    {
      "pos": [
        8461,
        8607
      ],
      "content": "<bpt id=\"p25\">[</bpt>Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results<ept id=\"p25\">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept>"
    },
    {
      "pos": [
        8611,
        8744
      ],
      "content": "<bpt id=\"p26\">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id=\"p26\">](hdinsight-apache-spark-eventhub-streaming.md)</ept>"
    },
    {
      "pos": [
        8748,
        8858
      ],
      "content": "<bpt id=\"p27\">[</bpt>Website log analysis using Spark in HDInsight<ept id=\"p27\">](hdinsight-apache-spark-custom-library-website-log-analysis.md)</ept>"
    },
    {
      "pos": [
        8864,
        8891
      ],
      "content": "Create and run applications"
    },
    {
      "pos": [
        8895,
        8997
      ],
      "content": "<bpt id=\"p28\">[</bpt>Create a standalone application using Scala<ept id=\"p28\">](hdinsight-apache-spark-create-standalone-application.md)</ept>"
    },
    {
      "pos": [
        9001,
        9097
      ],
      "content": "<bpt id=\"p29\">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id=\"p29\">](hdinsight-apache-spark-livy-rest-interface.md)</ept>"
    },
    {
      "pos": [
        9103,
        9123
      ],
      "content": "Tools and extensions"
    },
    {
      "pos": [
        9127,
        9266
      ],
      "content": "<bpt id=\"p30\">[</bpt>Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons<ept id=\"p30\">](hdinsight-apache-spark-intellij-tool-plugin.md)</ept>"
    },
    {
      "pos": [
        9270,
        9377
      ],
      "content": "<bpt id=\"p31\">[</bpt>Use Zeppelin notebooks with a Spark cluster on HDInsight<ept id=\"p31\">](hdinsight-apache-spark-use-zeppelin-notebook.md)</ept>"
    },
    {
      "pos": [
        9381,
        9504
      ],
      "content": "<bpt id=\"p32\">[</bpt>Kernels available for Jupyter notebook in Spark cluster for HDInsight<ept id=\"p32\">](hdinsight-apache-spark-jupyter-notebook-kernels.md)</ept>"
    },
    {
      "pos": [
        9510,
        9526
      ],
      "content": "Manage resources"
    },
    {
      "pos": [
        9530,
        9640
      ],
      "content": "<bpt id=\"p33\">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id=\"p33\">](hdinsight-apache-spark-resource-manager.md)</ept>"
    }
  ],
  "content": "<properties \n    pageTitle=\"An overview of Apache Spark in HDInsight | Microsoft Azure\" \n    description=\"An introduction to Apache Spark in HDInsight and scenarios in which to use Spark on HDInsight in your applications.\" \n    services=\"hdinsight\" \n    documentationCenter=\"\" \n    authors=\"nitinme\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags \n    ms.service=\"hdinsight\" \n    ms.workload=\"big-data\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"02/05/2016\" \n    ms.author=\"nitinme\"/>\n\n# Overview: Apache Spark on Azure HDInsight (Linux)\n \n<a href=\"http://spark.apache.org/\" target=\"_blank\">Apache Spark</a> is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications. Spark processing engine is built for speed, ease of use, and sophisticated analytics. Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations. Spark is also compatible with Azure Blob storage (WASB) so your existing data stored in Azure can easily be processed via Spark.\n\nWhen you create a Spark cluster in HDInsight, you create Azure compute resources with Spark installed and configured. It only takes about ten minutes to create a Spark cluster in HDInsight. The data to be processed is stored in Azure Blob storage. See [Use Azure Blob Storage with HDInsight][hdinsight-storage].\n\n![Apache Spark on Azure HDInsight](./media/hdinsight-apache-spark-overview/hdispark.architecture.png  \"Apache Spark on Azure HDInsight\")\n\n\n**Want to get started with Apache Spark on Azure HDInsight?** See [QuickStart: create a Spark cluster on HDInsight Linux and run sample applications using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).\n\n>[AZURE.NOTE] For a list of known issues and limitations with the current release, see [Known issues of Apache Spark in Azure HDInsight (Linux)](hdinsight-apache-spark-jupyter-spark-sql.md).\n\n\n## Why use Spark on Azure HDInsight? \n\nAzure HDInsight offers a fully managed Spark service. Benefits of using Spark on HDInsight are:\n\n| Feature                             | Description       |\n|-------------------------------------|-------------------|\n| Ease of creating            | You can create a new Spark cluster on HDInsight in minutes using the Azure Management Portal, Azure PowerShell, or the HDInsight .NET SDK. See [Get started with Spark cluster in HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md) |\n| Ease of use                     | Spark in HDInsight clusters includes Jupyter notebooks pre-configured. You can use these for interactive data processing and visualization. The URLs for the is https://CLUSTERNAME.azurehdinsight.net/jupyter. Replace __CLUSTERNAME__ with the name of your Spark HDInsight cluster.|\n| REST APIs                       | Spark in HDInsight includes [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), a REST-API based Spark job server to remotely submit and monitor running jobs. |\n| Concurrent Queries              | Spark in HDInsight supports concurrent queries. This enables multiple queries from one user or multiple queries from various users and applications to share the same cluster resources. |\n| Caching on SSDs                 | You can choose to cache data either in memory or in SSDs attached to the cluster nodes. Caching in memory provides the best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without the need to create a cluster of a size that is required to fit the entire dataset in memory.|\n| Integration with Azure services | Spark on HDInsight comes with a connector to Azure Event Hubs. Customers can build streaming applications using the Event Hubs, in addition to [Kafka](http://kafka.apache.org/), which is already available as part of Spark. |\n| Integration with BI Tools       | Spark for HDInsight provides connectors for popular BI tools such as [Power BI](http://www.powerbi.com/) and [Tableau](http://www.tableau.com/products/desktop) for data analytics.|\n| Pre-loaded Anaconda libraries        | Spark clusters on HDInsight come with Anaconda libraries pre-installed. [Anaconda](http://docs.continuum.io/anaconda/) provides close to 200 libraries for machine learning, data analysis, visualization, etc.|\n| Scalability                     | Although you can specify the number of nodes in your cluster during creation, you may want to grow or shrink the cluster to match workload. All HDInsight clusters allow you to change the number of nodes in the cluster. Also, Spark clusters can be dropped with no loss of data since all the data is stored in Azure Blob Storage. |\n| 24/7 Support                    | Spark on HDInsight comes with  enterprise-level 24/7 support and an SLA of 99.9% up-time.|\n\n\n\n## What are the use cases for Spark on HDInsight?\n\nApache Spark in HDInsight enables the following key scenarios.\n\n### Interactive data analysis and BI\n\n[Look at a tutorial](hdinsight-apache-spark-use-bi-tools.md)\n\nApache Spark in HDInsight stores data in Azure Blobs. Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI to build interactive reports from the analyzed data. Analysts can start from unstructured/semi structured data in Azure storage, define a schema for the data using notebooks and then build data models using Microsoft Power BI. Spark in HDInsight also supports a number of third party BI tools such as Tableau, Qlikview, and SAP Lumira making it an ideal platform for data analysts, business experts, and key decision makers.\n\n### Iterative Machine Learning\n\n[Look at a tutorial: Predict building temperatures uisng HVAC data](hdinsight-apache-spark-ipython-notebook-machine-learning.md)\n\n[Look at a tutorial: Predict food inspection results](hdinsight-apache-spark-machine-learning-mllib-ipython.md)\n\nApache Spark comes with [MLlib](http://spark.apache.org/mllib/), a machine learning library built on top of Spark. In addition to this, Spark on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning. Couple this with a built-in support for Jupyter notebooks, and you have a top-of-the-line environment for creating machine learning applications.  \n\n### Streaming and real-time data analysis\n\n[Look at a tutorial](hdinsight-apache-spark-eventhub-streaming.md)\n\nReal-time data analysis is used for scenarios ranging from reducing time to data insight by processing data as it lands, to building a true streaming solution. Spark in HDInsight offers a rich support for building real-time analytics solutions. While Spark already has connectors to ingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs. Event Hubs are the most widely used queuing service on Azure. Having an out-of-the-box support for Event Hubs makes Spark in HDInsight an ideal platform for building real time analytics pipeline.\n\n##<a name=\"next-steps\"></a>What components are included as part of a Spark cluster?\n\nSpark in HDInsight includes the following components that are available on the clusters by default.\n\n- [Spark Core](https://spark.apache.org/docs/1.5.1/). Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.\n- [Anaconda](http://docs.continuum.io/anaconda/)\n- [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)\n- [Jupyter Notebook](https://jupyter.org)\n\nSpark in HDInsight also provides an [ODBC driver](http://go.microsoft.com/fwlink/?LinkId=616229) for connectivity to Spark clusters in HDInsight from BI tools such as Microsoft Power BI and Tableau.\n\n## Where do I start?\n\nStart with creating a Spark cluster on HDInsight Linux. See [QuickStart: create a Spark cluster on HDInsight Linux and run sample applications using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md). \n\n## Next Steps\n\n### Scenarios\n\n* [Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools](hdinsight-apache-spark-use-bi-tools.md)\n\n* [Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data](hdinsight-apache-spark-ipython-notebook-machine-learning.md)\n\n* [Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results](hdinsight-apache-spark-machine-learning-mllib-ipython.md)\n\n* [Spark Streaming: Use Spark in HDInsight for building real-time streaming applications](hdinsight-apache-spark-eventhub-streaming.md)\n\n* [Website log analysis using Spark in HDInsight](hdinsight-apache-spark-custom-library-website-log-analysis.md)\n\n### Create and run applications\n\n* [Create a standalone application using Scala](hdinsight-apache-spark-create-standalone-application.md)\n\n* [Run jobs remotely on a Spark cluster using Livy](hdinsight-apache-spark-livy-rest-interface.md)\n\n### Tools and extensions\n\n* [Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons](hdinsight-apache-spark-intellij-tool-plugin.md)\n\n* [Use Zeppelin notebooks with a Spark cluster on HDInsight](hdinsight-apache-spark-use-zeppelin-notebook.md)\n\n* [Kernels available for Jupyter notebook in Spark cluster for HDInsight](hdinsight-apache-spark-jupyter-notebook-kernels.md)\n\n### Manage resources\n\n* [Manage resources for the Apache Spark cluster in Azure HDInsight](hdinsight-apache-spark-resource-manager.md)\n\n\n[hdinsight-storage]: hdinsight-hadoop-use-blob-storage.md\n"
}