{
  "nodes": [
    {
      "pos": [
        27,
        164
      ],
      "content": "Technical guide to the Cortana Analytics Solution Template for predictive maintenance in aerospace and other businesses | Microsoft Azure"
    },
    {
      "pos": [
        183,
        330
      ],
      "content": "A technical guide to the Solution Template with Microsoft Cortana Analytics for predictive maintenance in aerospace, utilities, and transportation."
    },
    {
      "pos": [
        654,
        773
      ],
      "content": "Technical guide to the Cortana Analytics Solution Template for predictive maintenance in aerospace and other businesses"
    },
    {
      "pos": [
        778,
        798
      ],
      "content": "<bpt id=\"p1\">**</bpt>Acknowledgements<ept id=\"p1\">**</ept>"
    },
    {
      "pos": [
        799,
        931
      ],
      "content": "This article is authored by data scientists Yan Zhang, Gauher Shaheen, Fidan Boylu Uz and software engineer Dan Grecoe at Microsoft."
    },
    {
      "pos": [
        936,
        948
      ],
      "content": "<bpt id=\"p2\">**</bpt>Overview<ept id=\"p2\">**</ept>"
    },
    {
      "pos": [
        950,
        1022
      ],
      "content": "Solution Templates are designed to accelerate the process of building an"
    },
    {
      "pos": [
        1023,
        1092
      ],
      "content": "E2E demo on top of Cortana Analytics Suite. A deployed template will\n",
      "nodes": [
        {
          "content": "E2E demo on top of Cortana Analytics Suite.",
          "pos": [
            0,
            43
          ]
        },
        {
          "content": "A deployed template will",
          "pos": [
            44,
            68
          ]
        }
      ]
    },
    {
      "pos": [
        1092,
        1163
      ],
      "content": "provision your subscription with necessary Cortana Analytics components"
    },
    {
      "pos": [
        1164,
        1788
      ],
      "content": "and build the relationships between them. It also seeds the data pipeline with sample data generated from a data generator application which you will download and install on your local machine after you deploy the solution template. The data generated from the generator will hydrate the data pipeline and start generating machine learning predictions which can then be visualized on the Power BI dashboard. The deployment process will guide you through several steps to set up your solution credentials. Make sure you record these credentials such as solution name, username, and password you provide during the deployment.",
      "nodes": [
        {
          "content": "and build the relationships between them.",
          "pos": [
            0,
            41
          ]
        },
        {
          "content": "It also seeds the data pipeline with sample data generated from a data generator application which you will download and install on your local machine after you deploy the solution template.",
          "pos": [
            42,
            232
          ]
        },
        {
          "content": "The data generated from the generator will hydrate the data pipeline and start generating machine learning predictions which can then be visualized on the Power BI dashboard.",
          "pos": [
            233,
            407
          ]
        },
        {
          "content": "The deployment process will guide you through several steps to set up your solution credentials.",
          "pos": [
            408,
            504
          ]
        },
        {
          "content": "Make sure you record these credentials such as solution name, username, and password you provide during the deployment.",
          "pos": [
            505,
            624
          ]
        }
      ]
    },
    {
      "pos": [
        1792,
        1862
      ],
      "content": "The goal of this document is to explain the reference architecture and"
    },
    {
      "pos": [
        1863,
        1932
      ],
      "content": "different components provisioned in your subscription as part of this"
    },
    {
      "pos": [
        1933,
        2001
      ],
      "content": "solution template. The document also talks about how to replace the\n",
      "nodes": [
        {
          "content": "solution template.",
          "pos": [
            0,
            18
          ]
        },
        {
          "content": "The document also talks about how to replace the",
          "pos": [
            19,
            67
          ]
        }
      ]
    },
    {
      "pos": [
        2001,
        2070
      ],
      "content": "sample data with real data of your own to be able to see insights and"
    },
    {
      "pos": [
        2071,
        2144
      ],
      "content": "predictions from your own data. Additionally, the document discusses the\n",
      "nodes": [
        {
          "content": "predictions from your own data.",
          "pos": [
            0,
            31
          ]
        },
        {
          "content": "Additionally, the document discusses the",
          "pos": [
            32,
            72
          ]
        }
      ]
    },
    {
      "pos": [
        2144,
        2212
      ],
      "content": "parts of the Solution Template that would need to be modified if you"
    },
    {
      "pos": [
        2213,
        2286
      ],
      "content": "wanted to customize the solution with your own data. Instructions on how\n",
      "nodes": [
        {
          "content": "wanted to customize the solution with your own data.",
          "pos": [
            0,
            52
          ]
        },
        {
          "content": "Instructions on how",
          "pos": [
            53,
            72
          ]
        }
      ]
    },
    {
      "pos": [
        2286,
        2357
      ],
      "content": "to build the Power BI dashboard for this Solution Template are provided"
    },
    {
      "pos": [
        2358,
        2369
      ],
      "content": "at the end."
    },
    {
      "pos": [
        2372,
        2588
      ],
      "content": "<ph id=\"ph2\">[AZURE.TIP]</ph><ph id=\"ph3\"/> You can download and print a <bpt id=\"p3\">[</bpt>PDF version of this document<ept id=\"p3\">](http://download.microsoft.com/download/F/4/D/F4D7D208-D080-42ED-8813-6030D23329E9/cortana-analytics-technical-guide-predictive-maintenance.pdf)</ept>."
    },
    {
      "pos": [
        2593,
        2608
      ],
      "content": "<bpt id=\"p4\">**</bpt>Big picture<ept id=\"p4\">**</ept>"
    },
    {
      "pos": [
        2719,
        3553
      ],
      "content": "When the solution is deployed, various Azure services within Cortana\nAnalytics Suite are activated (<bpt id=\"p5\">*</bpt>i.e.<ept id=\"p5\">*</ept><ph id=\"ph5\"/> Event Hub, Stream Analytics,\nHDInsight, Data Factory, Machine Learning, <bpt id=\"p6\">*</bpt>etc.<ept id=\"p6\">*</ept>). The architecture\ndiagram above shows, at a high level, how the Predictive Maintenance for\nAerospace Solution Template is constructed from end-to-end. You will be able to investigate these services in the azure portal by clicking on them on the solution template diagram created with the deployment of the solution with the exception of HDInsight as this service is provisioned on demand when the related pipeline activities are required to run and deleted afterwards.\nYou can download a <bpt id=\"p7\">[</bpt>full-size version of the diagram<ept id=\"p7\">](http://download.microsoft.com/download/1/9/B/19B815F0-D1B0-4F67-AED3-A40544225FD1/ca-topologies-maintenance-prediction.png)</ept>.",
      "nodes": [
        {
          "content": "When the solution is deployed, various Azure services within Cortana\nAnalytics Suite are activated (<bpt id=\"p5\">*</bpt>i.e.<ept id=\"p5\">*</ept><ph id=\"ph5\"/> Event Hub, Stream Analytics,\nHDInsight, Data Factory, Machine Learning, <bpt id=\"p6\">*</bpt>etc.<ept id=\"p6\">*</ept>).",
          "pos": [
            0,
            277
          ]
        },
        {
          "content": "The architecture\ndiagram above shows, at a high level, how the Predictive Maintenance for\nAerospace Solution Template is constructed from end-to-end.",
          "pos": [
            278,
            427
          ]
        },
        {
          "content": "You will be able to investigate these services in the azure portal by clicking on them on the solution template diagram created with the deployment of the solution with the exception of HDInsight as this service is provisioned on demand when the related pipeline activities are required to run and deleted afterwards.",
          "pos": [
            428,
            745
          ]
        },
        {
          "content": "You can download a <bpt id=\"p7\">[</bpt>full-size version of the diagram<ept id=\"p7\">](http://download.microsoft.com/download/1/9/B/19B815F0-D1B0-4F67-AED3-A40544225FD1/ca-topologies-maintenance-prediction.png)</ept>.",
          "pos": [
            746,
            962
          ]
        }
      ]
    },
    {
      "pos": [
        3555,
        3598
      ],
      "content": "The following sections describe each piece."
    },
    {
      "pos": [
        3603,
        3632
      ],
      "content": "<bpt id=\"p8\">**</bpt>Data source and ingestion<ept id=\"p8\">**</ept>"
    },
    {
      "pos": [
        3638,
        3659
      ],
      "content": "Synthetic data source"
    },
    {
      "pos": [
        3661,
        4472
      ],
      "content": "For this template the data source used is generated from a desktop\napplication that you will download and run locally after successful\ndeployment. You will find the instructions to download and install this application in the properties bar when you select the first node called Predictive Maintenance Data Generator on the solution template diagram. This application feeds the <bpt id=\"p9\">[</bpt>Azure Event Hub<ept id=\"p9\">](#azure-event-hub)</ept><ph id=\"ph6\"/> service\nwith data points, or events, that will be used in the rest of the solution flow. This data\nsource is comprised of or derived from publicly available data from the\n<bpt id=\"p10\">[</bpt>NASA data\nrepository<ept id=\"p10\">](http://ti.arc.nasa.gov/tech/dash/pcoe/prognostic-data-repository/)</ept>\nusing the <bpt id=\"p11\">[</bpt>Turbofan Engine Degradation Simulation Data Set<ept id=\"p11\">](http://ti.arc.nasa.gov/tech/dash/pcoe/prognostic-data-repository/#turbofan)</ept>.",
      "nodes": [
        {
          "content": "For this template the data source used is generated from a desktop\napplication that you will download and run locally after successful\ndeployment.",
          "pos": [
            0,
            146
          ]
        },
        {
          "content": "You will find the instructions to download and install this application in the properties bar when you select the first node called Predictive Maintenance Data Generator on the solution template diagram.",
          "pos": [
            147,
            350
          ]
        },
        {
          "content": "This application feeds the <bpt id=\"p9\">[</bpt>Azure Event Hub<ept id=\"p9\">](#azure-event-hub)</ept><ph id=\"ph6\"/> service\nwith data points, or events, that will be used in the rest of the solution flow.",
          "pos": [
            351,
            554
          ]
        },
        {
          "content": "This data\nsource is comprised of or derived from publicly available data from the\n<bpt id=\"p10\">[</bpt>NASA data\nrepository<ept id=\"p10\">](http://ti.arc.nasa.gov/tech/dash/pcoe/prognostic-data-repository/)</ept>\nusing the <bpt id=\"p11\">[</bpt>Turbofan Engine Degradation Simulation Data Set<ept id=\"p11\">](http://ti.arc.nasa.gov/tech/dash/pcoe/prognostic-data-repository/#turbofan)</ept>.",
          "pos": [
            555,
            943
          ]
        }
      ]
    },
    {
      "pos": [
        4474,
        4545
      ],
      "content": "The event generation application will populate the Azure Event Hub only"
    },
    {
      "pos": [
        4546,
        4584
      ],
      "content": "while it's executing on your computer."
    },
    {
      "pos": [
        4590,
        4605
      ],
      "content": "Azure event hub"
    },
    {
      "pos": [
        4607,
        4771
      ],
      "content": "The <bpt id=\"p12\">[</bpt>Azure Event\nHub<ept id=\"p12\">](https://azure.microsoft.com/services/event-hubs/)</ept><ph id=\"ph7\"/> service is\nthe recipient of the input provided by the Synthetic Data Source\ndescribed above."
    },
    {
      "pos": [
        4776,
        4809
      ],
      "content": "<bpt id=\"p13\">**</bpt>Data preparation and analysis<ept id=\"p13\">**</ept>"
    },
    {
      "pos": [
        4816,
        4838
      ],
      "content": "Azure Stream Analytics"
    },
    {
      "pos": [
        4840,
        5375
      ],
      "content": "The <bpt id=\"p14\">[</bpt>Azure Stream\nAnalytics<ept id=\"p14\">](https://azure.microsoft.com/services/stream-analytics/)</ept>\nservice is used to provide near real-time analytics on the input stream\nfrom the <bpt id=\"p15\">[</bpt>Azure Event Hub<ept id=\"p15\">](#azure-event-hub)</ept><ph id=\"ph8\"/> service and publish results\nonto a <bpt id=\"p16\">[</bpt>Power BI<ept id=\"p16\">](https://powerbi.microsoft.com)</ept><ph id=\"ph9\"/> dashboard as well as\narchiving all raw incoming events to the <bpt id=\"p17\">[</bpt>Azure\nStorage<ept id=\"p17\">](https://azure.microsoft.com/services/storage/)</ept><ph id=\"ph10\"/> service\nfor later processing by the <bpt id=\"p18\">[</bpt>Azure Data\nFactory<ept id=\"p18\">](https://azure.microsoft.com/documentation/services/data-factory/)</ept>\nservice."
    },
    {
      "pos": [
        5381,
        5411
      ],
      "content": "HD Insights custom aggregation"
    },
    {
      "pos": [
        5413,
        5710
      ],
      "content": "The Azure HD Insight service is used to run\n<bpt id=\"p19\">[</bpt>Hive<ept id=\"p19\">](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)</ept>\nscripts (orchestrated by Azure Data Factory) to provide aggregations on\nthe raw events that were archived using the Azure Stream Analytics\nservice."
    },
    {
      "pos": [
        5716,
        5738
      ],
      "content": "Azure Machine Learning"
    },
    {
      "pos": [
        5740,
        5991
      ],
      "content": "The <bpt id=\"p20\">[</bpt>Azure Machine\nLearning<ept id=\"p20\">](https://azure.microsoft.com/services/machine-learning/)</ept>\nservice is used (orchestrated by Azure Data Factory) to make predictions\non the remaining useful life (RUL) of a particular aircraft engine given\nthe inputs received."
    },
    {
      "pos": [
        5996,
        6015
      ],
      "content": "<bpt id=\"p21\">**</bpt>Data publishing<ept id=\"p21\">**</ept>"
    },
    {
      "pos": [
        6022,
        6048
      ],
      "content": "Azure SQL Database Service"
    },
    {
      "pos": [
        6050,
        6328
      ],
      "content": "The <bpt id=\"p22\">[</bpt>Azure SQL\nDatabase<ept id=\"p22\">](https://azure.microsoft.com/services/sql-database/)</ept>\nservice is used to store (managed by Azure Data Factory) the predictions\nreceived by the Azure Machine Learning service that will be consumed in\nthe <bpt id=\"p23\">[</bpt>Power BI<ept id=\"p23\">](https://powerbi.microsoft.com)</ept><ph id=\"ph11\"/> dashboard."
    },
    {
      "pos": [
        6333,
        6353
      ],
      "content": "<bpt id=\"p24\">**</bpt>Data consumption<ept id=\"p24\">**</ept>"
    },
    {
      "pos": [
        6359,
        6367
      ],
      "content": "Power BI"
    },
    {
      "pos": [
        6369,
        6934
      ],
      "content": "The <bpt id=\"p25\">[</bpt>Power BI<ept id=\"p25\">](https://powerbi.microsoft.com)</ept><ph id=\"ph12\"/> service is used to show a\ndashboard that contains aggregations and alerts provided by the <bpt id=\"p26\">[</bpt>Azure\nStream Analytics<ept id=\"p26\">](https://azure.microsoft.com/services/stream-analytics/)</ept><ph id=\"ph13\"/> service as well as RUL\npredictions stored in <bpt id=\"p27\">[</bpt>Azure SQL Database<ept id=\"p27\">](https://azure.microsoft.com/services/sql-database/)</ept><ph id=\"ph14\"/> that\nwere produced using the <bpt id=\"p28\">[</bpt>Azure Machine\nLearning<ept id=\"p28\">](https://azure.microsoft.com/services/machine-learning/)</ept>\nservice. For Instructions on how to build the Power BI dashboard for this\nSolution Template, refer to the section below.",
      "nodes": [
        {
          "content": "The <bpt id=\"p25\">[</bpt>Power BI<ept id=\"p25\">](https://powerbi.microsoft.com)</ept><ph id=\"ph12\"/> service is used to show a\ndashboard that contains aggregations and alerts provided by the <bpt id=\"p26\">[</bpt>Azure\nStream Analytics<ept id=\"p26\">](https://azure.microsoft.com/services/stream-analytics/)</ept><ph id=\"ph13\"/> service as well as RUL\npredictions stored in <bpt id=\"p27\">[</bpt>Azure SQL Database<ept id=\"p27\">](https://azure.microsoft.com/services/sql-database/)</ept><ph id=\"ph14\"/> that\nwere produced using the <bpt id=\"p28\">[</bpt>Azure Machine\nLearning<ept id=\"p28\">](https://azure.microsoft.com/services/machine-learning/)</ept>\nservice.",
          "pos": [
            0,
            658
          ]
        },
        {
          "content": "For Instructions on how to build the Power BI dashboard for this\nSolution Template, refer to the section below.",
          "pos": [
            659,
            770
          ]
        }
      ]
    },
    {
      "pos": [
        6939,
        6972
      ],
      "content": "<bpt id=\"p29\">**</bpt>How to bring in your own data<ept id=\"p29\">**</ept>"
    },
    {
      "pos": [
        6974,
        7042
      ],
      "content": "This section describes how to bring your own data to Azure, and what"
    },
    {
      "pos": [
        7043,
        7103
      ],
      "content": "areas would require changes for the data you bring into this"
    },
    {
      "pos": [
        7104,
        7117
      ],
      "content": "architecture."
    },
    {
      "pos": [
        7119,
        7681
      ],
      "content": "It's unlikely that any dataset you bring would match the dataset used by\nthe <bpt id=\"p30\">[</bpt>Turbofan Engine Degradation Simulation Data\nSet<ept id=\"p30\">](http://ti.arc.nasa.gov/tech/dash/pcoe/prognostic-data-repository/#turbofan)</ept>\nused for this solution template. Understanding your data and the\nrequirements will be crucial in how you modify this template to work\nwith your own data. If this is your first exposure to the Azure Machine\nLearning service, you can get an introduction to it by using the example\nin <bpt id=\"p31\">[</bpt>How to create your first\nexperiment<ept id=\"p31\">](machine-learning-create-experiment.md)</ept>.",
      "nodes": [
        {
          "content": "It's unlikely that any dataset you bring would match the dataset used by\nthe <bpt id=\"p30\">[</bpt>Turbofan Engine Degradation Simulation Data\nSet<ept id=\"p30\">](http://ti.arc.nasa.gov/tech/dash/pcoe/prognostic-data-repository/#turbofan)</ept>\nused for this solution template.",
          "pos": [
            0,
            275
          ]
        },
        {
          "content": "Understanding your data and the\nrequirements will be crucial in how you modify this template to work\nwith your own data.",
          "pos": [
            276,
            396
          ]
        },
        {
          "content": "If this is your first exposure to the Azure Machine\nLearning service, you can get an introduction to it by using the example\nin <bpt id=\"p31\">[</bpt>How to create your first\nexperiment<ept id=\"p31\">](machine-learning-create-experiment.md)</ept>.",
          "pos": [
            397,
            642
          ]
        }
      ]
    },
    {
      "pos": [
        7683,
        7752
      ],
      "content": "The following sections will discuss the sections of the template that"
    },
    {
      "pos": [
        7753,
        7813
      ],
      "content": "will require modifications when a new dataset is introduced."
    },
    {
      "pos": [
        7819,
        7834
      ],
      "content": "Azure Event Hub"
    },
    {
      "pos": [
        7836,
        7902
      ],
      "content": "The Azure Event Hub service is very generic, such that data can be"
    },
    {
      "pos": [
        7903,
        7973
      ],
      "content": "posted to the hub in either CSV or JSON format. No special processing\n",
      "nodes": [
        {
          "content": "posted to the hub in either CSV or JSON format.",
          "pos": [
            0,
            47
          ]
        },
        {
          "content": "No special processing",
          "pos": [
            48,
            69
          ]
        }
      ]
    },
    {
      "pos": [
        7973,
        8042
      ],
      "content": "occurs in the Azure Event Hub, but it's important that you understand"
    },
    {
      "pos": [
        8043,
        8071
      ],
      "content": "the data that's fed into it."
    },
    {
      "pos": [
        8073,
        8141
      ],
      "content": "This document does not describe how to ingest your data, but you can"
    },
    {
      "pos": [
        8142,
        8210
      ],
      "content": "easily send events or data to an Azure Event Hub using the Event Hub"
    },
    {
      "pos": [
        8211,
        8217
      ],
      "content": "API's."
    },
    {
      "pos": [
        8223,
        8245
      ],
      "content": "Azure Stream Analytics"
    },
    {
      "pos": [
        8247,
        8315
      ],
      "content": "The Azure Stream Analytics service is used to provide near real-time"
    },
    {
      "pos": [
        8316,
        8388
      ],
      "content": "analytics by reading from data streams and outputting data to any number"
    },
    {
      "pos": [
        8389,
        8400
      ],
      "content": "of sources."
    },
    {
      "pos": [
        8402,
        8469
      ],
      "content": "For the Predictive Maintenance for Aerospace Solution Template, the"
    },
    {
      "pos": [
        8470,
        8533
      ],
      "content": "Azure Stream Analytics query consists of four sub-queries, each"
    },
    {
      "pos": [
        8534,
        8606
      ],
      "content": "consuming events from the Azure Event Hub service, and having outputs to"
    },
    {
      "pos": [
        8607,
        8672
      ],
      "content": "four distinct locations. These outputs consist of three Power BI\n",
      "nodes": [
        {
          "content": "four distinct locations.",
          "pos": [
            0,
            24
          ]
        },
        {
          "content": "These outputs consist of three Power BI",
          "pos": [
            25,
            64
          ]
        }
      ]
    },
    {
      "pos": [
        8672,
        8712
      ],
      "content": "datasets and one Azure Storage location."
    },
    {
      "pos": [
        8714,
        8763
      ],
      "content": "The Azure Stream Analytics query can be found by:"
    },
    {
      "pos": [
        8769,
        8798
      ],
      "content": "Logging into the Azure portal"
    },
    {
      "pos": [
        8804,
        9102
      ],
      "leadings": [
        "",
        "    ",
        "    ",
        "    "
      ],
      "content": "Locating the stream analytics jobs <ph id=\"ph15\">![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-stream-analytics.png)</ph><ph id=\"ph16\"/> that were\ngenerated when the solution was deployed (<bpt id=\"p32\">*</bpt>e.g.<ept id=\"p32\">*</ept>,\n<bpt id=\"p33\">**</bpt>maintenancesa02asapbi<ept id=\"p33\">**</ept><ph id=\"ph17\"/> and <bpt id=\"p34\">**</bpt>maintenancesa02asablob<ept id=\"p34\">**</ept><ph id=\"ph18\"/> for the\npredictive maintenance solution)"
    },
    {
      "pos": [
        9108,
        9117
      ],
      "content": "Selecting"
    },
    {
      "pos": [
        9127,
        9163
      ],
      "content": "<bpt id=\"p35\">***</bpt><bpt id=\"p36\"/>INPUTS<ept id=\"p36\">***</ept><ept id=\"p35\"/><ph id=\"ph19\"/> to view the query input"
    },
    {
      "pos": [
        9173,
        9209
      ],
      "content": "<bpt id=\"p37\">***</bpt><bpt id=\"p38\"/>QUERY<ept id=\"p38\">***</ept><ept id=\"p37\"/><ph id=\"ph20\"/> to view the query itself"
    },
    {
      "pos": [
        9219,
        9262
      ],
      "content": "<bpt id=\"p39\">***</bpt><bpt id=\"p40\"/>OUTPUTS<ept id=\"p40\">***</ept><ept id=\"p39\"/><ph id=\"ph21\"/> to view the different outputs"
    },
    {
      "pos": [
        9264,
        9443
      ],
      "content": "Information about Azure Stream Analytics query construction can be found\nin the <bpt id=\"p41\">[</bpt>Stream Analytics Query\nReference<ept id=\"p41\">](https://msdn.microsoft.com/library/azure/dn834998.aspx)</ept>\non MSDN."
    },
    {
      "pos": [
        9445,
        9516
      ],
      "content": "In this solution, the queries output three datasets with near real-time"
    },
    {
      "pos": [
        9517,
        9583
      ],
      "content": "analytics information about the incoming data stream to a Power BI"
    },
    {
      "pos": [
        9584,
        9653
      ],
      "content": "dashboard that's provided as part of this solution template. Because\n",
      "nodes": [
        {
          "content": "dashboard that's provided as part of this solution template.",
          "pos": [
            0,
            60
          ]
        },
        {
          "content": "Because",
          "pos": [
            61,
            68
          ]
        }
      ]
    },
    {
      "pos": [
        9653,
        9725
      ],
      "content": "there's implicit knowledge about the incoming data format, these queries"
    },
    {
      "pos": [
        9726,
        9777
      ],
      "content": "would need to be altered based on your data format."
    },
    {
      "pos": [
        9779,
        10122
      ],
      "content": "The query in the second stream analytics job <bpt id=\"p42\">**</bpt>maintenancesa02asablob<ept id=\"p42\">**</ept><ph id=\"ph22\"/> simply outputs all <bpt id=\"p43\">[</bpt>Event\nHub<ept id=\"p43\">](https://azure.microsoft.com/services/event-hubs/)</ept><ph id=\"ph23\"/> events to\n<bpt id=\"p44\">[</bpt>Azure Storage<ept id=\"p44\">](https://azure.microsoft.com/services/storage/)</ept><ph id=\"ph24\"/> and\nhence requires no alteration regardless of your data format as the full\nevent information is streamed to storage."
    },
    {
      "pos": [
        10128,
        10146
      ],
      "content": "Azure Data Factory"
    },
    {
      "pos": [
        10148,
        10950
      ],
      "content": "The <bpt id=\"p45\">[</bpt>Azure Data\nFactory<ept id=\"p45\">](https://azure.microsoft.com/documentation/services/data-factory/)</ept>\nservice orchestrates the movement and processing of data. In the\nPredictive Maintenance for Aerospace Solution Template the data factory\nis made up of three\n<bpt id=\"p46\">[</bpt>pipelines<ept id=\"p46\">](../data-factory/data-factory-create-pipelines.md)</ept>\nthat move and process the data using various technologies.  You can access your data factory by opening the the Data Factory node at the bottom of the solution template diagram created with the deployment of the solution. This will take you to the data factory on your Azure portal. If you see errors under your datasets, you can ignore those as they are due to data factory being deployed before the data generator was started. Those errors do not prevent your data factory from functioning.",
      "nodes": [
        {
          "content": "The <bpt id=\"p45\">[</bpt>Azure Data\nFactory<ept id=\"p45\">](https://azure.microsoft.com/documentation/services/data-factory/)</ept>\nservice orchestrates the movement and processing of data.",
          "pos": [
            0,
            188
          ]
        },
        {
          "content": "In the\nPredictive Maintenance for Aerospace Solution Template the data factory\nis made up of three\n<bpt id=\"p46\">[</bpt>pipelines<ept id=\"p46\">](../data-factory/data-factory-create-pipelines.md)</ept>\nthat move and process the data using various technologies.",
          "pos": [
            189,
            448
          ]
        },
        {
          "content": "You can access your data factory by opening the the Data Factory node at the bottom of the solution template diagram created with the deployment of the solution.",
          "pos": [
            450,
            611
          ]
        },
        {
          "content": "This will take you to the data factory on your Azure portal.",
          "pos": [
            612,
            672
          ]
        },
        {
          "content": "If you see errors under your datasets, you can ignore those as they are due to data factory being deployed before the data generator was started.",
          "pos": [
            673,
            818
          ]
        },
        {
          "content": "Those errors do not prevent your data factory from functioning.",
          "pos": [
            819,
            882
          ]
        }
      ]
    },
    {
      "pos": [
        11052,
        11365
      ],
      "content": "This section discusses the necessary <bpt id=\"p47\">[</bpt>pipelines<ept id=\"p47\">](../data-factory/data-factory-create-pipelines.md)</ept><ph id=\"ph26\"/> and <bpt id=\"p48\">[</bpt>activities<ept id=\"p48\">](../data-factory/data-factory-create-pipelines.md)</ept><ph id=\"ph27\"/> contained in the <bpt id=\"p49\">[</bpt>Azure Data\nFactory<ept id=\"p49\">](https://azure.microsoft.com/documentation/services/data-factory/)</ept>. Below is the diagram view of the solution.",
      "nodes": [
        {
          "content": "This section discusses the necessary <bpt id=\"p47\">[</bpt>pipelines<ept id=\"p47\">](../data-factory/data-factory-create-pipelines.md)</ept><ph id=\"ph26\"/> and <bpt id=\"p48\">[</bpt>activities<ept id=\"p48\">](../data-factory/data-factory-create-pipelines.md)</ept><ph id=\"ph27\"/> contained in the <bpt id=\"p49\">[</bpt>Azure Data\nFactory<ept id=\"p49\">](https://azure.microsoft.com/documentation/services/data-factory/)</ept>.",
          "pos": [
            0,
            420
          ]
        },
        {
          "content": "Below is the diagram view of the solution.",
          "pos": [
            421,
            463
          ]
        }
      ]
    },
    {
      "pos": [
        11459,
        11951
      ],
      "content": "Two of the pipelines of this factory contain\n<bpt id=\"p50\">[</bpt>Hive<ept id=\"p50\">](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)</ept>\nscripts that are used to partition and aggregate the data. When noted,\nthe scripts will be located in the <bpt id=\"p51\">[</bpt>Azure\nStorage<ept id=\"p51\">](https://azure.microsoft.com/services/storage/)</ept><ph id=\"ph29\"/> account\ncreated during setup. Their location will be:\nmaintenancesascript\\\\\\\\script\\\\\\\\hive\\\\\\\\ (or https://[Your solution\nname].blob.core.windows.net/maintenancesascript).",
      "nodes": [
        {
          "content": "Two of the pipelines of this factory contain\n<bpt id=\"p50\">[</bpt>Hive<ept id=\"p50\">](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)</ept>\nscripts that are used to partition and aggregate the data.",
          "pos": [
            0,
            249
          ]
        },
        {
          "content": "When noted,\nthe scripts will be located in the <bpt id=\"p51\">[</bpt>Azure\nStorage<ept id=\"p51\">](https://azure.microsoft.com/services/storage/)</ept><ph id=\"ph29\"/> account\ncreated during setup.",
          "pos": [
            250,
            444
          ]
        },
        {
          "content": "Their location will be:\nmaintenancesascript\\\\\\\\script\\\\\\\\hive\\\\\\\\ (or https://[Your solution\nname].blob.core.windows.net/maintenancesascript).",
          "pos": [
            445,
            587
          ]
        }
      ]
    },
    {
      "pos": [
        11953,
        12362
      ],
      "content": "Similar to the <bpt id=\"p52\">[</bpt>Azure Stream Analytics<ept id=\"p52\">](#azure-stream-analytics-1)</ept>\nqueries, the\n<bpt id=\"p53\">[</bpt>Hive<ept id=\"p53\">](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)</ept>\nscripts have implicit knowledge about the incoming data format, these\nqueries would need to be altered based on your data format and <bpt id=\"p54\">[</bpt>feature\nengineering<ept id=\"p54\">](machine-learning-feature-selection-and-engineering.md)</ept>\nrequirements."
    },
    {
      "pos": [
        12369,
        12398
      ],
      "content": "<bpt id=\"p55\">*</bpt>AggregateFlightInfoPipeline<ept id=\"p55\">*</ept>"
    },
    {
      "pos": [
        12400,
        12972
      ],
      "content": "This\n<bpt id=\"p56\">[</bpt>pipeline<ept id=\"p56\">](../data-factory/data-factory-create-pipelines.md)</ept>\ncontains a single activity - an\n<bpt id=\"p57\">[</bpt>HDInsightHive<ept id=\"p57\">](../data-factory/data-factory-hive-activity.md)</ept>\nactivity using a\n<bpt id=\"p58\">[</bpt>HDInsightLinkedService<ept id=\"p58\">](https://msdn.microsoft.com/library/azure/dn893526.aspx)</ept>\nthat runs a\n<bpt id=\"p59\">[</bpt>Hive<ept id=\"p59\">](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)</ept>\nscript to partition the data put in <bpt id=\"p60\">[</bpt>Azure\nStorage<ept id=\"p60\">](https://azure.microsoft.com/services/storage/)</ept><ph id=\"ph30\"/> during the\n<bpt id=\"p61\">[</bpt>Azure Stream\nAnalytics<ept id=\"p61\">](https://azure.microsoft.com/services/stream-analytics/)</ept>\njob."
    },
    {
      "pos": [
        12974,
        13150
      ],
      "content": "The\n<bpt id=\"p62\">[</bpt>Hive<ept id=\"p62\">](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)</ept>\nscript for this partitioning task is <bpt id=\"p63\">***</bpt><bpt id=\"p64\"/>AggregateFlightInfo.hql<ept id=\"p64\">***</ept><ept id=\"p63\"/>"
    },
    {
      "pos": [
        13157,
        13176
      ],
      "content": "<bpt id=\"p65\">*</bpt>MLScoringPipeline<ept id=\"p65\">*</ept>"
    },
    {
      "pos": [
        13178,
        13459
      ],
      "content": "This\n<bpt id=\"p66\">[</bpt>pipeline<ept id=\"p66\">](../data-factory/data-factory-create-pipelines.md)</ept>\ncontains several activities and whose end result is the scored\npredictions from the <bpt id=\"p67\">[</bpt>Azure Machine\nLearning<ept id=\"p67\">](https://azure.microsoft.com/services/machine-learning/)</ept>\nexperiment associated with this solution template."
    },
    {
      "pos": [
        13461,
        13498
      ],
      "content": "The activities contained in this are:"
    },
    {
      "pos": [
        13504,
        14162
      ],
      "leadings": [
        "",
        "    ",
        "    ",
        "    ",
        "    ",
        "    ",
        "    ",
        "    ",
        "    ",
        "    ",
        "    "
      ],
      "content": "<bpt id=\"p68\">[</bpt>HDInsightHive<ept id=\"p68\">](../data-factory/data-factory-hive-activity.md)</ept>\nactivity using an\n<bpt id=\"p69\">[</bpt>HDInsightLinkedService<ept id=\"p69\">](https://msdn.microsoft.com/library/azure/dn893526.aspx)</ept>\nthat runs a\n<bpt id=\"p70\">[</bpt>Hive<ept id=\"p70\">](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)</ept>\nscript to perform aggregations and feature engineering necessary for\nthe <bpt id=\"p71\">[</bpt>Azure Machine\nLearning<ept id=\"p71\">](https://azure.microsoft.com/services/machine-learning/)</ept><ph id=\"ph31\"/> experiment.\nThe\n<bpt id=\"p72\">[</bpt>Hive<ept id=\"p72\">](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)</ept>\nscript for this partitioning task is <bpt id=\"p73\">***</bpt><bpt id=\"p74\"/>PrepareMLInput.hql<ept id=\"p74\">***</ept><ept id=\"p73\"/>.",
      "nodes": [
        {
          "content": "<bpt id=\"p68\">[</bpt>HDInsightHive<ept id=\"p68\">](../data-factory/data-factory-hive-activity.md)</ept>\nactivity using an\n<bpt id=\"p69\">[</bpt>HDInsightLinkedService<ept id=\"p69\">](https://msdn.microsoft.com/library/azure/dn893526.aspx)</ept>\nthat runs a\n<bpt id=\"p70\">[</bpt>Hive<ept id=\"p70\">](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)</ept>\nscript to perform aggregations and feature engineering necessary for\nthe <bpt id=\"p71\">[</bpt>Azure Machine\nLearning<ept id=\"p71\">](https://azure.microsoft.com/services/machine-learning/)</ept><ph id=\"ph31\"/> experiment.",
          "pos": [
            0,
            620
          ]
        },
        {
          "content": "The\n<bpt id=\"p72\">[</bpt>Hive<ept id=\"p72\">](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)</ept>\nscript for this partitioning task is <bpt id=\"p73\">***</bpt><bpt id=\"p74\"/>PrepareMLInput.hql<ept id=\"p74\">***</ept><ept id=\"p73\"/>.",
          "pos": [
            621,
            903
          ]
        }
      ]
    },
    {
      "pos": [
        14168,
        14561
      ],
      "leadings": [
        "",
        "    ",
        "    ",
        "    ",
        "    ",
        "    ",
        "    "
      ],
      "content": "<bpt id=\"p75\">[</bpt>Copy<ept id=\"p75\">](https://msdn.microsoft.com/library/azure/dn835035.aspx)</ept>\nactivity that moves the results from the\n<bpt id=\"p76\">[</bpt>HDInsightHive<ept id=\"p76\">](../data-factory/data-factory-hive-activity.md)</ept>\nactivity to a single <bpt id=\"p77\">[</bpt>Azure\nStorage<ept id=\"p77\">](https://azure.microsoft.com/services/storage/)</ept><ph id=\"ph32\"/> blob\nthat can be access by the\n<bpt id=\"p78\">[</bpt>AzureMLBatchScoring<ept id=\"p78\">](https://msdn.microsoft.com/library/azure/dn894009.aspx)</ept><ph id=\"ph33\"/> activity."
    },
    {
      "pos": [
        14567,
        14896
      ],
      "leadings": [
        "",
        "    ",
        "    ",
        "    ",
        "    "
      ],
      "content": "<bpt id=\"p79\">[</bpt>AzureMLBatchScoring<ept id=\"p79\">](https://msdn.microsoft.com/library/azure/dn894009.aspx)</ept>\nactivity that calls the <bpt id=\"p80\">[</bpt>Azure Machine\nLearning<ept id=\"p80\">](https://azure.microsoft.com/services/machine-learning/)</ept>\nexperiment which results in the results being put in a single <bpt id=\"p81\">[</bpt>Azure\nStorage<ept id=\"p81\">](https://azure.microsoft.com/services/storage/)</ept><ph id=\"ph34\"/> blob."
    },
    {
      "pos": [
        14903,
        14929
      ],
      "content": "<bpt id=\"p82\">*</bpt>CopyScoredResultPipeline<ept id=\"p82\">*</ept>"
    },
    {
      "pos": [
        14931,
        15371
      ],
      "content": "This\n<bpt id=\"p83\">[</bpt>pipeline<ept id=\"p83\">](../data-factory/data-factory-create-pipelines.md)</ept>\ncontains a single activity - a\n<bpt id=\"p84\">[</bpt>Copy<ept id=\"p84\">](https://msdn.microsoft.com/library/azure/dn835035.aspx)</ept>\nactivity that moves the results of the <bpt id=\"p85\">[</bpt>Azure Machine\nLearning<ept id=\"p85\">](#azure-machine-learning)</ept><ph id=\"ph35\"/> experiment from the\n<bpt id=\"p86\">***</bpt><bpt id=\"p87\"/>MLScoringPipeline<ept id=\"p87\">***</ept><ept id=\"p86\"/><ph id=\"ph36\"/> to the <bpt id=\"p88\">[</bpt>Azure SQL\nDatabase<ept id=\"p88\">](https://azure.microsoft.com/services/sql-database/)</ept><ph id=\"ph37\"/> that was provisioned as part of the\nsolution template installation."
    },
    {
      "pos": [
        15377,
        15399
      ],
      "content": "Azure Machine Learning"
    },
    {
      "pos": [
        15401,
        15739
      ],
      "content": "The <bpt id=\"p89\">[</bpt>Azure Machine\nLearning<ept id=\"p89\">](https://azure.microsoft.com/services/machine-learning/)</ept>\nexperiment used for this solution template provides the Remaining Useful\nLife (RUL) of an aircraft engine. The experiment is specific to the data\nset consumed and therefore will require modification or replacement\nspecific to the data that's brought in.",
      "nodes": [
        {
          "content": "The <bpt id=\"p89\">[</bpt>Azure Machine\nLearning<ept id=\"p89\">](https://azure.microsoft.com/services/machine-learning/)</ept>\nexperiment used for this solution template provides the Remaining Useful\nLife (RUL) of an aircraft engine.",
          "pos": [
            0,
            231
          ]
        },
        {
          "content": "The experiment is specific to the data\nset consumed and therefore will require modification or replacement\nspecific to the data that's brought in.",
          "pos": [
            232,
            378
          ]
        }
      ]
    },
    {
      "pos": [
        15741,
        16028
      ],
      "content": "For information about how the Azure Machine Learning experiment was\ncreated, see <bpt id=\"p90\">[</bpt>Predictive Maintenance: Step 1 of 3, data preparation and feature engineering<ept id=\"p90\">](http://gallery.cortanaanalytics.com/Experiment/Predictive-Maintenance-Step-1-of-3-data-preparation-and-feature-engineering-2)</ept>."
    },
    {
      "pos": [
        16033,
        16053
      ],
      "content": "<bpt id=\"p91\">**</bpt>Monitor Progress<ept id=\"p91\">**</ept>"
    },
    {
      "pos": [
        16055,
        16299
      ],
      "content": "Once the Data Generator is launched, the pipeline begins to get hydrated and the different components of your solution start kicking into action following the commands issued by the Data Factory. There are two ways you can monitor the pipeline.",
      "nodes": [
        {
          "content": "Once the Data Generator is launched, the pipeline begins to get hydrated and the different components of your solution start kicking into action following the commands issued by the Data Factory.",
          "pos": [
            0,
            195
          ]
        },
        {
          "content": "There are two ways you can monitor the pipeline.",
          "pos": [
            196,
            244
          ]
        }
      ]
    },
    {
      "pos": [
        16304,
        17076
      ],
      "content": "One of the Stream Analytics job writes the raw incoming data to blob storage. If you click on Blob Storage component of your solution from the screen you successfully deployed the solution and then click Open in the right panel, it will take you to the <bpt id=\"p92\">[</bpt>management portal<ept id=\"p92\">](https://portal.azure.com/)</ept>. Once there, click on Blobs. In the next panel, you will see a list of Containers. Click on <bpt id=\"p93\">**</bpt>maintenancesadata<ept id=\"p93\">**</ept>. In the next panel, you will see the <bpt id=\"p94\">**</bpt>rawdata<ept id=\"p94\">**</ept><ph id=\"ph38\"/> folder. Inside the rawdata folder, you will see folders with names such as hour=17, hour=18 etc. If you see these folders, it indicates that the raw data is successfully being generated on your computer and stored in blob storage. You should see csv files that should have finite sizes in MB in those folders.",
      "nodes": [
        {
          "content": "One of the Stream Analytics job writes the raw incoming data to blob storage.",
          "pos": [
            0,
            77
          ]
        },
        {
          "content": "If you click on Blob Storage component of your solution from the screen you successfully deployed the solution and then click Open in the right panel, it will take you to the <bpt id=\"p92\">[</bpt>management portal<ept id=\"p92\">](https://portal.azure.com/)</ept>.",
          "pos": [
            78,
            340
          ]
        },
        {
          "content": "Once there, click on Blobs.",
          "pos": [
            341,
            368
          ]
        },
        {
          "content": "In the next panel, you will see a list of Containers.",
          "pos": [
            369,
            422
          ]
        },
        {
          "content": "Click on <bpt id=\"p93\">**</bpt>maintenancesadata<ept id=\"p93\">**</ept>.",
          "pos": [
            423,
            494
          ]
        },
        {
          "content": "In the next panel, you will see the <bpt id=\"p94\">**</bpt>rawdata<ept id=\"p94\">**</ept><ph id=\"ph38\"/> folder.",
          "pos": [
            495,
            605
          ]
        },
        {
          "content": "Inside the rawdata folder, you will see folders with names such as hour=17, hour=18 etc. If you see these folders, it indicates that the raw data is successfully being generated on your computer and stored in blob storage.",
          "pos": [
            606,
            828
          ]
        },
        {
          "content": "You should see csv files that should have finite sizes in MB in those folders.",
          "pos": [
            829,
            907
          ]
        }
      ]
    },
    {
      "pos": [
        17081,
        17656
      ],
      "content": "The last step of the pipeline is to write data (e.g. predictions from machine learning) into SQL Database. You might have to wait a maximum of three hours for the data to appear in SQL Database. One way to monitor how much data is available in your SQL Database is through <bpt id=\"p95\">[</bpt>azure portal<ept id=\"p95\">](https://manage.windowsazure.com/)</ept>.On the left panel locate SQL DATABASES <ph id=\"ph39\">![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-SQL-databases.png)</ph><ph id=\"ph40\"/> and click it. Then locate your database <bpt id=\"p96\">**</bpt>pmaintenancedb<ept id=\"p96\">**</ept><ph id=\"ph41\"/> and click on it. On the next page at the bottom, click on MANAGE",
      "nodes": [
        {
          "content": "The last step of the pipeline is to write data (e.g. predictions from machine learning) into SQL Database.",
          "pos": [
            0,
            106
          ]
        },
        {
          "content": "You might have to wait a maximum of three hours for the data to appear in SQL Database.",
          "pos": [
            107,
            194
          ]
        },
        {
          "content": "One way to monitor how much data is available in your SQL Database is through <bpt id=\"p95\">[</bpt>azure portal<ept id=\"p95\">](https://manage.windowsazure.com/)</ept>.On the left panel locate SQL DATABASES <ph id=\"ph39\">![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-SQL-databases.png)</ph><ph id=\"ph40\"/> and click it.",
          "pos": [
            195,
            539
          ]
        },
        {
          "content": "Then locate your database <bpt id=\"p96\">**</bpt>pmaintenancedb<ept id=\"p96\">**</ept><ph id=\"ph41\"/> and click on it.",
          "pos": [
            540,
            656
          ]
        },
        {
          "content": "On the next page at the bottom, click on MANAGE",
          "pos": [
            657,
            704
          ]
        }
      ]
    },
    {
      "pos": [
        17662,
        17746
      ],
      "content": "<ph id=\"ph42\">![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-manage.png)</ph>."
    },
    {
      "pos": [
        17752,
        17930
      ],
      "content": "Here, you can click on New Query and query for the number of rows (e.g. select count(*) from PMResult ). As your database grows, the number of rows in the table should  increase.",
      "nodes": [
        {
          "content": "Here, you can click on New Query and query for the number of rows (e.g. select count(*) from PMResult ).",
          "pos": [
            0,
            104
          ]
        },
        {
          "content": "As your database grows, the number of rows in the table should  increase.",
          "pos": [
            105,
            178
          ]
        }
      ]
    },
    {
      "pos": [
        17936,
        17958
      ],
      "content": "<bpt id=\"p97\">**</bpt>Power BI Dashboard<ept id=\"p97\">**</ept>"
    },
    {
      "pos": [
        17964,
        17972
      ],
      "content": "Overview"
    },
    {
      "pos": [
        17974,
        18042
      ],
      "content": "This section describes how to set up Power BI dashboard to visualize"
    },
    {
      "pos": [
        18043,
        18113
      ],
      "content": "your real time data from Azure stream analytics (hot path), as well as"
    },
    {
      "pos": [
        18114,
        18179
      ],
      "content": "batch prediction results from Azure machine learning (cold path)."
    },
    {
      "pos": [
        18185,
        18210
      ],
      "content": "Setup cold path dashboard"
    },
    {
      "pos": [
        18212,
        18276
      ],
      "content": "In the cold path data pipeline, the essential goal is to get the"
    },
    {
      "pos": [
        18277,
        18347
      ],
      "content": "predictive RUL (remaining useful life) of each aircraft engine once it"
    },
    {
      "pos": [
        18348,
        18416
      ],
      "content": "finishes a flight (cycle). The prediction result is updated every 3\n",
      "nodes": [
        {
          "content": "finishes a flight (cycle).",
          "pos": [
            0,
            26
          ]
        },
        {
          "content": "The prediction result is updated every 3",
          "pos": [
            27,
            67
          ]
        }
      ]
    },
    {
      "pos": [
        18416,
        18485
      ],
      "content": "hours for predicting the aircraft engines that have finished a flight"
    },
    {
      "pos": [
        18486,
        18510
      ],
      "content": "during the past 3 hours."
    },
    {
      "pos": [
        18512,
        19028
      ],
      "content": "Power BI connects to an Azure SQL database as its data source, where the\nprediction results are stored. Note: 1) Upon deploying your\nsolution, a real prediction will show up in the database within 3 hours.\nThe pbix file that came with the Generator download contains some seed\ndata so that you may create the Power BI dashboard right away. 2) In\nthis step, the prerequisite is to download and install the free software\n<bpt id=\"p98\">[</bpt>Power BI\ndesktop<ept id=\"p98\">](https://powerbi.microsoft.com/documentation/powerbi-desktop-get-the-desktop/)</ept>.",
      "nodes": [
        {
          "content": "Power BI connects to an Azure SQL database as its data source, where the\nprediction results are stored.",
          "pos": [
            0,
            103
          ]
        },
        {
          "content": "Note: 1) Upon deploying your\nsolution, a real prediction will show up in the database within 3 hours.",
          "pos": [
            104,
            205
          ]
        },
        {
          "content": "The pbix file that came with the Generator download contains some seed\ndata so that you may create the Power BI dashboard right away.",
          "pos": [
            206,
            339
          ]
        },
        {
          "content": "2) In\nthis step, the prerequisite is to download and install the free software\n<bpt id=\"p98\">[</bpt>Power BI\ndesktop<ept id=\"p98\">](https://powerbi.microsoft.com/documentation/powerbi-desktop-get-the-desktop/)</ept>.",
          "pos": [
            340,
            556
          ]
        }
      ]
    },
    {
      "pos": [
        19030,
        19232
      ],
      "content": "The following steps will guide you on how to connect the pbix file to\nthe SQL Database that was spun up at the time of solution deployment\ncontaining data (<bpt id=\"p99\">*</bpt>e.g.<ept id=\"p99\">*</ept>. prediction results) for visualization.",
      "nodes": [
        {
          "content": "The following steps will guide you on how to connect the pbix file to\nthe SQL Database that was spun up at the time of solution deployment\ncontaining data (<bpt id=\"p99\">*</bpt>e.g.<ept id=\"p99\">*</ept>.",
          "pos": [
            0,
            203
          ]
        },
        {
          "content": "prediction results) for visualization.",
          "pos": [
            204,
            242
          ]
        }
      ]
    },
    {
      "pos": [
        19238,
        19267
      ],
      "content": "Get the database credentials."
    },
    {
      "pos": [
        19273,
        19435
      ],
      "leadings": [
        "",
        "    ",
        "    "
      ],
      "content": "You'll need <bpt id=\"p100\">**</bpt>database server name, database name, user name and\npassword<ept id=\"p100\">**</ept><ph id=\"ph43\"/> before moving to next steps. Here are the steps to guide\nyou how to find them.",
      "nodes": [
        {
          "content": "You'll need <bpt id=\"p100\">**</bpt>database server name, database name, user name and\npassword<ept id=\"p100\">**</ept><ph id=\"ph43\"/> before moving to next steps.",
          "pos": [
            0,
            161
          ]
        },
        {
          "content": "Here are the steps to guide\nyou how to find them.",
          "pos": [
            162,
            211
          ]
        }
      ]
    },
    {
      "pos": [
        19445,
        19557
      ],
      "content": "Once <bpt id=\"p101\">**</bpt>'Azure SQL Database'<ept id=\"p101\">**</ept><ph id=\"ph44\"/> on your solution template diagram turns green, click it and then click <bpt id=\"p102\">**</bpt>'Open'<ept id=\"p102\">**</ept>."
    },
    {
      "pos": [
        19567,
        19691
      ],
      "leadings": [
        "",
        "    "
      ],
      "content": "You'll see a new browser tab/window which displays the Azure\nportal page. Click <bpt id=\"p103\">**</bpt>'Resource groups'<ept id=\"p103\">**</ept><ph id=\"ph45\"/> on the left panel.",
      "nodes": [
        {
          "content": "You'll see a new browser tab/window which displays the Azure\nportal page.",
          "pos": [
            0,
            73
          ]
        },
        {
          "content": "Click <bpt id=\"p103\">**</bpt>'Resource groups'<ept id=\"p103\">**</ept><ph id=\"ph45\"/> on the left panel.",
          "pos": [
            74,
            177
          ]
        }
      ]
    },
    {
      "pos": [
        19701,
        19824
      ],
      "leadings": [
        "",
        "    "
      ],
      "content": "Select the subscription you're using for deploying the solution, and\nthen select <bpt id=\"p104\">**</bpt>'YourSolutionName\\_ResourceGroup'<ept id=\"p104\">**</ept>."
    },
    {
      "pos": [
        19834,
        20205
      ],
      "leadings": [
        "",
        "    "
      ],
      "content": "In the new pop out panel, click the  <ph id=\"ph46\">![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-sql.png)</ph><ph id=\"ph47\"/> icon to access your\ndatabase. Your database name is next to the this icon (<bpt id=\"p105\">*</bpt>e.g.<ept id=\"p105\">*</ept>, <bpt id=\"p106\">**</bpt>'pmaintenancedb'<ept id=\"p106\">**</ept>), and  the <bpt id=\"p107\">**</bpt>database server name<ept id=\"p107\">**</ept><ph id=\"ph48\"/> is listed under the Server name property and should look similar to <bpt id=\"p108\">**</bpt>YourSoutionName.database.windows.net<ept id=\"p108\">**</ept>.",
      "nodes": [
        {
          "content": "In the new pop out panel, click the  <ph id=\"ph46\">![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-sql.png)</ph><ph id=\"ph47\"/> icon to access your\ndatabase.",
          "pos": [
            0,
            181
          ]
        },
        {
          "content": "Your database name is next to the this icon (<bpt id=\"p105\">*</bpt>e.g.<ept id=\"p105\">*</ept>, <bpt id=\"p106\">**</bpt>'pmaintenancedb'<ept id=\"p106\">**</ept>), and  the <bpt id=\"p107\">**</bpt>database server name<ept id=\"p107\">**</ept><ph id=\"ph48\"/> is listed under the Server name property and should look similar to <bpt id=\"p108\">**</bpt>YourSoutionName.database.windows.net<ept id=\"p108\">**</ept>.",
          "pos": [
            182,
            584
          ]
        }
      ]
    },
    {
      "pos": [
        20215,
        20359
      ],
      "leadings": [
        "",
        "    "
      ],
      "content": "Your database <bpt id=\"p109\">**</bpt>username<ept id=\"p109\">**</ept><ph id=\"ph49\"/> and <bpt id=\"p110\">**</bpt>password<ept id=\"p110\">**</ept><ph id=\"ph50\"/> are the same as\nthe username and password previously recorded during deployment of the solution."
    },
    {
      "pos": [
        20365,
        20443
      ],
      "leadings": [
        "",
        "    "
      ],
      "content": "Update the data source of the cold path report file with Power\nBI Desktop."
    },
    {
      "pos": [
        20453,
        20730
      ],
      "leadings": [
        "",
        "    ",
        "    "
      ],
      "content": "In the folder on your PC where you downloaded and unzipped the\nGenerator file, double-click the\n<bpt id=\"p111\">**</bpt>PowerBI\\\\PredictiveMaintenanceAerospace.pbix<ept id=\"p111\">**</ept><ph id=\"ph51\"/> file. If you see any warning messages when you open the file, ignore them. On the top of the file, click <bpt id=\"p112\">**</bpt>'Edit Queries'<ept id=\"p112\">**</ept>.",
      "nodes": [
        {
          "content": "In the folder on your PC where you downloaded and unzipped the\nGenerator file, double-click the\n<bpt id=\"p111\">**</bpt>PowerBI\\\\PredictiveMaintenanceAerospace.pbix<ept id=\"p111\">**</ept><ph id=\"ph51\"/> file.",
          "pos": [
            0,
            207
          ]
        },
        {
          "content": "If you see any warning messages when you open the file, ignore them.",
          "pos": [
            208,
            276
          ]
        },
        {
          "content": "On the top of the file, click <bpt id=\"p112\">**</bpt>'Edit Queries'<ept id=\"p112\">**</ept>.",
          "pos": [
            277,
            368
          ]
        }
      ]
    },
    {
      "pos": [
        20834,
        21168
      ],
      "leadings": [
        "",
        "        ",
        "        "
      ],
      "content": "You'll see two tables, <bpt id=\"p113\">**</bpt>RemainingUsefulLife<ept id=\"p113\">**</ept><ph id=\"ph53\"/> and <bpt id=\"p114\">**</bpt>PMResult<ept id=\"p114\">**</ept>. Select the first table and click <ph id=\"ph54\">![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-query-settings.png)</ph><ph id=\"ph55\"/> next to <bpt id=\"p115\">**</bpt>'Source'<ept id=\"p115\">**</ept><ph id=\"ph56\"/> under\n<bpt id=\"p116\">**</bpt>'APPLIED STEPS'<ept id=\"p116\">**</ept><ph id=\"ph57\"/> on the right <bpt id=\"p117\">**</bpt>'Query Settings'<ept id=\"p117\">**</ept><ph id=\"ph58\"/> panel. Ignore\nany warning messages that appear.",
      "nodes": [
        {
          "content": "You'll see two tables, <bpt id=\"p113\">**</bpt>RemainingUsefulLife<ept id=\"p113\">**</ept><ph id=\"ph53\"/> and <bpt id=\"p114\">**</bpt>PMResult<ept id=\"p114\">**</ept>.",
          "pos": [
            0,
            163
          ]
        },
        {
          "content": "Select the first table and click <ph id=\"ph54\">![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-query-settings.png)</ph><ph id=\"ph55\"/> next to <bpt id=\"p115\">**</bpt>'Source'<ept id=\"p115\">**</ept><ph id=\"ph56\"/> under\n<bpt id=\"p116\">**</bpt>'APPLIED STEPS'<ept id=\"p116\">**</ept><ph id=\"ph57\"/> on the right <bpt id=\"p117\">**</bpt>'Query Settings'<ept id=\"p117\">**</ept><ph id=\"ph58\"/> panel.",
          "pos": [
            164,
            581
          ]
        },
        {
          "content": "Ignore\nany warning messages that appear.",
          "pos": [
            582,
            622
          ]
        }
      ]
    },
    {
      "pos": [
        21178,
        21528
      ],
      "leadings": [
        "",
        "    ",
        "    ",
        "    ",
        "    "
      ],
      "content": "In the pop out window, replace <bpt id=\"p118\">**</bpt>'Server'<ept id=\"p118\">**</ept><ph id=\"ph59\"/> and <bpt id=\"p119\">**</bpt>'Database'<ept id=\"p119\">**</ept><ph id=\"ph60\"/> with\nyour own server and database names, and then click <bpt id=\"p120\">**</bpt>'OK'<ept id=\"p120\">**</ept>. For server\nname, make sure you specify the port 1433\n(<bpt id=\"p121\">**</bpt>YourSoutionName.database.windows.net, 1433<ept id=\"p121\">**</ept>). Leave the Database field as <bpt id=\"p122\">**</bpt>pmaintenancedb<ept id=\"p122\">**</ept>. Ignore the warning\nmessages that appear on the screen.",
      "nodes": [
        {
          "content": "In the pop out window, replace <bpt id=\"p118\">**</bpt>'Server'<ept id=\"p118\">**</ept><ph id=\"ph59\"/> and <bpt id=\"p119\">**</bpt>'Database'<ept id=\"p119\">**</ept><ph id=\"ph60\"/> with\nyour own server and database names, and then click <bpt id=\"p120\">**</bpt>'OK'<ept id=\"p120\">**</ept>.",
          "pos": [
            0,
            284
          ]
        },
        {
          "content": "For server\nname, make sure you specify the port 1433\n(<bpt id=\"p121\">**</bpt>YourSoutionName.database.windows.net, 1433<ept id=\"p121\">**</ept>).",
          "pos": [
            285,
            429
          ]
        },
        {
          "content": "Leave the Database field as <bpt id=\"p122\">**</bpt>pmaintenancedb<ept id=\"p122\">**</ept>.",
          "pos": [
            430,
            519
          ]
        },
        {
          "content": "Ignore the warning\nmessages that appear on the screen.",
          "pos": [
            520,
            574
          ]
        }
      ]
    },
    {
      "pos": [
        21538,
        21961
      ],
      "leadings": [
        "",
        "    ",
        "    ",
        "    ",
        "    ",
        "    ",
        "    "
      ],
      "content": "In the next pop out window, you'll see two options on the left pane\n(<bpt id=\"p123\">**</bpt>Windows<ept id=\"p123\">**</ept><ph id=\"ph61\"/> and <bpt id=\"p124\">**</bpt>Database<ept id=\"p124\">**</ept>). Click <bpt id=\"p125\">**</bpt>'Database'<ept id=\"p125\">**</ept>, fill in your\n<bpt id=\"p126\">**</bpt>'Username'<ept id=\"p126\">**</ept><ph id=\"ph62\"/> and <bpt id=\"p127\">**</bpt>'Password'<ept id=\"p127\">**</ept><ph id=\"ph63\"/> (this is the username and password\nyou entered when you first deployed the solution and created an\nAzure SQL database). In <bpt id=\"p128\">***</bpt><bpt id=\"p129\"/>Select which level to apply these\nsettings to<ept id=\"p129\">***</ept><ept id=\"p128\"/>, check database level option. Then click\n<bpt id=\"p130\">**</bpt>'Connect'<ept id=\"p130\">**</ept>.",
      "nodes": [
        {
          "content": "In the next pop out window, you'll see two options on the left pane\n(<bpt id=\"p123\">**</bpt>Windows<ept id=\"p123\">**</ept><ph id=\"ph61\"/> and <bpt id=\"p124\">**</bpt>Database<ept id=\"p124\">**</ept>).",
          "pos": [
            0,
            198
          ]
        },
        {
          "content": "Click <bpt id=\"p125\">**</bpt>'Database'<ept id=\"p125\">**</ept>, fill in your\n<bpt id=\"p126\">**</bpt>'Username'<ept id=\"p126\">**</ept><ph id=\"ph62\"/> and <bpt id=\"p127\">**</bpt>'Password'<ept id=\"p127\">**</ept><ph id=\"ph63\"/> (this is the username and password\nyou entered when you first deployed the solution and created an\nAzure SQL database).",
          "pos": [
            199,
            543
          ]
        },
        {
          "content": "In <bpt id=\"p128\">***</bpt><bpt id=\"p129\"/>Select which level to apply these\nsettings to<ept id=\"p129\">***</ept><ept id=\"p128\"/>, check database level option.",
          "pos": [
            544,
            702
          ]
        },
        {
          "content": "Then click\n<bpt id=\"p130\">**</bpt>'Connect'<ept id=\"p130\">**</ept>.",
          "pos": [
            703,
            770
          ]
        }
      ]
    },
    {
      "pos": [
        21971,
        22285
      ],
      "leadings": [
        "",
        "    ",
        "    ",
        "    "
      ],
      "content": "Click on the second table <bpt id=\"p131\">**</bpt>PMResult<ept id=\"p131\">**</ept><ph id=\"ph64\"/> then click <ph id=\"ph65\">![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-navigation.png)</ph>\nnext to <bpt id=\"p132\">**</bpt>'Source'<ept id=\"p132\">**</ept><ph id=\"ph66\"/> under\n<bpt id=\"p133\">**</bpt>'APPLIED STEPS'<ept id=\"p133\">**</ept><ph id=\"ph67\"/> on the right <bpt id=\"p134\">**</bpt>'Query Settings'<ept id=\"p134\">**</ept><ph id=\"ph68\"/> panel, and update\nthe server and database names as in the above steps and click OK."
    },
    {
      "pos": [
        22295,
        23006
      ],
      "leadings": [
        "",
        "    "
      ],
      "content": "Once you're guided back to the previous page, close the window. A message will pop out - click <bpt id=\"p135\">**</bpt>Apply<ept id=\"p135\">**</ept>. Lastly, click the <bpt id=\"p136\">**</bpt>Save<ept id=\"p136\">**</ept><ph id=\"ph69\"/> button to save\nthe changes. Your Power BI file has now established connection to the server. If your visualizations are empty, make sure you clear the selections on the visualizations to visualize all the data by clicking the eraser icon on the upper right corner of the legends. Use the refresh button to reflect new data on the visualizations. Initially, you will only see the seed data on your visualizations as the data factory is scheduled to refresh every 3 hours. After 3 hours, you will see new predictions reflected in your visualizations when you refresh the data.",
      "nodes": [
        {
          "content": "Once you're guided back to the previous page, close the window.",
          "pos": [
            0,
            63
          ]
        },
        {
          "content": "A message will pop out - click <bpt id=\"p135\">**</bpt>Apply<ept id=\"p135\">**</ept>.",
          "pos": [
            64,
            147
          ]
        },
        {
          "content": "Lastly, click the <bpt id=\"p136\">**</bpt>Save<ept id=\"p136\">**</ept><ph id=\"ph69\"/> button to save\nthe changes.",
          "pos": [
            148,
            259
          ]
        },
        {
          "content": "Your Power BI file has now established connection to the server.",
          "pos": [
            260,
            324
          ]
        },
        {
          "content": "If your visualizations are empty, make sure you clear the selections on the visualizations to visualize all the data by clicking the eraser icon on the upper right corner of the legends.",
          "pos": [
            325,
            511
          ]
        },
        {
          "content": "Use the refresh button to reflect new data on the visualizations.",
          "pos": [
            512,
            577
          ]
        },
        {
          "content": "Initially, you will only see the seed data on your visualizations as the data factory is scheduled to refresh every 3 hours.",
          "pos": [
            578,
            702
          ]
        },
        {
          "content": "After 3 hours, you will see new predictions reflected in your visualizations when you refresh the data.",
          "pos": [
            703,
            806
          ]
        }
      ]
    },
    {
      "pos": [
        23012,
        23179
      ],
      "leadings": [
        "",
        "    ",
        "    "
      ],
      "content": "(Optional) Publish the cold path dashboard to <bpt id=\"p137\">[</bpt>Power BI\nonline<ept id=\"p137\">](http://www.powerbi.com/)</ept>. Note that this step needs a Power\nBI account (or Office 365 account).",
      "nodes": [
        {
          "content": "(Optional) Publish the cold path dashboard to <bpt id=\"p137\">[</bpt>Power BI\nonline<ept id=\"p137\">](http://www.powerbi.com/)</ept>.",
          "pos": [
            0,
            131
          ]
        },
        {
          "content": "Note that this step needs a Power\nBI account (or Office 365 account).",
          "pos": [
            132,
            201
          ]
        }
      ]
    },
    {
      "pos": [
        23189,
        23563
      ],
      "leadings": [
        "",
        "    ",
        "    ",
        "    "
      ],
      "content": "Click <bpt id=\"p138\">**</bpt>'Publish'<ept id=\"p138\">**</ept><ph id=\"ph70\"/> and few seconds later a window appears\ndisplaying \"Publishing to Power BI Success!\" with a green\ncheck mark. Click the link below \"Open\nPredictiveMaintenanceAerospace.pbix in Power BI\". To find detailed instructions, see <bpt id=\"p139\">[</bpt>Publish from Power BI Desktop<ept id=\"p139\">](https://support.powerbi.com/knowledgebase/articles/461278-publish-from-power-bi-desktop)</ept>.",
      "nodes": [
        {
          "content": "Click <bpt id=\"p138\">**</bpt>'Publish'<ept id=\"p138\">**</ept><ph id=\"ph70\"/> and few seconds later a window appears\ndisplaying \"Publishing to Power BI Success!\"",
          "pos": [
            0,
            160
          ]
        },
        {
          "content": "with a green\ncheck mark.",
          "pos": [
            161,
            185
          ]
        },
        {
          "content": "Click the link below \"Open\nPredictiveMaintenanceAerospace.pbix in Power BI\".",
          "pos": [
            186,
            262
          ]
        },
        {
          "content": "To find detailed instructions, see <bpt id=\"p139\">[</bpt>Publish from Power BI Desktop<ept id=\"p139\">](https://support.powerbi.com/knowledgebase/articles/461278-publish-from-power-bi-desktop)</ept>.",
          "pos": [
            263,
            461
          ]
        }
      ]
    },
    {
      "pos": [
        23573,
        23750
      ],
      "leadings": [
        "",
        "    ",
        "    "
      ],
      "content": "To create a new dashboard: click the <bpt id=\"p140\">**</bpt>+<ept id=\"p140\">**</ept><ph id=\"ph71\"/> sign next to the\n<bpt id=\"p141\">**</bpt>Dashboards<ept id=\"p141\">**</ept><ph id=\"ph72\"/> section on the left pane. Enter the name \"Predictive\nMaintenance Demo\" for this new dashboard.",
      "nodes": [
        {
          "content": "To create a new dashboard: click the <bpt id=\"p140\">**</bpt>+<ept id=\"p140\">**</ept><ph id=\"ph71\"/> sign next to the\n<bpt id=\"p141\">**</bpt>Dashboards<ept id=\"p141\">**</ept><ph id=\"ph72\"/> section on the left pane.",
          "pos": [
            0,
            214
          ]
        },
        {
          "content": "Enter the name \"Predictive\nMaintenance Demo\" for this new dashboard.",
          "pos": [
            215,
            283
          ]
        }
      ]
    },
    {
      "pos": [
        23760,
        24738
      ],
      "leadings": [
        "",
        "    ",
        "    ",
        "    ",
        "",
        "    ",
        ""
      ],
      "content": "Once you open the report, click <ph id=\"ph73\">![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-pin.png)</ph><ph id=\"ph74\"/> to pin all the\nvisualizations to your dashboard. To find detailed instructions, see <bpt id=\"p142\">[</bpt>Pin a tile to a Power BI dashboard from a report<ept id=\"p142\">](https://support.powerbi.com/knowledgebase/articles/430323-pin-a-tile-to-a-power-bi-dashboard-from-a-report)</ept>.\nGo to the dashboard page and\nadjust the size and location of your visualizations and edit their titles. To find detailed instructions on how to edit your tiles, see <bpt id=\"p143\">[</bpt>Edit a tile -- resize, move, rename, pin, delete, add hyperlink<ept id=\"p143\">](https://powerbi.microsoft.com/documentation/powerbi-service-edit-a-tile-in-a-dashboard/#rename)</ept>. Here is an example dashboard with some cold path visualizations pinned to it.  Depending on how long you run your data generator, your numbers on the visualizations may be different.\n<ph id=\"ph75\">&lt;br/&gt;</ph><ph id=\"ph76\">\n![](media\\cortana-analytics-technical-guide-predictive-maintenance\\final-view.png)</ph><ph id=\"ph77\">\n&lt;br/&gt;</ph>",
      "nodes": [
        {
          "content": "Once you open the report, click <ph id=\"ph73\">![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-pin.png)</ph><ph id=\"ph74\"/> to pin all the\nvisualizations to your dashboard.",
          "pos": [
            0,
            195
          ]
        },
        {
          "content": "To find detailed instructions, see <bpt id=\"p142\">[</bpt>Pin a tile to a Power BI dashboard from a report<ept id=\"p142\">](https://support.powerbi.com/knowledgebase/articles/430323-pin-a-tile-to-a-power-bi-dashboard-from-a-report)</ept>.",
          "pos": [
            196,
            432
          ]
        },
        {
          "content": "Go to the dashboard page and\nadjust the size and location of your visualizations and edit their titles.",
          "pos": [
            433,
            536
          ]
        },
        {
          "content": "To find detailed instructions on how to edit your tiles, see <bpt id=\"p143\">[</bpt>Edit a tile -- resize, move, rename, pin, delete, add hyperlink<ept id=\"p143\">](https://powerbi.microsoft.com/documentation/powerbi-service-edit-a-tile-in-a-dashboard/#rename)</ept>.",
          "pos": [
            537,
            802
          ]
        },
        {
          "content": "Here is an example dashboard with some cold path visualizations pinned to it.",
          "pos": [
            803,
            880
          ]
        },
        {
          "content": "Depending on how long you run your data generator, your numbers on the visualizations may be different.",
          "pos": [
            882,
            985
          ]
        },
        {
          "content": "<ph id=\"ph75\">&lt;br/&gt;</ph><ph id=\"ph76\">\n![](media\\cortana-analytics-technical-guide-predictive-maintenance\\final-view.png)</ph><ph id=\"ph77\">\n&lt;br/&gt;</ph>",
          "pos": [
            986,
            1149
          ]
        }
      ]
    },
    {
      "pos": [
        24747,
        25247
      ],
      "leadings": [
        "",
        "",
        "        ",
        "",
        "    ",
        ""
      ],
      "content": "To schedule refresh of the data, hover your mouse over the <bpt id=\"p144\">**</bpt>PredictiveMaintenanceAerospace<ept id=\"p144\">**</ept><ph id=\"ph78\"/> dataset, click <ph id=\"ph79\">![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-elipsis.png)</ph><ph id=\"ph80\"/> and then choose <bpt id=\"p145\">**</bpt>Schedule Refresh<ept id=\"p145\">**</ept>.\n<ph id=\"ph81\">&lt;br/&gt;</ph><bpt id=\"p146\">\n**</bpt>Note:<ept id=\"p146\">**</ept><ph id=\"ph82\"/> If you see a warning massage, click <bpt id=\"p147\">**</bpt>Edit Credentials<ept id=\"p147\">**</ept><ph id=\"ph83\"/> and make sure your database credentials are the same as those described in step 1.\n<ph id=\"ph84\">&lt;br/&gt;</ph><ph id=\"ph85\">\n![](media\\cortana-analytics-technical-guide-predictive-maintenance\\schedule-refresh.png)</ph><ph id=\"ph86\">\n&lt;br/&gt;</ph>",
      "nodes": [
        {
          "content": "To schedule refresh of the data, hover your mouse over the <bpt id=\"p144\">**</bpt>PredictiveMaintenanceAerospace<ept id=\"p144\">**</ept><ph id=\"ph78\"/> dataset, click <ph id=\"ph79\">![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-elipsis.png)</ph><ph id=\"ph80\"/> and then choose <bpt id=\"p145\">**</bpt>Schedule Refresh<ept id=\"p145\">**</ept>.",
          "pos": [
            0,
            364
          ]
        },
        {
          "content": "<ph id=\"ph81\">&lt;br/&gt;</ph><bpt id=\"p146\">\n**</bpt>Note:<ept id=\"p146\">**</ept><ph id=\"ph82\"/> If you see a warning massage, click <bpt id=\"p147\">**</bpt>Edit Credentials<ept id=\"p147\">**</ept><ph id=\"ph83\"/> and make sure your database credentials are the same as those described in step 1.",
          "pos": [
            365,
            659
          ]
        },
        {
          "content": "<ph id=\"ph84\">&lt;br/&gt;</ph><ph id=\"ph85\">\n![](media\\cortana-analytics-technical-guide-predictive-maintenance\\schedule-refresh.png)</ph><ph id=\"ph86\">\n&lt;br/&gt;</ph>",
          "pos": [
            660,
            829
          ]
        }
      ]
    },
    {
      "pos": [
        25256,
        25343
      ],
      "leadings": [
        "",
        "    ",
        ""
      ],
      "content": "Expand the <bpt id=\"p148\">**</bpt>Schedule Refresh<ept id=\"p148\">**</ept><ph id=\"ph87\"/> section. Turn on \"keep your\ndata up-to-date\".\n<ph id=\"ph88\">&lt;br/&gt;</ph>",
      "nodes": [
        {
          "content": "Expand the <bpt id=\"p148\">**</bpt>Schedule Refresh<ept id=\"p148\">**</ept><ph id=\"ph87\"/> section.",
          "pos": [
            0,
            97
          ]
        },
        {
          "content": "Turn on \"keep your\ndata up-to-date\".",
          "pos": [
            98,
            134
          ]
        },
        {
          "content": "<ph id=\"ph88\">&lt;br/&gt;</ph>",
          "pos": [
            135,
            165
          ]
        }
      ]
    },
    {
      "pos": [
        25352,
        25539
      ],
      "leadings": [
        "",
        "    "
      ],
      "content": "Schedule the refresh based on your needs. To find more information, see\n<bpt id=\"p149\">[</bpt>Data refresh in Power BI<ept id=\"p149\">](https://support.powerbi.com/knowledgebase/articles/474669-data-refresh-in-power-bi)</ept>.",
      "nodes": [
        {
          "content": "Schedule the refresh based on your needs.",
          "pos": [
            0,
            41
          ]
        },
        {
          "content": "To find more information, see\n<bpt id=\"p149\">[</bpt>Data refresh in Power BI<ept id=\"p149\">](https://support.powerbi.com/knowledgebase/articles/474669-data-refresh-in-power-bi)</ept>.",
          "pos": [
            42,
            225
          ]
        }
      ]
    },
    {
      "pos": [
        25545,
        25569
      ],
      "content": "Setup hot path dashboard"
    },
    {
      "pos": [
        25571,
        25915
      ],
      "content": "The following steps will guide you how to visualize real time data\noutput from Stream Analytics jobs that were generated at the time of\nsolution deployment. A <bpt id=\"p150\">[</bpt>Power BI online<ept id=\"p150\">](http://www.powerbi.com/)</ept>\naccount is required to perform the following steps. If you don't have an\naccount, you can <bpt id=\"p151\">[</bpt>create one<ept id=\"p151\">](https://powerbi.microsoft.com/pricing)</ept>.",
      "nodes": [
        {
          "content": "The following steps will guide you how to visualize real time data\noutput from Stream Analytics jobs that were generated at the time of\nsolution deployment.",
          "pos": [
            0,
            156
          ]
        },
        {
          "content": "A <bpt id=\"p150\">[</bpt>Power BI online<ept id=\"p150\">](http://www.powerbi.com/)</ept>\naccount is required to perform the following steps.",
          "pos": [
            157,
            295
          ]
        },
        {
          "content": "If you don't have an\naccount, you can <bpt id=\"p151\">[</bpt>create one<ept id=\"p151\">](https://powerbi.microsoft.com/pricing)</ept>.",
          "pos": [
            296,
            428
          ]
        }
      ]
    },
    {
      "pos": [
        25921,
        25973
      ],
      "content": "Add Power BI output in Azure Stream Analytics (ASA)."
    },
    {
      "pos": [
        25982,
        26269
      ],
      "leadings": [
        "",
        "    ",
        "    "
      ],
      "content": "You will need to follow the instructions in\n<bpt id=\"p152\">[</bpt>Azure Stream Analytics &amp; Power BI: A real-time analytics dashboard for real-time visibility of streaming data<ept id=\"p152\">](stream-analytics-power-bi-dashboard.md)</ept>\nto set up the output of your Azure Stream Analytics job as your Power BI dashboard."
    },
    {
      "pos": [
        26276,
        26930
      ],
      "content": "The ASA query has three outputs which are <bpt id=\"p153\">**</bpt>aircraftmonitor<ept id=\"p153\">**</ept>, <bpt id=\"p154\">**</bpt>aircraftalert<ept id=\"p154\">**</ept>, and <bpt id=\"p155\">**</bpt>flightsbyhour<ept id=\"p155\">**</ept>. You can view the query by clicking on query tab. Corresponding to each of these tables, you will need to add an output to ASA. When you add the first output (<bpt id=\"p156\">*</bpt>e.g.<ept id=\"p156\">*</ept> <bpt id=\"p157\">**</bpt>aircraftmonitor<ept id=\"p157\">**</ept>) make sure the <bpt id=\"p158\">**</bpt>Output Alias<ept id=\"p158\">**</ept>, <bpt id=\"p159\">**</bpt>Dataset Name<ept id=\"p159\">**</ept><ph id=\"ph89\"/> and <bpt id=\"p160\">**</bpt>Table Name<ept id=\"p160\">**</ept><ph id=\"ph90\"/> are the same (<bpt id=\"p161\">**</bpt>aircraftmonitor<ept id=\"p161\">**</ept>). Repeat the steps to add outputs for <bpt id=\"p162\">**</bpt>aircraftalert<ept id=\"p162\">**</ept>, and <bpt id=\"p163\">**</bpt>flightsbyhour<ept id=\"p163\">**</ept>. Once you have added all three output tables and started the ASA job, you should get a confirmation message (<bpt id=\"p164\">*</bpt>e.g.<ept id=\"p164\">*</ept>, \"Starting stream analytics job maintenancesa02asapbi succeeded\").",
      "nodes": [
        {
          "content": "The ASA query has three outputs which are <bpt id=\"p153\">**</bpt>aircraftmonitor<ept id=\"p153\">**</ept>, <bpt id=\"p154\">**</bpt>aircraftalert<ept id=\"p154\">**</ept>, and <bpt id=\"p155\">**</bpt>flightsbyhour<ept id=\"p155\">**</ept>.",
          "pos": [
            0,
            230
          ]
        },
        {
          "content": "You can view the query by clicking on query tab.",
          "pos": [
            231,
            279
          ]
        },
        {
          "content": "Corresponding to each of these tables, you will need to add an output to ASA.",
          "pos": [
            280,
            357
          ]
        },
        {
          "content": "When you add the first output (<bpt id=\"p156\">*</bpt>e.g.<ept id=\"p156\">*</ept> <bpt id=\"p157\">**</bpt>aircraftmonitor<ept id=\"p157\">**</ept>) make sure the <bpt id=\"p158\">**</bpt>Output Alias<ept id=\"p158\">**</ept>, <bpt id=\"p159\">**</bpt>Dataset Name<ept id=\"p159\">**</ept><ph id=\"ph89\"/> and <bpt id=\"p160\">**</bpt>Table Name<ept id=\"p160\">**</ept><ph id=\"ph90\"/> are the same (<bpt id=\"p161\">**</bpt>aircraftmonitor<ept id=\"p161\">**</ept>).",
          "pos": [
            358,
            802
          ]
        },
        {
          "content": "Repeat the steps to add outputs for <bpt id=\"p162\">**</bpt>aircraftalert<ept id=\"p162\">**</ept>, and <bpt id=\"p163\">**</bpt>flightsbyhour<ept id=\"p163\">**</ept>.",
          "pos": [
            803,
            964
          ]
        },
        {
          "content": "Once you have added all three output tables and started the ASA job, you should get a confirmation message (<bpt id=\"p164\">*</bpt>e.g.<ept id=\"p164\">*</ept>, \"Starting stream analytics job maintenancesa02asapbi succeeded\").",
          "pos": [
            965,
            1188
          ]
        }
      ]
    },
    {
      "pos": [
        26935,
        26986
      ],
      "content": "Log in to <bpt id=\"p165\">[</bpt>Power BI online<ept id=\"p165\">](http://www.powerbi.com)</ept>"
    },
    {
      "pos": [
        26996,
        27419
      ],
      "leadings": [
        "",
        "    ",
        "    "
      ],
      "content": "On the left panel Datasets section in My Workspace, the\n<bpt id=\"p166\">***</bpt><bpt id=\"p167\"/>DATASET<ept id=\"p167\">***</ept><ept id=\"p166\"/><ph id=\"ph91\"/> names <bpt id=\"p168\">**</bpt>aircraftmonitor<ept id=\"p168\">**</ept>, <bpt id=\"p169\">**</bpt>aircraftalert<ept id=\"p169\">**</ept>, and\n<bpt id=\"p170\">**</bpt>flightsbyhour<ept id=\"p170\">**</ept><ph id=\"ph92\"/> should appear.This is the streaming data you pushed from Azure Stream Analytics in the previous step.The dataset <bpt id=\"p171\">**</bpt>flightsbyhour<ept id=\"p171\">**</ept><ph id=\"ph93\"/> may not show up at the same time as the other two datasets due to the nature of the SQL query behind it. However, it should show up after an hour.",
      "nodes": [
        {
          "content": "On the left panel Datasets section in My Workspace, the\n<bpt id=\"p166\">***</bpt><bpt id=\"p167\"/>DATASET<ept id=\"p167\">***</ept><ept id=\"p166\"/><ph id=\"ph91\"/> names <bpt id=\"p168\">**</bpt>aircraftmonitor<ept id=\"p168\">**</ept>, <bpt id=\"p169\">**</bpt>aircraftalert<ept id=\"p169\">**</ept>, and\n<bpt id=\"p170\">**</bpt>flightsbyhour<ept id=\"p170\">**</ept><ph id=\"ph92\"/> should appear.This is the streaming data you pushed from Azure Stream Analytics in the previous step.The dataset <bpt id=\"p171\">**</bpt>flightsbyhour<ept id=\"p171\">**</ept><ph id=\"ph93\"/> may not show up at the same time as the other two datasets due to the nature of the SQL query behind it.",
          "pos": [
            0,
            660
          ]
        },
        {
          "content": "However, it should show up after an hour.",
          "pos": [
            661,
            702
          ]
        }
      ]
    },
    {
      "pos": [
        27428,
        27525
      ],
      "leadings": [
        "",
        "    "
      ],
      "content": "Make sure the <bpt id=\"p172\">***</bpt><bpt id=\"p173\"/>Visualizations<ept id=\"p173\">***</ept><ept id=\"p172\"/><ph id=\"ph94\"/> pane is open and is shown on the\nright side of the screen."
    },
    {
      "pos": [
        27530,
        27871
      ],
      "content": "Once you have the data flowing into Power BI, you can start visualizing the streaming data. Below is an example dashboard with some hot path visualizations pinned to it. You can create other dashboard tiles based on appropriate datasets. Depending on how long you run your data generator, your numbers on the visualizations may be different.",
      "nodes": [
        {
          "content": "Once you have the data flowing into Power BI, you can start visualizing the streaming data.",
          "pos": [
            0,
            91
          ]
        },
        {
          "content": "Below is an example dashboard with some hot path visualizations pinned to it.",
          "pos": [
            92,
            169
          ]
        },
        {
          "content": "You can create other dashboard tiles based on appropriate datasets.",
          "pos": [
            170,
            237
          ]
        },
        {
          "content": "Depending on how long you run your data generator, your numbers on the visualizations may be different.",
          "pos": [
            238,
            341
          ]
        }
      ]
    },
    {
      "pos": [
        27969,
        28080
      ],
      "content": "Here are some steps to create one of the tiles above   the \"Fleet View of Sensor 11 vs. Threshold 48.26\" tile:"
    },
    {
      "pos": [
        28090,
        28163
      ],
      "leadings": [
        "",
        "    "
      ],
      "content": "Click dataset <bpt id=\"p174\">**</bpt>aircraftmonitor<ept id=\"p174\">**</ept><ph id=\"ph95\"/> on the left panel\nDatasets section."
    },
    {
      "pos": [
        28173,
        28203
      ],
      "content": "Click the <bpt id=\"p175\">**</bpt>Line Chart<ept id=\"p175\">**</ept><ph id=\"ph96\"/> icon."
    },
    {
      "pos": [
        28213,
        28321
      ],
      "leadings": [
        "",
        "    "
      ],
      "content": "Click <bpt id=\"p176\">**</bpt>Processed<ept id=\"p176\">**</ept><ph id=\"ph97\"/> in the <bpt id=\"p177\">**</bpt>Fields<ept id=\"p177\">**</ept><ph id=\"ph98\"/> pane so that it shows under\n\"Axis\" in the <bpt id=\"p178\">**</bpt>Visualizations<ept id=\"p178\">**</ept><ph id=\"ph99\"/> pane."
    },
    {
      "pos": [
        28331,
        28493
      ],
      "leadings": [
        "",
        "    ",
        "    "
      ],
      "content": "Click \"s11\" and \"s11\\_alert\" so that they both appear\nunder \"Values\". Click the small arrow next to <bpt id=\"p179\">**</bpt>s11<ept id=\"p179\">**</ept><ph id=\"ph100\"/> and\n<bpt id=\"p180\">**</bpt>s11\\_alert<ept id=\"p180\">**</ept>, change \"Sum\" to \"Average\".",
      "nodes": [
        {
          "content": "Click \"s11\" and \"s11\\_alert\" so that they both appear\nunder \"Values\".",
          "pos": [
            0,
            69
          ]
        },
        {
          "content": "Click the small arrow next to <bpt id=\"p179\">**</bpt>s11<ept id=\"p179\">**</ept><ph id=\"ph100\"/> and\n<bpt id=\"p180\">**</bpt>s11\\_alert<ept id=\"p180\">**</ept>, change \"Sum\" to \"Average\".",
          "pos": [
            70,
            254
          ]
        }
      ]
    },
    {
      "pos": [
        28503,
        28690
      ],
      "leadings": [
        "",
        "    ",
        "    "
      ],
      "content": "Click <bpt id=\"p181\">**</bpt>SAVE<ept id=\"p181\">**</ept><ph id=\"ph101\"/> on the top and name the report \"aircraftmonitor\". The\nreport named \"aircraftmonitor\" will be shown in the <bpt id=\"p182\">**</bpt>Reports<ept id=\"p182\">**</ept>\nsection in the <bpt id=\"p183\">**</bpt>Navigator<ept id=\"p183\">**</ept><ph id=\"ph102\"/> pane on the left.",
      "nodes": [
        {
          "content": "Click <bpt id=\"p181\">**</bpt>SAVE<ept id=\"p181\">**</ept><ph id=\"ph101\"/> on the top and name the report \"aircraftmonitor\".",
          "pos": [
            0,
            122
          ]
        },
        {
          "content": "The\nreport named \"aircraftmonitor\" will be shown in the <bpt id=\"p182\">**</bpt>Reports<ept id=\"p182\">**</ept>\nsection in the <bpt id=\"p183\">**</bpt>Navigator<ept id=\"p183\">**</ept><ph id=\"ph102\"/> pane on the left.",
          "pos": [
            123,
            337
          ]
        }
      ]
    },
    {
      "pos": [
        28700,
        28912
      ],
      "leadings": [
        "",
        "    ",
        "    ",
        "    "
      ],
      "content": "Click the <bpt id=\"p184\">**</bpt>Pin Visual<ept id=\"p184\">**</ept><ph id=\"ph103\"/> icon on the top right corner of this\nline chart. A \"Pin to Dashboard\" window may show up for you to\nchoose a dashboard. Select \"Predictive Maintenance Demo\", then\nclick \"Pin\".",
      "nodes": [
        {
          "content": "Click the <bpt id=\"p184\">**</bpt>Pin Visual<ept id=\"p184\">**</ept><ph id=\"ph103\"/> icon on the top right corner of this\nline chart.",
          "pos": [
            0,
            131
          ]
        },
        {
          "content": "A \"Pin to Dashboard\" window may show up for you to\nchoose a dashboard.",
          "pos": [
            132,
            202
          ]
        },
        {
          "content": "Select \"Predictive Maintenance Demo\", then\nclick \"Pin\".",
          "pos": [
            203,
            258
          ]
        }
      ]
    },
    {
      "pos": [
        28922,
        29147
      ],
      "leadings": [
        "",
        "    ",
        "    ",
        "    "
      ],
      "content": "Hover the mouse over this tile on the dashboard, click the \"edit\"\nicon on the top right corner to change its title to \"Fleet View of\nSensor 11 vs. Threshold 48.26\" and subtitle to \"Average across fleet\nover time\"."
    },
    {
      "pos": [
        29152,
        29183
      ],
      "content": "<bpt id=\"p185\">**</bpt>How to delete your solution<ept id=\"p185\">**</ept>"
    },
    {
      "pos": [
        29184,
        29614
      ],
      "content": "Please ensure that you stop the data generator when not actively using the solution as running the data generator will incur higher costs. Please delete the solution if you are not using it. Deleting your solution will delete all the components provisioned in your subscription when you deployed the solution. To delete the solution right click on your solution name in the left panel of the solution template and click on delete.",
      "nodes": [
        {
          "content": "Please ensure that you stop the data generator when not actively using the solution as running the data generator will incur higher costs.",
          "pos": [
            0,
            138
          ]
        },
        {
          "content": "Please delete the solution if you are not using it.",
          "pos": [
            139,
            190
          ]
        },
        {
          "content": "Deleting your solution will delete all the components provisioned in your subscription when you deployed the solution.",
          "pos": [
            191,
            309
          ]
        },
        {
          "content": "To delete the solution right click on your solution name in the left panel of the solution template and click on delete.",
          "pos": [
            310,
            430
          ]
        }
      ]
    },
    {
      "pos": [
        29619,
        29644
      ],
      "content": "<bpt id=\"p186\">**</bpt>Cost estimation tools<ept id=\"p186\">**</ept>"
    },
    {
      "pos": [
        29646,
        29717
      ],
      "content": "The following two tools are available to help you better understand the"
    },
    {
      "pos": [
        29718,
        29790
      ],
      "content": "total costs involved in running the Predictive Maintenance for Aerospace"
    },
    {
      "pos": [
        29791,
        29830
      ],
      "content": "Solution Template in your subscription:"
    },
    {
      "pos": [
        29836,
        29935
      ],
      "leadings": [
        "",
        "    "
      ],
      "content": "<bpt id=\"p187\">[</bpt>Microsoft Azure Cost Estimator\nTool (online)<ept id=\"p187\">](https://azure.microsoft.com/pricing/calculator/)</ept>"
    },
    {
      "pos": [
        29941,
        30049
      ],
      "leadings": [
        "",
        "    "
      ],
      "content": "<bpt id=\"p188\">[</bpt>Microsoft Azure Cost Estimator\nTool (desktop)<ept id=\"p188\">](http://www.microsoft.com/download/details.aspx?id=43376)</ept>"
    }
  ],
  "content": "<properties\n    pageTitle=\"Technical guide to the Cortana Analytics Solution Template for predictive maintenance in aerospace and other businesses | Microsoft Azure\"\n    description=\"A technical guide to the Solution Template with Microsoft Cortana Analytics for predictive maintenance in aerospace, utilities, and transportation.\"\n    services=\"cortana-analytics\"\n    documentationCenter=\"\"\n    authors=\"fboylu\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\"/>\n\n<tags\n    ms.service=\"cortana-analytics\"\n    ms.workload=\"data-services\"\n    ms.tgt_pltfrm=\"na\"\n    ms.devlang=\"na\"\n    ms.topic=\"article\"\n    ms.date=\"01/29/2016\"\n    ms.author=\"fboylu\" />\n\n# Technical guide to the Cortana Analytics Solution Template for predictive maintenance in aerospace and other businesses\n\n## **Acknowledgements**\nThis article is authored by data scientists Yan Zhang, Gauher Shaheen, Fidan Boylu Uz and software engineer Dan Grecoe at Microsoft.\n\n## **Overview**\n\nSolution Templates are designed to accelerate the process of building an\nE2E demo on top of Cortana Analytics Suite. A deployed template will\nprovision your subscription with necessary Cortana Analytics components\nand build the relationships between them. It also seeds the data pipeline with sample data generated from a data generator application which you will download and install on your local machine after you deploy the solution template. The data generated from the generator will hydrate the data pipeline and start generating machine learning predictions which can then be visualized on the Power BI dashboard. The deployment process will guide you through several steps to set up your solution credentials. Make sure you record these credentials such as solution name, username, and password you provide during the deployment.  \n\nThe goal of this document is to explain the reference architecture and\ndifferent components provisioned in your subscription as part of this\nsolution template. The document also talks about how to replace the\nsample data with real data of your own to be able to see insights and\npredictions from your own data. Additionally, the document discusses the\nparts of the Solution Template that would need to be modified if you\nwanted to customize the solution with your own data. Instructions on how\nto build the Power BI dashboard for this Solution Template are provided\nat the end.\n\n>[AZURE.TIP] You can download and print a [PDF version of this document](http://download.microsoft.com/download/F/4/D/F4D7D208-D080-42ED-8813-6030D23329E9/cortana-analytics-technical-guide-predictive-maintenance.pdf).\n\n## **Big picture**\n\n![](media/cortana-analytics-technical-guide-predictive-maintenance\\predictive-maintenance-architecture.png)\n\nWhen the solution is deployed, various Azure services within Cortana\nAnalytics Suite are activated (*i.e.* Event Hub, Stream Analytics,\nHDInsight, Data Factory, Machine Learning, *etc.*). The architecture\ndiagram above shows, at a high level, how the Predictive Maintenance for\nAerospace Solution Template is constructed from end-to-end. You will be able to investigate these services in the azure portal by clicking on them on the solution template diagram created with the deployment of the solution with the exception of HDInsight as this service is provisioned on demand when the related pipeline activities are required to run and deleted afterwards.\nYou can download a [full-size version of the diagram](http://download.microsoft.com/download/1/9/B/19B815F0-D1B0-4F67-AED3-A40544225FD1/ca-topologies-maintenance-prediction.png).\n\nThe following sections describe each piece.\n\n## **Data source and ingestion**\n\n### Synthetic data source\n\nFor this template the data source used is generated from a desktop\napplication that you will download and run locally after successful\ndeployment. You will find the instructions to download and install this application in the properties bar when you select the first node called Predictive Maintenance Data Generator on the solution template diagram. This application feeds the [Azure Event Hub](#azure-event-hub) service\nwith data points, or events, that will be used in the rest of the solution flow. This data\nsource is comprised of or derived from publicly available data from the\n[NASA data\nrepository](http://ti.arc.nasa.gov/tech/dash/pcoe/prognostic-data-repository/)\nusing the [Turbofan Engine Degradation Simulation Data Set](http://ti.arc.nasa.gov/tech/dash/pcoe/prognostic-data-repository/#turbofan).\n\nThe event generation application will populate the Azure Event Hub only\nwhile it's executing on your computer.\n\n### Azure event hub\n\nThe [Azure Event\nHub](https://azure.microsoft.com/services/event-hubs/) service is\nthe recipient of the input provided by the Synthetic Data Source\ndescribed above.\n\n## **Data preparation and analysis**\n\n\n### Azure Stream Analytics\n\nThe [Azure Stream\nAnalytics](https://azure.microsoft.com/services/stream-analytics/)\nservice is used to provide near real-time analytics on the input stream\nfrom the [Azure Event Hub](#azure-event-hub) service and publish results\nonto a [Power BI](https://powerbi.microsoft.com) dashboard as well as\narchiving all raw incoming events to the [Azure\nStorage](https://azure.microsoft.com/services/storage/) service\nfor later processing by the [Azure Data\nFactory](https://azure.microsoft.com/documentation/services/data-factory/)\nservice.\n\n### HD Insights custom aggregation\n\nThe Azure HD Insight service is used to run\n[Hive](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)\nscripts (orchestrated by Azure Data Factory) to provide aggregations on\nthe raw events that were archived using the Azure Stream Analytics\nservice.\n\n### Azure Machine Learning\n\nThe [Azure Machine\nLearning](https://azure.microsoft.com/services/machine-learning/)\nservice is used (orchestrated by Azure Data Factory) to make predictions\non the remaining useful life (RUL) of a particular aircraft engine given\nthe inputs received.\n\n## **Data publishing**\n\n\n### Azure SQL Database Service\n\nThe [Azure SQL\nDatabase](https://azure.microsoft.com/services/sql-database/)\nservice is used to store (managed by Azure Data Factory) the predictions\nreceived by the Azure Machine Learning service that will be consumed in\nthe [Power BI](https://powerbi.microsoft.com) dashboard.\n\n## **Data consumption**\n\n### Power BI\n\nThe [Power BI](https://powerbi.microsoft.com) service is used to show a\ndashboard that contains aggregations and alerts provided by the [Azure\nStream Analytics](https://azure.microsoft.com/services/stream-analytics/) service as well as RUL\npredictions stored in [Azure SQL Database](https://azure.microsoft.com/services/sql-database/) that\nwere produced using the [Azure Machine\nLearning](https://azure.microsoft.com/services/machine-learning/)\nservice. For Instructions on how to build the Power BI dashboard for this\nSolution Template, refer to the section below.\n\n## **How to bring in your own data**\n\nThis section describes how to bring your own data to Azure, and what\nareas would require changes for the data you bring into this\narchitecture.\n\nIt's unlikely that any dataset you bring would match the dataset used by\nthe [Turbofan Engine Degradation Simulation Data\nSet](http://ti.arc.nasa.gov/tech/dash/pcoe/prognostic-data-repository/#turbofan)\nused for this solution template. Understanding your data and the\nrequirements will be crucial in how you modify this template to work\nwith your own data. If this is your first exposure to the Azure Machine\nLearning service, you can get an introduction to it by using the example\nin [How to create your first\nexperiment](machine-learning-create-experiment.md).\n\nThe following sections will discuss the sections of the template that\nwill require modifications when a new dataset is introduced.\n\n### Azure Event Hub\n\nThe Azure Event Hub service is very generic, such that data can be\nposted to the hub in either CSV or JSON format. No special processing\noccurs in the Azure Event Hub, but it's important that you understand\nthe data that's fed into it.\n\nThis document does not describe how to ingest your data, but you can\neasily send events or data to an Azure Event Hub using the Event Hub\nAPI's.\n\n### Azure Stream Analytics\n\nThe Azure Stream Analytics service is used to provide near real-time\nanalytics by reading from data streams and outputting data to any number\nof sources.\n\nFor the Predictive Maintenance for Aerospace Solution Template, the\nAzure Stream Analytics query consists of four sub-queries, each\nconsuming events from the Azure Event Hub service, and having outputs to\nfour distinct locations. These outputs consist of three Power BI\ndatasets and one Azure Storage location.\n\nThe Azure Stream Analytics query can be found by:\n\n-   Logging into the Azure portal\n\n-   Locating the stream analytics jobs ![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-stream-analytics.png) that were\n    generated when the solution was deployed (*e.g.*,\n    **maintenancesa02asapbi** and **maintenancesa02asablob** for the\n    predictive maintenance solution)\n\n-   Selecting\n\n    -   ***INPUTS*** to view the query input\n\n    -   ***QUERY*** to view the query itself\n\n    -   ***OUTPUTS*** to view the different outputs\n\nInformation about Azure Stream Analytics query construction can be found\nin the [Stream Analytics Query\nReference](https://msdn.microsoft.com/library/azure/dn834998.aspx)\non MSDN.\n\nIn this solution, the queries output three datasets with near real-time\nanalytics information about the incoming data stream to a Power BI\ndashboard that's provided as part of this solution template. Because\nthere's implicit knowledge about the incoming data format, these queries\nwould need to be altered based on your data format.\n\nThe query in the second stream analytics job **maintenancesa02asablob** simply outputs all [Event\nHub](https://azure.microsoft.com/services/event-hubs/) events to\n[Azure Storage](https://azure.microsoft.com/services/storage/) and\nhence requires no alteration regardless of your data format as the full\nevent information is streamed to storage.\n\n### Azure Data Factory\n\nThe [Azure Data\nFactory](https://azure.microsoft.com/documentation/services/data-factory/)\nservice orchestrates the movement and processing of data. In the\nPredictive Maintenance for Aerospace Solution Template the data factory\nis made up of three\n[pipelines](../data-factory/data-factory-create-pipelines.md)\nthat move and process the data using various technologies.  You can access your data factory by opening the the Data Factory node at the bottom of the solution template diagram created with the deployment of the solution. This will take you to the data factory on your Azure portal. If you see errors under your datasets, you can ignore those as they are due to data factory being deployed before the data generator was started. Those errors do not prevent your data factory from functioning.\n\n![](media/cortana-analytics-technical-guide-predictive-maintenance/data-factory-dataset-error.png)\n\nThis section discusses the necessary [pipelines](../data-factory/data-factory-create-pipelines.md) and [activities](../data-factory/data-factory-create-pipelines.md) contained in the [Azure Data\nFactory](https://azure.microsoft.com/documentation/services/data-factory/). Below is the diagram view of the solution.\n\n![](media/cortana-analytics-technical-guide-predictive-maintenance/azure-data-factory.png)\n\nTwo of the pipelines of this factory contain\n[Hive](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)\nscripts that are used to partition and aggregate the data. When noted,\nthe scripts will be located in the [Azure\nStorage](https://azure.microsoft.com/services/storage/) account\ncreated during setup. Their location will be:\nmaintenancesascript\\\\\\\\script\\\\\\\\hive\\\\\\\\ (or https://[Your solution\nname].blob.core.windows.net/maintenancesascript).\n\nSimilar to the [Azure Stream Analytics](#azure-stream-analytics-1)\nqueries, the\n[Hive](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)\nscripts have implicit knowledge about the incoming data format, these\nqueries would need to be altered based on your data format and [feature\nengineering](machine-learning-feature-selection-and-engineering.md)\nrequirements.\n\n#### *AggregateFlightInfoPipeline*\n\nThis\n[pipeline](../data-factory/data-factory-create-pipelines.md)\ncontains a single activity - an\n[HDInsightHive](../data-factory/data-factory-hive-activity.md)\nactivity using a\n[HDInsightLinkedService](https://msdn.microsoft.com/library/azure/dn893526.aspx)\nthat runs a\n[Hive](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)\nscript to partition the data put in [Azure\nStorage](https://azure.microsoft.com/services/storage/) during the\n[Azure Stream\nAnalytics](https://azure.microsoft.com/services/stream-analytics/)\njob.\n\nThe\n[Hive](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)\nscript for this partitioning task is ***AggregateFlightInfo.hql***\n\n#### *MLScoringPipeline*\n\nThis\n[pipeline](../data-factory/data-factory-create-pipelines.md)\ncontains several activities and whose end result is the scored\npredictions from the [Azure Machine\nLearning](https://azure.microsoft.com/services/machine-learning/)\nexperiment associated with this solution template.\n\nThe activities contained in this are:\n\n-   [HDInsightHive](../data-factory/data-factory-hive-activity.md)\n    activity using an\n    [HDInsightLinkedService](https://msdn.microsoft.com/library/azure/dn893526.aspx)\n    that runs a\n    [Hive](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)\n    script to perform aggregations and feature engineering necessary for\n    the [Azure Machine\n    Learning](https://azure.microsoft.com/services/machine-learning/) experiment.\n    The\n    [Hive](http://blogs.msdn.com/b/bigdatasupport/archive/2013/11/11/get-started-with-hive-on-hdinsight.aspx)\n    script for this partitioning task is ***PrepareMLInput.hql***.\n\n-   [Copy](https://msdn.microsoft.com/library/azure/dn835035.aspx)\n    activity that moves the results from the\n    [HDInsightHive](../data-factory/data-factory-hive-activity.md)\n    activity to a single [Azure\n    Storage](https://azure.microsoft.com/services/storage/) blob\n    that can be access by the\n    [AzureMLBatchScoring](https://msdn.microsoft.com/library/azure/dn894009.aspx) activity.\n\n-   [AzureMLBatchScoring](https://msdn.microsoft.com/library/azure/dn894009.aspx)\n    activity that calls the [Azure Machine\n    Learning](https://azure.microsoft.com/services/machine-learning/)\n    experiment which results in the results being put in a single [Azure\n    Storage](https://azure.microsoft.com/services/storage/) blob.\n\n#### *CopyScoredResultPipeline*\n\nThis\n[pipeline](../data-factory/data-factory-create-pipelines.md)\ncontains a single activity - a\n[Copy](https://msdn.microsoft.com/library/azure/dn835035.aspx)\nactivity that moves the results of the [Azure Machine\nLearning](#azure-machine-learning) experiment from the\n***MLScoringPipeline*** to the [Azure SQL\nDatabase](https://azure.microsoft.com/services/sql-database/) that was provisioned as part of the\nsolution template installation.\n\n### Azure Machine Learning\n\nThe [Azure Machine\nLearning](https://azure.microsoft.com/services/machine-learning/)\nexperiment used for this solution template provides the Remaining Useful\nLife (RUL) of an aircraft engine. The experiment is specific to the data\nset consumed and therefore will require modification or replacement\nspecific to the data that's brought in.\n\nFor information about how the Azure Machine Learning experiment was\ncreated, see [Predictive Maintenance: Step 1 of 3, data preparation and feature engineering](http://gallery.cortanaanalytics.com/Experiment/Predictive-Maintenance-Step-1-of-3-data-preparation-and-feature-engineering-2).\n\n## **Monitor Progress**\n Once the Data Generator is launched, the pipeline begins to get hydrated and the different components of your solution start kicking into action following the commands issued by the Data Factory. There are two ways you can monitor the pipeline.\n\n1. One of the Stream Analytics job writes the raw incoming data to blob storage. If you click on Blob Storage component of your solution from the screen you successfully deployed the solution and then click Open in the right panel, it will take you to the [management portal](https://portal.azure.com/). Once there, click on Blobs. In the next panel, you will see a list of Containers. Click on **maintenancesadata**. In the next panel, you will see the **rawdata** folder. Inside the rawdata folder, you will see folders with names such as hour=17, hour=18 etc. If you see these folders, it indicates that the raw data is successfully being generated on your computer and stored in blob storage. You should see csv files that should have finite sizes in MB in those folders.\n\n2. The last step of the pipeline is to write data (e.g. predictions from machine learning) into SQL Database. You might have to wait a maximum of three hours for the data to appear in SQL Database. One way to monitor how much data is available in your SQL Database is through [azure portal](https://manage.windowsazure.com/).On the left panel locate SQL DATABASES ![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-SQL-databases.png) and click it. Then locate your database **pmaintenancedb** and click on it. On the next page at the bottom, click on MANAGE\n\n    ![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-manage.png).\n\n    Here, you can click on New Query and query for the number of rows (e.g. select count(*) from PMResult ). As your database grows, the number of rows in the table should  increase.\n\n\n## **Power BI Dashboard**\n\n### Overview\n\nThis section describes how to set up Power BI dashboard to visualize\nyour real time data from Azure stream analytics (hot path), as well as\nbatch prediction results from Azure machine learning (cold path).\n\n### Setup cold path dashboard\n\nIn the cold path data pipeline, the essential goal is to get the\npredictive RUL (remaining useful life) of each aircraft engine once it\nfinishes a flight (cycle). The prediction result is updated every 3\nhours for predicting the aircraft engines that have finished a flight\nduring the past 3 hours.\n\nPower BI connects to an Azure SQL database as its data source, where the\nprediction results are stored. Note: 1) Upon deploying your\nsolution, a real prediction will show up in the database within 3 hours.\nThe pbix file that came with the Generator download contains some seed\ndata so that you may create the Power BI dashboard right away. 2) In\nthis step, the prerequisite is to download and install the free software\n[Power BI\ndesktop](https://powerbi.microsoft.com/documentation/powerbi-desktop-get-the-desktop/).\n\nThe following steps will guide you on how to connect the pbix file to\nthe SQL Database that was spun up at the time of solution deployment\ncontaining data (*e.g.*. prediction results) for visualization.\n\n1.  Get the database credentials.\n\n    You'll need **database server name, database name, user name and\n    password** before moving to next steps. Here are the steps to guide\n    you how to find them.\n\n    -   Once **'Azure SQL Database'** on your solution template diagram turns green, click it and then click **'Open'**.\n\n    -   You'll see a new browser tab/window which displays the Azure\n    portal page. Click **'Resource groups'** on the left panel.\n\n    -   Select the subscription you're using for deploying the solution, and\n    then select **'YourSolutionName\\_ResourceGroup'**.\n\n    -   In the new pop out panel, click the  ![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-sql.png) icon to access your\n    database. Your database name is next to the this icon (*e.g.*, **'pmaintenancedb'**), and  the **database server name** is listed under the Server name property and should look similar to **YourSoutionName.database.windows.net**.\n\n    -   Your database **username** and **password** are the same as\n    the username and password previously recorded during deployment of the solution.\n\n2.  Update the data source of the cold path report file with Power\n    BI Desktop.\n\n    -   In the folder on your PC where you downloaded and unzipped the\n    Generator file, double-click the\n    **PowerBI\\\\PredictiveMaintenanceAerospace.pbix** file. If you see any warning messages when you open the file, ignore them. On the top of the file, click **'Edit Queries'**.\n\n        ![](media\\cortana-analytics-technical-guide-predictive-maintenance\\edit-queries.png)\n\n    -   You'll see two tables, **RemainingUsefulLife** and **PMResult**. Select the first table and click ![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-query-settings.png) next to **'Source'** under\n        **'APPLIED STEPS'** on the right **'Query Settings'** panel. Ignore\n        any warning messages that appear.\n\n    -   In the pop out window, replace **'Server'** and **'Database'** with\n    your own server and database names, and then click **'OK'**. For server\n    name, make sure you specify the port 1433\n    (**YourSoutionName.database.windows.net, 1433**). Leave the Database field as **pmaintenancedb**. Ignore the warning\n    messages that appear on the screen.\n\n    -   In the next pop out window, you'll see two options on the left pane\n    (**Windows** and **Database**). Click **'Database'**, fill in your\n    **'Username'** and **'Password'** (this is the username and password\n    you entered when you first deployed the solution and created an\n    Azure SQL database). In ***Select which level to apply these\n    settings to***, check database level option. Then click\n    **'Connect'**.\n\n    -   Click on the second table **PMResult** then click ![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-navigation.png)\n    next to **'Source'** under\n    **'APPLIED STEPS'** on the right **'Query Settings'** panel, and update\n    the server and database names as in the above steps and click OK.\n\n    -   Once you're guided back to the previous page, close the window. A message will pop out - click **Apply**. Lastly, click the **Save** button to save\n    the changes. Your Power BI file has now established connection to the server. If your visualizations are empty, make sure you clear the selections on the visualizations to visualize all the data by clicking the eraser icon on the upper right corner of the legends. Use the refresh button to reflect new data on the visualizations. Initially, you will only see the seed data on your visualizations as the data factory is scheduled to refresh every 3 hours. After 3 hours, you will see new predictions reflected in your visualizations when you refresh the data.\n\n3.  (Optional) Publish the cold path dashboard to [Power BI\n    online](http://www.powerbi.com/). Note that this step needs a Power\n    BI account (or Office 365 account).\n\n    -   Click **'Publish'** and few seconds later a window appears\n    displaying \"Publishing to Power BI Success!\" with a green\n    check mark. Click the link below \"Open\n    PredictiveMaintenanceAerospace.pbix in Power BI\". To find detailed instructions, see [Publish from Power BI Desktop](https://support.powerbi.com/knowledgebase/articles/461278-publish-from-power-bi-desktop).\n\n    -   To create a new dashboard: click the **+** sign next to the\n    **Dashboards** section on the left pane. Enter the name \"Predictive\n    Maintenance Demo\" for this new dashboard.\n\n    -   Once you open the report, click ![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-pin.png) to pin all the\n    visualizations to your dashboard. To find detailed instructions, see [Pin a tile to a Power BI dashboard from a report](https://support.powerbi.com/knowledgebase/articles/430323-pin-a-tile-to-a-power-bi-dashboard-from-a-report).\n    Go to the dashboard page and\n    adjust the size and location of your visualizations and edit their titles. To find detailed instructions on how to edit your tiles, see [Edit a tile -- resize, move, rename, pin, delete, add hyperlink](https://powerbi.microsoft.com/documentation/powerbi-service-edit-a-tile-in-a-dashboard/#rename). Here is an example dashboard with some cold path visualizations pinned to it.  Depending on how long you run your data generator, your numbers on the visualizations may be different.\n<br/>\n    ![](media\\cortana-analytics-technical-guide-predictive-maintenance\\final-view.png)\n<br/>\n    -   To schedule refresh of the data, hover your mouse over the **PredictiveMaintenanceAerospace** dataset, click ![](media\\cortana-analytics-technical-guide-predictive-maintenance\\icon-elipsis.png) and then choose **Schedule Refresh**.\n<br/>\n        **Note:** If you see a warning massage, click **Edit Credentials** and make sure your database credentials are the same as those described in step 1.\n<br/>\n    ![](media\\cortana-analytics-technical-guide-predictive-maintenance\\schedule-refresh.png)\n<br/>\n    -   Expand the **Schedule Refresh** section. Turn on \"keep your\n    data up-to-date\".\n<br/>\n    -   Schedule the refresh based on your needs. To find more information, see\n    [Data refresh in Power BI](https://support.powerbi.com/knowledgebase/articles/474669-data-refresh-in-power-bi).\n\n### Setup hot path dashboard\n\nThe following steps will guide you how to visualize real time data\noutput from Stream Analytics jobs that were generated at the time of\nsolution deployment. A [Power BI online](http://www.powerbi.com/)\naccount is required to perform the following steps. If you don't have an\naccount, you can [create one](https://powerbi.microsoft.com/pricing).\n\n1.  Add Power BI output in Azure Stream Analytics (ASA).\n\n    -  You will need to follow the instructions in\n    [Azure Stream Analytics & Power BI: A real-time analytics dashboard for real-time visibility of streaming data](stream-analytics-power-bi-dashboard.md)\n    to set up the output of your Azure Stream Analytics job as your Power BI dashboard.\n    - The ASA query has three outputs which are **aircraftmonitor**, **aircraftalert**, and **flightsbyhour**. You can view the query by clicking on query tab. Corresponding to each of these tables, you will need to add an output to ASA. When you add the first output (*e.g.* **aircraftmonitor**) make sure the **Output Alias**, **Dataset Name** and **Table Name** are the same (**aircraftmonitor**). Repeat the steps to add outputs for **aircraftalert**, and **flightsbyhour**. Once you have added all three output tables and started the ASA job, you should get a confirmation message (*e.g.*, \"Starting stream analytics job maintenancesa02asapbi succeeded\").\n\n2. Log in to [Power BI online](http://www.powerbi.com)\n\n    -   On the left panel Datasets section in My Workspace, the\n    ***DATASET*** names **aircraftmonitor**, **aircraftalert**, and\n    **flightsbyhour** should appear.This is the streaming data you pushed from Azure Stream Analytics in the previous step.The dataset **flightsbyhour** may not show up at the same time as the other two datasets due to the nature of the SQL query behind it. However, it should show up after an hour.\n    -   Make sure the ***Visualizations*** pane is open and is shown on the\n    right side of the screen.\n\n3. Once you have the data flowing into Power BI, you can start visualizing the streaming data. Below is an example dashboard with some hot path visualizations pinned to it. You can create other dashboard tiles based on appropriate datasets. Depending on how long you run your data generator, your numbers on the visualizations may be different.\n\n\n    ![](media\\cortana-analytics-technical-guide-predictive-maintenance\\dashboard-view.png)\n\n4. Here are some steps to create one of the tiles above   the \"Fleet View of Sensor 11 vs. Threshold 48.26\" tile:\n\n    -   Click dataset **aircraftmonitor** on the left panel\n    Datasets section.\n\n    -   Click the **Line Chart** icon.\n\n    -   Click **Processed** in the **Fields** pane so that it shows under\n    \"Axis\" in the **Visualizations** pane.\n\n    -   Click \"s11\" and \"s11\\_alert\" so that they both appear\n    under \"Values\". Click the small arrow next to **s11** and\n    **s11\\_alert**, change \"Sum\" to \"Average\".\n\n    -   Click **SAVE** on the top and name the report \"aircraftmonitor\". The\n    report named \"aircraftmonitor\" will be shown in the **Reports**\n    section in the **Navigator** pane on the left.\n\n    -   Click the **Pin Visual** icon on the top right corner of this\n    line chart. A \"Pin to Dashboard\" window may show up for you to\n    choose a dashboard. Select \"Predictive Maintenance Demo\", then\n    click \"Pin\".\n\n    -   Hover the mouse over this tile on the dashboard, click the \"edit\"\n    icon on the top right corner to change its title to \"Fleet View of\n    Sensor 11 vs. Threshold 48.26\" and subtitle to \"Average across fleet\n    over time\".\n\n## **How to delete your solution**\nPlease ensure that you stop the data generator when not actively using the solution as running the data generator will incur higher costs. Please delete the solution if you are not using it. Deleting your solution will delete all the components provisioned in your subscription when you deployed the solution. To delete the solution right click on your solution name in the left panel of the solution template and click on delete.\n\n## **Cost estimation tools**\n\nThe following two tools are available to help you better understand the\ntotal costs involved in running the Predictive Maintenance for Aerospace\nSolution Template in your subscription:\n\n-   [Microsoft Azure Cost Estimator\n    Tool (online)](https://azure.microsoft.com/pricing/calculator/)\n\n-   [Microsoft Azure Cost Estimator\n    Tool (desktop)](http://www.microsoft.com/download/details.aspx?id=43376)\n"
}