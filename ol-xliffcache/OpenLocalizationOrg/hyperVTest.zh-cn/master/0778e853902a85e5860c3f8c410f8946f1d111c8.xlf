<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="zh-cn">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Kernels available with Jupyter notebooks on HDInsight Spark clusters on Linux| Microsoft Azure</source>
          <target state="new">Kernels available with Jupyter notebooks on HDInsight Spark clusters on Linux| Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn about the additional Jupyter notebook kernels available with Spark cluster on HDInsight Linux.</source>
          <target state="new">Learn about the additional Jupyter notebook kernels available with Spark cluster on HDInsight Linux.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Kernels available for Jupyter notebooks with Spark clusters on HDInsight (Linux)</source>
          <target state="new">Kernels available for Jupyter notebooks with Spark clusters on HDInsight (Linux)</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Apache Spark cluster on HDInsight (Linux) includes Jupyter notebooks that you can use to test your applications.</source>
          <target state="new">Apache Spark cluster on HDInsight (Linux) includes Jupyter notebooks that you can use to test your applications.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>By default Jupyter notebook comes with a <bpt id="p1">**</bpt>Python2<ept id="p1">**</ept><ph id="ph2" /> kernel.</source>
          <target state="new">By default Jupyter notebook comes with a <bpt id="p1">**</bpt>Python2<ept id="p1">**</ept><ph id="ph2" /> kernel.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>HDInsight Spark clusters provide two additional kernels that you can use with the Jupyter notebook.</source>
          <target state="new">HDInsight Spark clusters provide two additional kernels that you can use with the Jupyter notebook.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>These are:</source>
          <target state="new">These are:</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source><bpt id="p2">**</bpt>Spark<ept id="p2">**</ept><ph id="ph3" /> (for applications written in Scala)</source>
          <target state="new"><bpt id="p2">**</bpt>Spark<ept id="p2">**</ept><ph id="ph3" /> (for applications written in Scala)</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source><bpt id="p3">**</bpt>PySpark<ept id="p3">**</ept><ph id="ph4" /> (for applications written in Python)</source>
          <target state="new"><bpt id="p3">**</bpt>PySpark<ept id="p3">**</ept><ph id="ph4" /> (for applications written in Python)</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>In this article, you will learn about how to use these kernels and what are the benefits you get from using them.</source>
          <target state="new">In this article, you will learn about how to use these kernels and what are the benefits you get from using them.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source><bpt id="p4">**</bpt>Prerequisites:<ept id="p4">**</ept></source>
          <target state="new"><bpt id="p4">**</bpt>Prerequisites:<ept id="p4">**</ept></target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>You must have the following:</source>
          <target state="new">You must have the following:</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>An Azure subscription.</source>
          <target state="new">An Azure subscription.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>See <bpt id="p5">[</bpt>Get Azure free trial<ept id="p5">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.</source>
          <target state="new">See <bpt id="p5">[</bpt>Get Azure free trial<ept id="p5">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>An Apache Spark cluster on HDInsight Linux.</source>
          <target state="new">An Apache Spark cluster on HDInsight Linux.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>For instructions, see <bpt id="p6">[</bpt>Create Apache Spark clusters in Azure HDInsight<ept id="p6">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.</source>
          <target state="new">For instructions, see <bpt id="p6">[</bpt>Create Apache Spark clusters in Azure HDInsight<ept id="p6">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>How do I use the kernels?</source>
          <target state="new">How do I use the kernels?</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>From the <bpt id="p7">[</bpt>Azure Preview Portal<ept id="p7">](https://portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</source>
          <target state="new">From the <bpt id="p7">[</bpt>Azure Preview Portal<ept id="p7">](https://portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>You can also navigate to your cluster under <bpt id="p8">**</bpt>Browse All<ept id="p8">**</ept><ph id="ph5" /> &gt; <bpt id="p9">**</bpt>HDInsight Clusters<ept id="p9">**</ept>.</source>
          <target state="new">You can also navigate to your cluster under <bpt id="p8">**</bpt>Browse All<ept id="p8">**</ept><ph id="ph5" /> &gt; <bpt id="p9">**</bpt>HDInsight Clusters<ept id="p9">**</ept>.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>From the Spark cluster blade, click <bpt id="p10">**</bpt>Quick Links<ept id="p10">**</ept>, and then from the <bpt id="p11">**</bpt>Cluster Dashboard<ept id="p11">**</ept><ph id="ph6" /> blade, click <bpt id="p12">**</bpt>Jupyter Notebook<ept id="p12">**</ept>.</source>
          <target state="new">From the Spark cluster blade, click <bpt id="p10">**</bpt>Quick Links<ept id="p10">**</ept>, and then from the <bpt id="p11">**</bpt>Cluster Dashboard<ept id="p11">**</ept><ph id="ph6" /> blade, click <bpt id="p12">**</bpt>Jupyter Notebook<ept id="p12">**</ept>.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>If prompted, enter the admin credentials for the cluster.</source>
          <target state="new">If prompted, enter the admin credentials for the cluster.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source><ph id="ph7">[AZURE.NOTE]</ph><ph id="ph8" /> You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser.</source>
          <target state="new"><ph id="ph7">[AZURE.NOTE]</ph><ph id="ph8" /> You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Replace <bpt id="p13">__</bpt>CLUSTERNAME<ept id="p13">__</ept><ph id="ph9" /> with the name of your cluster:</source>
          <target state="new">Replace <bpt id="p13">__</bpt>CLUSTERNAME<ept id="p13">__</ept><ph id="ph9" /> with the name of your cluster:</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Create a new notebook with the new kernels.</source>
          <target state="new">Create a new notebook with the new kernels.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p14">**</bpt>New<ept id="p14">**</ept>, and then click <bpt id="p15">**</bpt>Pyspark<ept id="p15">**</ept><ph id="ph11" /> or <bpt id="p16">**</bpt>Spark<ept id="p16">**</ept>.</source>
          <target state="new">Click <bpt id="p14">**</bpt>New<ept id="p14">**</ept>, and then click <bpt id="p15">**</bpt>Pyspark<ept id="p15">**</ept><ph id="ph11" /> or <bpt id="p16">**</bpt>Spark<ept id="p16">**</ept>.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>You should use the Spark kernel for Scala applications and PySpark kernel for Python applications.</source>
          <target state="new">You should use the Spark kernel for Scala applications and PySpark kernel for Python applications.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source><ph id="ph12">![</ph>Create a new Jupyter notebook<ph id="ph13">](./media/hdinsight-apache-spark-jupyter-notebook-kernels/jupyter-kernels.png "Create a new Jupyter notebook")</ph></source>
          <target state="new"><ph id="ph12">![</ph>Create a new Jupyter notebook<ph id="ph13">](./media/hdinsight-apache-spark-jupyter-notebook-kernels/jupyter-kernels.png "Create a new Jupyter notebook")</ph></target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>This should open a new notebook with the kernel you selected.</source>
          <target state="new">This should open a new notebook with the kernel you selected.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Why should I use the new kernels?</source>
          <target state="new">Why should I use the new kernels?</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>There are a couple of benefits of using the new kernels.</source>
          <target state="new">There are a couple of benefits of using the new kernels.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>With the default <bpt id="p17">**</bpt>Python2<ept id="p17">**</ept><ph id="ph14" /> kernel, you need to set the Spark, SQL, or Hive contexts before you can start working with the application you are developing.</source>
          <target state="new">With the default <bpt id="p17">**</bpt>Python2<ept id="p17">**</ept><ph id="ph14" /> kernel, you need to set the Spark, SQL, or Hive contexts before you can start working with the application you are developing.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>If you use the new kernels (<bpt id="p18">**</bpt>Spark<ept id="p18">**</ept><ph id="ph15" /> or <bpt id="p19">**</bpt>PySpark<ept id="p19">**</ept>), these contexts are available for you by default.</source>
          <target state="new">If you use the new kernels (<bpt id="p18">**</bpt>Spark<ept id="p18">**</ept><ph id="ph15" /> or <bpt id="p19">**</bpt>PySpark<ept id="p19">**</ept>), these contexts are available for you by default.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>These contexts are:</source>
          <target state="new">These contexts are:</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source><bpt id="p20">**</bpt>sc<ept id="p20">**</ept><ph id="ph16" /> - for Spark context</source>
          <target state="new"><bpt id="p20">**</bpt>sc<ept id="p20">**</ept><ph id="ph16" /> - for Spark context</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source><bpt id="p21">**</bpt>sqlContext<ept id="p21">**</ept><ph id="ph17" /> - for SQL context</source>
          <target state="new"><bpt id="p21">**</bpt>sqlContext<ept id="p21">**</ept><ph id="ph17" /> - for SQL context</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source><bpt id="p22">**</bpt>hiveContext<ept id="p22">**</ept><ph id="ph18" /> - for Hive context</source>
          <target state="new"><bpt id="p22">**</bpt>hiveContext<ept id="p22">**</ept><ph id="ph18" /> - for Hive context</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>You can directly use the <bpt id="p23">**</bpt>%sql<ept id="p23">**</ept><ph id="ph19" /> and <bpt id="p24">**</bpt>%hive<ept id="p24">**</ept><ph id="ph20" /> magics to use SQL or Hive queries, respectively.</source>
          <target state="new">You can directly use the <bpt id="p23">**</bpt>%sql<ept id="p23">**</ept><ph id="ph19" /> and <bpt id="p24">**</bpt>%hive<ept id="p24">**</ept><ph id="ph20" /> magics to use SQL or Hive queries, respectively.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>So, something like this would directly work out-of-the-box, without any leading code statements.</source>
          <target state="new">So, something like this would directly work out-of-the-box, without any leading code statements.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Considerations while using the new kernels</source>
          <target state="new">Considerations while using the new kernels</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Whichever kernel you use (Python2, PySpark, or Spark), leaving the notebooks running will consume your cluster resources.</source>
          <target state="new">Whichever kernel you use (Python2, PySpark, or Spark), leaving the notebooks running will consume your cluster resources.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>With the Python2 notebook, because you create the contexts explicitly, you can also kill those contexts when you exit the application.</source>
          <target state="new">With the Python2 notebook, because you create the contexts explicitly, you can also kill those contexts when you exit the application.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>However, with PySpark and Spark kernels, because the contexts are preset, you cannot explicitly kill the context as well.</source>
          <target state="new">However, with PySpark and Spark kernels, because the contexts are preset, you cannot explicitly kill the context as well.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>So, if you just exit the notebook, the context might still be running, using your cluster resources.</source>
          <target state="new">So, if you just exit the notebook, the context might still be running, using your cluster resources.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>A good practice with the PySpark and Spark kernels would be to use the <bpt id="p25">**</bpt>Close and Halt<ept id="p25">**</ept><ph id="ph21" /> option from the notebook's <bpt id="p26">**</bpt>File<ept id="p26">**</ept><ph id="ph22" /> menu.</source>
          <target state="new">A good practice with the PySpark and Spark kernels would be to use the <bpt id="p25">**</bpt>Close and Halt<ept id="p25">**</ept><ph id="ph21" /> option from the notebook's <bpt id="p26">**</bpt>File<ept id="p26">**</ept><ph id="ph22" /> menu.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>This kills the context and then exits the notebook.</source>
          <target state="new">This kills the context and then exits the notebook.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Show me some examples</source>
          <target state="new">Show me some examples</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>When you open a Jupyter notebook, you will see two folders available at the root level.</source>
          <target state="new">When you open a Jupyter notebook, you will see two folders available at the root level.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>The <bpt id="p27">**</bpt>Python<ept id="p27">**</ept><ph id="ph23" /> folder has sample notebooks that use the default <bpt id="p28">**</bpt>Python2<ept id="p28">**</ept><ph id="ph24" /> kernel.</source>
          <target state="new">The <bpt id="p27">**</bpt>Python<ept id="p27">**</ept><ph id="ph23" /> folder has sample notebooks that use the default <bpt id="p28">**</bpt>Python2<ept id="p28">**</ept><ph id="ph24" /> kernel.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>The <bpt id="p29">**</bpt>Scala<ept id="p29">**</ept><ph id="ph25" /> folder has sample notebooks that use the new <bpt id="p30">**</bpt>Spark<ept id="p30">**</ept><ph id="ph26" /> kernel.</source>
          <target state="new">The <bpt id="p29">**</bpt>Scala<ept id="p29">**</ept><ph id="ph25" /> folder has sample notebooks that use the new <bpt id="p30">**</bpt>Spark<ept id="p30">**</ept><ph id="ph26" /> kernel.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>You can open the same (e.g. <bpt id="p31">**</bpt>READ ME FIRST - Learn the Basics of Spark on HDInsight<ept id="p31">**</ept>) notebook from the two folders to see how Python2 notebook always start with setting the required contexts, while the Spark notebook just uses the preset contexts.</source>
          <target state="new">You can open the same (e.g. <bpt id="p31">**</bpt>READ ME FIRST - Learn the Basics of Spark on HDInsight<ept id="p31">**</ept>) notebook from the two folders to see how Python2 notebook always start with setting the required contexts, while the Spark notebook just uses the preset contexts.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>Feedback</source>
          <target state="new">Feedback</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>The new kernels are in a pretty nascent stage and will evolve over time.</source>
          <target state="new">The new kernels are in a pretty nascent stage and will evolve over time.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>This could also mean that APIs could change as these kernels mature.</source>
          <target state="new">This could also mean that APIs could change as these kernels mature.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>We would appreciate any feedback that you have while using these new kernels.</source>
          <target state="new">We would appreciate any feedback that you have while using these new kernels.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>This will be very useful in shaping the final release of these kernels.</source>
          <target state="new">This will be very useful in shaping the final release of these kernels.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>You can leave your comments/feedback under the <bpt id="p32">**</bpt>Comments<ept id="p32">**</ept><ph id="ph27" /> section at the bottom of this article.</source>
          <target state="new">You can leave your comments/feedback under the <bpt id="p32">**</bpt>Comments<ept id="p32">**</ept><ph id="ph27" /> section at the bottom of this article.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>See also</source>
          <target state="new">See also</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source><bpt id="p33">[</bpt>Overview: Apache Spark on Azure HDInsight<ept id="p33">](hdinsight-apache-spark-overview.md)</ept></source>
          <target state="new"><bpt id="p33">[</bpt>Overview: Apache Spark on Azure HDInsight<ept id="p33">](hdinsight-apache-spark-overview.md)</ept></target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Scenarios</source>
          <target state="new">Scenarios</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source><bpt id="p34">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id="p34">](hdinsight-apache-spark-use-bi-tools.md)</ept></source>
          <target state="new"><bpt id="p34">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id="p34">](hdinsight-apache-spark-use-bi-tools.md)</ept></target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source><bpt id="p35">[</bpt>Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data<ept id="p35">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept></source>
          <target state="new"><bpt id="p35">[</bpt>Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data<ept id="p35">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept></target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source><bpt id="p36">[</bpt>Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results<ept id="p36">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept></source>
          <target state="new"><bpt id="p36">[</bpt>Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results<ept id="p36">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept></target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source><bpt id="p37">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id="p37">](hdinsight-apache-spark-eventhub-streaming.md)</ept></source>
          <target state="new"><bpt id="p37">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id="p37">](hdinsight-apache-spark-eventhub-streaming.md)</ept></target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source><bpt id="p38">[</bpt>Website log analysis using Spark in HDInsight<ept id="p38">](hdinsight-apache-spark-custom-library-website-log-analysis.md)</ept></source>
          <target state="new"><bpt id="p38">[</bpt>Website log analysis using Spark in HDInsight<ept id="p38">](hdinsight-apache-spark-custom-library-website-log-analysis.md)</ept></target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Create and run applications</source>
          <target state="new">Create and run applications</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source><bpt id="p39">[</bpt>Create a standalone application using Scala<ept id="p39">](hdinsight-apache-spark-create-standalone-application.md)</ept></source>
          <target state="new"><bpt id="p39">[</bpt>Create a standalone application using Scala<ept id="p39">](hdinsight-apache-spark-create-standalone-application.md)</ept></target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source><bpt id="p40">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id="p40">](hdinsight-apache-spark-livy-rest-interface.md)</ept></source>
          <target state="new"><bpt id="p40">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id="p40">](hdinsight-apache-spark-livy-rest-interface.md)</ept></target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Tools and extensions</source>
          <target state="new">Tools and extensions</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source><bpt id="p41">[</bpt>Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons<ept id="p41">](hdinsight-apache-spark-intellij-tool-plugin.md)</ept></source>
          <target state="new"><bpt id="p41">[</bpt>Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons<ept id="p41">](hdinsight-apache-spark-intellij-tool-plugin.md)</ept></target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source><bpt id="p42">[</bpt>Use Zeppelin notebooks with a Spark cluster on HDInsight<ept id="p42">](hdinsight-apache-spark-use-zeppelin-notebook.md)</ept></source>
          <target state="new"><bpt id="p42">[</bpt>Use Zeppelin notebooks with a Spark cluster on HDInsight<ept id="p42">](hdinsight-apache-spark-use-zeppelin-notebook.md)</ept></target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Manage resources</source>
          <target state="new">Manage resources</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source><bpt id="p43">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id="p43">](hdinsight-apache-spark-resource-manager.md)</ept></source>
          <target state="new"><bpt id="p43">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id="p43">](hdinsight-apache-spark-resource-manager.md)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">0778e853902a85e5860c3f8c410f8946f1d111c8</xliffext:olfilehash>
  </header>
</xliff>