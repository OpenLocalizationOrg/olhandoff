<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="fr-fr">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Use MapReduce and Curl with Hadoop in HDInsight | Microsoft Azure</source>
          <target state="new">Use MapReduce and Curl with Hadoop in HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to remotely run MapReduce jobs with Hadoop on HDInsight using Curl.</source>
          <target state="new">Learn how to remotely run MapReduce jobs with Hadoop on HDInsight using Curl.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Run MapReduce jobs with Hadoop on HDInsight using Curl</source>
          <target state="new">Run MapReduce jobs with Hadoop on HDInsight using Curl</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>In this document, you will learn how to use Curl to run MapReduce jobs on a Hadoop on HDInsight cluster.</source>
          <target state="new">In this document, you will learn how to use Curl to run MapReduce jobs on a Hadoop on HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Curl is used to demonstrate how you can interact with HDInsight by using raw HTTP requests to run MapReduce jobs.</source>
          <target state="new">Curl is used to demonstrate how you can interact with HDInsight by using raw HTTP requests to run MapReduce jobs.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>This works by using the WebHCat REST API (formerly known as Templeton) provided by your HDInsight cluster.</source>
          <target state="new">This works by using the WebHCat REST API (formerly known as Templeton) provided by your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source><ph id="ph3">[AZURE.NOTE]</ph><ph id="ph4" /> If you are already familiar with using Linux-based Hadoop servers, but you are new to HDInsight, see <bpt id="p1">[</bpt>What you need to know about Linux-based Hadoop on HDInsight<ept id="p1">](hdinsight-hadoop-linux-information.md)</ept>.</source>
          <target state="new"><ph id="ph3">[AZURE.NOTE]</ph><ph id="ph4" /> If you are already familiar with using Linux-based Hadoop servers, but you are new to HDInsight, see <bpt id="p1">[</bpt>What you need to know about Linux-based Hadoop on HDInsight<ept id="p1">](hdinsight-hadoop-linux-information.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Prerequisites</source>
          <target state="new">Prerequisites</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>To complete the steps in this article, you will need the following:</source>
          <target state="new">To complete the steps in this article, you will need the following:</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>A Hadoop on HDInsight cluster (Linux or Windows-based)</source>
          <target state="new">A Hadoop on HDInsight cluster (Linux or Windows-based)</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source><bpt id="p2">[</bpt>Curl<ept id="p2">](http://curl.haxx.se/)</ept></source>
          <target state="new"><bpt id="p2">[</bpt>Curl<ept id="p2">](http://curl.haxx.se/)</ept></target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source><bpt id="p3">[</bpt>jq<ept id="p3">](http://stedolan.github.io/jq/)</ept></source>
          <target state="new"><bpt id="p3">[</bpt>jq<ept id="p3">](http://stedolan.github.io/jq/)</ept></target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Run MapReduce jobs using Curl</source>
          <target state="new">Run MapReduce jobs using Curl</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source><ph id="ph5">[AZURE.NOTE]</ph><ph id="ph6" /> When you use Curl or any other REST communication with WebHCat, you must authenticate the requests by providing the HDInsight cluster administrator user name and password.</source>
          <target state="new"><ph id="ph5">[AZURE.NOTE]</ph><ph id="ph6" /> When you use Curl or any other REST communication with WebHCat, you must authenticate the requests by providing the HDInsight cluster administrator user name and password.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>You must also use the cluster name as part of the URI that is used to send the requests to the server.</source>
          <target state="new">You must also use the cluster name as part of the URI that is used to send the requests to the server.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>For the commands in this section, replace <bpt id="p4">**</bpt>USERNAME<ept id="p4">**</ept><ph id="ph7" /> with the user to authenticate to the cluster, and <bpt id="p5">**</bpt>PASSWORD<ept id="p5">**</ept><ph id="ph8" /> with the password for the user account.</source>
          <target state="new">For the commands in this section, replace <bpt id="p4">**</bpt>USERNAME<ept id="p4">**</ept><ph id="ph7" /> with the user to authenticate to the cluster, and <bpt id="p5">**</bpt>PASSWORD<ept id="p5">**</ept><ph id="ph8" /> with the password for the user account.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Replace <bpt id="p6">**</bpt>CLUSTERNAME<ept id="p6">**</ept><ph id="ph9" /> with the name of your cluster.</source>
          <target state="new">Replace <bpt id="p6">**</bpt>CLUSTERNAME<ept id="p6">**</ept><ph id="ph9" /> with the name of your cluster.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>The REST API is secured by using <bpt id="p7">[</bpt>basic access authentication<ept id="p7">](http://en.wikipedia.org/wiki/Basic_access_authentication)</ept>.</source>
          <target state="new">The REST API is secured by using <bpt id="p7">[</bpt>basic access authentication<ept id="p7">](http://en.wikipedia.org/wiki/Basic_access_authentication)</ept>.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>You should always make requests by using HTTPS to ensure that your credentials are securely sent to the server.</source>
          <target state="new">You should always make requests by using HTTPS to ensure that your credentials are securely sent to the server.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>From a command-line, use the following command to verify that you can connect to your HDInsight cluster:</source>
          <target state="new">From a command-line, use the following command to verify that you can connect to your HDInsight cluster:</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>You should receive a response similar to the following:</source>
          <target state="new">You should receive a response similar to the following:</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>The parameters used in this command are as follows:</source>
          <target state="new">The parameters used in this command are as follows:</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source><bpt id="p8">**</bpt>-u<ept id="p8">**</ept>: Indicates the user name and password used to authenticate the request</source>
          <target state="new"><bpt id="p8">**</bpt>-u<ept id="p8">**</ept>: Indicates the user name and password used to authenticate the request</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source><bpt id="p9">**</bpt>-G<ept id="p9">**</ept>: Indicates that this is a GET request</source>
          <target state="new"><bpt id="p9">**</bpt>-G<ept id="p9">**</ept>: Indicates that this is a GET request</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>The beginning of the URI, <bpt id="p10">**</bpt>https://CLUSTERNAME.azurehdinsight.net/templeton/v1<ept id="p10">**</ept>, is the same for all requests.</source>
          <target state="new">The beginning of the URI, <bpt id="p10">**</bpt>https://CLUSTERNAME.azurehdinsight.net/templeton/v1<ept id="p10">**</ept>, is the same for all requests.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>To submit a MapReduce job, use the following command:</source>
          <target state="new">To submit a MapReduce job, use the following command:</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>The end of the URI (/mapreduce/jar) tells WebHCat that this request will start a MapReduce job from a class in a jar file.</source>
          <target state="new">The end of the URI (/mapreduce/jar) tells WebHCat that this request will start a MapReduce job from a class in a jar file.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>The parameters used in this command are as follows:</source>
          <target state="new">The parameters used in this command are as follows:</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><bpt id="p11">**</bpt>-d<ept id="p11">**</ept>: <ph id="ph10">`-G`</ph><ph id="ph11" /> is not used, so the request defaults to the POST method.</source>
          <target state="new"><bpt id="p11">**</bpt>-d<ept id="p11">**</ept>: <ph id="ph10">`-G`</ph><ph id="ph11" /> is not used, so the request defaults to the POST method.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source><ph id="ph12">`-d`</ph><ph id="ph13" /> specifies the data values that are sent with the request.</source>
          <target state="new"><ph id="ph12">`-d`</ph><ph id="ph13" /> specifies the data values that are sent with the request.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source><bpt id="p12">**</bpt>user.name<ept id="p12">**</ept>: The user who is running the command</source>
          <target state="new"><bpt id="p12">**</bpt>user.name<ept id="p12">**</ept>: The user who is running the command</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source><bpt id="p13">**</bpt>jar<ept id="p13">**</ept>: The location of the jar file that contains class to be ran</source>
          <target state="new"><bpt id="p13">**</bpt>jar<ept id="p13">**</ept>: The location of the jar file that contains class to be ran</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source><bpt id="p14">**</bpt>class<ept id="p14">**</ept>: The class that contains the MapReduce logic</source>
          <target state="new"><bpt id="p14">**</bpt>class<ept id="p14">**</ept>: The class that contains the MapReduce logic</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source><bpt id="p15">**</bpt>arg<ept id="p15">**</ept>: The arguments to be passed to the MapReduce job; in this case, the input text file and the directory that are used for the output</source>
          <target state="new"><bpt id="p15">**</bpt>arg<ept id="p15">**</ept>: The arguments to be passed to the MapReduce job; in this case, the input text file and the directory that are used for the output</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>This command should return a job ID that can be used to check the status of the job:</source>
          <target state="new">This command should return a job ID that can be used to check the status of the job:</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>To check the status of the job, use the following command.</source>
          <target state="new">To check the status of the job, use the following command.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Replace the <bpt id="p16">**</bpt>JOBID<ept id="p16">**</ept><ph id="ph14" /> with the value returned in the previous step.</source>
          <target state="new">Replace the <bpt id="p16">**</bpt>JOBID<ept id="p16">**</ept><ph id="ph14" /> with the value returned in the previous step.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>For example, if the return value was <ph id="ph15">`{"id":"job_1415651640909_0026"}`</ph>, then the JOBID would be <ph id="ph16">`job_1415651640909_0026`</ph>.</source>
          <target state="new">For example, if the return value was <ph id="ph15">`{"id":"job_1415651640909_0026"}`</ph>, then the JOBID would be <ph id="ph16">`job_1415651640909_0026`</ph>.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>If the job is complete, the state will be "SUCCEEDED".</source>
          <target state="new">If the job is complete, the state will be "SUCCEEDED".</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source><ph id="ph17">[AZURE.NOTE]</ph><ph id="ph18" /> This Curl request returns a JSON document with information about the job; jq is used to retrieve only the state value.</source>
          <target state="new"><ph id="ph17">[AZURE.NOTE]</ph><ph id="ph18" /> This Curl request returns a JSON document with information about the job; jq is used to retrieve only the state value.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>When the state of the job has changed to <bpt id="p17">**</bpt>SUCCEEDED<ept id="p17">**</ept>, you can retrieve the results of the job from Azure Blob storage.</source>
          <target state="new">When the state of the job has changed to <bpt id="p17">**</bpt>SUCCEEDED<ept id="p17">**</ept>, you can retrieve the results of the job from Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>The <ph id="ph19">`statusdir`</ph><ph id="ph20" /> parameter that is passed with the query contains the location of the output file; in this case, <bpt id="p18">**</bpt>wasb:///example/curl<ept id="p18">**</ept>.</source>
          <target state="new">The <ph id="ph19">`statusdir`</ph><ph id="ph20" /> parameter that is passed with the query contains the location of the output file; in this case, <bpt id="p18">**</bpt>wasb:///example/curl<ept id="p18">**</ept>.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>This address stores the output of the job in the <bpt id="p19">**</bpt>example/curl<ept id="p19">**</ept><ph id="ph21" /> directory in the default storage container used by your HDInsight cluster.</source>
          <target state="new">This address stores the output of the job in the <bpt id="p19">**</bpt>example/curl<ept id="p19">**</ept><ph id="ph21" /> directory in the default storage container used by your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>You can list and download these files by using the <bpt id="p20">[</bpt>Azure CLI for Mac, Linux and Windows<ept id="p20">](../xplat-cli-install.md)</ept>.</source>
          <target state="new">You can list and download these files by using the <bpt id="p20">[</bpt>Azure CLI for Mac, Linux and Windows<ept id="p20">](../xplat-cli-install.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>For example, to list files in the <bpt id="p21">**</bpt>example/curl<ept id="p21">**</ept>, use the following command:</source>
          <target state="new">For example, to list files in the <bpt id="p21">**</bpt>example/curl<ept id="p21">**</ept>, use the following command:</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>To download a file, use the following:</source>
          <target state="new">To download a file, use the following:</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source><ph id="ph22">[AZURE.NOTE]</ph><ph id="ph23" /> You must specify the storage account name that contains the blob by using the <ph id="ph24">`-a`</ph><ph id="ph25" /> and <ph id="ph26">`-k`</ph><ph id="ph27" /> parameters, or set the <bpt id="p22">**</bpt>AZURE\_STORAGE\_ACCOUNT<ept id="p22">**</ept><ph id="ph28" /> and <bpt id="p23">**</bpt>AZURE\_STORAGE\_ACCESS\_KEY<ept id="p23">**</ept><ph id="ph29" /> environment variables.</source>
          <target state="new"><ph id="ph22">[AZURE.NOTE]</ph><ph id="ph23" /> You must specify the storage account name that contains the blob by using the <ph id="ph24">`-a`</ph><ph id="ph25" /> and <ph id="ph26">`-k`</ph><ph id="ph27" /> parameters, or set the <bpt id="p22">**</bpt>AZURE\_STORAGE\_ACCOUNT<ept id="p22">**</ept><ph id="ph28" /> and <bpt id="p23">**</bpt>AZURE\_STORAGE\_ACCESS\_KEY<ept id="p23">**</ept><ph id="ph29" /> environment variables.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>See <bpt id="p24">[</bpt>how to upload data to HDInsight<ept id="p24">](hdinsight-upload-data.md)</ept><ph id="ph30" /> for more information.</source>
          <target state="new">See <bpt id="p24">[</bpt>how to upload data to HDInsight<ept id="p24">](hdinsight-upload-data.md)</ept><ph id="ph30" /> for more information.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Summary</source>
          <target state="new">Summary</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>As demonstrated in this document, you can use raw HTTP request to run, monitor, and view the results of Hive jobs in your HDInsight cluster.</source>
          <target state="new">As demonstrated in this document, you can use raw HTTP request to run, monitor, and view the results of Hive jobs in your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>For more information about the REST interface that is used in this article, see the <bpt id="p25">[</bpt>WebHCat Reference<ept id="p25">](https://cwiki.apache.org/confluence/display/Hive/WebHCat+Reference)</ept>.</source>
          <target state="new">For more information about the REST interface that is used in this article, see the <bpt id="p25">[</bpt>WebHCat Reference<ept id="p25">](https://cwiki.apache.org/confluence/display/Hive/WebHCat+Reference)</ept>.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>For general information about MapReduce jobs in HDInsight:</source>
          <target state="new">For general information about MapReduce jobs in HDInsight:</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source><bpt id="p26">[</bpt>Use MapReduce with Hadoop on HDInsight<ept id="p26">](hdinsight-use-mapreduce.md)</ept></source>
          <target state="new"><bpt id="p26">[</bpt>Use MapReduce with Hadoop on HDInsight<ept id="p26">](hdinsight-use-mapreduce.md)</ept></target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>For information about other ways you can work with Hadoop on HDInsight:</source>
          <target state="new">For information about other ways you can work with Hadoop on HDInsight:</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source><bpt id="p27">[</bpt>Use Hive with Hadoop on HDInsight<ept id="p27">](hdinsight-use-hive.md)</ept></source>
          <target state="new"><bpt id="p27">[</bpt>Use Hive with Hadoop on HDInsight<ept id="p27">](hdinsight-use-hive.md)</ept></target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source><bpt id="p28">[</bpt>Use Pig with Hadoop on HDInsight<ept id="p28">](hdinsight-use-pig.md)</ept></source>
          <target state="new"><bpt id="p28">[</bpt>Use Pig with Hadoop on HDInsight<ept id="p28">](hdinsight-use-pig.md)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">81f5ff7e40c90befc0d0267e6655f03fc35f004e</xliffext:olfilehash>
  </header>
</xliff>