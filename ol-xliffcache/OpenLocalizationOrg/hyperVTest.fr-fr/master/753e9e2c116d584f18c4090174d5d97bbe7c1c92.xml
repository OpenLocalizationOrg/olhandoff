{
  "nodes": [
    {
      "pos": [
        28,
        79
      ],
      "content": "Sample data in Azure blob storage | Microsoft Azure"
    },
    {
      "pos": [
        99,
        132
      ],
      "content": "Sample data in Azure Blob Storage"
    },
    {
      "pos": [
        500,
        501
      ],
      "content": "#"
    },
    {
      "pos": [
        523,
        556
      ],
      "content": "Sample data in Azure blob storage"
    },
    {
      "pos": [
        561,
        573
      ],
      "content": "Introduction"
    },
    {
      "pos": [
        575,
        754
      ],
      "content": "This document covers sampling data stored in Azure blob storage by downloading it programmatically and then sampling it with sample Python code. The steps to do so are as follows:",
      "nodes": [
        {
          "content": "This document covers sampling data stored in Azure blob storage by downloading it programmatically and then sampling it with sample Python code.",
          "pos": [
            0,
            144
          ]
        },
        {
          "content": "The steps to do so are as follows:",
          "pos": [
            145,
            179
          ]
        }
      ]
    },
    {
      "pos": [
        756,
        1156
      ],
      "content": "<bpt id=\"p1\">**</bpt>Why sample your data?<ept id=\"p1\">**</ept>\nIf the dataset you plan to analyze is large, it is usually a good idea to down-sample the data to reduce it to a smaller but representative and more manageable size. This facilitates data understanding, exploration, and feature engineering. Its role in the Cortana Analytics Process is to enable fast prototyping of the data processing functions and machine learning models.",
      "nodes": [
        {
          "content": "<bpt id=\"p1\">**</bpt>Why sample your data?<ept id=\"p1\">**</ept>\nIf the dataset you plan to analyze is large, it is usually a good idea to down-sample the data to reduce it to a smaller but representative and more manageable size.",
          "pos": [
            0,
            229
          ]
        },
        {
          "content": "This facilitates data understanding, exploration, and feature engineering.",
          "pos": [
            230,
            304
          ]
        },
        {
          "content": "Its role in the Cortana Analytics Process is to enable fast prototyping of the data processing functions and machine learning models.",
          "pos": [
            305,
            438
          ]
        }
      ]
    },
    {
      "pos": [
        1158,
        1260
      ],
      "content": "The <bpt id=\"p2\">**</bpt>menu<ept id=\"p2\">**</ept><ph id=\"ph2\"/> below links to topics that describe how to sample data from various storage environments."
    },
    {
      "pos": [
        1351,
        1506
      ],
      "content": "This sampling task is a step in the <bpt id=\"p3\">[</bpt>Cortana Analytics Process (CAP)<ept id=\"p3\">](https://azure.microsoft.com/documentation/learning-paths/cortana-analytics-process/)</ept>."
    },
    {
      "pos": [
        1512,
        1541
      ],
      "content": "Download and down-sample data"
    },
    {
      "pos": [
        1545,
        1648
      ],
      "content": "Download the data from Azure blob storage using the blob service from the following sample Python code:"
    },
    {
      "pos": [
        2271,
        2337
      ],
      "content": "Read data into a Pandas data-frame from the file downloaded above."
    },
    {
      "pos": [
        2466,
        2534
      ],
      "content": "Down-sample the data using the <ph id=\"ph4\">`numpy`</ph>'s <ph id=\"ph5\">`random.choice`</ph><ph id=\"ph6\"/> as follows:"
    },
    {
      "pos": [
        2830,
        2946
      ],
      "content": "Now you can work with the above data frame with the 1 Percent sample for further exploration and feature generation."
    },
    {
      "pos": [
        2948,
        2950
      ],
      "content": "##"
    },
    {
      "pos": [
        2972,
        3023
      ],
      "content": "Upload data and read it into Azure Machine Learning"
    },
    {
      "pos": [
        3025,
        3119
      ],
      "content": "You can use the following sample code to down-sample the data and use it directly in Azure ML:"
    },
    {
      "pos": [
        3124,
        3160
      ],
      "content": "Write the data frame to a local file"
    },
    {
      "pos": [
        3273,
        3344
      ],
      "content": "Upload the local file to an Azure blob using the following sample code:"
    },
    {
      "pos": [
        4119,
        4285
      ],
      "content": "Read the data from the Azure blob using Azure ML <bpt id=\"p4\">[</bpt>Reader<ept id=\"p4\">](https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/)</ept><ph id=\"ph7\"/> as shown in the image below:"
    },
    {
      "pos": [
        4288,
        4305
      ],
      "content": "<ph id=\"ph8\">![</ph>reader blob<ph id=\"ph9\">][1]</ph>"
    },
    {
      "pos": [
        4412,
        4500
      ],
      "content": "[reader]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/"
    }
  ],
  "content": "<properties \n    pageTitle=\"Sample data in Azure blob storage | Microsoft Azure\" \n    description=\"Sample data in Azure Blob Storage\" \n    services=\"machine-learning,storage\" \n    documentationCenter=\"\" \n    authors=\"bradsev\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\" />\n\n<tags \n    ms.service=\"machine-learning\" \n    ms.workload=\"data-services\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"02/07/2016\" \n    ms.author=\"sunliangms;fashah;garye;bradsev\" /> \n\n#<a name=\"heading\"></a>Sample data in Azure blob storage\n\n## Introduction\n\nThis document covers sampling data stored in Azure blob storage by downloading it programmatically and then sampling it with sample Python code. The steps to do so are as follows:\n\n**Why sample your data?**\nIf the dataset you plan to analyze is large, it is usually a good idea to down-sample the data to reduce it to a smaller but representative and more manageable size. This facilitates data understanding, exploration, and feature engineering. Its role in the Cortana Analytics Process is to enable fast prototyping of the data processing functions and machine learning models.\n\nThe **menu** below links to topics that describe how to sample data from various storage environments. \n\n[AZURE.INCLUDE [cap-sample-data-selector](../../includes/cap-sample-data-selector.md)]\n\nThis sampling task is a step in the [Cortana Analytics Process (CAP)](https://azure.microsoft.com/documentation/learning-paths/cortana-analytics-process/).\n\n\n## Download and down-sample data\n1. Download the data from Azure blob storage using the blob service from the following sample Python code: \n\n        from azure.storage import BlobService\n        import tables\n        \n        STORAGEACCOUNTNAME= <storage_account_name>\n        STORAGEACCOUNTKEY= <storage_account_key>\n        LOCALFILENAME= <local_file_name>        \n        CONTAINERNAME= <container_name>\n        BLOBNAME= <blob_name>\n\n        #download from blob\n        t1=time.time()\n        blob_service=BlobService(account_name=STORAGEACCOUNTNAME,account_key=STORAGEACCOUNTKEY)\n        blob_service.get_blob_to_path(CONTAINERNAME,BLOBNAME,LOCALFILENAME)\n        t2=time.time()\n        print((\"It takes %s seconds to download \"+blobname) % (t2 - t1))\n\n2. Read data into a Pandas data-frame from the file downloaded above.\n\n        import pandas as pd\n\n        #directly ready from file on disk\n        dataframe_blobdata = pd.read_csv(LOCALFILE)\n\n3. Down-sample the data using the `numpy`'s `random.choice` as follows:\n\n        # A 1 percent sample\n        sample_ratio = 0.01 \n        sample_size = np.round(dataframe_blobdata.shape[0] * sample_ratio)\n        sample_rows = np.random.choice(dataframe_blobdata.index.values, sample_size)\n        dataframe_blobdata_sample = dataframe_blobdata.ix[sample_rows]\n\n    Now you can work with the above data frame with the 1 Percent sample for further exploration and feature generation.\n\n##<a name=\"heading\"></a>Upload data and read it into Azure Machine Learning\n\nYou can use the following sample code to down-sample the data and use it directly in Azure ML:\n\n1. Write the data frame to a local file\n\n        dataframe.to_csv(os.path.join(os.getcwd(),LOCALFILENAME), sep='\\t', encoding='utf-8', index=False)\n\n2. Upload the local file to an Azure blob using the following sample code:\n\n        from azure.storage import BlobService\n        import tables\n\n        STORAGEACCOUNTNAME= <storage_account_name>\n        LOCALFILENAME= <local_file_name>\n        STORAGEACCOUNTKEY= <storage_account_key>\n        CONTAINERNAME= <container_name>\n        BLOBNAME= <blob_name>\n\n        output_blob_service=BlobService(account_name=STORAGEACCOUNTNAME,account_key=STORAGEACCOUNTKEY)    \n        localfileprocessed = os.path.join(os.getcwd(),LOCALFILENAME) #assuming file is in current working directory\n        \n        try:\n       \n        #perform upload\n        output_blob_service.put_block_blob_from_path(CONTAINERNAME,BLOBNAME,localfileprocessed)\n        \n        except:         \n            print (\"Something went wrong with uploading to the blob:\"+ BLOBNAME)\n\n3. Read the data from the Azure blob using Azure ML [Reader](https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/) as shown in the image below:\n \n![reader blob][1]\n\n[1]: ./media/machine-learning-data-science-sample-data-blob/reader_blob.png\n\n\n<!-- Module References -->\n[reader]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/\n "
}