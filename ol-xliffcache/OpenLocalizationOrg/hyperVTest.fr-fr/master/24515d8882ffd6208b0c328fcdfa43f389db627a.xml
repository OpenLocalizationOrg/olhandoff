{
  "nodes": [
    {
      "pos": [
        27,
        133
      ],
      "content": "Create Hadoop, HBase, Storm, or Spark clusters on Linux in HDInsight using the Azure CLI | Microsoft Azure"
    },
    {
      "pos": [
        152,
        255
      ],
      "content": "Learn how to create Hadoop, HBase, Storm, or Spark clusters on Linux for HDInsight using the Azure CLI."
    },
    {
      "pos": [
        582,
        645
      ],
      "content": "Create Linux-based clusters in HDInsight using Azure PowerShell"
    },
    {
      "pos": [
        734,
        1029
      ],
      "content": "Azure PowerShell is a powerful scripting environment that you can use to control and automate the deployment and management of your workloads in Azure. This document provides information on how to provision a Linux-based HDInsight cluster by using Azure PowerShell, as well as an example script.",
      "nodes": [
        {
          "content": "Azure PowerShell is a powerful scripting environment that you can use to control and automate the deployment and management of your workloads in Azure.",
          "pos": [
            0,
            151
          ]
        },
        {
          "content": "This document provides information on how to provision a Linux-based HDInsight cluster by using Azure PowerShell, as well as an example script.",
          "pos": [
            152,
            295
          ]
        }
      ]
    },
    {
      "pos": [
        1033,
        1326
      ],
      "content": "<ph id=\"ph3\">[AZURE.NOTE]</ph><ph id=\"ph4\"/> Azure PowerShell is only available on Windows clients. If you are using a Linux, Unix, or Mac OS X client, see <bpt id=\"p1\">[</bpt>Create a Linux-based HDInsight cluster using Azure CLI<ept id=\"p1\">](hdinsight-hadoop-create-linux-clusters-azure-cli.md)</ept><ph id=\"ph5\"/> for information on using the Azure CLI to create a cluster.",
      "nodes": [
        {
          "content": "<ph id=\"ph3\">[AZURE.NOTE]</ph><ph id=\"ph4\"/> Azure PowerShell is only available on Windows clients.",
          "pos": [
            0,
            99
          ]
        },
        {
          "content": "If you are using a Linux, Unix, or Mac OS X client, see <bpt id=\"p1\">[</bpt>Create a Linux-based HDInsight cluster using Azure CLI<ept id=\"p1\">](hdinsight-hadoop-create-linux-clusters-azure-cli.md)</ept><ph id=\"ph5\"/> for information on using the Azure CLI to create a cluster.",
          "pos": [
            100,
            377
          ]
        }
      ]
    },
    {
      "pos": [
        1331,
        1344
      ],
      "content": "Prerequisites"
    },
    {
      "pos": [
        1348,
        1506
      ],
      "content": "<bpt id=\"p2\">**</bpt>An Azure subscription<ept id=\"p2\">**</ept>. See <bpt id=\"p3\">[</bpt>Get Azure free trial<ept id=\"p3\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
      "nodes": [
        {
          "content": "<bpt id=\"p2\">**</bpt>An Azure subscription<ept id=\"p2\">**</ept>.",
          "pos": [
            0,
            64
          ]
        },
        {
          "content": "See <bpt id=\"p3\">[</bpt>Get Azure free trial<ept id=\"p3\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
          "pos": [
            65,
            234
          ]
        }
      ]
    },
    {
      "pos": [
        1510,
        1999
      ],
      "content": "<bpt id=\"p4\">__</bpt>Azure PowerSHell<ept id=\"p4\">__</ept>. For information on configuring a workstation to run HDInsight Windows PowerShell cmdlets, see <bpt id=\"p5\">[</bpt>Install and configure Azure PowerShell<ept id=\"p5\">](../powershell-install-configure.md)</ept>. For more information on using Azure PowerShell with HDInsight, see <bpt id=\"p6\">[</bpt>Administer HDInsight using PowerShell<ept id=\"p6\">](hdinsight-administer-use-powershell.md)</ept>. For the list of the HDInsight Windows PowerShell cmdlets, see <bpt id=\"p7\">[</bpt>HDInsight cmdlet reference<ept id=\"p7\">](https://msdn.microsoft.com/library/azure/dn858087.aspx)</ept>.",
      "nodes": [
        {
          "content": "<bpt id=\"p4\">__</bpt>Azure PowerSHell<ept id=\"p4\">__</ept>.",
          "pos": [
            0,
            59
          ]
        },
        {
          "content": "For information on configuring a workstation to run HDInsight Windows PowerShell cmdlets, see <bpt id=\"p5\">[</bpt>Install and configure Azure PowerShell<ept id=\"p5\">](../powershell-install-configure.md)</ept>.",
          "pos": [
            60,
            269
          ]
        },
        {
          "content": "For more information on using Azure PowerShell with HDInsight, see <bpt id=\"p6\">[</bpt>Administer HDInsight using PowerShell<ept id=\"p6\">](hdinsight-administer-use-powershell.md)</ept>.",
          "pos": [
            270,
            455
          ]
        },
        {
          "content": "For the list of the HDInsight Windows PowerShell cmdlets, see <bpt id=\"p7\">[</bpt>HDInsight cmdlet reference<ept id=\"p7\">](https://msdn.microsoft.com/library/azure/dn858087.aspx)</ept>.",
          "pos": [
            456,
            641
          ]
        }
      ]
    },
    {
      "pos": [
        2003,
        2018
      ],
      "content": "Create clusters"
    },
    {
      "pos": [
        2020,
        2116
      ],
      "content": "The following procedures are needed to provision an HDInsight cluster by using Azure PowerShell:"
    },
    {
      "pos": [
        2120,
        2150
      ],
      "content": "Create an Azure resource group"
    },
    {
      "pos": [
        2153,
        2184
      ],
      "content": "Create an Azure Storage account"
    },
    {
      "pos": [
        2187,
        2217
      ],
      "content": "Create an Azure Blob container"
    },
    {
      "pos": [
        2220,
        2247
      ],
      "content": "Create an HDInsight cluster"
    },
    {
      "pos": [
        2249,
        2397
      ],
      "content": "The two most important parameters that you must set to provision Linux clusters are the ones where you specify the OS type and the SSH user details:"
    },
    {
      "pos": [
        2401,
        2462
      ],
      "content": "Make sure you specify the <bpt id=\"p8\">**</bpt>-OSType<ept id=\"p8\">**</ept><ph id=\"ph6\"/> parameter as <bpt id=\"p9\">**</bpt>Linux<ept id=\"p9\">**</ept>."
    },
    {
      "pos": [
        2465,
        2865
      ],
      "content": "To use SSH for remote sessions on the clusters, you can specify either SSH user password or the SSH public key. If you specify both the SSH user password and the SSH public key, the key will be ignored. If you want to use the SSH key for remote sessions, you must specify a blank SSH password when prompted for one. For more information on using SSH with HDInsight, see one of the following articles:",
      "nodes": [
        {
          "content": "To use SSH for remote sessions on the clusters, you can specify either SSH user password or the SSH public key.",
          "pos": [
            0,
            111
          ]
        },
        {
          "content": "If you specify both the SSH user password and the SSH public key, the key will be ignored.",
          "pos": [
            112,
            202
          ]
        },
        {
          "content": "If you want to use the SSH key for remote sessions, you must specify a blank SSH password when prompted for one.",
          "pos": [
            203,
            315
          ]
        },
        {
          "content": "For more information on using SSH with HDInsight, see one of the following articles:",
          "pos": [
            316,
            400
          ]
        }
      ]
    },
    {
      "pos": [
        2877,
        2989
      ],
      "content": "<bpt id=\"p10\">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X<ept id=\"p10\">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept>"
    },
    {
      "pos": [
        2996,
        3098
      ],
      "content": "<bpt id=\"p11\">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id=\"p11\">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept>"
    },
    {
      "pos": [
        3100,
        3162
      ],
      "content": "The following script demonstrates how to create a new cluster:"
    },
    {
      "pos": [
        6111,
        6454
      ],
      "content": "The values you specify for <bpt id=\"p12\">**</bpt>$clusterCredentials<ept id=\"p12\">**</ept><ph id=\"ph7\"/> are used to create the Hadoop user account for the cluster. You will use this account to connect to the cluster. The values you specify for the <bpt id=\"p13\">**</bpt>$sshCredentials<ept id=\"p13\">**</ept><ph id=\"ph8\"/> are used to create the SSH user for the cluster. You use this account to start a remote SSH session on the cluster and run jobs.",
      "nodes": [
        {
          "content": "The values you specify for <bpt id=\"p12\">**</bpt>$clusterCredentials<ept id=\"p12\">**</ept><ph id=\"ph7\"/> are used to create the Hadoop user account for the cluster.",
          "pos": [
            0,
            164
          ]
        },
        {
          "content": "You will use this account to connect to the cluster.",
          "pos": [
            165,
            217
          ]
        },
        {
          "content": "The values you specify for the <bpt id=\"p13\">**</bpt>$sshCredentials<ept id=\"p13\">**</ept><ph id=\"ph8\"/> are used to create the SSH user for the cluster.",
          "pos": [
            218,
            371
          ]
        },
        {
          "content": "You use this account to start a remote SSH session on the cluster and run jobs.",
          "pos": [
            372,
            451
          ]
        }
      ]
    },
    {
      "pos": [
        6458,
        6759
      ],
      "content": "<ph id=\"ph9\">[AZURE.IMPORTANT]</ph><ph id=\"ph10\"/> In this script, you must specify the number of worker nodes that will be in the cluster. If you plan to use more than 32 worker nodes, either at cluster creation or by scaling the cluster after creation, then you must also specify a head node size with at least 8 cores and 14GB ram.",
      "nodes": [
        {
          "content": "<ph id=\"ph9\">[AZURE.IMPORTANT]</ph><ph id=\"ph10\"/> In this script, you must specify the number of worker nodes that will be in the cluster.",
          "pos": [
            0,
            139
          ]
        },
        {
          "content": "If you plan to use more than 32 worker nodes, either at cluster creation or by scaling the cluster after creation, then you must also specify a head node size with at least 8 cores and 14GB ram.",
          "pos": [
            140,
            334
          ]
        }
      ]
    },
    {
      "pos": [
        6764,
        6901
      ],
      "content": "For more information on node sizes and associated costs, see <bpt id=\"p14\">[</bpt>HDInsight pricing<ept id=\"p14\">](https://azure.microsoft.com/pricing/details/hdinsight/)</ept>."
    },
    {
      "pos": [
        6903,
        6965
      ],
      "content": "It can take up to 15 minutes for the provisioning to complete."
    },
    {
      "pos": [
        6969,
        6987
      ],
      "content": "Customize clusters"
    },
    {
      "pos": [
        6991,
        7112
      ],
      "content": "See <bpt id=\"p15\">[</bpt>Customize HDInsight clusters using Bootstrap<ept id=\"p15\">](hdinsight-hadoop-customize-cluster-bootstrap.md#use-azure-powershell)</ept>."
    },
    {
      "pos": [
        7115,
        7259
      ],
      "content": "See <bpt id=\"p16\">[</bpt>Customize Windows-based HDInsight clusters using Script Action<ept id=\"p16\">](hdinsight-hadoop-customize-cluster.md#call-scripts-using-azure-powershell)</ept>."
    },
    {
      "pos": [
        7263,
        7273
      ],
      "content": "Next steps"
    },
    {
      "pos": [
        7275,
        7393
      ],
      "content": "Now that you have successfully created an HDInsight cluster, use the following to learn how to work with your cluster:"
    },
    {
      "pos": [
        7398,
        7413
      ],
      "content": "Hadoop clusters"
    },
    {
      "pos": [
        7417,
        7465
      ],
      "content": "<bpt id=\"p17\">[</bpt>Use Hive with HDInsight<ept id=\"p17\">](hdinsight-use-hive.md)</ept>"
    },
    {
      "pos": [
        7468,
        7514
      ],
      "content": "<bpt id=\"p18\">[</bpt>Use Pig with HDInsight<ept id=\"p18\">](hdinsight-use-pig.md)</ept>"
    },
    {
      "pos": [
        7517,
        7575
      ],
      "content": "<bpt id=\"p19\">[</bpt>Use MapReduce with HDInsight<ept id=\"p19\">](hdinsight-use-mapreduce.md)</ept>"
    },
    {
      "pos": [
        7580,
        7594
      ],
      "content": "HBase clusters"
    },
    {
      "pos": [
        7598,
        7682
      ],
      "content": "<bpt id=\"p20\">[</bpt>Get started with HBase on HDInsight<ept id=\"p20\">](hdinsight-hbase-tutorial-get-started-linux.md)</ept>"
    },
    {
      "pos": [
        7685,
        7775
      ],
      "content": "<bpt id=\"p21\">[</bpt>Develop Java applications for HBase on HDInsight<ept id=\"p21\">](hdinsight-hbase-build-java-maven-linux)</ept>"
    },
    {
      "pos": [
        7780,
        7794
      ],
      "content": "Storm clusters"
    },
    {
      "pos": [
        7798,
        7888
      ],
      "content": "<bpt id=\"p22\">[</bpt>Develop Java topologies for Storm on HDInsight<ept id=\"p22\">](hdinsight-storm-develop-java-topology.md)</ept>"
    },
    {
      "pos": [
        7891,
        7980
      ],
      "content": "<bpt id=\"p23\">[</bpt>Use Python components in Storm on HDInsight<ept id=\"p23\">](hdinsight-storm-develop-python-topology.md)</ept>"
    },
    {
      "pos": [
        7983,
        8088
      ],
      "content": "<bpt id=\"p24\">[</bpt>Deploy and monitor topologies with Storm on HDInsight<ept id=\"p24\">](hdinsight-storm-deploy-monitor-topology-linux.md)</ept>"
    },
    {
      "pos": [
        8093,
        8107
      ],
      "content": "Spark clusters"
    },
    {
      "pos": [
        8111,
        8213
      ],
      "content": "<bpt id=\"p25\">[</bpt>Create a standalone application using Scala<ept id=\"p25\">](hdinsight-apache-spark-create-standalone-application.md)</ept>"
    },
    {
      "pos": [
        8216,
        8312
      ],
      "content": "<bpt id=\"p26\">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id=\"p26\">](hdinsight-apache-spark-livy-rest-interface.md)</ept>"
    },
    {
      "pos": [
        8315,
        8444
      ],
      "content": "<bpt id=\"p27\">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id=\"p27\">](hdinsight-apache-spark-use-bi-tools.md)</ept>"
    },
    {
      "pos": [
        8447,
        8593
      ],
      "content": "<bpt id=\"p28\">[</bpt>Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results<ept id=\"p28\">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept>"
    },
    {
      "pos": [
        8596,
        8729
      ],
      "content": "<bpt id=\"p29\">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id=\"p29\">](hdinsight-apache-spark-eventhub-streaming.md)</ept>"
    }
  ],
  "content": "<properties\n    pageTitle=\"Create Hadoop, HBase, Storm, or Spark clusters on Linux in HDInsight using the Azure CLI | Microsoft Azure\"\n    description=\"Learn how to create Hadoop, HBase, Storm, or Spark clusters on Linux for HDInsight using the Azure CLI.\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    authors=\"nitinme\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.devlang=\"na\"\n    ms.topic=\"article\"\n    ms.tgt_pltfrm=\"na\"\n    ms.workload=\"big-data\"\n    ms.date=\"12/08/2015\"\n    ms.author=\"nitinme\"/>\n\n#Create Linux-based clusters in HDInsight using Azure PowerShell\n\n[AZURE.INCLUDE [selector](../../includes/hdinsight-create-linux-cluster-selector.md)]\n\nAzure PowerShell is a powerful scripting environment that you can use to control and automate the deployment and management of your workloads in Azure. This document provides information on how to provision a Linux-based HDInsight cluster by using Azure PowerShell, as well as an example script.\n\n> [AZURE.NOTE] Azure PowerShell is only available on Windows clients. If you are using a Linux, Unix, or Mac OS X client, see [Create a Linux-based HDInsight cluster using Azure CLI](hdinsight-hadoop-create-linux-clusters-azure-cli.md) for information on using the Azure CLI to create a cluster.\n\n###Prerequisites\n\n- **An Azure subscription**. See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).\n\n- __Azure PowerSHell__. For information on configuring a workstation to run HDInsight Windows PowerShell cmdlets, see [Install and configure Azure PowerShell](../powershell-install-configure.md). For more information on using Azure PowerShell with HDInsight, see [Administer HDInsight using PowerShell](hdinsight-administer-use-powershell.md). For the list of the HDInsight Windows PowerShell cmdlets, see [HDInsight cmdlet reference](https://msdn.microsoft.com/library/azure/dn858087.aspx).\n\n##Create clusters\n\nThe following procedures are needed to provision an HDInsight cluster by using Azure PowerShell:\n\n- Create an Azure resource group\n- Create an Azure Storage account\n- Create an Azure Blob container\n- Create an HDInsight cluster\n\nThe two most important parameters that you must set to provision Linux clusters are the ones where you specify the OS type and the SSH user details:\n\n- Make sure you specify the **-OSType** parameter as **Linux**.\n- To use SSH for remote sessions on the clusters, you can specify either SSH user password or the SSH public key. If you specify both the SSH user password and the SSH public key, the key will be ignored. If you want to use the SSH key for remote sessions, you must specify a blank SSH password when prompted for one. For more information on using SSH with HDInsight, see one of the following articles:\n    \n    * [Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X](hdinsight-hadoop-linux-use-ssh-unix.md)\n    * [Use SSH with Linux-based Hadoop on HDInsight from Windows](hdinsight-hadoop-linux-use-ssh-windows.md)\n\nThe following script demonstrates how to create a new cluster:\n\n    ###########################################\n    # Create required items, if none exist\n    ###########################################\n\n    # Sign in\n    Add-AzureRmAccount\n\n    # Select the subscription to use\n    $subscriptionID = \"<SubscriptionName>\"        # Provide your Subscription Name\n    Select-AzureRmSubscription -SubscriptionId $subscriptionID\n\n    # Create an Azure Resource Group\n    $resourceGroupName = \"<ResourceGroupName>\"      # Provide a Resource Group name\n    $location = \"<Location>\"                        # For example, \"West US\"\n    New-AzureRmResourceGroup -Name $resourceGroupName -Location $location\n\n    # Create an Azure Storage account\n    $storageAccountName = \"<StorageAcccountName>\"   # Provide a Storage account name\n    New-AzureRmStorageAccount -ResourceGroupName $resourceGroupName -StorageAccountName $storageAccountName -Location $location -Type Standard_GRS\n\n    # Create an Azure Blob Storage container\n    $containerName = \"<ContainerName>\"              # Provide a container name\n    $storageAccountKey = Get-AzureRmStorageAccountKey -Name $storageAccountName -ResourceGroupName $resourceGroupName | %{ $_.Key1 }\n    $destContext = New-AzureRmStorageContext -StorageAccountName $storageAccountName -StorageAccountKey $storageAccountKey\n    New-AzureRmStorageContainer -Name $containerName -Context $destContext\n\n    ###########################################\n    # Create an HDInsight Cluster\n    ###########################################\n\n    # Skip these variables if you just created them\n    $resourceGroupName = \"<ResourceGroupName>\"      # Provide the Resource Group name\n    $storageAccountName = \"<StorageAcccountName>\"   # Provide the Storage account name\n    $containerName = \"<ContainerName>\"              # Provide the container name\n    $storageAccountKey = Get-AzureStorageAccountKey -Name $storageAccountName -ResourceGroupName $resourceGroupName | %{ $_.Key1 }\n\n    # Set these variables\n    $clusterName = $containerName                   # As a best practice, have the same name for the cluster and container\n    $clusterNodes = <ClusterSizeInNodes>            # The number of nodes in the HDInsight cluster\n    $credentials = Get-Credential\n    $sshCredentials = Get-Credential\n\n    # The location of the HDInsight cluster. It must be in the same data center as the Storage account.\n    $location = Get-AzureRmStorageAccount -ResourceGroupName $resourceGroupName -StorageAccountName $storageAccountName | %{$_.Location}\n\n    # Create a new HDInsight cluster\n    New-AzureRmHDInsightCluster -ClusterName $clusterName -ResourceGroupName $resourceGroupName -HttpCredential $credentials -Location $location -DefaultStorageAccountName \"$storageAccountName.blob.core.windows.net\" -DefaultStorageAccountKey $storageAccountKey -DefaultStorageContainer $containerName  -ClusterSizeInNodes $clusterNodes -ClusterType Hadoop -OSType Linux -Version \"3.2\" -SshCredential $sshCredentials\n\nThe values you specify for **$clusterCredentials** are used to create the Hadoop user account for the cluster. You will use this account to connect to the cluster. The values you specify for the **$sshCredentials** are used to create the SSH user for the cluster. You use this account to start a remote SSH session on the cluster and run jobs.\n\n> [AZURE.IMPORTANT] In this script, you must specify the number of worker nodes that will be in the cluster. If you plan to use more than 32 worker nodes, either at cluster creation or by scaling the cluster after creation, then you must also specify a head node size with at least 8 cores and 14GB ram.\n>\n> For more information on node sizes and associated costs, see [HDInsight pricing](https://azure.microsoft.com/pricing/details/hdinsight/).\n\nIt can take up to 15 minutes for the provisioning to complete.\n\n##Customize clusters\n\n- See [Customize HDInsight clusters using Bootstrap](hdinsight-hadoop-customize-cluster-bootstrap.md#use-azure-powershell).\n- See [Customize Windows-based HDInsight clusters using Script Action](hdinsight-hadoop-customize-cluster.md#call-scripts-using-azure-powershell).\n\n##Next steps\n\nNow that you have successfully created an HDInsight cluster, use the following to learn how to work with your cluster:\n\n###Hadoop clusters\n\n* [Use Hive with HDInsight](hdinsight-use-hive.md)\n* [Use Pig with HDInsight](hdinsight-use-pig.md)\n* [Use MapReduce with HDInsight](hdinsight-use-mapreduce.md)\n\n###HBase clusters\n\n* [Get started with HBase on HDInsight](hdinsight-hbase-tutorial-get-started-linux.md)\n* [Develop Java applications for HBase on HDInsight](hdinsight-hbase-build-java-maven-linux)\n\n###Storm clusters\n\n* [Develop Java topologies for Storm on HDInsight](hdinsight-storm-develop-java-topology.md)\n* [Use Python components in Storm on HDInsight](hdinsight-storm-develop-python-topology.md)\n* [Deploy and monitor topologies with Storm on HDInsight](hdinsight-storm-deploy-monitor-topology-linux.md)\n\n###Spark clusters\n\n* [Create a standalone application using Scala](hdinsight-apache-spark-create-standalone-application.md)\n* [Run jobs remotely on a Spark cluster using Livy](hdinsight-apache-spark-livy-rest-interface.md)\n* [Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools](hdinsight-apache-spark-use-bi-tools.md)\n* [Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results](hdinsight-apache-spark-machine-learning-mllib-ipython.md)\n* [Spark Streaming: Use Spark in HDInsight for building real-time streaming applications](hdinsight-apache-spark-eventhub-streaming.md)\n"
}