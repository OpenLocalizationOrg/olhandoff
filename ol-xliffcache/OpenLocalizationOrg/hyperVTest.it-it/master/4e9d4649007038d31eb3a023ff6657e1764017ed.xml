{
  "nodes": [
    {
      "pos": [
        28,
        114
      ],
      "content": "Use Apache Spark to build machine learning applications on HDInsight | Microsoft Azure"
    },
    {
      "pos": [
        134,
        240
      ],
      "content": "Step-by-step instructions on how to use notebooks with Apache Spark to build machine learning applications"
    },
    {
      "pos": [
        581,
        662
      ],
      "content": "Build Machine Learning applications using Apache Spark on Azure HDInsight (Linux)"
    },
    {
      "pos": [
        664,
        962
      ],
      "content": "Learn how to build a machine learning application using an Apache Spark cluster in HDInsight. This article shows how to use the Jupyter notebook available with the cluster to build and test our application. The application uses the sample HVAC.csv data that is available on all clusters by default.",
      "nodes": [
        {
          "content": "Learn how to build a machine learning application using an Apache Spark cluster in HDInsight.",
          "pos": [
            0,
            93
          ]
        },
        {
          "content": "This article shows how to use the Jupyter notebook available with the cluster to build and test our application.",
          "pos": [
            94,
            206
          ]
        },
        {
          "content": "The application uses the sample HVAC.csv data that is available on all clusters by default.",
          "pos": [
            207,
            298
          ]
        }
      ]
    },
    {
      "pos": [
        966,
        1456
      ],
      "content": "<ph id=\"ph2\">[AZURE.TIP]</ph><ph id=\"ph3\"/> This tutorial is also available as a Jupyter notebook on a Spark (Linux) cluster that you create in HDInsight. The notebook experience lets you run the Python snippets from the notebook itself. To perform the tutorial from within a notebook, create a Spark cluster, launch a Jupyter notebook (<ph id=\"ph4\">`https://CLUSTERNAME.azurehdinsight.net/jupyter`</ph>), and then run the notebook <bpt id=\"p1\">**</bpt>Spark Machine Learning - Predict building temperature using HVAC data.ipynb<ept id=\"p1\">**</ept><ph id=\"ph5\"/> under the <bpt id=\"p2\">**</bpt>Python<ept id=\"p2\">**</ept><ph id=\"ph6\"/> folder.",
      "nodes": [
        {
          "content": "<ph id=\"ph2\">[AZURE.TIP]</ph><ph id=\"ph3\"/> This tutorial is also available as a Jupyter notebook on a Spark (Linux) cluster that you create in HDInsight.",
          "pos": [
            0,
            154
          ]
        },
        {
          "content": "The notebook experience lets you run the Python snippets from the notebook itself.",
          "pos": [
            155,
            237
          ]
        },
        {
          "content": "To perform the tutorial from within a notebook, create a Spark cluster, launch a Jupyter notebook (<ph id=\"ph4\">`https://CLUSTERNAME.azurehdinsight.net/jupyter`</ph>), and then run the notebook <bpt id=\"p1\">**</bpt>Spark Machine Learning - Predict building temperature using HVAC data.ipynb<ept id=\"p1\">**</ept><ph id=\"ph5\"/> under the <bpt id=\"p2\">**</bpt>Python<ept id=\"p2\">**</ept><ph id=\"ph6\"/> folder.",
          "pos": [
            238,
            644
          ]
        }
      ]
    },
    {
      "pos": [
        1458,
        1476
      ],
      "content": "<bpt id=\"p3\">**</bpt>Prerequisites:<ept id=\"p3\">**</ept>"
    },
    {
      "pos": [
        1478,
        1506
      ],
      "content": "You must have the following:"
    },
    {
      "pos": [
        1510,
        1664
      ],
      "content": "An Azure subscription. See <bpt id=\"p4\">[</bpt>Get Azure free trial<ept id=\"p4\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
      "nodes": [
        {
          "content": "An Azure subscription.",
          "pos": [
            0,
            22
          ]
        },
        {
          "content": "See <bpt id=\"p4\">[</bpt>Get Azure free trial<ept id=\"p4\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
          "pos": [
            23,
            192
          ]
        }
      ]
    },
    {
      "pos": [
        1667,
        1828
      ],
      "content": "An Apache Spark cluster on HDInsight Linux. For instructions, see <bpt id=\"p5\">[</bpt>Create Apache Spark clusters in Azure HDInsight<ept id=\"p5\">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.",
      "nodes": [
        {
          "content": "An Apache Spark cluster on HDInsight Linux.",
          "pos": [
            0,
            43
          ]
        },
        {
          "content": "For instructions, see <bpt id=\"p5\">[</bpt>Create Apache Spark clusters in Azure HDInsight<ept id=\"p5\">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept>.",
          "pos": [
            44,
            199
          ]
        }
      ]
    },
    {
      "pos": [
        1831,
        1833
      ],
      "content": "##"
    },
    {
      "pos": [
        1852,
        1868
      ],
      "content": "Show me the data"
    },
    {
      "pos": [
        1870,
        2004
      ],
      "content": "Before we start building the application, let us understand the structure of the data and the kind of analysis we will do on the data."
    },
    {
      "pos": [
        2007,
        2234
      ],
      "content": "In this article, we use the sample <bpt id=\"p6\">**</bpt>HVAC.csv<ept id=\"p6\">**</ept><ph id=\"ph7\"/> data file that is available on all HDInsight clusters by default at <bpt id=\"p7\">**</bpt>\\HdiSamples\\HdiSamples\\SensorSampleData\\hvac<ept id=\"p7\">**</ept>. Download and open the CSV file to get a snapshot of the data.",
      "nodes": [
        {
          "content": "In this article, we use the sample <bpt id=\"p6\">**</bpt>HVAC.csv<ept id=\"p6\">**</ept><ph id=\"ph7\"/> data file that is available on all HDInsight clusters by default at <bpt id=\"p7\">**</bpt>\\HdiSamples\\HdiSamples\\SensorSampleData\\hvac<ept id=\"p7\">**</ept>.",
          "pos": [
            0,
            255
          ]
        },
        {
          "content": "Download and open the CSV file to get a snapshot of the data.",
          "pos": [
            256,
            317
          ]
        }
      ]
    },
    {
      "pos": [
        2238,
        2379
      ],
      "content": "<ph id=\"ph8\">![</ph>HVAC data snapshot<ph id=\"ph9\">](./media/hdinsight-apache-spark-ipython-notebook-machine-learning/hdispark.ml.show.data.png \"Snapshot of the HVAC data\")</ph>"
    },
    {
      "pos": [
        2381,
        2663
      ],
      "content": "The data shows the target temperature and the actual temperature of a building that has HVAC systems installed. Let's assume the <bpt id=\"p8\">**</bpt>System<ept id=\"p8\">**</ept><ph id=\"ph10\"/> column represents the system ID and the <bpt id=\"p9\">**</bpt>SystemAge<ept id=\"p9\">**</ept><ph id=\"ph11\"/> column represents the number of years the HVAC system has been in place at the building.",
      "nodes": [
        {
          "content": "The data shows the target temperature and the actual temperature of a building that has HVAC systems installed.",
          "pos": [
            0,
            111
          ]
        },
        {
          "content": "Let's assume the <bpt id=\"p8\">**</bpt>System<ept id=\"p8\">**</ept><ph id=\"ph10\"/> column represents the system ID and the <bpt id=\"p9\">**</bpt>SystemAge<ept id=\"p9\">**</ept><ph id=\"ph11\"/> column represents the number of years the HVAC system has been in place at the building.",
          "pos": [
            112,
            388
          ]
        }
      ]
    },
    {
      "pos": [
        2665,
        2803
      ],
      "content": "We use this data to predict whether a building will be hotter or colder based on the target temperature, given a system ID and system age."
    },
    {
      "pos": [
        2805,
        2807
      ],
      "content": "##"
    },
    {
      "pos": [
        2825,
        2879
      ],
      "content": "Write a machine learning application using Spark MLlib"
    },
    {
      "pos": [
        2884,
        3125
      ],
      "content": "From the <bpt id=\"p10\">[</bpt>Azure Preview Portal<ept id=\"p10\">](https://portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard). You can also navigate to your cluster under <bpt id=\"p11\">**</bpt>Browse All<ept id=\"p11\">**</ept><ph id=\"ph12\"/> &gt; <bpt id=\"p12\">**</bpt>HDInsight Clusters<ept id=\"p12\">**</ept>.",
      "nodes": [
        {
          "content": "From the <bpt id=\"p10\">[</bpt>Azure Preview Portal<ept id=\"p10\">](https://portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).",
          "pos": [
            0,
            196
          ]
        },
        {
          "content": "You can also navigate to your cluster under <bpt id=\"p11\">**</bpt>Browse All<ept id=\"p11\">**</ept><ph id=\"ph12\"/> &gt; <bpt id=\"p12\">**</bpt>HDInsight Clusters<ept id=\"p12\">**</ept>.",
          "pos": [
            197,
            379
          ]
        }
      ]
    },
    {
      "pos": [
        3133,
        3318
      ],
      "content": "From the Spark cluster blade, click <bpt id=\"p13\">**</bpt>Quick Links<ept id=\"p13\">**</ept>, and then from the <bpt id=\"p14\">**</bpt>Cluster Dashboard<ept id=\"p14\">**</ept><ph id=\"ph13\"/> blade, click <bpt id=\"p15\">**</bpt>Jupyter Notebook<ept id=\"p15\">**</ept>. If prompted, enter the admin credentials for the cluster.",
      "nodes": [
        {
          "content": "From the Spark cluster blade, click <bpt id=\"p13\">**</bpt>Quick Links<ept id=\"p13\">**</ept>, and then from the <bpt id=\"p14\">**</bpt>Cluster Dashboard<ept id=\"p14\">**</ept><ph id=\"ph13\"/> blade, click <bpt id=\"p15\">**</bpt>Jupyter Notebook<ept id=\"p15\">**</ept>.",
          "pos": [
            0,
            262
          ]
        },
        {
          "content": "If prompted, enter the admin credentials for the cluster.",
          "pos": [
            263,
            320
          ]
        }
      ]
    },
    {
      "pos": [
        3326,
        3496
      ],
      "content": "<ph id=\"ph14\">[AZURE.NOTE]</ph><ph id=\"ph15\"/> You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser. Replace <bpt id=\"p16\">__</bpt>CLUSTERNAME<ept id=\"p16\">__</ept><ph id=\"ph16\"/> with the name of your cluster:",
      "nodes": [
        {
          "content": "<ph id=\"ph14\">[AZURE.NOTE]</ph><ph id=\"ph15\"/> You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser.",
          "pos": [
            0,
            149
          ]
        },
        {
          "content": "Replace <bpt id=\"p16\">__</bpt>CLUSTERNAME<ept id=\"p16\">__</ept><ph id=\"ph16\"/> with the name of your cluster:",
          "pos": [
            150,
            259
          ]
        }
      ]
    },
    {
      "pos": [
        3562,
        3628
      ],
      "content": "Create a new notebook. Click <bpt id=\"p17\">**</bpt>New<ept id=\"p17\">**</ept>, and then click <bpt id=\"p18\">**</bpt>Python 2<ept id=\"p18\">**</ept>.",
      "nodes": [
        {
          "content": "Create a new notebook.",
          "pos": [
            0,
            22
          ]
        },
        {
          "content": "Click <bpt id=\"p17\">**</bpt>New<ept id=\"p17\">**</ept>, and then click <bpt id=\"p18\">**</bpt>Python 2<ept id=\"p18\">**</ept>.",
          "pos": [
            23,
            146
          ]
        }
      ]
    },
    {
      "pos": [
        3634,
        3805
      ],
      "content": "<ph id=\"ph18\">![</ph>Create a new Jupyter notebook<ph id=\"ph19\">](./media/hdinsight-apache-spark-ipython-notebook-machine-learning/hdispark.note.jupyter.createnotebook.png \"Create a new Jupyter notebook\")</ph>"
    },
    {
      "pos": [
        3810,
        3938
      ],
      "content": "A new notebook is created and opened with the name Untitled.pynb. Click the notebook name at the top, and enter a friendly name.",
      "nodes": [
        {
          "content": "A new notebook is created and opened with the name Untitled.pynb.",
          "pos": [
            0,
            65
          ]
        },
        {
          "content": "Click the notebook name at the top, and enter a friendly name.",
          "pos": [
            66,
            128
          ]
        }
      ]
    },
    {
      "pos": [
        3944,
        4118
      ],
      "content": "<ph id=\"ph20\">![</ph>Provide a name for the notebook<ph id=\"ph21\">](./media/hdinsight-apache-spark-ipython-notebook-machine-learning/hdispark.note.jupyter.notebook.name.png \"Provide a name for the notebook\")</ph>"
    },
    {
      "pos": [
        4123,
        4434
      ],
      "content": "Start building your machine learning application. In this application we use a Spark ML pipeline to perform a document classification. In the pipeline, we split the document into words, convert the words into a numerical feature vector, and finally build a prediction model using the feature vectors and labels.",
      "nodes": [
        {
          "content": "Start building your machine learning application.",
          "pos": [
            0,
            49
          ]
        },
        {
          "content": "In this application we use a Spark ML pipeline to perform a document classification.",
          "pos": [
            50,
            134
          ]
        },
        {
          "content": "In the pipeline, we split the document into words, convert the words into a numerical feature vector, and finally build a prediction model using the feature vectors and labels.",
          "pos": [
            135,
            311
          ]
        }
      ]
    },
    {
      "pos": [
        4440,
        4651
      ],
      "content": "To start building the application, first import the required modules and assign resources to the application. In the empty cell in the new notebook, paste the following snippet, and then press <bpt id=\"p19\">**</bpt>SHIFT + ENTER<ept id=\"p19\">**</ept>.",
      "nodes": [
        {
          "content": "To start building the application, first import the required modules and assign resources to the application.",
          "pos": [
            0,
            109
          ]
        },
        {
          "content": "In the empty cell in the new notebook, paste the following snippet, and then press <bpt id=\"p19\">**</bpt>SHIFT + ENTER<ept id=\"p19\">**</ept>.",
          "pos": [
            110,
            251
          ]
        }
      ]
    },
    {
      "pos": [
        6047,
        6435
      ],
      "content": "You must now load the data (hvac.csv), parse it, and use it to train the model. For this, you define a function that checks whether the actual temperature of the building is greater than the target temperature. If the actual temperature is greater, the building is hot, denoted by the value <bpt id=\"p20\">**</bpt>1.0<ept id=\"p20\">**</ept>. If the actual temperature is lesser, the building is cold, denoted by the value <bpt id=\"p21\">**</bpt>0.0<ept id=\"p21\">**</ept>.",
      "nodes": [
        {
          "content": "You must now load the data (hvac.csv), parse it, and use it to train the model.",
          "pos": [
            0,
            79
          ]
        },
        {
          "content": "For this, you define a function that checks whether the actual temperature of the building is greater than the target temperature.",
          "pos": [
            80,
            210
          ]
        },
        {
          "content": "If the actual temperature is greater, the building is hot, denoted by the value <bpt id=\"p20\">**</bpt>1.0<ept id=\"p20\">**</ept>.",
          "pos": [
            211,
            339
          ]
        },
        {
          "content": "If the actual temperature is lesser, the building is cold, denoted by the value <bpt id=\"p21\">**</bpt>0.0<ept id=\"p21\">**</ept>.",
          "pos": [
            340,
            468
          ]
        }
      ]
    },
    {
      "pos": [
        6442,
        6515
      ],
      "content": "Paste the following snippet in an empty cell and press <bpt id=\"p22\">**</bpt>SHIFT + ENTER<ept id=\"p22\">**</ept>."
    },
    {
      "pos": [
        7689,
        7988
      ],
      "content": "Configure the Spark machine learning pipeline that consists of three stages: tokenizer, hashingTF, and lr. For more information about what is a pipeline and how it works see <ph id=\"ph22\">&lt;a href=\"http://spark.apache.org/docs/latest/ml-guide.html#how-it-works\" target=\"_blank\"&gt;</ph>Spark machine learning pipeline<ph id=\"ph23\">&lt;/a&gt;</ph>.",
      "nodes": [
        {
          "content": "Configure the Spark machine learning pipeline that consists of three stages: tokenizer, hashingTF, and lr.",
          "pos": [
            0,
            106
          ]
        },
        {
          "content": "For more information about what is a pipeline and how it works see <ph id=\"ph22\">&lt;a href=\"http://spark.apache.org/docs/latest/ml-guide.html#how-it-works\" target=\"_blank\"&gt;</ph>Spark machine learning pipeline<ph id=\"ph23\">&lt;/a&gt;</ph>.",
          "pos": [
            107,
            349
          ]
        }
      ]
    },
    {
      "pos": [
        7994,
        8067
      ],
      "content": "Paste the following snippet in an empty cell and press <bpt id=\"p23\">**</bpt>SHIFT + ENTER<ept id=\"p23\">**</ept>."
    },
    {
      "pos": [
        8354,
        8470
      ],
      "content": "Fit the pipeline to the training document. Paste the following snippet in an empty cell and press <bpt id=\"p24\">**</bpt>SHIFT + ENTER<ept id=\"p24\">**</ept>.",
      "nodes": [
        {
          "content": "Fit the pipeline to the training document.",
          "pos": [
            0,
            42
          ]
        },
        {
          "content": "Paste the following snippet in an empty cell and press <bpt id=\"p24\">**</bpt>SHIFT + ENTER<ept id=\"p24\">**</ept>.",
          "pos": [
            43,
            156
          ]
        }
      ]
    },
    {
      "pos": [
        8515,
        8667
      ],
      "content": "Verify the training document to checkpoint your progress with the application. Paste the following snippet in an empty cell and press <bpt id=\"p25\">**</bpt>SHIFT + ENTER<ept id=\"p25\">**</ept>.",
      "nodes": [
        {
          "content": "Verify the training document to checkpoint your progress with the application.",
          "pos": [
            0,
            78
          ]
        },
        {
          "content": "Paste the following snippet in an empty cell and press <bpt id=\"p25\">**</bpt>SHIFT + ENTER<ept id=\"p25\">**</ept>.",
          "pos": [
            79,
            192
          ]
        }
      ]
    },
    {
      "pos": [
        8698,
        8751
      ],
      "content": "This should give the output similar to the following:"
    },
    {
      "pos": [
        9671,
        9781
      ],
      "content": "Go back and verify the output against the raw CSV file. For example, the first row the CSV file has this data:",
      "nodes": [
        {
          "content": "Go back and verify the output against the raw CSV file.",
          "pos": [
            0,
            55
          ]
        },
        {
          "content": "For example, the first row the CSV file has this data:",
          "pos": [
            56,
            110
          ]
        }
      ]
    },
    {
      "pos": [
        9787,
        9938
      ],
      "content": "<ph id=\"ph24\">![</ph>HVAC data snapshot<ph id=\"ph25\">](./media/hdinsight-apache-spark-ipython-notebook-machine-learning/hdispark.ml.show.data.first.row.png \"Snapshot of the HVAC data\")</ph>"
    },
    {
      "pos": [
        9944,
        10166
      ],
      "content": "Notice how the actual temperature is less than the target temperature suggesting the building is cold. Hence in the training output, the value for <bpt id=\"p26\">**</bpt>label<ept id=\"p26\">**</ept><ph id=\"ph26\"/> in the first row is <bpt id=\"p27\">**</bpt>0.0<ept id=\"p27\">**</ept>, which means the building is not hot.",
      "nodes": [
        {
          "content": "Notice how the actual temperature is less than the target temperature suggesting the building is cold.",
          "pos": [
            0,
            102
          ]
        },
        {
          "content": "Hence in the training output, the value for <bpt id=\"p26\">**</bpt>label<ept id=\"p26\">**</ept><ph id=\"ph26\"/> in the first row is <bpt id=\"p27\">**</bpt>0.0<ept id=\"p27\">**</ept>, which means the building is not hot.",
          "pos": [
            103,
            317
          ]
        }
      ]
    },
    {
      "pos": [
        10172,
        10475
      ],
      "content": "Prepare a data set to run the trained model against. To do so, we would pass on a system ID and system age (denoted as <bpt id=\"p28\">**</bpt>SystemInfo<ept id=\"p28\">**</ept><ph id=\"ph27\"/> in the training output), and the model would predict whether the building with that system ID and system age would be hotter (denoted by 1.0) or cooler (denoted by 0.0).",
      "nodes": [
        {
          "content": "Prepare a data set to run the trained model against.",
          "pos": [
            0,
            52
          ]
        },
        {
          "content": "To do so, we would pass on a system ID and system age (denoted as <bpt id=\"p28\">**</bpt>SystemInfo<ept id=\"p28\">**</ept><ph id=\"ph27\"/> in the training output), and the model would predict whether the building with that system ID and system age would be hotter (denoted by 1.0) or cooler (denoted by 0.0).",
          "pos": [
            53,
            358
          ]
        }
      ]
    },
    {
      "pos": [
        10481,
        10554
      ],
      "content": "Paste the following snippet in an empty cell and press <bpt id=\"p29\">**</bpt>SHIFT + ENTER<ept id=\"p29\">**</ept>."
    },
    {
      "pos": [
        10969,
        11086
      ],
      "content": "Finally, make predictions on the test data. Paste the following snippet in an empty cell and press <bpt id=\"p30\">**</bpt>SHIFT + ENTER<ept id=\"p30\">**</ept>.",
      "nodes": [
        {
          "content": "Finally, make predictions on the test data.",
          "pos": [
            0,
            43
          ]
        },
        {
          "content": "Paste the following snippet in an empty cell and press <bpt id=\"p30\">**</bpt>SHIFT + ENTER<ept id=\"p30\">**</ept>.",
          "pos": [
            44,
            157
          ]
        }
      ]
    },
    {
      "pos": [
        11352,
        11402
      ],
      "content": "You should see an output similar to the following:"
    },
    {
      "pos": [
        11957,
        12365
      ],
      "content": "From the first row in the prediction, you can see that for an HVAC system with ID 20 and system age of 25 years, the building will be hot (<bpt id=\"p31\">**</bpt>prediction=1.0<ept id=\"p31\">**</ept>). The first value for DenseVector (0.49999) corresponds to the  prediction 0.0 and the second value (0.5001) corresponds to the prediction 1.0. In the output, even though the second value is only marginally higher, the model shows <bpt id=\"p32\">**</bpt>prediction=1.0<ept id=\"p32\">**</ept>.",
      "nodes": [
        {
          "content": "From the first row in the prediction, you can see that for an HVAC system with ID 20 and system age of 25 years, the building will be hot (<bpt id=\"p31\">**</bpt>prediction=1.0<ept id=\"p31\">**</ept>).",
          "pos": [
            0,
            199
          ]
        },
        {
          "content": "The first value for DenseVector (0.49999) corresponds to the  prediction 0.0 and the second value (0.5001) corresponds to the prediction 1.0.",
          "pos": [
            200,
            341
          ]
        },
        {
          "content": "In the output, even though the second value is only marginally higher, the model shows <bpt id=\"p32\">**</bpt>prediction=1.0<ept id=\"p32\">**</ept>.",
          "pos": [
            342,
            488
          ]
        }
      ]
    },
    {
      "pos": [
        12371,
        12597
      ],
      "content": "After you have finished running the application, you should shutdown the notebook to release the resources. To do so, from the <bpt id=\"p33\">**</bpt>File<ept id=\"p33\">**</ept><ph id=\"ph28\"/> menu on the notebook, click <bpt id=\"p34\">**</bpt>Close and Halt<ept id=\"p34\">**</ept>. This will shutdown and close the notebook.",
      "nodes": [
        {
          "content": "After you have finished running the application, you should shutdown the notebook to release the resources.",
          "pos": [
            0,
            107
          ]
        },
        {
          "content": "To do so, from the <bpt id=\"p33\">**</bpt>File<ept id=\"p33\">**</ept><ph id=\"ph28\"/> menu on the notebook, click <bpt id=\"p34\">**</bpt>Close and Halt<ept id=\"p34\">**</ept>.",
          "pos": [
            108,
            278
          ]
        },
        {
          "content": "This will shutdown and close the notebook.",
          "pos": [
            279,
            321
          ]
        }
      ]
    },
    {
      "pos": [
        12611,
        12613
      ],
      "content": "##"
    },
    {
      "pos": [
        12636,
        12690
      ],
      "content": "Use Anaconda scikit-learn library for Machine Learning"
    },
    {
      "pos": [
        12692,
        13116
      ],
      "content": "Apache Spark clusters on HDInsight include Anaconda libraries. This also includes the <bpt id=\"p35\">**</bpt>scikit-learn<ept id=\"p35\">**</ept><ph id=\"ph29\"/> library for machine learning. The library also includes various data sets that you can use to build sample applications directly from a Jupyter notebook. For examples on using the scikit-learn library, see <bpt id=\"p36\">[</bpt>http://scikit-learn.org/stable/auto_examples/index.html<ept id=\"p36\">](http://scikit-learn.org/stable/auto_examples/index.html)</ept>.",
      "nodes": [
        {
          "content": "Apache Spark clusters on HDInsight include Anaconda libraries.",
          "pos": [
            0,
            62
          ]
        },
        {
          "content": "This also includes the <bpt id=\"p35\">**</bpt>scikit-learn<ept id=\"p35\">**</ept><ph id=\"ph29\"/> library for machine learning.",
          "pos": [
            63,
            187
          ]
        },
        {
          "content": "The library also includes various data sets that you can use to build sample applications directly from a Jupyter notebook.",
          "pos": [
            188,
            311
          ]
        },
        {
          "content": "For examples on using the scikit-learn library, see <bpt id=\"p36\">[</bpt>http://scikit-learn.org/stable/auto_examples/index.html<ept id=\"p36\">](http://scikit-learn.org/stable/auto_examples/index.html)</ept>.",
          "pos": [
            312,
            519
          ]
        }
      ]
    },
    {
      "pos": [
        13118,
        13120
      ],
      "content": "##"
    },
    {
      "pos": [
        13142,
        13150
      ],
      "content": "See also"
    },
    {
      "pos": [
        13154,
        13233
      ],
      "content": "<bpt id=\"p37\">[</bpt>Overview: Apache Spark on Azure HDInsight<ept id=\"p37\">](hdinsight-apache-spark-overview.md)</ept>"
    },
    {
      "pos": [
        13239,
        13248
      ],
      "content": "Scenarios"
    },
    {
      "pos": [
        13252,
        13381
      ],
      "content": "<bpt id=\"p38\">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id=\"p38\">](hdinsight-apache-spark-use-bi-tools.md)</ept>"
    },
    {
      "pos": [
        13385,
        13531
      ],
      "content": "<bpt id=\"p39\">[</bpt>Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results<ept id=\"p39\">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept>"
    },
    {
      "pos": [
        13535,
        13668
      ],
      "content": "<bpt id=\"p40\">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id=\"p40\">](hdinsight-apache-spark-eventhub-streaming.md)</ept>"
    },
    {
      "pos": [
        13672,
        13782
      ],
      "content": "<bpt id=\"p41\">[</bpt>Website log analysis using Spark in HDInsight<ept id=\"p41\">](hdinsight-apache-spark-custom-library-website-log-analysis.md)</ept>"
    },
    {
      "pos": [
        13788,
        13815
      ],
      "content": "Create and run applications"
    },
    {
      "pos": [
        13819,
        13921
      ],
      "content": "<bpt id=\"p42\">[</bpt>Create a standalone application using Scala<ept id=\"p42\">](hdinsight-apache-spark-create-standalone-application.md)</ept>"
    },
    {
      "pos": [
        13925,
        14021
      ],
      "content": "<bpt id=\"p43\">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id=\"p43\">](hdinsight-apache-spark-livy-rest-interface.md)</ept>"
    },
    {
      "pos": [
        14027,
        14047
      ],
      "content": "Tools and extensions"
    },
    {
      "pos": [
        14051,
        14190
      ],
      "content": "<bpt id=\"p44\">[</bpt>Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons<ept id=\"p44\">](hdinsight-apache-spark-intellij-tool-plugin.md)</ept>"
    },
    {
      "pos": [
        14194,
        14301
      ],
      "content": "<bpt id=\"p45\">[</bpt>Use Zeppelin notebooks with a Spark cluster on HDInsight<ept id=\"p45\">](hdinsight-apache-spark-use-zeppelin-notebook.md)</ept>"
    },
    {
      "pos": [
        14305,
        14428
      ],
      "content": "<bpt id=\"p46\">[</bpt>Kernels available for Jupyter notebook in Spark cluster for HDInsight<ept id=\"p46\">](hdinsight-apache-spark-jupyter-notebook-kernels.md)</ept>"
    },
    {
      "pos": [
        14434,
        14450
      ],
      "content": "Manage resources"
    },
    {
      "pos": [
        14454,
        14564
      ],
      "content": "<bpt id=\"p47\">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id=\"p47\">](hdinsight-apache-spark-resource-manager.md)</ept>"
    }
  ],
  "content": "<properties \n    pageTitle=\"Use Apache Spark to build machine learning applications on HDInsight | Microsoft Azure\" \n    description=\"Step-by-step instructions on how to use notebooks with Apache Spark to build machine learning applications\" \n    services=\"hdinsight\" \n    documentationCenter=\"\" \n    authors=\"nitinme\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags \n    ms.service=\"hdinsight\" \n    ms.workload=\"big-data\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"02/05/2016\" \n    ms.author=\"nitinme\"/>\n\n\n# Build Machine Learning applications using Apache Spark on Azure HDInsight (Linux)\n\nLearn how to build a machine learning application using an Apache Spark cluster in HDInsight. This article shows how to use the Jupyter notebook available with the cluster to build and test our application. The application uses the sample HVAC.csv data that is available on all clusters by default.\n\n> [AZURE.TIP] This tutorial is also available as a Jupyter notebook on a Spark (Linux) cluster that you create in HDInsight. The notebook experience lets you run the Python snippets from the notebook itself. To perform the tutorial from within a notebook, create a Spark cluster, launch a Jupyter notebook (`https://CLUSTERNAME.azurehdinsight.net/jupyter`), and then run the notebook **Spark Machine Learning - Predict building temperature using HVAC data.ipynb** under the **Python** folder.\n\n**Prerequisites:**\n\nYou must have the following:\n\n- An Azure subscription. See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).\n- An Apache Spark cluster on HDInsight Linux. For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md). \n\n##<a name=\"data\"></a>Show me the data\n\nBefore we start building the application, let us understand the structure of the data and the kind of analysis we will do on the data. \n\nIn this article, we use the sample **HVAC.csv** data file that is available on all HDInsight clusters by default at **\\HdiSamples\\HdiSamples\\SensorSampleData\\hvac**. Download and open the CSV file to get a snapshot of the data.  \n\n![HVAC data snapshot](./media/hdinsight-apache-spark-ipython-notebook-machine-learning/hdispark.ml.show.data.png \"Snapshot of the HVAC data\")\n\nThe data shows the target temperature and the actual temperature of a building that has HVAC systems installed. Let's assume the **System** column represents the system ID and the **SystemAge** column represents the number of years the HVAC system has been in place at the building.\n\nWe use this data to predict whether a building will be hotter or colder based on the target temperature, given a system ID and system age.\n\n##<a name=\"app\"></a>Write a machine learning application using Spark MLlib\n\n1. From the [Azure Preview Portal](https://portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard). You can also navigate to your cluster under **Browse All** > **HDInsight Clusters**.   \n\n2. From the Spark cluster blade, click **Quick Links**, and then from the **Cluster Dashboard** blade, click **Jupyter Notebook**. If prompted, enter the admin credentials for the cluster.\n\n    > [AZURE.NOTE] You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser. Replace __CLUSTERNAME__ with the name of your cluster:\n    >\n    > `https://CLUSTERNAME.azurehdinsight.net/jupyter`\n\n2. Create a new notebook. Click **New**, and then click **Python 2**.\n\n    ![Create a new Jupyter notebook](./media/hdinsight-apache-spark-ipython-notebook-machine-learning/hdispark.note.jupyter.createnotebook.png \"Create a new Jupyter notebook\")\n\n3. A new notebook is created and opened with the name Untitled.pynb. Click the notebook name at the top, and enter a friendly name.\n\n    ![Provide a name for the notebook](./media/hdinsight-apache-spark-ipython-notebook-machine-learning/hdispark.note.jupyter.notebook.name.png \"Provide a name for the notebook\")\n\n3. Start building your machine learning application. In this application we use a Spark ML pipeline to perform a document classification. In the pipeline, we split the document into words, convert the words into a numerical feature vector, and finally build a prediction model using the feature vectors and labels.\n\n    To start building the application, first import the required modules and assign resources to the application. In the empty cell in the new notebook, paste the following snippet, and then press **SHIFT + ENTER**.\n\n\n        from pyspark.ml import Pipeline\n        from pyspark.ml.classification import LogisticRegression\n        from pyspark.ml.feature import HashingTF, Tokenizer\n        from pyspark.sql import Row, SQLContext\n        \n        import os\n        import sys\n        from pyspark import SparkConf\n        from pyspark import SparkContext\n        from pyspark.sql import SQLContext\n        from pyspark.sql.types import *\n        \n        from pyspark.mllib.classification import LogisticRegressionWithSGD\n        from pyspark.mllib.regression import LabeledPoint\n        from numpy import array\n        \n        # Assign resources to the application\n        conf = SparkConf()\n        conf.setMaster('yarn-client')\n        conf.setAppName('pysparkregression')\n        conf.set(\"spark.cores.max\", \"4\")\n        conf.set(\"spark.executor.memory\", \"4g\")\n        \n        sc = SparkContext(conf=conf)\n        sqlContext = SQLContext(sc)\n\n    Everytime you run a job in Jupyter, your web browser window title will show a **(Busy)** status along with the notebook title. You will also see a solid circle next to the **Python 2** text in the top-right corner. After the job completes, this will change to a hollow circle.\n\n     ![Status of a Jupyter notebook job](./media/hdinsight-apache-spark-ipython-notebook-machine-learning/hdispark.jupyter.job.status.png \"Status of a Jupyter notebook job\")\n \n4. You must now load the data (hvac.csv), parse it, and use it to train the model. For this, you define a function that checks whether the actual temperature of the building is greater than the target temperature. If the actual temperature is greater, the building is hot, denoted by the value **1.0**. If the actual temperature is lesser, the building is cold, denoted by the value **0.0**. \n\n    Paste the following snippet in an empty cell and press **SHIFT + ENTER**.\n\n        \n        # List the structure of data for better understanding. Becuase the data will be\n        # loaded as an array, this structure makes it easy to understand what each element\n        # in the array corresponds to\n\n        # 0 Date\n        # 1 Time\n        # 2 TargetTemp\n        # 3 ActualTemp\n        # 4 System\n        # 5 SystemAge\n        # 6 BuildingID\n\n        LabeledDocument = Row(\"BuildingID\", \"SystemInfo\", \"label\")\n\n        # Define a function that parses the raw CSV file and returns an object of type LabeledDocument\n        \n        def parseDocument(line):\n            values = [str(x) for x in line.split(',')]\n            if (values[3] > values[2]):\n                hot = 1.0\n            else:\n                hot = 0.0        \n    \n            textValue = str(values[4]) + \" \" + str(values[5])\n    \n            return LabeledDocument((values[6]), textValue, hot)\n\n        # Load the raw HVAC.csv file, parse it using the function\n        data = sc.textFile(\"wasb:///HdiSamples/HdiSamples/SensorSampleData/hvac/HVAC.csv\")\n\n        documents = data.filter(lambda s: \"Date\" not in s).map(parseDocument)\n        training = documents.toDF()\n\n\n5. Configure the Spark machine learning pipeline that consists of three stages: tokenizer, hashingTF, and lr. For more information about what is a pipeline and how it works see <a href=\"http://spark.apache.org/docs/latest/ml-guide.html#how-it-works\" target=\"_blank\">Spark machine learning pipeline</a>.\n\n    Paste the following snippet in an empty cell and press **SHIFT + ENTER**.\n\n        tokenizer = Tokenizer(inputCol=\"SystemInfo\", outputCol=\"words\")\n        hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n        lr = LogisticRegression(maxIter=10, regParam=0.01)\n        pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n\n6. Fit the pipeline to the training document. Paste the following snippet in an empty cell and press **SHIFT + ENTER**.\n\n        model = pipeline.fit(training)\n\n7. Verify the training document to checkpoint your progress with the application. Paste the following snippet in an empty cell and press **SHIFT + ENTER**.\n\n        training.show()\n\n    This should give the output similar to the following:\n\n        +----------+----------+-----+\n        |BuildingID|SystemInfo|label|\n        +----------+----------+-----+\n        |         4|     13 20|  0.0|\n        |        17|      3 20|  0.0|\n        |        18|     17 20|  1.0|\n        |        15|      2 23|  0.0|\n        |         3|      16 9|  1.0|\n        |         4|     13 28|  0.0|\n        |         2|     12 24|  0.0|\n        |        16|     20 26|  1.0|\n        |         9|      16 9|  1.0|\n        |        12|       6 5|  0.0|\n        |        15|     10 17|  1.0|\n        |         7|      2 11|  0.0|\n        |        15|      14 2|  1.0|\n        |         6|       3 2|  0.0|\n        |        20|     19 22|  0.0|\n        |         8|     19 11|  0.0|\n        |         6|      15 7|  0.0|\n        |        13|      12 5|  0.0|\n        |         4|      8 22|  0.0|\n        |         7|      17 5|  0.0|\n        +----------+----------+-----+\n\n\n    Go back and verify the output against the raw CSV file. For example, the first row the CSV file has this data:\n\n    ![HVAC data snapshot](./media/hdinsight-apache-spark-ipython-notebook-machine-learning/hdispark.ml.show.data.first.row.png \"Snapshot of the HVAC data\")\n\n    Notice how the actual temperature is less than the target temperature suggesting the building is cold. Hence in the training output, the value for **label** in the first row is **0.0**, which means the building is not hot.\n\n8.  Prepare a data set to run the trained model against. To do so, we would pass on a system ID and system age (denoted as **SystemInfo** in the training output), and the model would predict whether the building with that system ID and system age would be hotter (denoted by 1.0) or cooler (denoted by 0.0).\n\n    Paste the following snippet in an empty cell and press **SHIFT + ENTER**.\n        \n        # SystemInfo here is a combination of system ID followed by system age\n        Document = Row(\"id\", \"SystemInfo\")\n        test = sc.parallelize([(1L, \"20 25\"),\n                      (2L, \"4 15\"),\n                      (3L, \"16 9\"),\n                      (4L, \"9 22\"),\n                      (5L, \"17 10\"),\n                      (6L, \"7 22\")]) \\\n            .map(lambda x: Document(*x)).toDF() \n\n9. Finally, make predictions on the test data. Paste the following snippet in an empty cell and press **SHIFT + ENTER**.\n\n        # Make predictions on test documents and print columns of interest\n        prediction = model.transform(test)\n        selected = prediction.select(\"SystemInfo\", \"prediction\", \"probability\")\n        for row in selected.collect():\n            print row\n\n10. You should see an output similar to the following:\n\n        Row(SystemInfo=u'20 25', prediction=1.0, probability=DenseVector([0.4999, 0.5001]))\n        Row(SystemInfo=u'4 15', prediction=0.0, probability=DenseVector([0.5016, 0.4984]))\n        Row(SystemInfo=u'16 9', prediction=1.0, probability=DenseVector([0.4785, 0.5215]))\n        Row(SystemInfo=u'9 22', prediction=1.0, probability=DenseVector([0.4549, 0.5451]))\n        Row(SystemInfo=u'17 10', prediction=1.0, probability=DenseVector([0.4925, 0.5075]))\n        Row(SystemInfo=u'7 22', prediction=0.0, probability=DenseVector([0.5015, 0.4985]))\n\n    From the first row in the prediction, you can see that for an HVAC system with ID 20 and system age of 25 years, the building will be hot (**prediction=1.0**). The first value for DenseVector (0.49999) corresponds to the  prediction 0.0 and the second value (0.5001) corresponds to the prediction 1.0. In the output, even though the second value is only marginally higher, the model shows **prediction=1.0**.\n\n11. After you have finished running the application, you should shutdown the notebook to release the resources. To do so, from the **File** menu on the notebook, click **Close and Halt**. This will shutdown and close the notebook.\n           \n\n##<a name=\"anaconda\"></a>Use Anaconda scikit-learn library for Machine Learning\n\nApache Spark clusters on HDInsight include Anaconda libraries. This also includes the **scikit-learn** library for machine learning. The library also includes various data sets that you can use to build sample applications directly from a Jupyter notebook. For examples on using the scikit-learn library, see [http://scikit-learn.org/stable/auto_examples/index.html](http://scikit-learn.org/stable/auto_examples/index.html).\n\n##<a name=\"seealso\"></a>See also\n\n* [Overview: Apache Spark on Azure HDInsight](hdinsight-apache-spark-overview.md)\n\n### Scenarios\n\n* [Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools](hdinsight-apache-spark-use-bi-tools.md)\n\n* [Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results](hdinsight-apache-spark-machine-learning-mllib-ipython.md)\n\n* [Spark Streaming: Use Spark in HDInsight for building real-time streaming applications](hdinsight-apache-spark-eventhub-streaming.md)\n\n* [Website log analysis using Spark in HDInsight](hdinsight-apache-spark-custom-library-website-log-analysis.md)\n\n### Create and run applications\n\n* [Create a standalone application using Scala](hdinsight-apache-spark-create-standalone-application.md)\n\n* [Run jobs remotely on a Spark cluster using Livy](hdinsight-apache-spark-livy-rest-interface.md)\n\n### Tools and extensions\n\n* [Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons](hdinsight-apache-spark-intellij-tool-plugin.md)\n\n* [Use Zeppelin notebooks with a Spark cluster on HDInsight](hdinsight-apache-spark-use-zeppelin-notebook.md)\n\n* [Kernels available for Jupyter notebook in Spark cluster for HDInsight](hdinsight-apache-spark-jupyter-notebook-kernels.md)\n\n### Manage resources\n\n* [Manage resources for the Apache Spark cluster in Azure HDInsight](hdinsight-apache-spark-resource-manager.md)\n\n\n[hdinsight-versions]: hdinsight-component-versioning.md\n[hdinsight-upload-data]: hdinsight-upload-data.md\n[hdinsight-storage]: hdinsight-hadoop-use-blob-storage.md\n\n[hdinsight-weblogs-sample]: hdinsight-hive-analyze-website-log.md\n[hdinsight-sensor-data-sample]: hdinsight-hive-analyze-sensor-data.md\n\n[azure-purchase-options]: http://azure.microsoft.com/pricing/purchase-options/\n[azure-member-offers]: http://azure.microsoft.com/pricing/member-offers/\n[azure-free-trial]: http://azure.microsoft.com/pricing/free-trial/\n[azure-management-portal]: https://manage.windowsazure.com/\n[azure-create-storageaccount]: storage-create-storage-account.md\n"
}