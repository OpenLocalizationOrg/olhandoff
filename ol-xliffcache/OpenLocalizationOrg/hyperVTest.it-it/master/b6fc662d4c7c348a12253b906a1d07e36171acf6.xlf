<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="it-it">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Use Hadoop Pig with Remote Desktop in HDInsight | Microsoft Azure</source>
          <target state="new">Use Hadoop Pig with Remote Desktop in HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to use the Pig command to run Pig Latin statements from a Remote Desktop connection to a Windows-based Hadoop cluster in HDInsight.</source>
          <target state="new">Learn how to use the Pig command to run Pig Latin statements from a Remote Desktop connection to a Windows-based Hadoop cluster in HDInsight.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Run Pig jobs from a Remote Desktop connection</source>
          <target state="new">Run Pig jobs from a Remote Desktop connection</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>This document provides a walkthrough for using the Pig command to run Pig Latin statements from a Remote Desktop connection to a Windows-based HDInsight cluster.</source>
          <target state="new">This document provides a walkthrough for using the Pig command to run Pig Latin statements from a Remote Desktop connection to a Windows-based HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Pig Latin allows you to create MapReduce applications by describing data transformations, rather than map and reduce functions.</source>
          <target state="new">Pig Latin allows you to create MapReduce applications by describing data transformations, rather than map and reduce functions.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>In this document, learn how to</source>
          <target state="new">In this document, learn how to</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Prerequisites</source>
          <target state="new">Prerequisites</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>To complete the steps in this article, you will need the following.</source>
          <target state="new">To complete the steps in this article, you will need the following.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>A Windows-based HDInsight (Hadoop on HDInsight) cluster</source>
          <target state="new">A Windows-based HDInsight (Hadoop on HDInsight) cluster</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>A client computer running Windows 10, Windows 8, or Windows 7</source>
          <target state="new">A client computer running Windows 10, Windows 8, or Windows 7</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Connect with Remote Desktop</source>
          <target state="new">Connect with Remote Desktop</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Enable Remote Desktop for the HDInsight cluster, then connect to it by following the instructions at <bpt id="p1">[</bpt>Connect to HDInsight clusters using RDP<ept id="p1">](hdinsight-administer-use-management-portal.md#rdp)</ept>.</source>
          <target state="new">Enable Remote Desktop for the HDInsight cluster, then connect to it by following the instructions at <bpt id="p1">[</bpt>Connect to HDInsight clusters using RDP<ept id="p1">](hdinsight-administer-use-management-portal.md#rdp)</ept>.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Use the Pig command</source>
          <target state="new">Use the Pig command</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>After you have a Remote Desktop connection, start the <bpt id="p2">**</bpt>Hadoop Command Line<ept id="p2">**</ept><ph id="ph3" /> by using the icon on the desktop.</source>
          <target state="new">After you have a Remote Desktop connection, start the <bpt id="p2">**</bpt>Hadoop Command Line<ept id="p2">**</ept><ph id="ph3" /> by using the icon on the desktop.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Use the following to start the Pig command:</source>
          <target state="new">Use the following to start the Pig command:</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>You will be presented with a <ph id="ph4">`grunt&gt;`</ph><ph id="ph5" /> prompt.</source>
          <target state="new">You will be presented with a <ph id="ph4">`grunt&gt;`</ph><ph id="ph5" /> prompt.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Enter the following statement:</source>
          <target state="new">Enter the following statement:</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>This command loads the contents of the sample.log file into the LOGS file.</source>
          <target state="new">This command loads the contents of the sample.log file into the LOGS file.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>You can view the contents of the file by using the following command:</source>
          <target state="new">You can view the contents of the file by using the following command:</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Transform the data by applying a regular expression to extract only the logging level from each record:</source>
          <target state="new">Transform the data by applying a regular expression to extract only the logging level from each record:</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>You can use <bpt id="p3">**</bpt>DUMP<ept id="p3">**</ept><ph id="ph6" /> to view the data after the transformation.</source>
          <target state="new">You can use <bpt id="p3">**</bpt>DUMP<ept id="p3">**</ept><ph id="ph6" /> to view the data after the transformation.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>In this case, <ph id="ph7">`DUMP LEVELS;`</ph>.</source>
          <target state="new">In this case, <ph id="ph7">`DUMP LEVELS;`</ph>.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Continue applying transformations by using the following statements.</source>
          <target state="new">Continue applying transformations by using the following statements.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Use <ph id="ph8">`DUMP`</ph><ph id="ph9" /> to view the result of the transformation after each step.</source>
          <target state="new">Use <ph id="ph8">`DUMP`</ph><ph id="ph9" /> to view the result of the transformation after each step.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source><ph id="ph10">&lt;table&gt;</ph><ph id="ph11">
 &lt;tr&gt;</ph><ph id="ph12">
 &lt;th&gt;</ph>Statement<ph id="ph13">&lt;/th&gt;</ph><ph id="ph14">&lt;th&gt;</ph>What it does<ph id="ph15">&lt;/th&gt;</ph><ph id="ph16">
 &lt;/tr&gt;</ph><ph id="ph17">
 &lt;tr&gt;</ph><ph id="ph18">
 &lt;td&gt;</ph>FILTEREDLEVELS = FILTER LEVELS by LOGLEVEL is not null;<ph id="ph19">&lt;/td&gt;</ph><ph id="ph20">&lt;td&gt;</ph>Removes rows that contain a null value for the log level and stores the results into FILTEREDLEVELS.<ph id="ph21">&lt;/td&gt;</ph><ph id="ph22">
 &lt;/tr&gt;</ph><ph id="ph23">
 &lt;tr&gt;</ph><ph id="ph24">
 &lt;td&gt;</ph>GROUPEDLEVELS = GROUP FILTEREDLEVELS by LOGLEVEL;<ph id="ph25">&lt;/td&gt;</ph><ph id="ph26">&lt;td&gt;</ph>Groups the rows by log level and stores the results into GROUPEDLEVELS.<ph id="ph27">&lt;/td&gt;</ph><ph id="ph28">
 &lt;/tr&gt;</ph><ph id="ph29">
 &lt;tr&gt;</ph><ph id="ph30">
 &lt;td&gt;</ph>FREQUENCIES = foreach GROUPEDLEVELS generate group as LOGLEVEL, COUNT(FILTEREDLEVELS.LOGLEVEL) as COUNT;<ph id="ph31">&lt;/td&gt;</ph><ph id="ph32">&lt;td&gt;</ph>Creates a new set of data that contains each unique log level value and how many times it occurs.</source>
          <target state="new"><ph id="ph10">&lt;table&gt;</ph><ph id="ph11">
 &lt;tr&gt;</ph><ph id="ph12">
 &lt;th&gt;</ph>Statement<ph id="ph13">&lt;/th&gt;</ph><ph id="ph14">&lt;th&gt;</ph>What it does<ph id="ph15">&lt;/th&gt;</ph><ph id="ph16">
 &lt;/tr&gt;</ph><ph id="ph17">
 &lt;tr&gt;</ph><ph id="ph18">
 &lt;td&gt;</ph>FILTEREDLEVELS = FILTER LEVELS by LOGLEVEL is not null;<ph id="ph19">&lt;/td&gt;</ph><ph id="ph20">&lt;td&gt;</ph>Removes rows that contain a null value for the log level and stores the results into FILTEREDLEVELS.<ph id="ph21">&lt;/td&gt;</ph><ph id="ph22">
 &lt;/tr&gt;</ph><ph id="ph23">
 &lt;tr&gt;</ph><ph id="ph24">
 &lt;td&gt;</ph>GROUPEDLEVELS = GROUP FILTEREDLEVELS by LOGLEVEL;<ph id="ph25">&lt;/td&gt;</ph><ph id="ph26">&lt;td&gt;</ph>Groups the rows by log level and stores the results into GROUPEDLEVELS.<ph id="ph27">&lt;/td&gt;</ph><ph id="ph28">
 &lt;/tr&gt;</ph><ph id="ph29">
 &lt;tr&gt;</ph><ph id="ph30">
 &lt;td&gt;</ph>FREQUENCIES = foreach GROUPEDLEVELS generate group as LOGLEVEL, COUNT(FILTEREDLEVELS.LOGLEVEL) as COUNT;<ph id="ph31">&lt;/td&gt;</ph><ph id="ph32">&lt;td&gt;</ph>Creates a new set of data that contains each unique log level value and how many times it occurs.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>This is stored into FREQUENCIES<ph id="ph33">&lt;/td&gt;</ph><ph id="ph34">
 &lt;/tr&gt;</ph><ph id="ph35">
 &lt;tr&gt;</ph><ph id="ph36">
 &lt;td&gt;</ph>RESULT = order FREQUENCIES by COUNT desc;<ph id="ph37">&lt;/td&gt;</ph><ph id="ph38">&lt;td&gt;</ph>Orders the log levels by count (descending,) and stores into RESULT<ph id="ph39">&lt;/td&gt;</ph><ph id="ph40">
 &lt;/tr&gt;</ph><ph id="ph41">
 &lt;/table&gt;</ph></source>
          <target state="new">This is stored into FREQUENCIES<ph id="ph33">&lt;/td&gt;</ph><ph id="ph34">
 &lt;/tr&gt;</ph><ph id="ph35">
 &lt;tr&gt;</ph><ph id="ph36">
 &lt;td&gt;</ph>RESULT = order FREQUENCIES by COUNT desc;<ph id="ph37">&lt;/td&gt;</ph><ph id="ph38">&lt;td&gt;</ph>Orders the log levels by count (descending,) and stores into RESULT<ph id="ph39">&lt;/td&gt;</ph><ph id="ph40">
 &lt;/tr&gt;</ph><ph id="ph41">
 &lt;/table&gt;</ph></target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>You can also save the results of a transformation by using the <ph id="ph42">`STORE`</ph><ph id="ph43" /> statement.</source>
          <target state="new">You can also save the results of a transformation by using the <ph id="ph42">`STORE`</ph><ph id="ph43" /> statement.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>For example, the following command saves the <ph id="ph44">`RESULT`</ph><ph id="ph45" /> to the <bpt id="p4">**</bpt>/example/data/pigout<ept id="p4">**</ept><ph id="ph46" /> directory in the default storage container for your cluster:</source>
          <target state="new">For example, the following command saves the <ph id="ph44">`RESULT`</ph><ph id="ph45" /> to the <bpt id="p4">**</bpt>/example/data/pigout<ept id="p4">**</ept><ph id="ph46" /> directory in the default storage container for your cluster:</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source><ph id="ph47">[AZURE.NOTE]</ph><ph id="ph48" /> The data is stored in the specified directory in files named <bpt id="p5">**</bpt>part-nnnnn<ept id="p5">**</ept>.</source>
          <target state="new"><ph id="ph47">[AZURE.NOTE]</ph><ph id="ph48" /> The data is stored in the specified directory in files named <bpt id="p5">**</bpt>part-nnnnn<ept id="p5">**</ept>.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>If the directory already exists, you will receive an error message.</source>
          <target state="new">If the directory already exists, you will receive an error message.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>To exit the grunt prompt, enter the following statement.</source>
          <target state="new">To exit the grunt prompt, enter the following statement.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Pig Latin batch files</source>
          <target state="new">Pig Latin batch files</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>You can also use the Pig command to run Pig Latin that is contained in a file.</source>
          <target state="new">You can also use the Pig command to run Pig Latin that is contained in a file.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>After exiting the grunt prompt, open <bpt id="p6">**</bpt>Notepad<ept id="p6">**</ept><ph id="ph49" /> and create a new file named <bpt id="p7">**</bpt>pigbatch.pig<ept id="p7">**</ept><ph id="ph50" /> in the <bpt id="p8">**</bpt>%PIG_HOME%<ept id="p8">**</ept><ph id="ph51" /> directory.</source>
          <target state="new">After exiting the grunt prompt, open <bpt id="p6">**</bpt>Notepad<ept id="p6">**</ept><ph id="ph49" /> and create a new file named <bpt id="p7">**</bpt>pigbatch.pig<ept id="p7">**</ept><ph id="ph50" /> in the <bpt id="p8">**</bpt>%PIG_HOME%<ept id="p8">**</ept><ph id="ph51" /> directory.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Type or paste the following lines into the <bpt id="p9">**</bpt>pigbatch.pig<ept id="p9">**</ept><ph id="ph52" /> file, and then save it:</source>
          <target state="new">Type or paste the following lines into the <bpt id="p9">**</bpt>pigbatch.pig<ept id="p9">**</ept><ph id="ph52" /> file, and then save it:</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Use the following to run the <bpt id="p10">**</bpt>pigbatch.pig<ept id="p10">**</ept><ph id="ph53" /> file using the pig command.</source>
          <target state="new">Use the following to run the <bpt id="p10">**</bpt>pigbatch.pig<ept id="p10">**</ept><ph id="ph53" /> file using the pig command.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>When the batch job completes, you should see the following output, which should be the same as when you used <ph id="ph54">`DUMP RESULT;`</ph><ph id="ph55" /> in the previous steps:</source>
          <target state="new">When the batch job completes, you should see the following output, which should be the same as when you used <ph id="ph54">`DUMP RESULT;`</ph><ph id="ph55" /> in the previous steps:</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Summary</source>
          <target state="new">Summary</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>As you can see, the Pig command allows you to interactively run MapReduce operations, or run Pig Latin jobs that are stored in a batch file.</source>
          <target state="new">As you can see, the Pig command allows you to interactively run MapReduce operations, or run Pig Latin jobs that are stored in a batch file.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>For general information about Pig in HDInsight:</source>
          <target state="new">For general information about Pig in HDInsight:</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source><bpt id="p11">[</bpt>Use Pig with Hadoop on HDInsight<ept id="p11">](hdinsight-use-pig.md)</ept></source>
          <target state="new"><bpt id="p11">[</bpt>Use Pig with Hadoop on HDInsight<ept id="p11">](hdinsight-use-pig.md)</ept></target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>For information about other ways you can work with Hadoop on HDInsight:</source>
          <target state="new">For information about other ways you can work with Hadoop on HDInsight:</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source><bpt id="p12">[</bpt>Use Hive with Hadoop on HDInsight<ept id="p12">](hdinsight-use-hive.md)</ept></source>
          <target state="new"><bpt id="p12">[</bpt>Use Hive with Hadoop on HDInsight<ept id="p12">](hdinsight-use-hive.md)</ept></target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source><bpt id="p13">[</bpt>Use MapReduce with Hadoop on HDInsight<ept id="p13">](hdinsight-use-mapreduce.md)</ept></source>
          <target state="new"><bpt id="p13">[</bpt>Use MapReduce with Hadoop on HDInsight<ept id="p13">](hdinsight-use-mapreduce.md)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">b6fc662d4c7c348a12253b906a1d07e36171acf6</xliffext:olfilehash>
  </header>
</xliff>