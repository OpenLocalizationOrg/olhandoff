<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="it-it">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Use Hadoop Pig in HDInsight | Microsoft Azure</source>
          <target state="new">Use Hadoop Pig in HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to use Pig with Hadoop on HDInsight.</source>
          <target state="new">Learn how to use Pig with Hadoop on HDInsight.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Use Pig with Hadoop on HDInsight</source>
          <target state="new">Use Pig with Hadoop on HDInsight</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Apache Pig<ept id="p1">](http://pig.apache.org/)</ept><ph id="ph3" /> is a platform for creating programs for Hadoop by using a procedural language known as <bpt id="p2">*</bpt>Pig Latin<ept id="p2">*</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Apache Pig<ept id="p1">](http://pig.apache.org/)</ept><ph id="ph3" /> is a platform for creating programs for Hadoop by using a procedural language known as <bpt id="p2">*</bpt>Pig Latin<ept id="p2">*</ept>.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Pig is an alternative to Java for creating <bpt id="p3">*</bpt>MapReduce<ept id="p3">*</ept><ph id="ph4" /> solutions, and it is included with Azure HDInsight.</source>
          <target state="new">Pig is an alternative to Java for creating <bpt id="p3">*</bpt>MapReduce<ept id="p3">*</ept><ph id="ph4" /> solutions, and it is included with Azure HDInsight.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>In this article, you will learn how you can use Pig with HDInsight.</source>
          <target state="new">In this article, you will learn how you can use Pig with HDInsight.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Why use Pig?</source>
          <target state="new">Why use Pig?</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>One of the challenges of processing data by using MapReduce in Hadoop is implementing your processing logic by using only a map and a reduce function.</source>
          <target state="new">One of the challenges of processing data by using MapReduce in Hadoop is implementing your processing logic by using only a map and a reduce function.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>For complex processing, you often have to break processing into multiple MapReduce operations that are chained together to achieve the desired result.</source>
          <target state="new">For complex processing, you often have to break processing into multiple MapReduce operations that are chained together to achieve the desired result.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Instead of forcing you to use only map and reduce functions, Pig allows you to define processing as a series of transformations that the data flows through to produce the desired output.</source>
          <target state="new">Instead of forcing you to use only map and reduce functions, Pig allows you to define processing as a series of transformations that the data flows through to produce the desired output.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>The Pig Latin language allows you to describe the data flow from raw input, through one or more transformations, to produce the desired output.</source>
          <target state="new">The Pig Latin language allows you to describe the data flow from raw input, through one or more transformations, to produce the desired output.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Pig Latin programs follow this general pattern:</source>
          <target state="new">Pig Latin programs follow this general pattern:</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source><bpt id="p4">**</bpt>Load<ept id="p4">**</ept>: Read data to be manipulated from the file system</source>
          <target state="new"><bpt id="p4">**</bpt>Load<ept id="p4">**</ept>: Read data to be manipulated from the file system</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source><bpt id="p5">**</bpt>Transform<ept id="p5">**</ept>: Manipulate the data</source>
          <target state="new"><bpt id="p5">**</bpt>Transform<ept id="p5">**</ept>: Manipulate the data</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source><bpt id="p6">**</bpt>Dump or store<ept id="p6">**</ept>: Output data to the screen or store it for processing</source>
          <target state="new"><bpt id="p6">**</bpt>Dump or store<ept id="p6">**</ept>: Output data to the screen or store it for processing</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Pig Latin also supports user-defined functions (UDF), which allows you to invoke external components that implement logic that is difficult to model in Pig Latin.</source>
          <target state="new">Pig Latin also supports user-defined functions (UDF), which allows you to invoke external components that implement logic that is difficult to model in Pig Latin.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>For more information about Pig Latin, see <bpt id="p7">[</bpt>Pig Latin Reference Manual 1<ept id="p7">](http://pig.apache.org/docs/r0.7.0/piglatin_ref1.html)</ept><ph id="ph5" /> and <bpt id="p8">[</bpt>Pig Latin Reference Manual 2<ept id="p8">](http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html)</ept>.</source>
          <target state="new">For more information about Pig Latin, see <bpt id="p7">[</bpt>Pig Latin Reference Manual 1<ept id="p7">](http://pig.apache.org/docs/r0.7.0/piglatin_ref1.html)</ept><ph id="ph5" /> and <bpt id="p8">[</bpt>Pig Latin Reference Manual 2<ept id="p8">](http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html)</ept>.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>For an example of using UDFs with Pig, see the following documents:</source>
          <target state="new">For an example of using UDFs with Pig, see the following documents:</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p9">[</bpt>Use DataFu with Pig in HDInsight<ept id="p9">](hdinsight-hadoop-use-pig-datafu-udf.md)</ept><ph id="ph6" /> - DataFu is a collection of useful UDFs maintained by Apache</source>
          <target state="new"><bpt id="p9">[</bpt>Use DataFu with Pig in HDInsight<ept id="p9">](hdinsight-hadoop-use-pig-datafu-udf.md)</ept><ph id="ph6" /> - DataFu is a collection of useful UDFs maintained by Apache</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source><bpt id="p10">[</bpt>Use Python with Pig and Hive in HDInsight<ept id="p10">](hdinsight-python.md)</ept></source>
          <target state="new"><bpt id="p10">[</bpt>Use Python with Pig and Hive in HDInsight<ept id="p10">](hdinsight-python.md)</ept></target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source><bpt id="p11">[</bpt>Use C# with Hive and Pig in HDInsight<ept id="p11">](hdinsight-hadoop-hive-pig-udf-dotnet-csharp.md)</ept></source>
          <target state="new"><bpt id="p11">[</bpt>Use C# with Hive and Pig in HDInsight<ept id="p11">](hdinsight-hadoop-hive-pig-udf-dotnet-csharp.md)</ept></target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>About the sample data</source>
          <target state="new">About the sample data</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>This example uses a <bpt id="p12">*</bpt>log4j<ept id="p12">*</ept><ph id="ph7" /> sample file, which is stored at <bpt id="p13">**</bpt>/example/data/sample.log<ept id="p13">**</ept><ph id="ph8" /> in your blob storage container.</source>
          <target state="new">This example uses a <bpt id="p12">*</bpt>log4j<ept id="p12">*</ept><ph id="ph7" /> sample file, which is stored at <bpt id="p13">**</bpt>/example/data/sample.log<ept id="p13">**</ept><ph id="ph8" /> in your blob storage container.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Each log inside the file consists of a line of fields that contains a <ph id="ph9">`[LOG LEVEL]`</ph><ph id="ph10" /> field to show the type and the severity, for example:</source>
          <target state="new">Each log inside the file consists of a line of fields that contains a <ph id="ph9">`[LOG LEVEL]`</ph><ph id="ph10" /> field to show the type and the severity, for example:</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>In the previous example, the log level is ERROR.</source>
          <target state="new">In the previous example, the log level is ERROR.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source><ph id="ph11">[AZURE.NOTE]</ph><ph id="ph12" /> You can also generate a log4j file by using the <bpt id="p14">[</bpt>Apache Log4j<ept id="p14">](http://en.wikipedia.org/wiki/Log4j)</ept><ph id="ph13" /> logging tool and then upload that file to your blob.</source>
          <target state="new"><ph id="ph11">[AZURE.NOTE]</ph><ph id="ph12" /> You can also generate a log4j file by using the <bpt id="p14">[</bpt>Apache Log4j<ept id="p14">](http://en.wikipedia.org/wiki/Log4j)</ept><ph id="ph13" /> logging tool and then upload that file to your blob.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>See <bpt id="p15">[</bpt>Upload Data to HDInsight<ept id="p15">](hdinsight-upload-data.md)</ept><ph id="ph14" /> for instructions.</source>
          <target state="new">See <bpt id="p15">[</bpt>Upload Data to HDInsight<ept id="p15">](hdinsight-upload-data.md)</ept><ph id="ph14" /> for instructions.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>For more information about how blobs in Azure storage are used with HDInsight, see <bpt id="p16">[</bpt>Use Azure Blob Storage with HDInsight<ept id="p16">](hdinsight-hadoop-use-blob-storage.md)</ept>.</source>
          <target state="new">For more information about how blobs in Azure storage are used with HDInsight, see <bpt id="p16">[</bpt>Use Azure Blob Storage with HDInsight<ept id="p16">](hdinsight-hadoop-use-blob-storage.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>The sample data is stored in Azure Blob storage, which HDInsight uses as the default file system for Hadoop clusters.</source>
          <target state="new">The sample data is stored in Azure Blob storage, which HDInsight uses as the default file system for Hadoop clusters.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>HDInsight can access files stored in blobs by using the <bpt id="p17">**</bpt>wasb<ept id="p17">**</ept><ph id="ph15" /> prefix.</source>
          <target state="new">HDInsight can access files stored in blobs by using the <bpt id="p17">**</bpt>wasb<ept id="p17">**</ept><ph id="ph15" /> prefix.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>For example, to access the sample.log file, you would use the following syntax:</source>
          <target state="new">For example, to access the sample.log file, you would use the following syntax:</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Because WASB is the default storage for HDInsight, you can also access the file by using <bpt id="p18">**</bpt>/example/data/sample.log<ept id="p18">**</ept><ph id="ph16" /> from Pig Latin.</source>
          <target state="new">Because WASB is the default storage for HDInsight, you can also access the file by using <bpt id="p18">**</bpt>/example/data/sample.log<ept id="p18">**</ept><ph id="ph16" /> from Pig Latin.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source><ph id="ph17">[AZURE.NOTE]</ph><ph id="ph18" /> The syntax, <bpt id="p19">**</bpt>wasb:///<ept id="p19">**</ept>, is used to access files stored in the default storage container for your HDInsight cluster.</source>
          <target state="new"><ph id="ph17">[AZURE.NOTE]</ph><ph id="ph18" /> The syntax, <bpt id="p19">**</bpt>wasb:///<ept id="p19">**</ept>, is used to access files stored in the default storage container for your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>If you specified additional storage accounts when you provisioned your cluster, and you want to access files stored in these accounts, you can access the data by specifying the container name and storage account address, for example: <bpt id="p20">**</bpt>wasb://mycontainer@mystorage.blob.core.windows.net/example/data/sample.log<ept id="p20">**</ept>.</source>
          <target state="new">If you specified additional storage accounts when you provisioned your cluster, and you want to access files stored in these accounts, you can access the data by specifying the container name and storage account address, for example: <bpt id="p20">**</bpt>wasb://mycontainer@mystorage.blob.core.windows.net/example/data/sample.log<ept id="p20">**</ept>.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>About the sample job</source>
          <target state="new">About the sample job</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>The following Pig Latin job loads the <bpt id="p21">**</bpt>sample.log<ept id="p21">**</ept><ph id="ph19" /> file from the default storage for your HDInsight cluster.</source>
          <target state="new">The following Pig Latin job loads the <bpt id="p21">**</bpt>sample.log<ept id="p21">**</ept><ph id="ph19" /> file from the default storage for your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Then it performs a series of transformations that result in a count of how many times each log level occurred in the input data.</source>
          <target state="new">Then it performs a series of transformations that result in a count of how many times each log level occurred in the input data.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>The results are dumped into STDOUT.</source>
          <target state="new">The results are dumped into STDOUT.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>The following image shows a breakdown of what each transformation does to the data.</source>
          <target state="new">The following image shows a breakdown of what each transformation does to the data.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source><ph id="ph20">![</ph>Graphical representation of the transformations<ph id="ph21">][image-hdi-pig-data-transformation]</ph></source>
          <target state="new"><ph id="ph20">![</ph>Graphical representation of the transformations<ph id="ph21">][image-hdi-pig-data-transformation]</ph></target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Run the Pig Latin job</source>
          <target state="new">Run the Pig Latin job</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>HDInsight can run Pig Latin jobs by using a variety of methods.</source>
          <target state="new">HDInsight can run Pig Latin jobs by using a variety of methods.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>Use the following table to decide which method is right for you, then follow the link for a walkthrough.</source>
          <target state="new">Use the following table to decide which method is right for you, then follow the link for a walkthrough.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source><bpt id="p22">**</bpt>Use this<ept id="p22">**</ept><ph id="ph22" /> if you want...</source>
          <target state="new"><bpt id="p22">**</bpt>Use this<ept id="p22">**</ept><ph id="ph22" /> if you want...</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>...an <bpt id="p23">**</bpt>interactive<ept id="p23">**</ept><ph id="ph23" /> shell</source>
          <target state="new">...an <bpt id="p23">**</bpt>interactive<ept id="p23">**</ept><ph id="ph23" /> shell</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>...<bpt id="p24">**</bpt>batch<ept id="p24">**</ept><ph id="ph24" /> processing</source>
          <target state="new">...<bpt id="p24">**</bpt>batch<ept id="p24">**</ept><ph id="ph24" /> processing</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>...with this <bpt id="p25">**</bpt>cluster operating system<ept id="p25">**</ept></source>
          <target state="new">...with this <bpt id="p25">**</bpt>cluster operating system<ept id="p25">**</ept></target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>...from this <bpt id="p26">**</bpt>client operating system<ept id="p26">**</ept></source>
          <target state="new">...from this <bpt id="p26">**</bpt>client operating system<ept id="p26">**</ept></target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source><bpt id="p27">[</bpt>SSH<ept id="p27">](hdinsight-hadoop-use-pig-ssh.md)</ept></source>
          <target state="new"><bpt id="p27">[</bpt>SSH<ept id="p27">](hdinsight-hadoop-use-pig-ssh.md)</ept></target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Linux</source>
          <target state="new">Linux</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Linux, Unix, Mac OS X, or Windows</source>
          <target state="new">Linux, Unix, Mac OS X, or Windows</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source><bpt id="p28">[</bpt>Curl<ept id="p28">](hdinsight-hadoop-use-pig-curl.md)</ept></source>
          <target state="new"><bpt id="p28">[</bpt>Curl<ept id="p28">](hdinsight-hadoop-use-pig-curl.md)</ept></target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>&amp;nbsp;</source>
          <target state="new">&amp;nbsp;</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Linux or Windows</source>
          <target state="new">Linux or Windows</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>Linux, Unix, Mac OS X, or Windows</source>
          <target state="new">Linux, Unix, Mac OS X, or Windows</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source><bpt id="p29">[</bpt>.NET SDK for Hadoop<ept id="p29">](hdinsight-hadoop-use-pig-dotnet-sdk.md)</ept></source>
          <target state="new"><bpt id="p29">[</bpt>.NET SDK for Hadoop<ept id="p29">](hdinsight-hadoop-use-pig-dotnet-sdk.md)</ept></target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>&amp;nbsp;</source>
          <target state="new">&amp;nbsp;</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Linux or Windows</source>
          <target state="new">Linux or Windows</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Windows (for now)</source>
          <target state="new">Windows (for now)</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source><bpt id="p30">[</bpt>Windows PowerShell<ept id="p30">](hdinsight-hadoop-use-pig-powershell.md)</ept></source>
          <target state="new"><bpt id="p30">[</bpt>Windows PowerShell<ept id="p30">](hdinsight-hadoop-use-pig-powershell.md)</ept></target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>&amp;nbsp;</source>
          <target state="new">&amp;nbsp;</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Linux or Windows</source>
          <target state="new">Linux or Windows</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>Windows</source>
          <target state="new">Windows</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source><bpt id="p31">[</bpt>Remote Desktop<ept id="p31">](hdinsight-hadoop-use-pig-remote-desktop.md)</ept></source>
          <target state="new"><bpt id="p31">[</bpt>Remote Desktop<ept id="p31">](hdinsight-hadoop-use-pig-remote-desktop.md)</ept></target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Windows</source>
          <target state="new">Windows</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>Windows</source>
          <target state="new">Windows</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>Running Pig jobs on Azure HDInsight using on-premises SQL Server Integration Services</source>
          <target state="new">Running Pig jobs on Azure HDInsight using on-premises SQL Server Integration Services</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>You can also use SQL Server Integration Services (SSIS) to run a Pig job.</source>
          <target state="new">You can also use SQL Server Integration Services (SSIS) to run a Pig job.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>The Azure Feature Pack for SSIS provides the following components that work with Pig jobs on HDInsight.</source>
          <target state="new">The Azure Feature Pack for SSIS provides the following components that work with Pig jobs on HDInsight.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source><bpt id="p32">[</bpt>Azure HDInsight Pig Task<ept id="p32">][pigtask]</ept></source>
          <target state="new"><bpt id="p32">[</bpt>Azure HDInsight Pig Task<ept id="p32">][pigtask]</ept></target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source><bpt id="p33">[</bpt>Azure Subscription Connection Manager<ept id="p33">][connectionmanager]</ept></source>
          <target state="new"><bpt id="p33">[</bpt>Azure Subscription Connection Manager<ept id="p33">][connectionmanager]</ept></target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>Learn more about the Azure Feature Pack for SSIS <bpt id="p34">[</bpt>here<ept id="p34">][ssispack]</ept>.</source>
          <target state="new">Learn more about the Azure Feature Pack for SSIS <bpt id="p34">[</bpt>here<ept id="p34">][ssispack]</ept>.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>Now that you have learned how to use Pig with HDInsight, use the following links to explore other ways to work with Azure HDInsight.</source>
          <target state="new">Now that you have learned how to use Pig with HDInsight, use the following links to explore other ways to work with Azure HDInsight.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source><bpt id="p35">[</bpt>Upload data to HDInsight<ept id="p35">][hdinsight-upload-data]</ept></source>
          <target state="new"><bpt id="p35">[</bpt>Upload data to HDInsight<ept id="p35">][hdinsight-upload-data]</ept></target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source><bpt id="p36">[</bpt>Use Hive with HDInsight<ept id="p36">][hdinsight-use-hive]</ept></source>
          <target state="new"><bpt id="p36">[</bpt>Use Hive with HDInsight<ept id="p36">][hdinsight-use-hive]</ept></target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source><bpt id="p37">[</bpt>Use MapReduce jobs with HDInsight<ept id="p37">][hdinsight-use-mapreduce]</ept></source>
          <target state="new"><bpt id="p37">[</bpt>Use MapReduce jobs with HDInsight<ept id="p37">][hdinsight-use-mapreduce]</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">abb1c553d8308b8357f0621ea0d63826db3189fd</xliffext:olfilehash>
  </header>
</xliff>