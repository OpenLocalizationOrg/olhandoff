{
  "nodes": [
    {
      "pos": [
        27,
        99
      ],
      "content": "What is Hadoop in the cloud? Introduction to HDInsight | Microsoft Azure",
      "nodes": [
        {
          "content": "What is Hadoop in the cloud?",
          "pos": [
            0,
            28
          ]
        },
        {
          "content": "Introduction to HDInsight | Microsoft Azure",
          "pos": [
            29,
            72
          ]
        }
      ]
    },
    {
      "pos": [
        118,
        241
      ],
      "content": "What is Hadoop in the cloud and how is it managed in HDInsight? An introduction to Hadoop components and big data analysis.",
      "nodes": [
        {
          "content": "What is Hadoop in the cloud and how is it managed in HDInsight?",
          "pos": [
            0,
            63
          ]
        },
        {
          "content": "An introduction to Hadoop components and big data analysis.",
          "pos": [
            64,
            123
          ]
        }
      ]
    },
    {
      "pos": [
        634,
        734
      ],
      "content": "What is Hadoop in the cloud? An introduction to Hadoop components in HDInsight for big data analysis",
      "nodes": [
        {
          "content": "What is Hadoop in the cloud?",
          "pos": [
            0,
            28
          ]
        },
        {
          "content": "An introduction to Hadoop components in HDInsight for big data analysis",
          "pos": [
            29,
            100
          ]
        }
      ]
    },
    {
      "pos": [
        736,
        1041
      ],
      "content": "Get an introduction to Hadoop, its ecosystem, and big data in Azure HDInsight: What is Hadoop in HDInsight and what are the Hadoop components, common terminology, and scenarios for big data analysis? Also, learn about Hadoop tutorials, documentation, and resources for using Hadoop the cloud in HDInsight.",
      "nodes": [
        {
          "content": "Get an introduction to Hadoop, its ecosystem, and big data in Azure HDInsight: What is Hadoop in HDInsight and what are the Hadoop components, common terminology, and scenarios for big data analysis?",
          "pos": [
            0,
            199
          ]
        },
        {
          "content": "Also, learn about Hadoop tutorials, documentation, and resources for using Hadoop the cloud in HDInsight.",
          "pos": [
            200,
            305
          ]
        }
      ]
    },
    {
      "pos": [
        1046,
        1087
      ],
      "content": "What is Hadoop in the cloud in HDInsight?"
    },
    {
      "pos": [
        1089,
        1638
      ],
      "content": "Azure HDInsight deploys and provisions managed Apache Hadoop clusters in the cloud, providing a software framework designed to process, analyze, and report on big data with high reliability and availability. HDInsight uses the <bpt id=\"p1\">**</bpt>Hortonworks Data Platform (HDP)<ept id=\"p1\">**</ept><ph id=\"ph2\"/> Hadoop distribution. Hadoop often refers to the entire Hadoop ecosystem of components, which includes Apache HBase, Apache Spark, and Apache Storm, as well as other technologies under the Hadoop umbrella. See <bpt id=\"p2\">[</bpt>Overview of the Hadoop ecosystem on HDInsight<ept id=\"p2\">](#overview)</ept><ph id=\"ph3\"/> below for details.",
      "nodes": [
        {
          "content": "Azure HDInsight deploys and provisions managed Apache Hadoop clusters in the cloud, providing a software framework designed to process, analyze, and report on big data with high reliability and availability.",
          "pos": [
            0,
            207
          ]
        },
        {
          "content": "HDInsight uses the <bpt id=\"p1\">**</bpt>Hortonworks Data Platform (HDP)<ept id=\"p1\">**</ept><ph id=\"ph2\"/> Hadoop distribution.",
          "pos": [
            208,
            335
          ]
        },
        {
          "content": "Hadoop often refers to the entire Hadoop ecosystem of components, which includes Apache HBase, Apache Spark, and Apache Storm, as well as other technologies under the Hadoop umbrella.",
          "pos": [
            336,
            519
          ]
        },
        {
          "content": "See <bpt id=\"p2\">[</bpt>Overview of the Hadoop ecosystem on HDInsight<ept id=\"p2\">](#overview)</ept><ph id=\"ph3\"/> below for details.",
          "pos": [
            520,
            653
          ]
        }
      ]
    },
    {
      "pos": [
        1644,
        1661
      ],
      "content": "What is big data?"
    },
    {
      "pos": [
        1662,
        1848
      ],
      "content": "Big data refers to data being collected in ever-escalating volumes, at increasingly higher velocities, and in an expanding variety of unstructured formats and variable semantic contexts."
    },
    {
      "pos": [
        1850,
        2175
      ],
      "content": "Big data describes any large body of digital information, from the text in a Twitter feed, to the sensor information from industrial equipment, to information about customer browsing and purchases on an online catalog. Big data can be historical (meaning stored data) or real-time (meaning streamed directly from the source).",
      "nodes": [
        {
          "content": "Big data describes any large body of digital information, from the text in a Twitter feed, to the sensor information from industrial equipment, to information about customer browsing and purchases on an online catalog.",
          "pos": [
            0,
            218
          ]
        },
        {
          "content": "Big data can be historical (meaning stored data) or real-time (meaning streamed directly from the source).",
          "pos": [
            219,
            325
          ]
        }
      ]
    },
    {
      "pos": [
        2177,
        2462
      ],
      "content": "For big data to provide actionable intelligence or insight, not only must you collect relevant data and ask the right questions, but also the data must be accessible, cleaned, analyzed, and then presented in a useful way. That's where big data analysis on Hadoop in HDInsight can help.",
      "nodes": [
        {
          "content": "For big data to provide actionable intelligence or insight, not only must you collect relevant data and ask the right questions, but also the data must be accessible, cleaned, analyzed, and then presented in a useful way.",
          "pos": [
            0,
            221
          ]
        },
        {
          "content": "That's where big data analysis on Hadoop in HDInsight can help.",
          "pos": [
            222,
            285
          ]
        }
      ]
    },
    {
      "pos": [
        2491,
        2536
      ],
      "content": "Overview of the Hadoop ecosystem on HDInsight"
    },
    {
      "pos": [
        2538,
        2955
      ],
      "content": "HDInsight is a cloud implementation on Microsoft Azure of the rapidly expanding Apache Hadoop technology stack that is the go-to solution for big data analysis. It includes implementations of Apache Spark, HBase, Storm, Pig, Hive, Sqoop, Oozie, Ambari, and so on. HDInsight also integrates with business intelligence (BI) tools such as Power BI, Excel, SQL Server Analysis Services, and SQL Server Reporting Services.",
      "nodes": [
        {
          "content": "HDInsight is a cloud implementation on Microsoft Azure of the rapidly expanding Apache Hadoop technology stack that is the go-to solution for big data analysis.",
          "pos": [
            0,
            160
          ]
        },
        {
          "content": "It includes implementations of Apache Spark, HBase, Storm, Pig, Hive, Sqoop, Oozie, Ambari, and so on.",
          "pos": [
            161,
            263
          ]
        },
        {
          "content": "HDInsight also integrates with business intelligence (BI) tools such as Power BI, Excel, SQL Server Analysis Services, and SQL Server Reporting Services.",
          "pos": [
            264,
            417
          ]
        }
      ]
    },
    {
      "pos": [
        2961,
        2978
      ],
      "content": "Clusters on Linux"
    },
    {
      "pos": [
        2980,
        3094
      ],
      "content": "Azure HDInsight deploys and provisions Hadoop clusters in the cloud on <bpt id=\"p3\">**</bpt>Linux<ept id=\"p3\">**</ept>. See the table below for details.",
      "nodes": [
        {
          "content": "Azure HDInsight deploys and provisions Hadoop clusters in the cloud on <bpt id=\"p3\">**</bpt>Linux<ept id=\"p3\">**</ept>.",
          "pos": [
            0,
            119
          ]
        },
        {
          "content": "See the table below for details.",
          "pos": [
            120,
            152
          ]
        }
      ]
    },
    {
      "pos": [
        3096,
        3104
      ],
      "content": "Category"
    },
    {
      "pos": [
        3107,
        3122
      ],
      "content": "Hadoop on Linux"
    },
    {
      "pos": [
        3154,
        3168
      ],
      "content": "<bpt id=\"p4\">**</bpt>Cluster OS<ept id=\"p4\">**</ept>"
    },
    {
      "pos": [
        3171,
        3207
      ],
      "content": "Ubuntu 12.04 Long Term Support (LTS)"
    },
    {
      "pos": [
        3208,
        3224
      ],
      "content": "<bpt id=\"p5\">**</bpt>Cluster Type<ept id=\"p5\">**</ept>"
    },
    {
      "pos": [
        3227,
        3254
      ],
      "content": "Hadoop, Spark, HBase, Storm"
    },
    {
      "pos": [
        3255,
        3269
      ],
      "content": "<bpt id=\"p6\">**</bpt>Deployment<ept id=\"p6\">**</ept>"
    },
    {
      "pos": [
        3272,
        3313
      ],
      "content": "Azure portal, Azure CLI, Azure PowerShell"
    },
    {
      "pos": [
        3314,
        3328
      ],
      "content": "<bpt id=\"p7\">**</bpt>Cluster UI<ept id=\"p7\">**</ept>"
    },
    {
      "pos": [
        3331,
        3337
      ],
      "content": "Ambari"
    },
    {
      "pos": [
        3338,
        3355
      ],
      "content": "<bpt id=\"p8\">**</bpt>Remote Access<ept id=\"p8\">**</ept>"
    },
    {
      "pos": [
        3358,
        3398
      ],
      "content": "Secure Shell (SSH), REST API, ODBC, JDBC"
    },
    {
      "pos": [
        3406,
        3458
      ],
      "content": "Hadoop, HBase, Spark, Storm, and customized clusters"
    },
    {
      "pos": [
        3460,
        3643
      ],
      "content": "HDInsight provides cluster configurations for Apache Hadoop, Spark, HBase, or Storm. Or, you can <bpt id=\"p9\">[</bpt>customize clusters with script actions<ept id=\"p9\">](hdinsight-hadoop-customize-cluster-linux.md)</ept>.",
      "nodes": [
        {
          "content": "HDInsight provides cluster configurations for Apache Hadoop, Spark, HBase, or Storm.",
          "pos": [
            0,
            84
          ]
        },
        {
          "content": "Or, you can <bpt id=\"p9\">[</bpt>customize clusters with script actions<ept id=\"p9\">](hdinsight-hadoop-customize-cluster-linux.md)</ept>.",
          "pos": [
            85,
            221
          ]
        }
      ]
    },
    {
      "pos": [
        3647,
        3828
      ],
      "content": "<bpt id=\"p10\">**</bpt>Hadoop<ept id=\"p10\">**</ept><ph id=\"ph4\"/> (the \"Query\" workload): Provides reliable data storage with <bpt id=\"p11\">[</bpt>HDFS<ept id=\"p11\">](#HDFS)</ept>, and a simple <bpt id=\"p12\">[</bpt>MapReduce<ept id=\"p12\">](#mapreduce)</ept><ph id=\"ph5\"/> programming model to process and analyze data in parallel."
    },
    {
      "pos": [
        3832,
        4177
      ],
      "content": "<bpt id=\"p13\">**</bpt><ph id=\"ph6\">&lt;a target=\"_blank\" href=\"http://spark.apache.org/\"&gt;</ph>Apache Spark<ph id=\"ph7\">&lt;/a&gt;</ph><ept id=\"p13\">**</ept>: A parallel processing framework that supports in-memory processing to boost the performance of big-data analysis applications, Spark works for SQL, streaming data, and machine learning. See <bpt id=\"p14\">[</bpt>Overview: What is Apache Spark in HDInsight?<ept id=\"p14\">](hdinsight-apache-spark-overview.md)</ept>",
      "nodes": [
        {
          "content": "<bpt id=\"p13\">**</bpt><ph id=\"ph6\">&lt;a target=\"_blank\" href=\"http://spark.apache.org/\"&gt;</ph>Apache Spark<ph id=\"ph7\">&lt;/a&gt;</ph><ept id=\"p13\">**</ept>: A parallel processing framework that supports in-memory processing to boost the performance of big-data analysis applications, Spark works for SQL, streaming data, and machine learning.",
          "pos": [
            0,
            346
          ]
        },
        {
          "content": "See <bpt id=\"p14\">[</bpt>Overview: What is Apache Spark in HDInsight?<ept id=\"p14\">](hdinsight-apache-spark-overview.md)</ept>",
          "pos": [
            347,
            473
          ]
        }
      ]
    },
    {
      "pos": [
        4181,
        4537
      ],
      "content": "<bpt id=\"p15\">**</bpt><ph id=\"ph8\">&lt;a target=\"_blank\" href=\"http://hbase.apache.org/\"&gt;</ph>HBase<ph id=\"ph9\">&lt;/a&gt;</ph><ept id=\"p15\">**</ept><ph id=\"ph10\"/> (the \"NoSQL\" workload): A NoSQL database built on Hadoop that provides random access and strong consistency for large amounts of unstructured and semi-structured data - potentially billions of rows times millions of columns. See <bpt id=\"p16\">[</bpt>Overview of HBase on HDInsight<ept id=\"p16\">](hdinsight-hbase-overview.md)</ept>.",
      "nodes": [
        {
          "content": "<bpt id=\"p15\">**</bpt><ph id=\"ph8\">&lt;a target=\"_blank\" href=\"http://hbase.apache.org/\"&gt;</ph>HBase<ph id=\"ph9\">&lt;/a&gt;</ph><ept id=\"p15\">**</ept><ph id=\"ph10\"/> (the \"NoSQL\" workload): A NoSQL database built on Hadoop that provides random access and strong consistency for large amounts of unstructured and semi-structured data - potentially billions of rows times millions of columns.",
          "pos": [
            0,
            392
          ]
        },
        {
          "content": "See <bpt id=\"p16\">[</bpt>Overview of HBase on HDInsight<ept id=\"p16\">](hdinsight-hbase-overview.md)</ept>.",
          "pos": [
            393,
            499
          ]
        }
      ]
    },
    {
      "pos": [
        4541,
        4889
      ],
      "content": "<bpt id=\"p17\">**</bpt><ph id=\"ph11\">&lt;a  target=\"_blank\" href=\"https://storm.incubator.apache.org/\"&gt;</ph>Apache Storm<ph id=\"ph12\">&lt;/a&gt;</ph><ept id=\"p17\">**</ept><ph id=\"ph13\"/> (the \"Stream\" workload): A distributed, real-time computation system for processing large streams of data fast. Storm is offered as a managed cluster in HDInsight. See <bpt id=\"p18\">[</bpt>Analyze real-time sensor data using Storm and Hadoop<ept id=\"p18\">](hdinsight-storm-sensor-data-analysis.md)</ept>.",
      "nodes": [
        {
          "content": "<bpt id=\"p17\">**</bpt><ph id=\"ph11\">&lt;a  target=\"_blank\" href=\"https://storm.incubator.apache.org/\"&gt;</ph>Apache Storm<ph id=\"ph12\">&lt;/a&gt;</ph><ept id=\"p17\">**</ept><ph id=\"ph13\"/> (the \"Stream\" workload): A distributed, real-time computation system for processing large streams of data fast.",
          "pos": [
            0,
            300
          ]
        },
        {
          "content": "Storm is offered as a managed cluster in HDInsight.",
          "pos": [
            301,
            352
          ]
        },
        {
          "content": "See <bpt id=\"p18\">[</bpt>Analyze real-time sensor data using Storm and Hadoop<ept id=\"p18\">](hdinsight-storm-sensor-data-analysis.md)</ept>.",
          "pos": [
            353,
            493
          ]
        }
      ]
    },
    {
      "pos": [
        4896,
        4925
      ],
      "content": "Example customization scripts"
    },
    {
      "pos": [
        4927,
        5106
      ],
      "content": "Script Actions are scripts that run during cluster provisioning, and can be used to install additional components on the cluster. For Linux-based clusters, these are Bash scripts.",
      "nodes": [
        {
          "content": "Script Actions are scripts that run during cluster provisioning, and can be used to install additional components on the cluster.",
          "pos": [
            0,
            129
          ]
        },
        {
          "content": "For Linux-based clusters, these are Bash scripts.",
          "pos": [
            130,
            179
          ]
        }
      ]
    },
    {
      "pos": [
        5108,
        5173
      ],
      "content": "The following example scripts are provided by the HDInsight team:"
    },
    {
      "pos": [
        5177,
        5294
      ],
      "content": "<bpt id=\"p19\">[</bpt>Hue<ept id=\"p19\">](hdinsight-hadoop-hue-linux.md)</ept>: A set of web applications used to interact with a cluster. Linux clusters only.",
      "nodes": [
        {
          "content": "<bpt id=\"p19\">[</bpt>Hue<ept id=\"p19\">](hdinsight-hadoop-hue-linux.md)</ept>: A set of web applications used to interact with a cluster.",
          "pos": [
            0,
            136
          ]
        },
        {
          "content": "Linux clusters only.",
          "pos": [
            137,
            157
          ]
        }
      ]
    },
    {
      "pos": [
        5298,
        5415
      ],
      "content": "<bpt id=\"p20\">[</bpt>Giraph<ept id=\"p20\">](hdinsight-hadoop-giraph-install-linux.md)</ept>: Graph processing to model relationships between things or people."
    },
    {
      "pos": [
        5419,
        5552
      ],
      "content": "<bpt id=\"p21\">[</bpt>R<ept id=\"p21\">](hdinsight-hadoop-r-scripts-linux.md)</ept>: An open-source language and environment for statistical computing used in machine learning."
    },
    {
      "pos": [
        5556,
        5677
      ],
      "content": "<bpt id=\"p22\">[</bpt>Solr<ept id=\"p22\">](hdinsight-hadoop-solr-install-linux.md)</ept>: An enterprise-scale search platform that allows full-text search on data."
    },
    {
      "pos": [
        5679,
        5823
      ],
      "content": "For information on developing your own Script Actions, see <bpt id=\"p23\">[</bpt>Script Action development with HDInsight<ept id=\"p23\">](hdinsight-hadoop-script-actions-linux.md)</ept>."
    },
    {
      "pos": [
        5828,
        5872
      ],
      "content": "What are the Hadoop components and utilties?"
    },
    {
      "pos": [
        5874,
        5948
      ],
      "content": "The following components and utilities are included on HDInsight clusters."
    },
    {
      "pos": [
        5952,
        6035
      ],
      "content": "<bpt id=\"p24\">**</bpt><bpt id=\"p25\">[</bpt>Ambari<ept id=\"p25\">](#ambari)</ept><ept id=\"p24\">**</ept>: Cluster provisioning, management, monitoring, and utilities."
    },
    {
      "pos": [
        6039,
        6146
      ],
      "content": "<bpt id=\"p26\">**</bpt><bpt id=\"p27\">[</bpt>Avro<ept id=\"p27\">](#avro)</ept><ept id=\"p26\">**</ept><ph id=\"ph14\"/> (Microsoft .NET Library for Avro): Data serialization for the Microsoft .NET environment."
    },
    {
      "pos": [
        6150,
        6268
      ],
      "content": "<bpt id=\"p28\">**</bpt><bpt id=\"p29\">[</bpt>Hive &amp; HCatalog<ept id=\"p29\">](#hive)</ept><ept id=\"p28\">**</ept>: Structured Query Language (SQL)-like querying, and a table and storage management layer."
    },
    {
      "pos": [
        6272,
        6312
      ],
      "content": "<bpt id=\"p30\">**</bpt><bpt id=\"p31\">[</bpt>Mahout<ept id=\"p31\">](#mahout)</ept><ept id=\"p30\">**</ept>: Machine learning."
    },
    {
      "pos": [
        6316,
        6479
      ],
      "content": "<bpt id=\"p32\">**</bpt><bpt id=\"p33\">[</bpt>MapReduce<ept id=\"p33\">](#mapreduce)</ept><ept id=\"p32\">**</ept>: Legacy framework for Hadoop distributed processing and resource management. See <bpt id=\"p34\">[</bpt>YARN<ept id=\"p34\">](#yarn)</ept>, the next-generation resource framework.",
      "nodes": [
        {
          "content": "<bpt id=\"p32\">**</bpt><bpt id=\"p33\">[</bpt>MapReduce<ept id=\"p33\">](#mapreduce)</ept><ept id=\"p32\">**</ept>: Legacy framework for Hadoop distributed processing and resource management.",
          "pos": [
            0,
            184
          ]
        },
        {
          "content": "See <bpt id=\"p34\">[</bpt>YARN<ept id=\"p34\">](#yarn)</ept>, the next-generation resource framework.",
          "pos": [
            185,
            283
          ]
        }
      ]
    },
    {
      "pos": [
        6483,
        6524
      ],
      "content": "<bpt id=\"p35\">**</bpt><bpt id=\"p36\">[</bpt>Oozie<ept id=\"p36\">](#oozie)</ept><ept id=\"p35\">**</ept>: Workflow management."
    },
    {
      "pos": [
        6528,
        6590
      ],
      "content": "<bpt id=\"p37\">**</bpt><bpt id=\"p38\">[</bpt>Phoenix<ept id=\"p38\">](#phoenix)</ept><ept id=\"p37\">**</ept>: Relational database layer over HBase."
    },
    {
      "pos": [
        6594,
        6659
      ],
      "content": "<bpt id=\"p39\">**</bpt><bpt id=\"p40\">[</bpt>Pig<ept id=\"p40\">](#pig)</ept><ept id=\"p39\">**</ept>: Simpler scripting for MapReduce transformations."
    },
    {
      "pos": [
        6663,
        6707
      ],
      "content": "<bpt id=\"p41\">**</bpt><bpt id=\"p42\">[</bpt>Sqoop<ept id=\"p42\">](#sqoop)</ept><ept id=\"p41\">**</ept>: Data import and export."
    },
    {
      "pos": [
        6711,
        6788
      ],
      "content": "<bpt id=\"p43\">**</bpt><bpt id=\"p44\">[</bpt>Tez<ept id=\"p44\">](#tez)</ept><ept id=\"p43\">**</ept>: Allows data-intensive processes to run efficiently at scale."
    },
    {
      "pos": [
        6792,
        6899
      ],
      "content": "<bpt id=\"p45\">**</bpt><bpt id=\"p46\">[</bpt>YARN<ept id=\"p46\">](#yarn)</ept><ept id=\"p45\">**</ept>: Part of the Hadoop core library and next generation of the MapReduce software framework."
    },
    {
      "pos": [
        6903,
        6981
      ],
      "content": "<bpt id=\"p47\">**</bpt><bpt id=\"p48\">[</bpt>ZooKeeper<ept id=\"p48\">](#zookeeper)</ept><ept id=\"p47\">**</ept>: Coordination of processes in distributed systems."
    },
    {
      "pos": [
        6985,
        7158
      ],
      "content": "<ph id=\"ph15\">[AZURE.NOTE]</ph><ph id=\"ph16\"/> For information on the specific components and version information, see <bpt id=\"p49\">[</bpt>What's new in the Hadoop cluster versions provided by HDInsight?<ept id=\"p49\">][component-versioning]</ept>"
    },
    {
      "pos": [
        7185,
        7191
      ],
      "content": "Ambari"
    },
    {
      "pos": [
        7193,
        7645
      ],
      "content": "Apache Ambari is for provisioning, managing and monitoring Apache Hadoop clusters. It includes an intuitive collection of operator tools and a robust set of APIs that hide the complexity of Hadoop, simplifying the operation of clusters. Linux-based HDInsight clusters provide both the Ambari web UI and the Ambari REST API, while Windows-based clusters provide a subset of the REST API. Ambari Views on HDInsight clusters allow plug-in UI capabilities.",
      "nodes": [
        {
          "content": "Apache Ambari is for provisioning, managing and monitoring Apache Hadoop clusters.",
          "pos": [
            0,
            82
          ]
        },
        {
          "content": "It includes an intuitive collection of operator tools and a robust set of APIs that hide the complexity of Hadoop, simplifying the operation of clusters.",
          "pos": [
            83,
            236
          ]
        },
        {
          "content": "Linux-based HDInsight clusters provide both the Ambari web UI and the Ambari REST API, while Windows-based clusters provide a subset of the REST API.",
          "pos": [
            237,
            386
          ]
        },
        {
          "content": "Ambari Views on HDInsight clusters allow plug-in UI capabilities.",
          "pos": [
            387,
            452
          ]
        }
      ]
    },
    {
      "pos": [
        7647,
        7980
      ],
      "content": "See <bpt id=\"p50\">[</bpt>Manage HDInsight clusters using Ambari<ept id=\"p50\">](hdinsight-hadoop-manage-ambari.md)</ept><ph id=\"ph17\"/> (Linux only), <bpt id=\"p51\">[</bpt>Monitor Hadoop clusters in HDInsight using the Ambari API<ept id=\"p51\">](hdinsight-monitor-use-ambari-api.md)</ept>, and <ph id=\"ph18\">&lt;a target=\"_blank\" href=\"https://github.com/apache/ambari/blob/trunk/ambari-server/docs/api/v1/index.md\"&gt;</ph>Apache Ambari API reference<ph id=\"ph19\">&lt;/a&gt;</ph>."
    },
    {
      "pos": [
        8005,
        8043
      ],
      "content": "Avro (Microsoft .NET Library for Avro)"
    },
    {
      "pos": [
        8045,
        8903
      ],
      "content": "The Microsoft .NET Library for Avro implements the Apache Avro compact binary data interchange format for serialization for the Microsoft .NET environment. It uses <ph id=\"ph20\">&lt;a target=\"_blank\" href=\"http://www.json.org/\"&gt;</ph>JavaScript Object Notation (JSON)<ph id=\"ph21\">&lt;/a&gt;</ph><ph id=\"ph22\"/> to define a language-agnostic schema that underwrites language interoperability, meaning data serialized in one language can be read in another. Detailed information on the format can be found in the &lt;a target=_\"blank\" href=\"http://avro.apache.org/docs/current/spec.html\"&gt;Apache Avro Specification<ph id=\"ph23\">&lt;/a&gt;</ph>.\nThe format of Avro files supports the distributed MapReduce programming model. Files are “splittable”, meaning you can seek any point in a file and start reading from a particular block. To find out how, see <bpt id=\"p52\">[</bpt>Serialize data with the Microsoft .NET Library for Avro<ept id=\"p52\">](hdinsight-dotnet-avro-serialization.md)</ept>.",
      "nodes": [
        {
          "content": "The Microsoft .NET Library for Avro implements the Apache Avro compact binary data interchange format for serialization for the Microsoft .NET environment.",
          "pos": [
            0,
            155
          ]
        },
        {
          "content": "It uses <ph id=\"ph20\">&lt;a target=\"_blank\" href=\"http://www.json.org/\"&gt;</ph>JavaScript Object Notation (JSON)<ph id=\"ph21\">&lt;/a&gt;</ph><ph id=\"ph22\"/> to define a language-agnostic schema that underwrites language interoperability, meaning data serialized in one language can be read in another. Detai",
          "pos": [
            156,
            464
          ]
        },
        {
          "content": "led information on the format can be found in the &lt;a target=_\"blank\" href=\"http://avro.apache.org/docs/current/spec.html\"&gt;Apache Avro Specification<ph id=\"ph23\">&lt;/a&gt;</ph>.",
          "pos": [
            464,
            647
          ]
        },
        {
          "content": "The format of Avro files supports the distributed MapReduce programming model.",
          "pos": [
            648,
            726
          ]
        },
        {
          "content": "Files are “splittable”, meaning you can seek any point in a file and start reading from a particular block.",
          "pos": [
            727,
            834
          ]
        },
        {
          "content": "To find out how, see <bpt id=\"p52\">[</bpt>Serialize data with the Microsoft .NET Library for Avro<ept id=\"p52\">](hdinsight-dotnet-avro-serialization.md)</ept>.",
          "pos": [
            835,
            994
          ]
        }
      ]
    },
    {
      "pos": [
        8929,
        8933
      ],
      "content": "HDFS"
    },
    {
      "pos": [
        8935,
        9136
      ],
      "content": "Hadoop Distributed File System (HDFS) is a distributed file system that, with MapReduce and YARN, is the core of the Hadoop ecosystem. HDFS is the standard file system for Hadoop clusters on HDInsight.",
      "nodes": [
        {
          "content": "Hadoop Distributed File System (HDFS) is a distributed file system that, with MapReduce and YARN, is the core of the Hadoop ecosystem.",
          "pos": [
            0,
            134
          ]
        },
        {
          "content": "HDFS is the standard file system for Hadoop clusters on HDInsight.",
          "pos": [
            135,
            201
          ]
        }
      ]
    },
    {
      "pos": [
        9161,
        9176
      ],
      "content": "Hive &amp; HCatalog"
    },
    {
      "pos": [
        9178,
        9784
      ],
      "content": "<ph id=\"ph24\">&lt;a target=\"_blank\" href=\"http://hive.apache.org/\"&gt;</ph>Apache Hive<ph id=\"ph25\">&lt;/a&gt;</ph><ph id=\"ph26\"/> is data warehouse software built on Hadoop that allows you to query and manage large datasets in distributed storage by using a SQL-like language called HiveQL. Hive, like Pig, is an abstraction on top of MapReduce. When run, Hive translates queries into a series of MapReduce jobs. Hive is conceptually closer to a relational database management system than Pig, and is therefore appropriate for use with more structured data. For unstructured data, Pig is the better choice. See <bpt id=\"p53\">[</bpt>Use Hive with Hadoop in HDInsight<ept id=\"p53\">](hdinsight-use-hive.md)</ept>.",
      "nodes": [
        {
          "content": "<ph id=\"ph24\">&lt;a target=\"_blank\" href=\"http://hive.apache.org/\"&gt;</ph>Apache Hive<ph id=\"ph25\">&lt;/a&gt;</ph><ph id=\"ph26\"/> is data warehouse software built on Hadoop that allows you to query and manage large datasets in distributed storage by using a SQL-like language called HiveQL.",
          "pos": [
            0,
            291
          ]
        },
        {
          "content": "Hive, like Pig, is an abstraction on top of MapReduce.",
          "pos": [
            292,
            346
          ]
        },
        {
          "content": "When run, Hive translates queries into a series of MapReduce jobs.",
          "pos": [
            347,
            413
          ]
        },
        {
          "content": "Hive is conceptually closer to a relational database management system than Pig, and is therefore appropriate for use with more structured data.",
          "pos": [
            414,
            558
          ]
        },
        {
          "content": "For unstructured data, Pig is the better choice.",
          "pos": [
            559,
            607
          ]
        },
        {
          "content": "See <bpt id=\"p53\">[</bpt>Use Hive with Hadoop in HDInsight<ept id=\"p53\">](hdinsight-use-hive.md)</ept>.",
          "pos": [
            608,
            711
          ]
        }
      ]
    },
    {
      "pos": [
        9871,
        9886
      ],
      "content": "Apache HCatalog"
    },
    {
      "pos": [
        9891,
        10114
      ],
      "content": "is a table and storage management layer for Hadoop that presents users with a relational view of data. In HCatalog, you can read and write files in any format for which a Hive SerDe (serializer-deserializer) can be written.",
      "nodes": [
        {
          "content": "is a table and storage management layer for Hadoop that presents users with a relational view of data.",
          "pos": [
            0,
            102
          ]
        },
        {
          "content": "In HCatalog, you can read and write files in any format for which a Hive SerDe (serializer-deserializer) can be written.",
          "pos": [
            103,
            223
          ]
        }
      ]
    },
    {
      "pos": [
        10141,
        10147
      ],
      "content": "Mahout"
    },
    {
      "pos": [
        10149,
        10524
      ],
      "content": "<ph id=\"ph27\">&lt;a target=\"_blank\" href=\"https://mahout.apache.org/\"&gt;</ph>Apache Mahout<ph id=\"ph28\">&lt;/a&gt;</ph><ph id=\"ph29\"/> is a scalable library of machine learning algorithms that run on Hadoop. Using principles of statistics, machine learning applications teach systems to learn from data and to use past outcomes to determine future behavior. See <bpt id=\"p54\">[</bpt>Generate movie recommendations using Mahout on Hadoop<ept id=\"p54\">](hdinsight-mahout.md)</ept>.",
      "nodes": [
        {
          "content": "<ph id=\"ph27\">&lt;a target=\"_blank\" href=\"https://mahout.apache.org/\"&gt;</ph>Apache Mahout<ph id=\"ph28\">&lt;/a&gt;</ph><ph id=\"ph29\"/> is a scalable library of machine learning algorithms that run on Hadoop.",
          "pos": [
            0,
            208
          ]
        },
        {
          "content": "Using principles of statistics, machine learning applications teach systems to learn from data and to use past outcomes to determine future behavior.",
          "pos": [
            209,
            358
          ]
        },
        {
          "content": "See <bpt id=\"p54\">[</bpt>Generate movie recommendations using Mahout on Hadoop<ept id=\"p54\">](hdinsight-mahout.md)</ept>.",
          "pos": [
            359,
            480
          ]
        }
      ]
    },
    {
      "pos": [
        10554,
        10563
      ],
      "content": "MapReduce"
    },
    {
      "pos": [
        10564,
        10784
      ],
      "content": "MapReduce is the legacy software framework for Hadoop for writing applications to batch process big data sets in parallel. A MapReduce job splits large datasets and organizes the data into key-value pairs for processing.",
      "nodes": [
        {
          "content": "MapReduce is the legacy software framework for Hadoop for writing applications to batch process big data sets in parallel.",
          "pos": [
            0,
            122
          ]
        },
        {
          "content": "A MapReduce job splits large datasets and organizes the data into key-value pairs for processing.",
          "pos": [
            123,
            220
          ]
        }
      ]
    },
    {
      "pos": [
        10786,
        10943
      ],
      "content": "<bpt id=\"p55\">[</bpt>YARN<ept id=\"p55\">](#yarn)</ept><ph id=\"ph30\"/> is the Hadoop next-generation resource manager and application framework, and is referred to as MapReduce 2.0. MapReduce jobs will run on YARN.",
      "nodes": [
        {
          "content": "<bpt id=\"p55\">[</bpt>YARN<ept id=\"p55\">](#yarn)</ept><ph id=\"ph30\"/> is the Hadoop next-generation resource manager and application framework, and is referred to as MapReduce 2.0.",
          "pos": [
            0,
            179
          ]
        },
        {
          "content": "MapReduce jobs will run on YARN.",
          "pos": [
            180,
            212
          ]
        }
      ]
    },
    {
      "pos": [
        10945,
        10983
      ],
      "content": "For more information on MapReduce, see"
    },
    {
      "pos": [
        11050,
        11059
      ],
      "content": "MapReduce"
    },
    {
      "pos": [
        11064,
        11083
      ],
      "content": "in the Hadoop Wiki."
    },
    {
      "pos": [
        11109,
        11114
      ],
      "content": "Oozie"
    },
    {
      "pos": [
        11115,
        11534
      ],
      "content": "<ph id=\"ph31\">&lt;a target=\"_blank\" href=\"http://oozie.apache.org/\"&gt;</ph>Apache Oozie<ph id=\"ph32\">&lt;/a&gt;</ph><ph id=\"ph33\"/> is a workflow coordination system that manages Hadoop jobs. It is integrated with the Hadoop stack and supports Hadoop jobs for MapReduce, Pig, Hive, and Sqoop. It can also be used to schedule jobs specific to a system, like Java programs or shell scripts. See <bpt id=\"p56\">[</bpt>Use a time-based Oozie Coordinator with Hadoop<ept id=\"p56\">](hdinsight-use-oozie-coordinator-time.md)</ept>.",
      "nodes": [
        {
          "content": "<ph id=\"ph31\">&lt;a target=\"_blank\" href=\"http://oozie.apache.org/\"&gt;</ph>Apache Oozie<ph id=\"ph32\">&lt;/a&gt;</ph><ph id=\"ph33\"/> is a workflow coordination system that manages Hadoop jobs.",
          "pos": [
            0,
            192
          ]
        },
        {
          "content": "It is integrated with the Hadoop stack and supports Hadoop jobs for MapReduce, Pig, Hive, and Sqoop.",
          "pos": [
            193,
            293
          ]
        },
        {
          "content": "It can also be used to schedule jobs specific to a system, like Java programs or shell scripts.",
          "pos": [
            294,
            389
          ]
        },
        {
          "content": "See <bpt id=\"p56\">[</bpt>Use a time-based Oozie Coordinator with Hadoop<ept id=\"p56\">](hdinsight-use-oozie-coordinator-time.md)</ept>.",
          "pos": [
            390,
            524
          ]
        }
      ]
    },
    {
      "pos": [
        11562,
        11569
      ],
      "content": "Phoenix"
    },
    {
      "pos": [
        11570,
        12036
      ],
      "content": "<ph id=\"ph34\">&lt;a  target=\"_blank\" href=\"http://phoenix.apache.org/\"&gt;</ph>Apache Phoenix<ph id=\"ph35\">&lt;/a&gt;</ph><ph id=\"ph36\"/> is a relational database layer over HBase. Phoenix includes a JDBC driver that allows users to query and manage SQL tables directly. Phoenix translates queries and other statements into native NoSQL API calls - instead of using MapReduce - thus enabling faster applications on top of NoSQL stores. See <bpt id=\"p57\">[</bpt>Use Apache Phoenix and SQuirreL with HBase clusters<ept id=\"p57\">](hdinsight-hbase-phoenix-squirrel.md)</ept>.",
      "nodes": [
        {
          "content": "<ph id=\"ph34\">&lt;a  target=\"_blank\" href=\"http://phoenix.apache.org/\"&gt;</ph>Apache Phoenix<ph id=\"ph35\">&lt;/a&gt;</ph><ph id=\"ph36\"/> is a relational database layer over HBase.",
          "pos": [
            0,
            180
          ]
        },
        {
          "content": "Phoenix includes a JDBC driver that allows users to query and manage SQL tables directly.",
          "pos": [
            181,
            270
          ]
        },
        {
          "content": "Phoenix translates queries and other statements into native NoSQL API calls - instead of using MapReduce - thus enabling faster applications on top of NoSQL stores.",
          "pos": [
            271,
            435
          ]
        },
        {
          "content": "See <bpt id=\"p57\">[</bpt>Use Apache Phoenix and SQuirreL with HBase clusters<ept id=\"p57\">](hdinsight-hbase-phoenix-squirrel.md)</ept>.",
          "pos": [
            436,
            571
          ]
        }
      ]
    },
    {
      "pos": [
        12061,
        12064
      ],
      "content": "Pig"
    },
    {
      "pos": [
        12065,
        12505
      ],
      "content": "<ph id=\"ph37\">&lt;a  target=\"_blank\" href=\"http://pig.apache.org/\"&gt;</ph>Apache Pig<ph id=\"ph38\">&lt;/a&gt;</ph><ph id=\"ph39\"/> is a high-level platform that allows you to perform complex MapReduce transformations on very large datasets by using a simple scripting language called Pig Latin. Pig translates the Pig Latin scripts so they’ll run within Hadoop. You can create User Defined Functions (UDFs) to extend Pig Latin. See <bpt id=\"p58\">[</bpt>Use Pig with Hadoop to analyze an Apache log file<ept id=\"p58\">](hdinsight-use-pig.md)</ept>.",
      "nodes": [
        {
          "content": "<ph id=\"ph37\">&lt;a  target=\"_blank\" href=\"http://pig.apache.org/\"&gt;</ph>Apache Pig<ph id=\"ph38\">&lt;/a&gt;</ph><ph id=\"ph39\"/> is a high-level platform that allows you to perform complex MapReduce transformations on very large datasets by using a simple scripting language called Pig Latin.",
          "pos": [
            0,
            293
          ]
        },
        {
          "content": "Pig translates the Pig Latin scripts so they’ll run within Hadoop.",
          "pos": [
            294,
            360
          ]
        },
        {
          "content": "You can create User Defined Functions (UDFs) to extend Pig Latin.",
          "pos": [
            361,
            426
          ]
        },
        {
          "content": "See <bpt id=\"p58\">[</bpt>Use Pig with Hadoop to analyze an Apache log file<ept id=\"p58\">](hdinsight-use-pig.md)</ept>.",
          "pos": [
            427,
            545
          ]
        }
      ]
    },
    {
      "pos": [
        12531,
        12536
      ],
      "content": "Sqoop"
    },
    {
      "pos": [
        12537,
        12804
      ],
      "content": "<ph id=\"ph40\">&lt;a  target=\"_blank\" href=\"http://sqoop.apache.org/\"&gt;</ph>Apache Sqoop<ph id=\"ph41\">&lt;/a&gt;</ph><ph id=\"ph42\"/> is tool that transfers bulk data between Hadoop and relational databases such a SQL, or other structured data stores, as efficiently as possible. See <bpt id=\"p59\">[</bpt>Use Sqoop with Hadoop<ept id=\"p59\">](hdinsight-use-sqoop.md)</ept>.",
      "nodes": [
        {
          "content": "<ph id=\"ph40\">&lt;a  target=\"_blank\" href=\"http://sqoop.apache.org/\"&gt;</ph>Apache Sqoop<ph id=\"ph41\">&lt;/a&gt;</ph><ph id=\"ph42\"/> is tool that transfers bulk data between Hadoop and relational databases such a SQL, or other structured data stores, as efficiently as possible.",
          "pos": [
            0,
            279
          ]
        },
        {
          "content": "See <bpt id=\"p59\">[</bpt>Use Sqoop with Hadoop<ept id=\"p59\">](hdinsight-use-sqoop.md)</ept>.",
          "pos": [
            280,
            372
          ]
        }
      ]
    },
    {
      "pos": [
        12828,
        12831
      ],
      "content": "Tez"
    },
    {
      "pos": [
        12832,
        13270
      ],
      "content": "<ph id=\"ph43\">&lt;a  target=\"_blank\" href=\"http://tez.apache.org/\"&gt;</ph>Apache Tez<ph id=\"ph44\">&lt;/a&gt;</ph><ph id=\"ph45\"/> is an application framework built on Hadoop YARN that executes complex, acyclic graphs of general data processing. It's a more flexible and powerful successor to the MapReduce framework that allows data-intensive processes, such as Hive, to run more efficiently at scale. See <bpt id=\"p60\">[</bpt>\"Use Apache Tez for improved performance\" in Use Hive and HiveQL<ept id=\"p60\">](hdinsight-use-hive.md#usetez)</ept>.",
      "nodes": [
        {
          "content": "<ph id=\"ph43\">&lt;a  target=\"_blank\" href=\"http://tez.apache.org/\"&gt;</ph>Apache Tez<ph id=\"ph44\">&lt;/a&gt;</ph><ph id=\"ph45\"/> is an application framework built on Hadoop YARN that executes complex, acyclic graphs of general data processing.",
          "pos": [
            0,
            244
          ]
        },
        {
          "content": "It's a more flexible and powerful successor to the MapReduce framework that allows data-intensive processes, such as Hive, to run more efficiently at scale.",
          "pos": [
            245,
            401
          ]
        },
        {
          "content": "See <bpt id=\"p60\">[</bpt>\"Use Apache Tez for improved performance\" in Use Hive and HiveQL<ept id=\"p60\">](hdinsight-use-hive.md#usetez)</ept>.",
          "pos": [
            402,
            543
          ]
        }
      ]
    },
    {
      "pos": [
        13295,
        13299
      ],
      "content": "YARN"
    },
    {
      "pos": [
        13300,
        13604
      ],
      "content": "Apache YARN is the next generation of MapReduce (MapReduce 2.0, or MRv2) and supports data processing scenarios beyond MapReduce batch processing with greater scalability and real-time processing. YARN provides resource management and a distributed application framework. MapReduce jobs will run on YARN.",
      "nodes": [
        {
          "content": "Apache YARN is the next generation of MapReduce (MapReduce 2.0, or MRv2) and supports data processing scenarios beyond MapReduce batch processing with greater scalability and real-time processing.",
          "pos": [
            0,
            196
          ]
        },
        {
          "content": "YARN provides resource management and a distributed application framework.",
          "pos": [
            197,
            271
          ]
        },
        {
          "content": "MapReduce jobs will run on YARN.",
          "pos": [
            272,
            304
          ]
        }
      ]
    },
    {
      "pos": [
        13606,
        13630
      ],
      "content": "To learn about YARN, see"
    },
    {
      "pos": [
        13734,
        13772
      ],
      "content": "Apache Hadoop NextGen MapReduce (YARN)"
    },
    {
      "pos": [
        13776,
        13777
      ],
      "content": "."
    },
    {
      "pos": [
        13808,
        13817
      ],
      "content": "ZooKeeper"
    },
    {
      "pos": [
        13874,
        13890
      ],
      "content": "Apache ZooKeeper"
    },
    {
      "pos": [
        13895,
        14142
      ],
      "content": "coordinates processes in large distributed systems by means of a shared hierarchical namespace of data registers (znodes). Znodes contain small amounts of meta information needed to coordinate processes: status, location, configuration, and so on.",
      "nodes": [
        {
          "content": "coordinates processes in large distributed systems by means of a shared hierarchical namespace of data registers (znodes).",
          "pos": [
            0,
            122
          ]
        },
        {
          "content": "Znodes contain small amounts of meta information needed to coordinate processes: status, location, configuration, and so on.",
          "pos": [
            123,
            247
          ]
        }
      ]
    },
    {
      "pos": [
        14147,
        14181
      ],
      "content": "Programming languages on HDInsight"
    },
    {
      "pos": [
        14183,
        14523
      ],
      "content": "HDInsight clusters--Hadoop, HBase, Storm, and Spark clusters--support a number of programming languages, but some aren't installed by default. For libraries, modules, or packages not installed by default, use a script action to install the component. See <bpt id=\"p61\">[</bpt>Script action development with HDInsight<ept id=\"p61\">](hdinsight-hadoop-script-actions-linux.md)</ept>.",
      "nodes": [
        {
          "content": "HDInsight clusters--Hadoop, HBase, Storm, and Spark clusters--support a number of programming languages, but some aren't installed by default.",
          "pos": [
            0,
            142
          ]
        },
        {
          "content": "For libraries, modules, or packages not installed by default, use a script action to install the component.",
          "pos": [
            143,
            250
          ]
        },
        {
          "content": "See <bpt id=\"p61\">[</bpt>Script action development with HDInsight<ept id=\"p61\">](hdinsight-hadoop-script-actions-linux.md)</ept>.",
          "pos": [
            251,
            380
          ]
        }
      ]
    },
    {
      "pos": [
        14529,
        14565
      ],
      "content": "Default programming language support"
    },
    {
      "pos": [
        14567,
        14606
      ],
      "content": "By default, HDInsight clusters support:"
    },
    {
      "pos": [
        14610,
        14614
      ],
      "content": "Java"
    },
    {
      "pos": [
        14618,
        14624
      ],
      "content": "Python"
    },
    {
      "pos": [
        14626,
        14771
      ],
      "content": "Additional languages can be installed using script actions: <bpt id=\"p62\">[</bpt>Script action development with HDInsight<ept id=\"p62\">](hdinsight-hadoop-script-actions-linux.md)</ept>."
    },
    {
      "pos": [
        14777,
        14813
      ],
      "content": "Java virtual machine (JVM) languages"
    },
    {
      "pos": [
        14815,
        14993
      ],
      "content": "Many languages other than Java can be run using a Java virtual machine (JVM); however, running some of these languages may require additional components installed on the cluster."
    },
    {
      "pos": [
        14995,
        15057
      ],
      "content": "These JVM-based languages are supported on HDInsight clusters:"
    },
    {
      "pos": [
        15061,
        15068
      ],
      "content": "Clojure"
    },
    {
      "pos": [
        15072,
        15096
      ],
      "content": "Jython (Python for Java)"
    },
    {
      "pos": [
        15100,
        15105
      ],
      "content": "Scala"
    },
    {
      "pos": [
        15111,
        15136
      ],
      "content": "Hadoop-specific languages"
    },
    {
      "pos": [
        15138,
        15243
      ],
      "content": "HDInsight clusters provide support for the following languages that are specific to the Hadoop ecosystem:"
    },
    {
      "pos": [
        15247,
        15269
      ],
      "content": "Pig Latin for Pig jobs"
    },
    {
      "pos": [
        15273,
        15306
      ],
      "content": "HiveQL for Hive jobs and SparkSQL"
    },
    {
      "pos": [
        15336,
        15369
      ],
      "content": "Advantages of Hadoop in the cloud"
    },
    {
      "pos": [
        15371,
        15469
      ],
      "content": "As part of the Azure cloud ecosystem, Hadoop in HDInsight offers a number of benefits, among them:"
    },
    {
      "pos": [
        15473,
        15708
      ],
      "content": "Automatic provisioning of Hadoop clusters. HDInsight clusters are much easier to create than manually configuring Hadoop clusters. For details, see <bpt id=\"p63\">[</bpt>Provision Hadoop clusters in HDInsight<ept id=\"p63\">](hdinsight-hadoop-provision-linux-clusters.md)</ept>.",
      "nodes": [
        {
          "content": "Automatic provisioning of Hadoop clusters.",
          "pos": [
            0,
            42
          ]
        },
        {
          "content": "HDInsight clusters are much easier to create than manually configuring Hadoop clusters.",
          "pos": [
            43,
            130
          ]
        },
        {
          "content": "For details, see <bpt id=\"p63\">[</bpt>Provision Hadoop clusters in HDInsight<ept id=\"p63\">](hdinsight-hadoop-provision-linux-clusters.md)</ept>.",
          "pos": [
            131,
            275
          ]
        }
      ]
    },
    {
      "pos": [
        15712,
        15854
      ],
      "content": "State-of-the-art Hadoop components. For details, see <bpt id=\"p64\">[</bpt>What's new in the Hadoop cluster versions provided by HDInsight?<ept id=\"p64\">][component-versioning]</ept>.",
      "nodes": [
        {
          "content": "State-of-the-art Hadoop components.",
          "pos": [
            0,
            35
          ]
        },
        {
          "content": "For details, see <bpt id=\"p64\">[</bpt>What's new in the Hadoop cluster versions provided by HDInsight?<ept id=\"p64\">][component-versioning]</ept>.",
          "pos": [
            36,
            182
          ]
        }
      ]
    },
    {
      "pos": [
        15858,
        16022
      ],
      "content": "High availability and reliability of clusters. See <bpt id=\"p65\">[</bpt>Availability and reliability of Hadoop clusters in HDInsight<ept id=\"p65\">](hdinsight-high-availability-linux.md)</ept><ph id=\"ph46\"/> for details.",
      "nodes": [
        {
          "content": "High availability and reliability of clusters.",
          "pos": [
            0,
            46
          ]
        },
        {
          "content": "See <bpt id=\"p65\">[</bpt>Availability and reliability of Hadoop clusters in HDInsight<ept id=\"p65\">](hdinsight-high-availability-linux.md)</ept><ph id=\"ph46\"/> for details.",
          "pos": [
            47,
            219
          ]
        }
      ]
    },
    {
      "pos": [
        16026,
        16221
      ],
      "content": "Efficient and economical data storage with Azure Blob storage, a Hadoop-compatible option. See <bpt id=\"p66\">[</bpt>Use Azure Blob storage with Hadoop in HDInsight<ept id=\"p66\">](hdinsight-hadoop-use-blob-storage.md)</ept><ph id=\"ph47\"/> for details.",
      "nodes": [
        {
          "content": "Efficient and economical data storage with Azure Blob storage, a Hadoop-compatible option.",
          "pos": [
            0,
            90
          ]
        },
        {
          "content": "See <bpt id=\"p66\">[</bpt>Use Azure Blob storage with Hadoop in HDInsight<ept id=\"p66\">](hdinsight-hadoop-use-blob-storage.md)</ept><ph id=\"ph47\"/> for details.",
          "pos": [
            91,
            250
          ]
        }
      ]
    },
    {
      "pos": [
        16225,
        16389
      ],
      "content": "Integration with other Azure services, including <bpt id=\"p67\">[</bpt>Web apps<ept id=\"p67\">](../documentation/services/app-service/web/)</ept><ph id=\"ph48\"/> and <bpt id=\"p68\">[</bpt>SQL Database<ept id=\"p68\">](../documentation/services/sql-database/)</ept>."
    },
    {
      "pos": [
        16393,
        16521
      ],
      "content": "Low entry cost. Start a <bpt id=\"p69\">[</bpt>free trial<ept id=\"p69\">](/pricing/free-trial/)</ept>, or consult <bpt id=\"p70\">[</bpt>HDInsight pricing details<ept id=\"p70\">](/pricing/details/hdinsight/)</ept>.",
      "nodes": [
        {
          "content": "Low entry cost.",
          "pos": [
            0,
            15
          ]
        },
        {
          "content": "Start a <bpt id=\"p69\">[</bpt>free trial<ept id=\"p69\">](/pricing/free-trial/)</ept>, or consult <bpt id=\"p70\">[</bpt>HDInsight pricing details<ept id=\"p70\">](/pricing/details/hdinsight/)</ept>.",
          "pos": [
            16,
            208
          ]
        }
      ]
    },
    {
      "pos": [
        16524,
        16643
      ],
      "content": "To read more about the advantages on Hadoop in HDInsight, see the  <bpt id=\"p71\">[</bpt>Azure features page for HDInsight<ept id=\"p71\">][marketing-page]</ept>."
    },
    {
      "pos": [
        16672,
        16746
      ],
      "content": "Resources for learning more about big-data analysis, Hadoop, and HDInsight"
    },
    {
      "pos": [
        16748,
        16845
      ],
      "content": "Build on this introduction to Hadoop in the cloud and big data analysis with the resources below."
    },
    {
      "pos": [
        16852,
        16886
      ],
      "content": "Hadoop documentation for HDInsight"
    },
    {
      "pos": [
        16890,
        17074
      ],
      "content": "<bpt id=\"p72\">[</bpt>HDInsight documentation<ept id=\"p72\">](https://azure.microsoft.com/documentation/services/hdinsight/)</ept>: The documentation page for Azure HDInsight with links to articles, videos, and more resources."
    },
    {
      "pos": [
        17078,
        17272
      ],
      "content": "<bpt id=\"p73\">[</bpt>Get started with HDInsight on Linux<ept id=\"p73\">](hdinsight-hadoop-linux-tutorial-get-started.md)</ept>: A quick-start tutorial for provisioning HDInsight Hadoop clusters on Linux and running sample Hive queries."
    },
    {
      "pos": [
        17276,
        17486
      ],
      "content": "<bpt id=\"p74\">[</bpt>Get started with Linux-based Storm on HDInsight<ept id=\"p74\">](hdinsight-apache-storm-tutorial-get-started-linux.md)</ept>: A quick-start tutorial for provisioning a Storm on HDInsight cluster and running sample Storm topologies."
    },
    {
      "pos": [
        17490,
        17685
      ],
      "content": "<bpt id=\"p75\">[</bpt>Provision HDInsight on Linux<ept id=\"p75\">](hdinsight-hadoop-provision-linux-clusters.md)</ept>: Learn how to provision an HDInsight Hadoop cluster on Linux through the Azure Portal, Azure CLI, or Azure PowerShell."
    },
    {
      "pos": [
        17689,
        17842
      ],
      "content": "<bpt id=\"p76\">[</bpt>Working with HDInsight on Linux<ept id=\"p76\">](hdinsight-hadoop-linux-information.md)</ept>: Get some quick tips on working with Hadoop Linux clusters provisioned on Azure."
    },
    {
      "pos": [
        17846,
        18044
      ],
      "content": "<bpt id=\"p77\">[</bpt>Manage HDInsight clusters using Ambari<ept id=\"p77\">](hdinsight-hadoop-manage-ambari.md)</ept>: Learn how to monitor and manage your Linux-based Hadoop on HDInsight cluster by using Ambari Web, or the Ambari REST API."
    },
    {
      "pos": [
        18051,
        18064
      ],
      "content": "Apache Hadoop"
    },
    {
      "pos": [
        18068,
        18294
      ],
      "content": "<ph id=\"ph49\">&lt;a target=\"_blank\" href=\"http://hadoop.apache.org/\"&gt;</ph>Apache Hadoop<ph id=\"ph50\">&lt;/a&gt;</ph>: Learn more about the Apache Hadoop software library, a framework that allows for the distributed processing of large datasets across clusters of computers."
    },
    {
      "pos": [
        18298,
        18527
      ],
      "content": "<ph id=\"ph51\">&lt;a target=\"_blank\" href=\"http://hadoop.apache.org/docs/r1.0.4/hdfs_design.html\"&gt;</ph>HDFS<ph id=\"ph52\">&lt;/a&gt;</ph>: Learn more about the architecture and design of the Hadoop Distributed File System, the primary storage system used by Hadoop applications."
    },
    {
      "pos": [
        18531,
        18804
      ],
      "content": "<ph id=\"ph53\">&lt;a target=\"_blank\" href=\"http://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html\"&gt;</ph>MapReduce Tutorial<ph id=\"ph54\">&lt;/a&gt;</ph>: Learn more about the programming framework for writing Hadoop applications that rapidly process large amounts of data in parallel on large clusters of compute nodes."
    },
    {
      "pos": [
        18810,
        18831
      ],
      "content": "SQL Database on Azure"
    },
    {
      "pos": [
        18835,
        18950
      ],
      "content": "<bpt id=\"p78\">[</bpt>Azure SQL Database<ept id=\"p78\">](/documentation/services/sql-database/)</ept>: Documentation, tutorials, and videos for SQL Database."
    },
    {
      "pos": [
        18954,
        19115
      ],
      "content": "<bpt id=\"p79\">[</bpt>SQL Database on the Azure Portal<ept id=\"p79\">](sql-database-manage-portal.md)</ept>: A lightweight and easy-to-use database management tool for managing SQL Database in the cloud."
    },
    {
      "pos": [
        19119,
        19263
      ],
      "content": "<bpt id=\"p80\">[</bpt>Adventure Works for SQL Database<ept id=\"p80\">](http://msftdbprodsamples.codeplex.com/releases/view/37304)</ept>: Download page for a SQL Database sample database."
    },
    {
      "pos": [
        19269,
        19327
      ],
      "content": "Microsoft business intelligence (for HDInsight on Windows)"
    },
    {
      "pos": [
        19329,
        19600
      ],
      "content": "Familiar business intelligence (BI) tools - such as Excel, PowerPivot, SQL Server Analysis Services, and SQL Server Reporting Services - retrieve, analyze, and report data integrated with HDInsight by using either the Power Query add-in or the Microsoft Hive ODBC Driver."
    },
    {
      "pos": [
        19602,
        19652
      ],
      "content": "These BI tools can help in your big-data analysis:"
    },
    {
      "pos": [
        19656,
        19897
      ],
      "content": "<bpt id=\"p81\">[</bpt>Connect Excel to Hadoop with Power Query<ept id=\"p81\">](hdinsight-connect-excel-power-query.md)</ept>: Learn how to connect Excel to the Azure Storage account that stores the data associated with your HDInsight cluster by using Microsoft Power Query for Excel."
    },
    {
      "pos": [
        19901,
        20085
      ],
      "content": "<bpt id=\"p82\">[</bpt>Connect Excel to Hadoop with the Microsoft Hive ODBC Driver<ept id=\"p82\">](hdinsight-connect-excel-hive-ODBC-driver.md)</ept>: Learn how to import data from HDInsight with the Microsoft Hive ODBC Driver."
    },
    {
      "pos": [
        20089,
        20321
      ],
      "content": "<bpt id=\"p83\">[</bpt>Microsoft Cloud Platform<ept id=\"p83\">](http://www.microsoft.com/server-cloud/solutions/business-intelligence/default.aspx)</ept>: Learn about Power BI for Office 365, download the SQL Server trial, and set up SharePoint Server 2013 and SQL Server BI."
    },
    {
      "pos": [
        20325,
        20449
      ],
      "content": "<ph id=\"ph55\">&lt;a target=\"_blank\" href=\"http://msdn.microsoft.com/library/hh231701.aspx\"&gt;</ph>Learn more about SQL Server Analysis Services<ph id=\"ph56\">&lt;/a&gt;</ph>."
    },
    {
      "pos": [
        20453,
        20573
      ],
      "content": "<ph id=\"ph57\">&lt;a target=\"_blank\" href=\"http://msdn.microsoft.com/library/ms159106.aspx\"&gt;</ph>Learn about SQL Server Reporting Services<ph id=\"ph58\">&lt;/a&gt;</ph>."
    },
    {
      "pos": [
        20580,
        20649
      ],
      "content": "Try Hadoop solutions for big-data analysis (for HDInsight on Windows)"
    },
    {
      "pos": [
        20651,
        20761
      ],
      "content": "Use big data analysis on your organization's data to gain insights into your business. Here are some examples:",
      "nodes": [
        {
          "content": "Use big data analysis on your organization's data to gain insights into your business.",
          "pos": [
            0,
            86
          ]
        },
        {
          "content": "Here are some examples:",
          "pos": [
            87,
            110
          ]
        }
      ]
    },
    {
      "pos": [
        20765,
        21099
      ],
      "content": "<bpt id=\"p84\">[</bpt>Analyze HVAC sensor data<ept id=\"p84\">](hdinsight-hive-analyze-sensor-data.md)</ept>: Learn how to analyze sensor data by using Hive with HDInsight (Hadoop), and then visualize the data in Microsoft Excel. In this sample, you'll use Hive to process historical data produced by HVAC systems to see which systems can't reliably maintain a set temperature.",
      "nodes": [
        {
          "content": "<bpt id=\"p84\">[</bpt>Analyze HVAC sensor data<ept id=\"p84\">](hdinsight-hive-analyze-sensor-data.md)</ept>: Learn how to analyze sensor data by using Hive with HDInsight (Hadoop), and then visualize the data in Microsoft Excel.",
          "pos": [
            0,
            226
          ]
        },
        {
          "content": "In this sample, you'll use Hive to process historical data produced by HVAC systems to see which systems can't reliably maintain a set temperature.",
          "pos": [
            227,
            374
          ]
        }
      ]
    },
    {
      "pos": [
        21103,
        21389
      ],
      "content": "<bpt id=\"p85\">[</bpt>Use Hive with HDInsight to analyze website logs<ept id=\"p85\">](hdinsight-hive-analyze-website-log.md)</ept>: Learn how to use HiveQL in HDInsight to analyze website logs to get insight into the frequency of visits in a day from external websites, and a summary of website errors that the users experience."
    },
    {
      "pos": [
        21393,
        21727
      ],
      "content": "<bpt id=\"p86\">[</bpt>Analyze sensor data in real-time with Storm and HBase in HDInsight (Hadoop)<ept id=\"p86\">](hdinsight-storm-sensor-data-analysis.md)</ept>: Learn how to build a solution that uses a Storm cluster in HDInsight to process sensor data from Azure Event Hubs, and then displays the processed sensor data as near-real-time information on a web-based dashboard."
    }
  ],
  "content": "<properties\n    pageTitle=\"What is Hadoop in the cloud? Introduction to HDInsight | Microsoft Azure\"\n    description=\"What is Hadoop in the cloud and how is it managed in HDInsight? An introduction to Hadoop components and big data analysis.\"\n    keywords=\"big data analysis,introduction to hadoop,what is hadoop,hadoop in the cloud\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    authors=\"cjgronlund\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\"/>\n\n<tags\n   ms.service=\"hdinsight\"\n   ms.devlang=\"na\"\n   ms.topic=\"article\"\n   ms.tgt_pltfrm=\"na\"\n   ms.workload=\"big-data\"\n   ms.date=\"01/27/2016\"\n   ms.author=\"cgronlun\"/>\n\n\n# What is Hadoop in the cloud? An introduction to Hadoop components in HDInsight for big data analysis\n\nGet an introduction to Hadoop, its ecosystem, and big data in Azure HDInsight: What is Hadoop in HDInsight and what are the Hadoop components, common terminology, and scenarios for big data analysis? Also, learn about Hadoop tutorials, documentation, and resources for using Hadoop the cloud in HDInsight.\n\n## What is Hadoop in the cloud in HDInsight?\n\nAzure HDInsight deploys and provisions managed Apache Hadoop clusters in the cloud, providing a software framework designed to process, analyze, and report on big data with high reliability and availability. HDInsight uses the **Hortonworks Data Platform (HDP)** Hadoop distribution. Hadoop often refers to the entire Hadoop ecosystem of components, which includes Apache HBase, Apache Spark, and Apache Storm, as well as other technologies under the Hadoop umbrella. See [Overview of the Hadoop ecosystem on HDInsight](#overview) below for details.\n\n\n## What is big data?\nBig data refers to data being collected in ever-escalating volumes, at increasingly higher velocities, and in an expanding variety of unstructured formats and variable semantic contexts.\n\nBig data describes any large body of digital information, from the text in a Twitter feed, to the sensor information from industrial equipment, to information about customer browsing and purchases on an online catalog. Big data can be historical (meaning stored data) or real-time (meaning streamed directly from the source).\n\nFor big data to provide actionable intelligence or insight, not only must you collect relevant data and ask the right questions, but also the data must be accessible, cleaned, analyzed, and then presented in a useful way. That's where big data analysis on Hadoop in HDInsight can help.\n\n\n## <a name=\"overview\"></a>Overview of the Hadoop ecosystem on HDInsight\n\nHDInsight is a cloud implementation on Microsoft Azure of the rapidly expanding Apache Hadoop technology stack that is the go-to solution for big data analysis. It includes implementations of Apache Spark, HBase, Storm, Pig, Hive, Sqoop, Oozie, Ambari, and so on. HDInsight also integrates with business intelligence (BI) tools such as Power BI, Excel, SQL Server Analysis Services, and SQL Server Reporting Services.\n\n### Clusters on Linux\n\nAzure HDInsight deploys and provisions Hadoop clusters in the cloud on **Linux**. See the table below for details.\n\nCategory | Hadoop on Linux\n---------| -------------------\n**Cluster OS** | Ubuntu 12.04 Long Term Support (LTS)\n**Cluster Type** | Hadoop, Spark, HBase, Storm\n**Deployment** | Azure portal, Azure CLI, Azure PowerShell\n**Cluster UI** | Ambari\n**Remote Access** | Secure Shell (SSH), REST API, ODBC, JDBC\n\n\n\n### Hadoop, HBase, Spark, Storm, and customized clusters\n\nHDInsight provides cluster configurations for Apache Hadoop, Spark, HBase, or Storm. Or, you can [customize clusters with script actions](hdinsight-hadoop-customize-cluster-linux.md).\n\n* **Hadoop** (the \"Query\" workload): Provides reliable data storage with [HDFS](#HDFS), and a simple [MapReduce](#mapreduce) programming model to process and analyze data in parallel.\n\n* **<a target=\"_blank\" href=\"http://spark.apache.org/\">Apache Spark</a>**: A parallel processing framework that supports in-memory processing to boost the performance of big-data analysis applications, Spark works for SQL, streaming data, and machine learning. See [Overview: What is Apache Spark in HDInsight?](hdinsight-apache-spark-overview.md)\n\n* **<a target=\"_blank\" href=\"http://hbase.apache.org/\">HBase</a>** (the \"NoSQL\" workload): A NoSQL database built on Hadoop that provides random access and strong consistency for large amounts of unstructured and semi-structured data - potentially billions of rows times millions of columns. See [Overview of HBase on HDInsight](hdinsight-hbase-overview.md).\n\n* **<a  target=\"_blank\" href=\"https://storm.incubator.apache.org/\">Apache Storm</a>** (the \"Stream\" workload): A distributed, real-time computation system for processing large streams of data fast. Storm is offered as a managed cluster in HDInsight. See [Analyze real-time sensor data using Storm and Hadoop](hdinsight-storm-sensor-data-analysis.md).\n\n#### Example customization scripts\n\nScript Actions are scripts that run during cluster provisioning, and can be used to install additional components on the cluster. For Linux-based clusters, these are Bash scripts.\n\nThe following example scripts are provided by the HDInsight team:\n\n* [Hue](hdinsight-hadoop-hue-linux.md): A set of web applications used to interact with a cluster. Linux clusters only.\n\n* [Giraph](hdinsight-hadoop-giraph-install-linux.md): Graph processing to model relationships between things or people.\n\n* [R](hdinsight-hadoop-r-scripts-linux.md): An open-source language and environment for statistical computing used in machine learning.\n\n* [Solr](hdinsight-hadoop-solr-install-linux.md): An enterprise-scale search platform that allows full-text search on data.\n\nFor information on developing your own Script Actions, see [Script Action development with HDInsight](hdinsight-hadoop-script-actions-linux.md).\n\n## What are the Hadoop components and utilties?\n\nThe following components and utilities are included on HDInsight clusters.\n\n* **[Ambari](#ambari)**: Cluster provisioning, management, monitoring, and utilities.\n\n* **[Avro](#avro)** (Microsoft .NET Library for Avro): Data serialization for the Microsoft .NET environment.\n\n* **[Hive & HCatalog](#hive)**: Structured Query Language (SQL)-like querying, and a table and storage management layer.\n\n* **[Mahout](#mahout)**: Machine learning.\n\n* **[MapReduce](#mapreduce)**: Legacy framework for Hadoop distributed processing and resource management. See [YARN](#yarn), the next-generation resource framework.\n\n* **[Oozie](#oozie)**: Workflow management.\n\n* **[Phoenix](#phoenix)**: Relational database layer over HBase.\n\n* **[Pig](#pig)**: Simpler scripting for MapReduce transformations.\n\n* **[Sqoop](#sqoop)**: Data import and export.\n\n* **[Tez](#tez)**: Allows data-intensive processes to run efficiently at scale.\n\n* **[YARN](#yarn)**: Part of the Hadoop core library and next generation of the MapReduce software framework.\n\n* **[ZooKeeper](#zookeeper)**: Coordination of processes in distributed systems.\n\n> [AZURE.NOTE] For information on the specific components and version information, see [What's new in the Hadoop cluster versions provided by HDInsight?][component-versioning]\n\n### <a name=\"ambari\"></a>Ambari\n\nApache Ambari is for provisioning, managing and monitoring Apache Hadoop clusters. It includes an intuitive collection of operator tools and a robust set of APIs that hide the complexity of Hadoop, simplifying the operation of clusters. Linux-based HDInsight clusters provide both the Ambari web UI and the Ambari REST API, while Windows-based clusters provide a subset of the REST API. Ambari Views on HDInsight clusters allow plug-in UI capabilities.\n\nSee [Manage HDInsight clusters using Ambari](hdinsight-hadoop-manage-ambari.md) (Linux only), [Monitor Hadoop clusters in HDInsight using the Ambari API](hdinsight-monitor-use-ambari-api.md), and <a target=\"_blank\" href=\"https://github.com/apache/ambari/blob/trunk/ambari-server/docs/api/v1/index.md\">Apache Ambari API reference</a>.\n\n### <a name=\"avro\"></a>Avro (Microsoft .NET Library for Avro)\n\nThe Microsoft .NET Library for Avro implements the Apache Avro compact binary data interchange format for serialization for the Microsoft .NET environment. It uses <a target=\"_blank\" href=\"http://www.json.org/\">JavaScript Object Notation (JSON)</a> to define a language-agnostic schema that underwrites language interoperability, meaning data serialized in one language can be read in another. Detailed information on the format can be found in the <a target=_\"blank\" href=\"http://avro.apache.org/docs/current/spec.html\">Apache Avro Specification</a>.\nThe format of Avro files supports the distributed MapReduce programming model. Files are “splittable”, meaning you can seek any point in a file and start reading from a particular block. To find out how, see [Serialize data with the Microsoft .NET Library for Avro](hdinsight-dotnet-avro-serialization.md).\n\n\n### <a name=\"hdfs\"></a>HDFS\n\nHadoop Distributed File System (HDFS) is a distributed file system that, with MapReduce and YARN, is the core of the Hadoop ecosystem. HDFS is the standard file system for Hadoop clusters on HDInsight.\n\n### <a name=\"hive\"></a>Hive & HCatalog\n\n<a target=\"_blank\" href=\"http://hive.apache.org/\">Apache Hive</a> is data warehouse software built on Hadoop that allows you to query and manage large datasets in distributed storage by using a SQL-like language called HiveQL. Hive, like Pig, is an abstraction on top of MapReduce. When run, Hive translates queries into a series of MapReduce jobs. Hive is conceptually closer to a relational database management system than Pig, and is therefore appropriate for use with more structured data. For unstructured data, Pig is the better choice. See [Use Hive with Hadoop in HDInsight](hdinsight-use-hive.md).\n\n<a target=\"_blank\" href=\"https://cwiki.apache.org/confluence/display/Hive/HCatalog/\">Apache HCatalog</a> is a table and storage management layer for Hadoop that presents users with a relational view of data. In HCatalog, you can read and write files in any format for which a Hive SerDe (serializer-deserializer) can be written.\n\n### <a name=\"mahout\"></a>Mahout\n\n<a target=\"_blank\" href=\"https://mahout.apache.org/\">Apache Mahout</a> is a scalable library of machine learning algorithms that run on Hadoop. Using principles of statistics, machine learning applications teach systems to learn from data and to use past outcomes to determine future behavior. See [Generate movie recommendations using Mahout on Hadoop](hdinsight-mahout.md).\n\n### <a name=\"mapreduce\"></a>MapReduce\nMapReduce is the legacy software framework for Hadoop for writing applications to batch process big data sets in parallel. A MapReduce job splits large datasets and organizes the data into key-value pairs for processing.\n\n[YARN](#yarn) is the Hadoop next-generation resource manager and application framework, and is referred to as MapReduce 2.0. MapReduce jobs will run on YARN.\n\nFor more information on MapReduce, see <a target=\"_blank\" href=\"http://wiki.apache.org/hadoop/MapReduce\">MapReduce</a> in the Hadoop Wiki.\n\n### <a name=\"oozie\"></a>Oozie\n<a target=\"_blank\" href=\"http://oozie.apache.org/\">Apache Oozie</a> is a workflow coordination system that manages Hadoop jobs. It is integrated with the Hadoop stack and supports Hadoop jobs for MapReduce, Pig, Hive, and Sqoop. It can also be used to schedule jobs specific to a system, like Java programs or shell scripts. See [Use a time-based Oozie Coordinator with Hadoop](hdinsight-use-oozie-coordinator-time.md).\n\n### <a name=\"phoenix\"></a>Phoenix\n<a  target=\"_blank\" href=\"http://phoenix.apache.org/\">Apache Phoenix</a> is a relational database layer over HBase. Phoenix includes a JDBC driver that allows users to query and manage SQL tables directly. Phoenix translates queries and other statements into native NoSQL API calls - instead of using MapReduce - thus enabling faster applications on top of NoSQL stores. See [Use Apache Phoenix and SQuirreL with HBase clusters](hdinsight-hbase-phoenix-squirrel.md).\n\n\n### <a name=\"pig\"></a>Pig\n<a  target=\"_blank\" href=\"http://pig.apache.org/\">Apache Pig</a> is a high-level platform that allows you to perform complex MapReduce transformations on very large datasets by using a simple scripting language called Pig Latin. Pig translates the Pig Latin scripts so they’ll run within Hadoop. You can create User Defined Functions (UDFs) to extend Pig Latin. See [Use Pig with Hadoop to analyze an Apache log file](hdinsight-use-pig.md).\n\n### <a name=\"sqoop\"></a>Sqoop\n<a  target=\"_blank\" href=\"http://sqoop.apache.org/\">Apache Sqoop</a> is tool that transfers bulk data between Hadoop and relational databases such a SQL, or other structured data stores, as efficiently as possible. See [Use Sqoop with Hadoop](hdinsight-use-sqoop.md).\n\n### <a name=\"tez\"></a>Tez\n<a  target=\"_blank\" href=\"http://tez.apache.org/\">Apache Tez</a> is an application framework built on Hadoop YARN that executes complex, acyclic graphs of general data processing. It's a more flexible and powerful successor to the MapReduce framework that allows data-intensive processes, such as Hive, to run more efficiently at scale. See [\"Use Apache Tez for improved performance\" in Use Hive and HiveQL](hdinsight-use-hive.md#usetez).\n\n### <a name=\"yarn\"></a>YARN\nApache YARN is the next generation of MapReduce (MapReduce 2.0, or MRv2) and supports data processing scenarios beyond MapReduce batch processing with greater scalability and real-time processing. YARN provides resource management and a distributed application framework. MapReduce jobs will run on YARN.\n\nTo learn about YARN, see <a target=\"_blank\" href=\"http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html\">Apache Hadoop NextGen MapReduce (YARN)</a>.\n\n\n### <a name=\"zookeeper\"></a>ZooKeeper\n<a  target=\"_blank\" href=\"http://zookeeper.apache.org/\">Apache ZooKeeper</a> coordinates processes in large distributed systems by means of a shared hierarchical namespace of data registers (znodes). Znodes contain small amounts of meta information needed to coordinate processes: status, location, configuration, and so on.\n\n## Programming languages on HDInsight\n\nHDInsight clusters--Hadoop, HBase, Storm, and Spark clusters--support a number of programming languages, but some aren't installed by default. For libraries, modules, or packages not installed by default, use a script action to install the component. See [Script action development with HDInsight](hdinsight-hadoop-script-actions-linux.md).\n\n### Default programming language support\n\nBy default, HDInsight clusters support:\n\n* Java\n\n* Python\n\nAdditional languages can be installed using script actions: [Script action development with HDInsight](hdinsight-hadoop-script-actions-linux.md).\n\n### Java virtual machine (JVM) languages\n\nMany languages other than Java can be run using a Java virtual machine (JVM); however, running some of these languages may require additional components installed on the cluster.\n\nThese JVM-based languages are supported on HDInsight clusters:\n\n* Clojure\n\n* Jython (Python for Java)\n\n* Scala\n\n### Hadoop-specific languages\n\nHDInsight clusters provide support for the following languages that are specific to the Hadoop ecosystem:\n\n* Pig Latin for Pig jobs\n\n* HiveQL for Hive jobs and SparkSQL\n\n\n## <a name=\"advantage\"></a>Advantages of Hadoop in the cloud\n\nAs part of the Azure cloud ecosystem, Hadoop in HDInsight offers a number of benefits, among them:\n\n* Automatic provisioning of Hadoop clusters. HDInsight clusters are much easier to create than manually configuring Hadoop clusters. For details, see [Provision Hadoop clusters in HDInsight](hdinsight-hadoop-provision-linux-clusters.md).\n\n* State-of-the-art Hadoop components. For details, see [What's new in the Hadoop cluster versions provided by HDInsight?][component-versioning].\n\n* High availability and reliability of clusters. See [Availability and reliability of Hadoop clusters in HDInsight](hdinsight-high-availability-linux.md) for details.\n\n* Efficient and economical data storage with Azure Blob storage, a Hadoop-compatible option. See [Use Azure Blob storage with Hadoop in HDInsight](hdinsight-hadoop-use-blob-storage.md) for details.\n\n* Integration with other Azure services, including [Web apps](../documentation/services/app-service/web/) and [SQL Database](../documentation/services/sql-database/).\n\n* Low entry cost. Start a [free trial](/pricing/free-trial/), or consult [HDInsight pricing details](/pricing/details/hdinsight/).\n\n\nTo read more about the advantages on Hadoop in HDInsight, see the  [Azure features page for HDInsight][marketing-page].\n\n\n\n## <a id=\"resources\"></a>Resources for learning more about big-data analysis, Hadoop, and HDInsight\n\nBuild on this introduction to Hadoop in the cloud and big data analysis with the resources below.\n\n\n### Hadoop documentation for HDInsight\n\n* [HDInsight documentation](https://azure.microsoft.com/documentation/services/hdinsight/): The documentation page for Azure HDInsight with links to articles, videos, and more resources.\n\n* [Get started with HDInsight on Linux](hdinsight-hadoop-linux-tutorial-get-started.md): A quick-start tutorial for provisioning HDInsight Hadoop clusters on Linux and running sample Hive queries.\n\n* [Get started with Linux-based Storm on HDInsight](hdinsight-apache-storm-tutorial-get-started-linux.md): A quick-start tutorial for provisioning a Storm on HDInsight cluster and running sample Storm topologies.\n\n* [Provision HDInsight on Linux](hdinsight-hadoop-provision-linux-clusters.md): Learn how to provision an HDInsight Hadoop cluster on Linux through the Azure Portal, Azure CLI, or Azure PowerShell.\n\n* [Working with HDInsight on Linux](hdinsight-hadoop-linux-information.md): Get some quick tips on working with Hadoop Linux clusters provisioned on Azure.\n\n* [Manage HDInsight clusters using Ambari](hdinsight-hadoop-manage-ambari.md): Learn how to monitor and manage your Linux-based Hadoop on HDInsight cluster by using Ambari Web, or the Ambari REST API.\n\n\n### Apache Hadoop\n\n* <a target=\"_blank\" href=\"http://hadoop.apache.org/\">Apache Hadoop</a>: Learn more about the Apache Hadoop software library, a framework that allows for the distributed processing of large datasets across clusters of computers.\n\n* <a target=\"_blank\" href=\"http://hadoop.apache.org/docs/r1.0.4/hdfs_design.html\">HDFS</a>: Learn more about the architecture and design of the Hadoop Distributed File System, the primary storage system used by Hadoop applications.\n\n* <a target=\"_blank\" href=\"http://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html\">MapReduce Tutorial</a>: Learn more about the programming framework for writing Hadoop applications that rapidly process large amounts of data in parallel on large clusters of compute nodes.\n\n### SQL Database on Azure\n\n* [Azure SQL Database](/documentation/services/sql-database/): Documentation, tutorials, and videos for SQL Database.\n\n* [SQL Database on the Azure Portal](sql-database-manage-portal.md): A lightweight and easy-to-use database management tool for managing SQL Database in the cloud.\n\n* [Adventure Works for SQL Database](http://msftdbprodsamples.codeplex.com/releases/view/37304): Download page for a SQL Database sample database.\n\n### Microsoft business intelligence (for HDInsight on Windows)\n\nFamiliar business intelligence (BI) tools - such as Excel, PowerPivot, SQL Server Analysis Services, and SQL Server Reporting Services - retrieve, analyze, and report data integrated with HDInsight by using either the Power Query add-in or the Microsoft Hive ODBC Driver.\n\nThese BI tools can help in your big-data analysis:\n\n* [Connect Excel to Hadoop with Power Query](hdinsight-connect-excel-power-query.md): Learn how to connect Excel to the Azure Storage account that stores the data associated with your HDInsight cluster by using Microsoft Power Query for Excel.\n\n* [Connect Excel to Hadoop with the Microsoft Hive ODBC Driver](hdinsight-connect-excel-hive-ODBC-driver.md): Learn how to import data from HDInsight with the Microsoft Hive ODBC Driver.\n\n* [Microsoft Cloud Platform](http://www.microsoft.com/server-cloud/solutions/business-intelligence/default.aspx): Learn about Power BI for Office 365, download the SQL Server trial, and set up SharePoint Server 2013 and SQL Server BI.\n\n* <a target=\"_blank\" href=\"http://msdn.microsoft.com/library/hh231701.aspx\">Learn more about SQL Server Analysis Services</a>.\n\n* <a target=\"_blank\" href=\"http://msdn.microsoft.com/library/ms159106.aspx\">Learn about SQL Server Reporting Services</a>.\n\n\n### Try Hadoop solutions for big-data analysis (for HDInsight on Windows)\n\nUse big data analysis on your organization's data to gain insights into your business. Here are some examples:\n\n* [Analyze HVAC sensor data](hdinsight-hive-analyze-sensor-data.md): Learn how to analyze sensor data by using Hive with HDInsight (Hadoop), and then visualize the data in Microsoft Excel. In this sample, you'll use Hive to process historical data produced by HVAC systems to see which systems can't reliably maintain a set temperature.\n\n* [Use Hive with HDInsight to analyze website logs](hdinsight-hive-analyze-website-log.md): Learn how to use HiveQL in HDInsight to analyze website logs to get insight into the frequency of visits in a day from external websites, and a summary of website errors that the users experience.\n\n* [Analyze sensor data in real-time with Storm and HBase in HDInsight (Hadoop)](hdinsight-storm-sensor-data-analysis.md): Learn how to build a solution that uses a Storm cluster in HDInsight to process sensor data from Azure Event Hubs, and then displays the processed sensor data as near-real-time information on a web-based dashboard.\n\n\n[marketing-page]: ../services/hdinsight/\n[component-versioning]: hdinsight-component-versioning.md\n[zookeeper]: http://zookeeper.apache.org/\n"
}