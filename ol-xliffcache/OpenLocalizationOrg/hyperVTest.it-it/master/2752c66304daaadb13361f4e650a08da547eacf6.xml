{
  "nodes": [
    {
      "pos": [
        27,
        113
      ],
      "content": "Create Hadoop, HBase, Storm, or Spark clusters on Linux in HDInsight | Microsoft Azure"
    },
    {
      "pos": [
        132,
        289
      ],
      "content": "Learn how to create Hadoop, HBase, Storm, or Spark clusters on Linux for HDInsight using a browser, the Azure CLI, Azure PowerShell, REST, or through an SDK."
    },
    {
      "pos": [
        617,
        664
      ],
      "content": "Create Linux-based Hadoop clusters in HDInsight"
    },
    {
      "pos": [
        753,
        1039
      ],
      "content": "In this document, you will learn about the different ways to create a Linux-based HDInsight cluster on Azure, as well as optional configurations that can be used with your cluster. HDInsight provides Apache Hadoop, Apache Storm, and Apache HBase as services on the Azure cloud platform.",
      "nodes": [
        {
          "content": "In this document, you will learn about the different ways to create a Linux-based HDInsight cluster on Azure, as well as optional configurations that can be used with your cluster.",
          "pos": [
            0,
            180
          ]
        },
        {
          "content": "HDInsight provides Apache Hadoop, Apache Storm, and Apache HBase as services on the Azure cloud platform.",
          "pos": [
            181,
            286
          ]
        }
      ]
    },
    {
      "pos": [
        1043,
        1298
      ],
      "content": "<ph id=\"ph3\">[AZURE.NOTE]</ph><ph id=\"ph4\"/> This document provides instructions on the different ways to create a cluster. If you are looking for a quick-start approach to create a cluster, see <bpt id=\"p1\">[</bpt>Get Started with Azure HDInsight on Linux<ept id=\"p1\">](hdinsight-hadoop-linux-tutorial-get-started.md)</ept>.",
      "nodes": [
        {
          "content": "<ph id=\"ph3\">[AZURE.NOTE]</ph><ph id=\"ph4\"/> This document provides instructions on the different ways to create a cluster.",
          "pos": [
            0,
            123
          ]
        },
        {
          "content": "If you are looking for a quick-start approach to create a cluster, see <bpt id=\"p1\">[</bpt>Get Started with Azure HDInsight on Linux<ept id=\"p1\">](hdinsight-hadoop-linux-tutorial-get-started.md)</ept>.",
          "pos": [
            124,
            325
          ]
        }
      ]
    },
    {
      "pos": [
        1303,
        1332
      ],
      "content": "What is an HDInsight cluster?"
    },
    {
      "pos": [
        1334,
        1624
      ],
      "content": "A Hadoop cluster consists of several virtual machines (nodes,) which are used for distributed processing of tasks on the cluster. Azure abstracts the implementation details of installation and configuration of individual nodes, so you only have to provide general configuration information.",
      "nodes": [
        {
          "content": "A Hadoop cluster consists of several virtual machines (nodes,) which are used for distributed processing of tasks on the cluster.",
          "pos": [
            0,
            129
          ]
        },
        {
          "content": "Azure abstracts the implementation details of installation and configuration of individual nodes, so you only have to provide general configuration information.",
          "pos": [
            130,
            290
          ]
        }
      ]
    },
    {
      "pos": [
        1629,
        1642
      ],
      "content": "Cluster types"
    },
    {
      "pos": [
        1644,
        1691
      ],
      "content": "There are several types of HDInsight available:"
    },
    {
      "pos": [
        1695,
        1707
      ],
      "content": "Cluster type"
    },
    {
      "pos": [
        1710,
        1733
      ],
      "content": "Use this if you need..."
    },
    {
      "pos": [
        1787,
        1793
      ],
      "content": "Hadoop"
    },
    {
      "pos": [
        1802,
        1833
      ],
      "content": "query and analysis (batch jobs)"
    },
    {
      "pos": [
        1842,
        1847
      ],
      "content": "HBase"
    },
    {
      "pos": [
        1857,
        1875
      ],
      "content": "NoSQL data storage"
    },
    {
      "pos": [
        1891,
        1896
      ],
      "content": "Storm"
    },
    {
      "pos": [
        1906,
        1932
      ],
      "content": "Real-time event processing"
    },
    {
      "pos": [
        1937,
        1952
      ],
      "content": "Spark (Preview)"
    },
    {
      "pos": [
        1955,
        2027
      ],
      "content": "In-memory processing, interactive queries, micro-batch stream processing"
    },
    {
      "pos": [
        2031,
        2215
      ],
      "content": "During configuration, you will select one of these types for the cluster. You can add other technologies such as Hue or R to these basic types by using <bpt id=\"p2\">[</bpt>Script Actions<ept id=\"p2\">](#scriptaction)</ept>.",
      "nodes": [
        {
          "content": "During configuration, you will select one of these types for the cluster.",
          "pos": [
            0,
            73
          ]
        },
        {
          "content": "You can add other technologies such as Hue or R to these basic types by using <bpt id=\"p2\">[</bpt>Script Actions<ept id=\"p2\">](#scriptaction)</ept>.",
          "pos": [
            74,
            222
          ]
        }
      ]
    },
    {
      "pos": [
        2217,
        2363
      ],
      "content": "Each cluster type has its own terminology for nodes within the cluster, as well as the number of nodes and the default VM size for each node type:"
    },
    {
      "pos": [
        2367,
        2569
      ],
      "content": "<ph id=\"ph5\">[AZURE.IMPORTANT]</ph><ph id=\"ph6\"/> If you plan on more than 32 worker nodes, either at cluster creation or by scaling the cluster after creation, then you must select a head node size with at least 8 cores and 14GB ram."
    },
    {
      "pos": [
        2571,
        2669
      ],
      "content": "<ph id=\"ph7\">![</ph>HDInsight Hadoop cluster nodes<ph id=\"ph8\">](./media/hdinsight-provision-clusters/HDInsight.Hadoop.roles.png)</ph>"
    },
    {
      "pos": [
        2671,
        2722
      ],
      "content": "Hadoop clusters for HDInsight have two types nodes:"
    },
    {
      "pos": [
        2726,
        2745
      ],
      "content": "Head node (2 nodes)"
    },
    {
      "pos": [
        2748,
        2775
      ],
      "content": "Data node (at least 1 node)"
    },
    {
      "pos": [
        2777,
        2873
      ],
      "content": "<ph id=\"ph9\">![</ph>HDInsight HBase cluster nodes<ph id=\"ph10\">](./media/hdinsight-provision-clusters/HDInsight.HBase.roles.png)</ph>"
    },
    {
      "pos": [
        2875,
        2930
      ],
      "content": "HBase clusters for HDInsight have three types of nodes:"
    },
    {
      "pos": [
        2933,
        2955
      ],
      "content": "Head servers (2 nodes)"
    },
    {
      "pos": [
        2958,
        2990
      ],
      "content": "Region servers (at least 1 node)"
    },
    {
      "pos": [
        2993,
        3025
      ],
      "content": "Master/Zookeeper nodes (3 nodes)"
    },
    {
      "pos": [
        3027,
        3123
      ],
      "content": "<ph id=\"ph11\">![</ph>HDInsight Storm cluster nodes<ph id=\"ph12\">](./media/hdinsight-provision-clusters/HDInsight.Storm.roles.png)</ph>"
    },
    {
      "pos": [
        3125,
        3177
      ],
      "content": "Storm clusters for HDInsight have three types nodes:"
    },
    {
      "pos": [
        3180,
        3202
      ],
      "content": "Nimbus nodes (2 nodes)"
    },
    {
      "pos": [
        3205,
        3241
      ],
      "content": "Supervisor servers (at least 1 node)"
    },
    {
      "pos": [
        3244,
        3269
      ],
      "content": "Zookeeper nodes (3 nodes)"
    },
    {
      "pos": [
        3272,
        3368
      ],
      "content": "<ph id=\"ph13\">![</ph>HDInsight Spark cluster nodes<ph id=\"ph14\">](./media/hdinsight-provision-clusters/HDInsight.Spark.roles.png)</ph>"
    },
    {
      "pos": [
        3370,
        3425
      ],
      "content": "Spark clusters for HDInsight have three types of nodes:"
    },
    {
      "pos": [
        3428,
        3447
      ],
      "content": "Head node (2 nodes)"
    },
    {
      "pos": [
        3450,
        3479
      ],
      "content": "Worker node (at least 1 node)"
    },
    {
      "pos": [
        3482,
        3540
      ],
      "content": "Zookeeper nodes (3 nodes) (Free for A1 Zookeepers VM size)"
    },
    {
      "pos": [
        3545,
        3572
      ],
      "content": "Azure Storage for HDInsight"
    },
    {
      "pos": [
        3574,
        4087
      ],
      "content": "Each cluster type will also have one or more Azure Storage accounts associated with the cluster. HDInsight uses Azure blobs from these storage accounts as the data store for your cluster. Keeping the data separate from the cluster allows you to delete clusters when they aren't in use, and still preserve your data. You can then use the same storage account for a new cluster if you need to do more analysis. For more information, see <bpt id=\"p3\">[</bpt>Use Azure Blob storage with HDInsight<ept id=\"p3\">](hdinsight-hadoop-use-blob-storage.md)</ept>.",
      "nodes": [
        {
          "content": "Each cluster type will also have one or more Azure Storage accounts associated with the cluster.",
          "pos": [
            0,
            96
          ]
        },
        {
          "content": "HDInsight uses Azure blobs from these storage accounts as the data store for your cluster.",
          "pos": [
            97,
            187
          ]
        },
        {
          "content": "Keeping the data separate from the cluster allows you to delete clusters when they aren't in use, and still preserve your data.",
          "pos": [
            188,
            315
          ]
        },
        {
          "content": "You can then use the same storage account for a new cluster if you need to do more analysis.",
          "pos": [
            316,
            408
          ]
        },
        {
          "content": "For more information, see <bpt id=\"p3\">[</bpt>Use Azure Blob storage with HDInsight<ept id=\"p3\">](hdinsight-hadoop-use-blob-storage.md)</ept>.",
          "pos": [
            409,
            551
          ]
        }
      ]
    },
    {
      "pos": [
        4118,
        4145
      ],
      "content": "Basic configuration options"
    },
    {
      "pos": [
        4147,
        4259
      ],
      "content": "The following sections describe the required configuration options available when creating an HDInsight cluster."
    },
    {
      "pos": [
        4264,
        4276
      ],
      "content": "Cluster name"
    },
    {
      "pos": [
        4278,
        4536
      ],
      "content": "The cluster name provides a unique identifier for the cluster, and is used as part of the domain name for accessing the cluster over the Internet. For example, a cluster named <bpt id=\"p4\">_</bpt>mycluster<ept id=\"p4\">_</ept><ph id=\"ph15\"/> will be available over the internet as <bpt id=\"p5\">_</bpt>mycluster<ept id=\"p5\">_</ept>.azurehdinsight.net.",
      "nodes": [
        {
          "content": "The cluster name provides a unique identifier for the cluster, and is used as part of the domain name for accessing the cluster over the Internet.",
          "pos": [
            0,
            146
          ]
        },
        {
          "content": "For example, a cluster named <bpt id=\"p4\">_</bpt>mycluster<ept id=\"p4\">_</ept><ph id=\"ph15\"/> will be available over the internet as <bpt id=\"p5\">_</bpt>mycluster<ept id=\"p5\">_</ept>.azurehdinsight.net.",
          "pos": [
            147,
            349
          ]
        }
      ]
    },
    {
      "pos": [
        4538,
        4592
      ],
      "content": "The cluster name must follow the following guidelines:"
    },
    {
      "pos": [
        4596,
        4663
      ],
      "content": "The field must contain a string that is between 3 and 63 characters"
    },
    {
      "pos": [
        4666,
        4722
      ],
      "content": "The field can contain only letters, numbers, and hyphens"
    },
    {
      "pos": [
        4727,
        4739
      ],
      "content": "Cluster type"
    },
    {
      "pos": [
        4741,
        4887
      ],
      "content": "Cluster type allows you to select special purpose configurations for the cluster. The following are the types available for Linux-based HDInsight:",
      "nodes": [
        {
          "content": "Cluster type allows you to select special purpose configurations for the cluster.",
          "pos": [
            0,
            81
          ]
        },
        {
          "content": "The following are the types available for Linux-based HDInsight:",
          "pos": [
            82,
            146
          ]
        }
      ]
    },
    {
      "pos": [
        4891,
        4903
      ],
      "content": "Cluster type"
    },
    {
      "pos": [
        4906,
        4929
      ],
      "content": "Use this if you need..."
    },
    {
      "pos": [
        4983,
        4989
      ],
      "content": "Hadoop"
    },
    {
      "pos": [
        4998,
        5029
      ],
      "content": "query and analysis (batch jobs)"
    },
    {
      "pos": [
        5038,
        5043
      ],
      "content": "HBase"
    },
    {
      "pos": [
        5053,
        5071
      ],
      "content": "NoSQL data storage"
    },
    {
      "pos": [
        5087,
        5092
      ],
      "content": "Storm"
    },
    {
      "pos": [
        5102,
        5128
      ],
      "content": "Real-time event processing"
    },
    {
      "pos": [
        5133,
        5148
      ],
      "content": "Spark (Preview)"
    },
    {
      "pos": [
        5151,
        5223
      ],
      "content": "In-memory processing, interactive queries, micro-batch stream processing"
    },
    {
      "pos": [
        5227,
        5337
      ],
      "content": "You can add other technologies such as Hue or R to these basic types by using <bpt id=\"p6\">[</bpt>Script Actions<ept id=\"p6\">](#scriptaction)</ept>."
    },
    {
      "pos": [
        5342,
        5366
      ],
      "content": "Cluster operating system"
    },
    {
      "pos": [
        5368,
        5451
      ],
      "content": "You can provision HDInsight clusters on one of the following two operating systems:"
    },
    {
      "pos": [
        5455,
        5723
      ],
      "content": "<bpt id=\"p7\">**</bpt>HDInsight on Windows (Windows Server 2012 R2 Datacenter)<ept id=\"p7\">**</ept>: Select this option if you need to integrate with Windows-based services and technologies that will run on the cluster with Hadoop, or if you are migrating from an existing Windows-based Hadoop distribution."
    },
    {
      "pos": [
        5727,
        6092
      ],
      "content": "<bpt id=\"p8\">**</bpt>HDInsight on Linux (Ubuntu 12.04 LTS for Linux)<ept id=\"p8\">**</ept>: Select this option if you are familiar with Linux or Unix, migrating from an existing Linux-based Hadoop solution, or want easy integration with Hadoop ecosystem components built for Linux. For more information, see <bpt id=\"p9\">[</bpt>Get started with Hadoop on Linux in HDInsight<ept id=\"p9\">](hdinsight-hadoop-linux-tutorial-get-started.md)</ept>.",
      "nodes": [
        {
          "content": "<bpt id=\"p8\">**</bpt>HDInsight on Linux (Ubuntu 12.04 LTS for Linux)<ept id=\"p8\">**</ept>: Select this option if you are familiar with Linux or Unix, migrating from an existing Linux-based Hadoop solution, or want easy integration with Hadoop ecosystem components built for Linux.",
          "pos": [
            0,
            280
          ]
        },
        {
          "content": "For more information, see <bpt id=\"p9\">[</bpt>Get started with Hadoop on Linux in HDInsight<ept id=\"p9\">](hdinsight-hadoop-linux-tutorial-get-started.md)</ept>.",
          "pos": [
            281,
            441
          ]
        }
      ]
    },
    {
      "pos": [
        6096,
        6347
      ],
      "content": "<ph id=\"ph16\">[AZURE.NOTE]</ph><ph id=\"ph17\"/> Information in this document assumes that you are using a Linux-based HDInsight cluster. For information that is specific to Windows-based clusters, see <bpt id=\"p10\">[</bpt>Create Windows-based Hadoop clusters in HDInsight<ept id=\"p10\">](hdinsight-provision-clusters.md)</ept>.",
      "nodes": [
        {
          "content": "<ph id=\"ph16\">[AZURE.NOTE]</ph><ph id=\"ph17\"/> Information in this document assumes that you are using a Linux-based HDInsight cluster.",
          "pos": [
            0,
            135
          ]
        },
        {
          "content": "For information that is specific to Windows-based clusters, see <bpt id=\"p10\">[</bpt>Create Windows-based Hadoop clusters in HDInsight<ept id=\"p10\">](hdinsight-provision-clusters.md)</ept>.",
          "pos": [
            136,
            325
          ]
        }
      ]
    },
    {
      "pos": [
        6352,
        6369
      ],
      "content": "Subscription name"
    },
    {
      "pos": [
        6371,
        6492
      ],
      "content": "If you have multiple Azure subscriptions, use this to select the one you want to use when creating the HDInsight cluster."
    },
    {
      "pos": [
        6497,
        6511
      ],
      "content": "Resource group"
    },
    {
      "pos": [
        6513,
        7230
      ],
      "content": "Applications are typically made up of many components, for example a web app, database, database server, storage, and 3rd party services. Azure Resource Manager (ARM) enables you to work with the resources in your application as a group, referred to as an Azure Resource Group. You can deploy, update, monitor or delete all of the resources for your application in a single, coordinated operation. You use a template for deployment and that template can work for different environments such as testing, staging and production. You can clarify billing for your organization by viewing the rolled-up costs for the entire group. For more information, see <bpt id=\"p11\">[</bpt>Azure Resource Manager Overview<ept id=\"p11\">](../resource-group-overview.md)</ept>.",
      "nodes": [
        {
          "content": "Applications are typically made up of many components, for example a web app, database, database server, storage, and 3rd party services.",
          "pos": [
            0,
            137
          ]
        },
        {
          "content": "Azure Resource Manager (ARM) enables you to work with the resources in your application as a group, referred to as an Azure Resource Group.",
          "pos": [
            138,
            277
          ]
        },
        {
          "content": "You can deploy, update, monitor or delete all of the resources for your application in a single, coordinated operation.",
          "pos": [
            278,
            397
          ]
        },
        {
          "content": "You use a template for deployment and that template can work for different environments such as testing, staging and production.",
          "pos": [
            398,
            526
          ]
        },
        {
          "content": "You can clarify billing for your organization by viewing the rolled-up costs for the entire group.",
          "pos": [
            527,
            625
          ]
        },
        {
          "content": "For more information, see <bpt id=\"p11\">[</bpt>Azure Resource Manager Overview<ept id=\"p11\">](../resource-group-overview.md)</ept>.",
          "pos": [
            626,
            757
          ]
        }
      ]
    },
    {
      "pos": [
        7235,
        7246
      ],
      "content": "Credentials"
    },
    {
      "pos": [
        7248,
        7315
      ],
      "content": "There are two types of authentication used with HDInsight clusters:"
    },
    {
      "pos": [
        7319,
        7509
      ],
      "content": "<bpt id=\"p12\">__</bpt>Admin<ept id=\"p12\">__</ept><ph id=\"ph18\"/> or <bpt id=\"p13\">__</bpt>HTTPs<ept id=\"p13\">__</ept><ph id=\"ph19\"/> user: The admin account for a cluster is primarily used when accessing web or REST services exposed by the cluster. It cannot be used to directly login to the cluster.",
      "nodes": [
        {
          "content": "<bpt id=\"p12\">__</bpt>Admin<ept id=\"p12\">__</ept><ph id=\"ph18\"/> or <bpt id=\"p13\">__</bpt>HTTPs<ept id=\"p13\">__</ept><ph id=\"ph19\"/> user: The admin account for a cluster is primarily used when accessing web or REST services exposed by the cluster.",
          "pos": [
            0,
            248
          ]
        },
        {
          "content": "It cannot be used to directly login to the cluster.",
          "pos": [
            249,
            300
          ]
        }
      ]
    },
    {
      "pos": [
        7513,
        7755
      ],
      "content": "<bpt id=\"p14\">__</bpt>SSH username<ept id=\"p14\">__</ept>: An SSH user account is used to remotely access the cluster using a <bpt id=\"p15\">[</bpt>Secure Shell<ept id=\"p15\">](https://en.wikipedia.org/wiki/Secure_Shell)</ept><ph id=\"ph20\"/> client. This is most often used to provide a remote command-line access to the cluster head nodes.",
      "nodes": [
        {
          "content": "<bpt id=\"p14\">__</bpt>SSH username<ept id=\"p14\">__</ept>: An SSH user account is used to remotely access the cluster using a <bpt id=\"p15\">[</bpt>Secure Shell<ept id=\"p15\">](https://en.wikipedia.org/wiki/Secure_Shell)</ept><ph id=\"ph20\"/> client.",
          "pos": [
            0,
            246
          ]
        },
        {
          "content": "This is most often used to provide a remote command-line access to the cluster head nodes.",
          "pos": [
            247,
            337
          ]
        }
      ]
    },
    {
      "pos": [
        7757,
        7918
      ],
      "content": "The admin account is secured by a password, and all web communications to the cluster using the admin account should be performed over a secure HTTPS connection."
    },
    {
      "pos": [
        7920,
        8140
      ],
      "content": "The SSH user can be authenticated using either a password or a certificate. Certificate authentication is the most secure option, however it requires the creation and maintenance of a public and private certificate pair.",
      "nodes": [
        {
          "content": "The SSH user can be authenticated using either a password or a certificate.",
          "pos": [
            0,
            75
          ]
        },
        {
          "content": "Certificate authentication is the most secure option, however it requires the creation and maintenance of a public and private certificate pair.",
          "pos": [
            76,
            220
          ]
        }
      ]
    },
    {
      "pos": [
        8142,
        8268
      ],
      "content": "For more information on using SSH with HDInsight, including how to create and use SSH keys, see one of the following articles:"
    },
    {
      "pos": [
        8272,
        8377
      ],
      "content": "<bpt id=\"p16\">[</bpt>For Linux, Unix, or Mac OS X clients - using SSH with HDInsight<ept id=\"p16\">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept>"
    },
    {
      "pos": [
        8380,
        8471
      ],
      "content": "<bpt id=\"p17\">[</bpt>For Windows clients - using SSH with HDInsight<ept id=\"p17\">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept>"
    },
    {
      "pos": [
        8476,
        8487
      ],
      "content": "Data source"
    },
    {
      "pos": [
        8489,
        8698
      ],
      "content": "HDInsight uses Azure Blob Storage as the underlying storage for the cluster. Internally, Hadoop and other software on the cluster sees this storage as a Hadoop Distributed File System (HDFS) compatible system.",
      "nodes": [
        {
          "content": "HDInsight uses Azure Blob Storage as the underlying storage for the cluster.",
          "pos": [
            0,
            76
          ]
        },
        {
          "content": "Internally, Hadoop and other software on the cluster sees this storage as a Hadoop Distributed File System (HDFS) compatible system.",
          "pos": [
            77,
            209
          ]
        }
      ]
    },
    {
      "pos": [
        8701,
        8805
      ],
      "content": "When creating a new cluster, you must either create a new Azure Storage Account, or use an existing one."
    },
    {
      "pos": [
        8809,
        9018
      ],
      "content": "<ph id=\"ph21\">[AZURE.IMPORTANT]</ph><ph id=\"ph22\"/> The geographic location you select for the storage account will determine the location of the HDInsight cluster, as the cluster must be in the same data center as the default storage account."
    },
    {
      "pos": [
        9024,
        9176
      ],
      "content": "For a list of supported regions, click the <bpt id=\"p18\">**</bpt>Region<ept id=\"p18\">**</ept><ph id=\"ph23\"/> drop-down list on <bpt id=\"p19\">[</bpt>HDInsight pricing<ept id=\"p19\">](https://go.microsoft.com/fwLink/?LinkID=282635&amp;clcid=0x409)</ept>."
    },
    {
      "pos": [
        9182,
        9207
      ],
      "content": "Default storage container"
    },
    {
      "pos": [
        9209,
        9344
      ],
      "content": "HDInsight will also create a <bpt id=\"p20\">_</bpt>default storage container<ept id=\"p20\">_</ept><ph id=\"ph24\"/> on the storage account. This is the default storage for the HDInsight cluster.",
      "nodes": [
        {
          "content": "HDInsight will also create a <bpt id=\"p20\">_</bpt>default storage container<ept id=\"p20\">_</ept><ph id=\"ph24\"/> on the storage account.",
          "pos": [
            0,
            135
          ]
        },
        {
          "content": "This is the default storage for the HDInsight cluster.",
          "pos": [
            136,
            190
          ]
        }
      ]
    },
    {
      "pos": [
        9347,
        9585
      ],
      "content": "By default, this container has the same name as the cluster. For more information on how HDInsight works with Azure Blob Storage, see <bpt id=\"p21\">[</bpt>Use HDFS-compatible Azure Blob storage with Hadoop in HDInsight<ept id=\"p21\">](hdinsight-hadoop-use-blob-storage.md)</ept>.",
      "nodes": [
        {
          "content": "By default, this container has the same name as the cluster.",
          "pos": [
            0,
            60
          ]
        },
        {
          "content": "For more information on how HDInsight works with Azure Blob Storage, see <bpt id=\"p21\">[</bpt>Use HDFS-compatible Azure Blob storage with Hadoop in HDInsight<ept id=\"p21\">](hdinsight-hadoop-use-blob-storage.md)</ept>.",
          "pos": [
            61,
            278
          ]
        }
      ]
    },
    {
      "pos": [
        9588,
        9675
      ],
      "content": "<ph id=\"ph25\">[AZURE.WARNING]</ph><ph id=\"ph26\"/> Don't share one container for multiple clusters. This is not supported.",
      "nodes": [
        {
          "content": "<ph id=\"ph25\">[AZURE.WARNING]</ph><ph id=\"ph26\"/> Don't share one container for multiple clusters.",
          "pos": [
            0,
            98
          ]
        },
        {
          "content": "This is not supported.",
          "pos": [
            99,
            121
          ]
        }
      ]
    },
    {
      "pos": [
        9680,
        9689
      ],
      "content": "Node size"
    },
    {
      "pos": [
        9691,
        9907
      ],
      "content": "You can select the size of compute resources used by the cluster. For example, if you know that you will be performing operations that need a lot of memory, you may want to select a compute resource with more memory.",
      "nodes": [
        {
          "content": "You can select the size of compute resources used by the cluster.",
          "pos": [
            0,
            65
          ]
        },
        {
          "content": "For example, if you know that you will be performing operations that need a lot of memory, you may want to select a compute resource with more memory.",
          "pos": [
            66,
            216
          ]
        }
      ]
    },
    {
      "pos": [
        9910,
        10419
      ],
      "content": "<ph id=\"ph27\">[AZURE.NOTE]</ph><ph id=\"ph28\"/> The nodes used by your cluster do not count as Virtual Machines, as the Virtual Machines images used for the nodes are an implementation detail of the HDInsight service; however, the compute cores used by the nodes do count against the total number of compute cores available to your subscription. You can see the number of cores that will be used by the cluster, as well as the number of cores available, in the summary section of the Node Pricing Tiers blade when creating an HDInsight cluster.",
      "nodes": [
        {
          "content": "<ph id=\"ph27\">[AZURE.NOTE]</ph><ph id=\"ph28\"/> The nodes used by your cluster do not count as Virtual Machines, as the Virtual Machines images used for the nodes are an implementation detail of the HDInsight service; however, the compute cores used by the nodes do count against the total number of compute cores available to your subscription.",
          "pos": [
            0,
            344
          ]
        },
        {
          "content": "You can see the number of cores that will be used by the cluster, as well as the number of cores available, in the summary section of the Node Pricing Tiers blade when creating an HDInsight cluster.",
          "pos": [
            345,
            543
          ]
        }
      ]
    },
    {
      "pos": [
        10421,
        10714
      ],
      "content": "Different cluster types have different node types, number of nodes, and node sizes. For example, a Hadoop cluster type has two <bpt id=\"p22\">_</bpt>head nodes<ept id=\"p22\">_</ept><ph id=\"ph29\"/> and a default of four <bpt id=\"p23\">_</bpt>data nodes<ept id=\"p23\">_</ept>, while a Storm cluster type has two <bpt id=\"p24\">_</bpt>nimbus nodes<ept id=\"p24\">_</ept>, three <bpt id=\"p25\">_</bpt>zookeeper nodes<ept id=\"p25\">_</ept>, and a default of four <bpt id=\"p26\">_</bpt>supervisor nodes<ept id=\"p26\">_</ept>.",
      "nodes": [
        {
          "content": "Different cluster types have different node types, number of nodes, and node sizes.",
          "pos": [
            0,
            83
          ]
        },
        {
          "content": "For example, a Hadoop cluster type has two <bpt id=\"p22\">_</bpt>head nodes<ept id=\"p22\">_</ept><ph id=\"ph29\"/> and a default of four <bpt id=\"p23\">_</bpt>data nodes<ept id=\"p23\">_</ept>, while a Storm cluster type has two <bpt id=\"p24\">_</bpt>nimbus nodes<ept id=\"p24\">_</ept>, three <bpt id=\"p25\">_</bpt>zookeeper nodes<ept id=\"p25\">_</ept>, and a default of four <bpt id=\"p26\">_</bpt>supervisor nodes<ept id=\"p26\">_</ept>.",
          "pos": [
            84,
            508
          ]
        }
      ]
    },
    {
      "pos": [
        10718,
        10920
      ],
      "content": "<ph id=\"ph30\">[AZURE.IMPORTANT]</ph><ph id=\"ph31\"/> If you plan on more than 32 worker nodes, either at cluster creation or by scaling the cluster after creation, then you must select a head node size with at least 8 cores and 14GB RAM."
    },
    {
      "pos": [
        10922,
        11124
      ],
      "content": "When using the Azure preview portal to configure the cluster, the Node size is available through the <bpt id=\"p27\">__</bpt>Node Pricing Tier<ept id=\"p27\">__</ept><ph id=\"ph32\"/> blade, and will also display the cost associated with the different node sizes."
    },
    {
      "pos": [
        11129,
        11354
      ],
      "content": "<ph id=\"ph33\">[AZURE.IMPORTANT]</ph><ph id=\"ph34\"/> Billing starts once a cluster is created, and only stops when the cluster is deleted. For more information on pricing, see <bpt id=\"p28\">[</bpt>HDInsight pricing details<ept id=\"p28\">](https://azure.microsoft.com/pricing/details/hdinsight/)</ept>.",
      "nodes": [
        {
          "content": "<ph id=\"ph33\">[AZURE.IMPORTANT]</ph><ph id=\"ph34\"/> Billing starts once a cluster is created, and only stops when the cluster is deleted.",
          "pos": [
            0,
            137
          ]
        },
        {
          "content": "For more information on pricing, see <bpt id=\"p28\">[</bpt>HDInsight pricing details<ept id=\"p28\">](https://azure.microsoft.com/pricing/details/hdinsight/)</ept>.",
          "pos": [
            138,
            299
          ]
        }
      ]
    },
    {
      "pos": [
        11356,
        11358
      ],
      "content": "##"
    },
    {
      "pos": [
        11392,
        11414
      ],
      "content": "Optional configuration"
    },
    {
      "pos": [
        11416,
        11541
      ],
      "content": "The following sections describe optional configuration options, as well as scenarios that would require these configurations."
    },
    {
      "pos": [
        11547,
        11564
      ],
      "content": "HDInsight version"
    },
    {
      "pos": [
        11566,
        11775
      ],
      "content": "Use this to determine the version of HDInsight used for this cluster. For more information, see <bpt id=\"p29\">[</bpt>Hadoop cluster versions and components in HDInsight<ept id=\"p29\">](https://go.microsoft.com/fwLink/?LinkID=320896&amp;clcid=0x409)</ept>",
      "nodes": [
        {
          "content": "Use this to determine the version of HDInsight used for this cluster.",
          "pos": [
            0,
            69
          ]
        },
        {
          "content": "For more information, see <bpt id=\"p29\">[</bpt>Hadoop cluster versions and components in HDInsight<ept id=\"p29\">](https://go.microsoft.com/fwLink/?LinkID=320896&amp;clcid=0x409)</ept>",
          "pos": [
            70,
            253
          ]
        }
      ]
    },
    {
      "pos": [
        11781,
        11807
      ],
      "content": "Use Azure virtual networks"
    },
    {
      "pos": [
        11809,
        12040
      ],
      "content": "An <bpt id=\"p30\">[</bpt>Azure Virtual Network<ept id=\"p30\">](https://azure.microsoft.com/documentation/services/virtual-network/)</ept><ph id=\"ph35\"/> allows you to create a secure, persistent network containing the resources you need for your solution. A virtual network allows you to:",
      "nodes": [
        {
          "content": "An <bpt id=\"p30\">[</bpt>Azure Virtual Network<ept id=\"p30\">](https://azure.microsoft.com/documentation/services/virtual-network/)</ept><ph id=\"ph35\"/> allows you to create a secure, persistent network containing the resources you need for your solution.",
          "pos": [
            0,
            253
          ]
        },
        {
          "content": "A virtual network allows you to:",
          "pos": [
            254,
            286
          ]
        }
      ]
    },
    {
      "pos": [
        12044,
        12111
      ],
      "content": "Connect cloud resources together in a private network (cloud-only)."
    },
    {
      "pos": [
        12117,
        12236
      ],
      "content": "<ph id=\"ph36\">![</ph>diagram of cloud-only configuration<ph id=\"ph37\">](./media/hdinsight-hadoop-provision-linux-clusters/hdinsight-vnet-cloud-only.png)</ph>"
    },
    {
      "pos": [
        12240,
        12376
      ],
      "content": "Connect your cloud resources to your local data-center network (site-to-site or point-to-site) by using a virtual private network (VPN)."
    },
    {
      "pos": [
        12384,
        12410
      ],
      "content": "Site-to-site configuration"
    },
    {
      "pos": [
        12413,
        12440
      ],
      "content": "Point-to-site configuration"
    },
    {
      "pos": [
        12514,
        12827
      ],
      "content": "Site-to-site configuration allows you to connect multiple resources from your data center to the Azure virtual network by using a hardware VPN or the Routing and Remote Access Service.<ph id=\"ph38\">&lt;br /&gt;</ph><ph id=\"ph39\">![</ph>diagram of site-to-site configuration<ph id=\"ph40\">](./media/hdinsight-hadoop-provision-linux-clusters/hdinsight-vnet-site-to-site.png)</ph>"
    },
    {
      "pos": [
        12830,
        13084
      ],
      "content": "Point-to-site configuration allows you to connect a specific resource to the Azure virtual network by using a software VPN.<ph id=\"ph41\">&lt;br /&gt;</ph><ph id=\"ph42\">![</ph>diagram of point-to-site configuration<ph id=\"ph43\">](./media/hdinsight-hadoop-provision-linux-clusters/hdinsight-vnet-point-to-site.png)</ph>"
    },
    {
      "pos": [
        13088,
        13336
      ],
      "content": "For more information on using HDInsight with a Virtual Network, including specific configuration requirements for the Virtual Network, see <bpt id=\"p31\">[</bpt>Extend HDInsight capbilities by using an Azure Virtual Network<ept id=\"p31\">](hdinsight-extend-hadoop-virtual-network.md)</ept>."
    },
    {
      "pos": [
        13342,
        13351
      ],
      "content": "Metastore"
    },
    {
      "pos": [
        13353,
        13633
      ],
      "content": "The metastore contains Hive and Oozie metadata, such as information about Hive tables, partitions, schemas, and columns. Using the metastore helps you retain your Hive and Oozie metadata, so that you don't have to re-create Hive tables or Oozie jobs when you create a new cluster.",
      "nodes": [
        {
          "content": "The metastore contains Hive and Oozie metadata, such as information about Hive tables, partitions, schemas, and columns.",
          "pos": [
            0,
            120
          ]
        },
        {
          "content": "Using the metastore helps you retain your Hive and Oozie metadata, so that you don't have to re-create Hive tables or Oozie jobs when you create a new cluster.",
          "pos": [
            121,
            280
          ]
        }
      ]
    },
    {
      "pos": [
        13635,
        14011
      ],
      "content": "Using the Metastore configuration option allows you to specify an external metastore using SQL Database. This allows the metadata information to be preserved when you delete a cluster, as it is stored externally in the database. For instructions on how to create a SQL database in Azure, see <bpt id=\"p32\">[</bpt>Create your first Azure SQL Database<ept id=\"p32\">](../sql-database/sql-database-get-started.md)</ept>.",
      "nodes": [
        {
          "content": "Using the Metastore configuration option allows you to specify an external metastore using SQL Database.",
          "pos": [
            0,
            104
          ]
        },
        {
          "content": "This allows the metadata information to be preserved when you delete a cluster, as it is stored externally in the database.",
          "pos": [
            105,
            228
          ]
        },
        {
          "content": "For instructions on how to create a SQL database in Azure, see <bpt id=\"p32\">[</bpt>Create your first Azure SQL Database<ept id=\"p32\">](../sql-database/sql-database-get-started.md)</ept>.",
          "pos": [
            229,
            416
          ]
        }
      ]
    },
    {
      "pos": [
        14015,
        14093
      ],
      "content": "<ph id=\"ph44\">[AZURE.NOTE]</ph><ph id=\"ph45\"/> Metastore configuration is not available for HBase cluster types."
    },
    {
      "pos": [
        14095,
        14098
      ],
      "content": "###"
    },
    {
      "pos": [
        14123,
        14136
      ],
      "content": "Script action"
    },
    {
      "pos": [
        14138,
        14426
      ],
      "content": "You can install additional components or customize cluster configuration by using scripts during cluster provisioning. Such scripts are invoked via <bpt id=\"p33\">**</bpt>Script Action<ept id=\"p33\">**</ept>. For more information, see <bpt id=\"p34\">[</bpt>Customize HDInsight cluster using Script Action<ept id=\"p34\">](hdinsight-hadoop-customize-cluster-linux.md)</ept>.",
      "nodes": [
        {
          "content": "You can install additional components or customize cluster configuration by using scripts during cluster provisioning.",
          "pos": [
            0,
            118
          ]
        },
        {
          "content": "Such scripts are invoked via <bpt id=\"p33\">**</bpt>Script Action<ept id=\"p33\">**</ept>.",
          "pos": [
            119,
            206
          ]
        },
        {
          "content": "For more information, see <bpt id=\"p34\">[</bpt>Customize HDInsight cluster using Script Action<ept id=\"p34\">](hdinsight-hadoop-customize-cluster-linux.md)</ept>.",
          "pos": [
            207,
            368
          ]
        }
      ]
    },
    {
      "pos": [
        14430,
        14697
      ],
      "content": "<ph id=\"ph46\">[AZURE.IMPORTANT]</ph><ph id=\"ph47\"/> Adding additional components after a cluster has been created is not supported, as these components will not be available after a cluster node is reimaged. Components installed through script actions are reinstalled as part of the reimaging process.",
      "nodes": [
        {
          "content": "<ph id=\"ph46\">[AZURE.IMPORTANT]</ph><ph id=\"ph47\"/> Adding additional components after a cluster has been created is not supported, as these components will not be available after a cluster node is reimaged.",
          "pos": [
            0,
            207
          ]
        },
        {
          "content": "Components installed through script actions are reinstalled as part of the reimaging process.",
          "pos": [
            208,
            301
          ]
        }
      ]
    },
    {
      "pos": [
        14703,
        14721
      ],
      "content": "Additional storage"
    },
    {
      "pos": [
        14723,
        14957
      ],
      "content": "In some cases, you may wish to add additional storage to the cluster. For example, if you have multiple Azure Storage Accounts for different geographical regions, or for different services, but want to analyze them all with HDInsight.",
      "nodes": [
        {
          "content": "In some cases, you may wish to add additional storage to the cluster.",
          "pos": [
            0,
            69
          ]
        },
        {
          "content": "For example, if you have multiple Azure Storage Accounts for different geographical regions, or for different services, but want to analyze them all with HDInsight.",
          "pos": [
            70,
            234
          ]
        }
      ]
    },
    {
      "pos": [
        14959,
        15096
      ],
      "content": "For more information on using secondary blob stores, see <bpt id=\"p35\">[</bpt>Using Azure Blob storage with HDInsight<ept id=\"p35\">](hdinsight-hadoop-use-blob-storage.md)</ept>."
    },
    {
      "pos": [
        15098,
        15100
      ],
      "content": "##"
    },
    {
      "pos": [
        15143,
        15159
      ],
      "content": "Creation methods"
    },
    {
      "pos": [
        15161,
        15379
      ],
      "content": "In this article, you have learned basic information about creating a Linux-based HDInsight cluster. Use the table below to find specific information on how to create a cluster using a method that best suits your needs:",
      "nodes": [
        {
          "content": "In this article, you have learned basic information about creating a Linux-based HDInsight cluster.",
          "pos": [
            0,
            99
          ]
        },
        {
          "content": "Use the table below to find specific information on how to create a cluster using a method that best suits your needs:",
          "pos": [
            100,
            218
          ]
        }
      ]
    },
    {
      "pos": [
        15383,
        15414
      ],
      "content": "Use this to create a cluster..."
    },
    {
      "pos": [
        15417,
        15439
      ],
      "content": "Using a web browser..."
    },
    {
      "pos": [
        15442,
        15462
      ],
      "content": "Using a command-line"
    },
    {
      "pos": [
        15465,
        15483
      ],
      "content": "Using the REST API"
    },
    {
      "pos": [
        15486,
        15498
      ],
      "content": "Using an SDK"
    },
    {
      "pos": [
        15501,
        15530
      ],
      "content": "From Linux, Mac OS X, or Unix"
    },
    {
      "pos": [
        15533,
        15545
      ],
      "content": "From Windows"
    },
    {
      "pos": [
        15717,
        15789
      ],
      "content": "<bpt id=\"p36\">[</bpt>Azure preview portal<ept id=\"p36\">](hdinsight-hadoop-create-linux-clusters-portal.md)</ept>"
    },
    {
      "pos": [
        15792,
        15793
      ],
      "content": "✔"
    },
    {
      "pos": [
        15800,
        15806
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        15809,
        15815
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        15818,
        15824
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        15827,
        15828
      ],
      "content": "✔"
    },
    {
      "pos": [
        15836,
        15837
      ],
      "content": "✔"
    },
    {
      "pos": [
        15842,
        15906
      ],
      "content": "<bpt id=\"p37\">[</bpt>Azure CLI<ept id=\"p37\">](hdinsight-hadoop-create-linux-clusters-azure-cli.md)</ept>"
    },
    {
      "pos": [
        15917,
        15923
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        15926,
        15927
      ],
      "content": "✔"
    },
    {
      "pos": [
        15934,
        15940
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        15943,
        15949
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        15952,
        15953
      ],
      "content": "✔"
    },
    {
      "pos": [
        15961,
        15962
      ],
      "content": "✔"
    },
    {
      "pos": [
        15967,
        16045
      ],
      "content": "<bpt id=\"p38\">[</bpt>Azure PowerShell<ept id=\"p38\">](hdinsight-hadoop-create-linux-clusters-azure-powershell.md)</ept>"
    },
    {
      "pos": [
        16048,
        16054
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        16057,
        16058
      ],
      "content": "✔"
    },
    {
      "pos": [
        16065,
        16071
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        16074,
        16080
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        16083,
        16089
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        16092,
        16093
      ],
      "content": "✔"
    },
    {
      "pos": [
        16098,
        16157
      ],
      "content": "<bpt id=\"p39\">[</bpt>cURL<ept id=\"p39\">](hdinsight-hadoop-create-linux-clusters-curl-rest.md)</ept>"
    },
    {
      "pos": [
        16160,
        16166
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        16169,
        16170
      ],
      "content": "✔"
    },
    {
      "pos": [
        16177,
        16178
      ],
      "content": "✔"
    },
    {
      "pos": [
        16181,
        16187
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        16190,
        16191
      ],
      "content": "✔"
    },
    {
      "pos": [
        16199,
        16200
      ],
      "content": "✔"
    },
    {
      "pos": [
        16205,
        16269
      ],
      "content": "<bpt id=\"p40\">[</bpt>.NET SDK<ept id=\"p40\">](hdinsight-hadoop-create-linux-clusters-dotnet-sdk.md)</ept>"
    },
    {
      "pos": [
        16272,
        16278
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        16281,
        16287
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        16290,
        16296
      ],
      "content": "&amp;nbsp;"
    },
    {
      "pos": [
        16299,
        16300
      ],
      "content": "✔"
    },
    {
      "pos": [
        16303,
        16304
      ],
      "content": "✔"
    },
    {
      "pos": [
        16312,
        16313
      ],
      "content": "✔"
    }
  ],
  "content": "<properties\n    pageTitle=\"Create Hadoop, HBase, Storm, or Spark clusters on Linux in HDInsight | Microsoft Azure\"\n    description=\"Learn how to create Hadoop, HBase, Storm, or Spark clusters on Linux for HDInsight using a browser, the Azure CLI, Azure PowerShell, REST, or through an SDK.\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    authors=\"nitinme\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.devlang=\"na\"\n    ms.topic=\"article\"\n    ms.tgt_pltfrm=\"na\"\n    ms.workload=\"big-data\"\n    ms.date=\"01/28/2016\"\n    ms.author=\"nitinme\"/>\n\n\n#Create Linux-based Hadoop clusters in HDInsight\n\n[AZURE.INCLUDE [selector](../../includes/hdinsight-create-linux-cluster-selector.md)]\n\nIn this document, you will learn about the different ways to create a Linux-based HDInsight cluster on Azure, as well as optional configurations that can be used with your cluster. HDInsight provides Apache Hadoop, Apache Storm, and Apache HBase as services on the Azure cloud platform.\n\n> [AZURE.NOTE] This document provides instructions on the different ways to create a cluster. If you are looking for a quick-start approach to create a cluster, see [Get Started with Azure HDInsight on Linux](hdinsight-hadoop-linux-tutorial-get-started.md).\n\n## What is an HDInsight cluster?\n\nA Hadoop cluster consists of several virtual machines (nodes,) which are used for distributed processing of tasks on the cluster. Azure abstracts the implementation details of installation and configuration of individual nodes, so you only have to provide general configuration information.\n\n###Cluster types\n\nThere are several types of HDInsight available:\n\n| Cluster type | Use this if you need... |\n| ------------ | ----------------------------- |\n| Hadoop       | query and analysis (batch jobs)     |\n| HBase        | NoSQL data storage            |\n| Storm        | Real-time event processing |\n| Spark (Preview) | In-memory processing, interactive queries, micro-batch stream processing |\n\nDuring configuration, you will select one of these types for the cluster. You can add other technologies such as Hue or R to these basic types by using [Script Actions](#scriptaction).\n\nEach cluster type has its own terminology for nodes within the cluster, as well as the number of nodes and the default VM size for each node type:\n\n> [AZURE.IMPORTANT] If you plan on more than 32 worker nodes, either at cluster creation or by scaling the cluster after creation, then you must select a head node size with at least 8 cores and 14GB ram.\n\n![HDInsight Hadoop cluster nodes](./media/hdinsight-provision-clusters/HDInsight.Hadoop.roles.png)\n\nHadoop clusters for HDInsight have two types nodes:\n\n- Head node (2 nodes)\n- Data node (at least 1 node)\n\n![HDInsight HBase cluster nodes](./media/hdinsight-provision-clusters/HDInsight.HBase.roles.png)\n\nHBase clusters for HDInsight have three types of nodes:\n- Head servers (2 nodes)\n- Region servers (at least 1 node)\n- Master/Zookeeper nodes (3 nodes)\n\n![HDInsight Storm cluster nodes](./media/hdinsight-provision-clusters/HDInsight.Storm.roles.png)\n\nStorm clusters for HDInsight have three types nodes:\n- Nimbus nodes (2 nodes)\n- Supervisor servers (at least 1 node)\n- Zookeeper nodes (3 nodes)\n\n\n![HDInsight Spark cluster nodes](./media/hdinsight-provision-clusters/HDInsight.Spark.roles.png)\n\nSpark clusters for HDInsight have three types of nodes:\n- Head node (2 nodes)\n- Worker node (at least 1 node)\n- Zookeeper nodes (3 nodes) (Free for A1 Zookeepers VM size)\n\n###Azure Storage for HDInsight\n\nEach cluster type will also have one or more Azure Storage accounts associated with the cluster. HDInsight uses Azure blobs from these storage accounts as the data store for your cluster. Keeping the data separate from the cluster allows you to delete clusters when they aren't in use, and still preserve your data. You can then use the same storage account for a new cluster if you need to do more analysis. For more information, see [Use Azure Blob storage with HDInsight](hdinsight-hadoop-use-blob-storage.md).\n\n## <a id=\"configuration\"></a>Basic configuration options\n\nThe following sections describe the required configuration options available when creating an HDInsight cluster.\n\n###Cluster name\n\nThe cluster name provides a unique identifier for the cluster, and is used as part of the domain name for accessing the cluster over the Internet. For example, a cluster named _mycluster_ will be available over the internet as _mycluster_.azurehdinsight.net.\n\nThe cluster name must follow the following guidelines:\n\n- The field must contain a string that is between 3 and 63 characters\n- The field can contain only letters, numbers, and hyphens\n\n###Cluster type\n\nCluster type allows you to select special purpose configurations for the cluster. The following are the types available for Linux-based HDInsight:\n\n| Cluster type | Use this if you need... |\n| ------------ | ----------------------------- |\n| Hadoop       | query and analysis (batch jobs)     |\n| HBase        | NoSQL data storage            |\n| Storm        | Real-time event processing |\n| Spark (Preview) | In-memory processing, interactive queries, micro-batch stream processing |\n\nYou can add other technologies such as Hue or R to these basic types by using [Script Actions](#scriptaction).\n\n###Cluster operating system\n\nYou can provision HDInsight clusters on one of the following two operating systems:\n\n- **HDInsight on Windows (Windows Server 2012 R2 Datacenter)**: Select this option if you need to integrate with Windows-based services and technologies that will run on the cluster with Hadoop, or if you are migrating from an existing Windows-based Hadoop distribution.\n\n- **HDInsight on Linux (Ubuntu 12.04 LTS for Linux)**: Select this option if you are familiar with Linux or Unix, migrating from an existing Linux-based Hadoop solution, or want easy integration with Hadoop ecosystem components built for Linux. For more information, see [Get started with Hadoop on Linux in HDInsight](hdinsight-hadoop-linux-tutorial-get-started.md).\n\n> [AZURE.NOTE] Information in this document assumes that you are using a Linux-based HDInsight cluster. For information that is specific to Windows-based clusters, see [Create Windows-based Hadoop clusters in HDInsight](hdinsight-provision-clusters.md).\n\n###Subscription name\n\nIf you have multiple Azure subscriptions, use this to select the one you want to use when creating the HDInsight cluster.\n\n###Resource group\n\nApplications are typically made up of many components, for example a web app, database, database server, storage, and 3rd party services. Azure Resource Manager (ARM) enables you to work with the resources in your application as a group, referred to as an Azure Resource Group. You can deploy, update, monitor or delete all of the resources for your application in a single, coordinated operation. You use a template for deployment and that template can work for different environments such as testing, staging and production. You can clarify billing for your organization by viewing the rolled-up costs for the entire group. For more information, see [Azure Resource Manager Overview](../resource-group-overview.md).\n\n###Credentials\n\nThere are two types of authentication used with HDInsight clusters:\n\n* __Admin__ or __HTTPs__ user: The admin account for a cluster is primarily used when accessing web or REST services exposed by the cluster. It cannot be used to directly login to the cluster.\n\n* __SSH username__: An SSH user account is used to remotely access the cluster using a [Secure Shell](https://en.wikipedia.org/wiki/Secure_Shell) client. This is most often used to provide a remote command-line access to the cluster head nodes.\n\nThe admin account is secured by a password, and all web communications to the cluster using the admin account should be performed over a secure HTTPS connection.\n\nThe SSH user can be authenticated using either a password or a certificate. Certificate authentication is the most secure option, however it requires the creation and maintenance of a public and private certificate pair.\n\nFor more information on using SSH with HDInsight, including how to create and use SSH keys, see one of the following articles:\n\n* [For Linux, Unix, or Mac OS X clients - using SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md)\n* [For Windows clients - using SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-windows.md)\n\n###Data source\n\nHDInsight uses Azure Blob Storage as the underlying storage for the cluster. Internally, Hadoop and other software on the cluster sees this storage as a Hadoop Distributed File System (HDFS) compatible system. \n\nWhen creating a new cluster, you must either create a new Azure Storage Account, or use an existing one.\n\n> [AZURE.IMPORTANT] The geographic location you select for the storage account will determine the location of the HDInsight cluster, as the cluster must be in the same data center as the default storage account. \n>\n> For a list of supported regions, click the **Region** drop-down list on [HDInsight pricing](https://go.microsoft.com/fwLink/?LinkID=282635&clcid=0x409).\n\n####Default storage container\n\nHDInsight will also create a _default storage container_ on the storage account. This is the default storage for the HDInsight cluster. \n\nBy default, this container has the same name as the cluster. For more information on how HDInsight works with Azure Blob Storage, see [Use HDFS-compatible Azure Blob storage with Hadoop in HDInsight](hdinsight-hadoop-use-blob-storage.md).\n\n>[AZURE.WARNING] Don't share one container for multiple clusters. This is not supported.\n\n###Node size\n\nYou can select the size of compute resources used by the cluster. For example, if you know that you will be performing operations that need a lot of memory, you may want to select a compute resource with more memory.\n\n>[AZURE.NOTE] The nodes used by your cluster do not count as Virtual Machines, as the Virtual Machines images used for the nodes are an implementation detail of the HDInsight service; however, the compute cores used by the nodes do count against the total number of compute cores available to your subscription. You can see the number of cores that will be used by the cluster, as well as the number of cores available, in the summary section of the Node Pricing Tiers blade when creating an HDInsight cluster.\n\nDifferent cluster types have different node types, number of nodes, and node sizes. For example, a Hadoop cluster type has two _head nodes_ and a default of four _data nodes_, while a Storm cluster type has two _nimbus nodes_, three _zookeeper nodes_, and a default of four _supervisor nodes_.\n\n> [AZURE.IMPORTANT] If you plan on more than 32 worker nodes, either at cluster creation or by scaling the cluster after creation, then you must select a head node size with at least 8 cores and 14GB RAM.\n\nWhen using the Azure preview portal to configure the cluster, the Node size is available through the __Node Pricing Tier__ blade, and will also display the cost associated with the different node sizes. \n\n> [AZURE.IMPORTANT] Billing starts once a cluster is created, and only stops when the cluster is deleted. For more information on pricing, see [HDInsight pricing details](https://azure.microsoft.com/pricing/details/hdinsight/).\n\n##<a id=\"optionalconfiguration\"></a>Optional configuration\n\nThe following sections describe optional configuration options, as well as scenarios that would require these configurations.\n\n### HDInsight version\n\nUse this to determine the version of HDInsight used for this cluster. For more information, see [Hadoop cluster versions and components in HDInsight](https://go.microsoft.com/fwLink/?LinkID=320896&clcid=0x409)\n\n### Use Azure virtual networks\n\nAn [Azure Virtual Network](https://azure.microsoft.com/documentation/services/virtual-network/) allows you to create a secure, persistent network containing the resources you need for your solution. A virtual network allows you to:\n\n* Connect cloud resources together in a private network (cloud-only).\n\n    ![diagram of cloud-only configuration](./media/hdinsight-hadoop-provision-linux-clusters/hdinsight-vnet-cloud-only.png)\n\n* Connect your cloud resources to your local data-center network (site-to-site or point-to-site) by using a virtual private network (VPN).\n\n    | Site-to-site configuration | Point-to-site configuration |\n    | -------------------------- | --------------------------- |\n    | Site-to-site configuration allows you to connect multiple resources from your data center to the Azure virtual network by using a hardware VPN or the Routing and Remote Access Service.<br />![diagram of site-to-site configuration](./media/hdinsight-hadoop-provision-linux-clusters/hdinsight-vnet-site-to-site.png) | Point-to-site configuration allows you to connect a specific resource to the Azure virtual network by using a software VPN.<br />![diagram of point-to-site configuration](./media/hdinsight-hadoop-provision-linux-clusters/hdinsight-vnet-point-to-site.png) |\n\nFor more information on using HDInsight with a Virtual Network, including specific configuration requirements for the Virtual Network, see [Extend HDInsight capbilities by using an Azure Virtual Network](hdinsight-extend-hadoop-virtual-network.md).\n\n### Metastore\n\nThe metastore contains Hive and Oozie metadata, such as information about Hive tables, partitions, schemas, and columns. Using the metastore helps you retain your Hive and Oozie metadata, so that you don't have to re-create Hive tables or Oozie jobs when you create a new cluster.\n\nUsing the Metastore configuration option allows you to specify an external metastore using SQL Database. This allows the metadata information to be preserved when you delete a cluster, as it is stored externally in the database. For instructions on how to create a SQL database in Azure, see [Create your first Azure SQL Database](../sql-database/sql-database-get-started.md).\n\n> [AZURE.NOTE] Metastore configuration is not available for HBase cluster types.\n\n###<a id=\"scriptaction\"></a>Script action\n\nYou can install additional components or customize cluster configuration by using scripts during cluster provisioning. Such scripts are invoked via **Script Action**. For more information, see [Customize HDInsight cluster using Script Action](hdinsight-hadoop-customize-cluster-linux.md).\n\n> [AZURE.IMPORTANT] Adding additional components after a cluster has been created is not supported, as these components will not be available after a cluster node is reimaged. Components installed through script actions are reinstalled as part of the reimaging process.\n\n### Additional storage\n\nIn some cases, you may wish to add additional storage to the cluster. For example, if you have multiple Azure Storage Accounts for different geographical regions, or for different services, but want to analyze them all with HDInsight.\n\nFor more information on using secondary blob stores, see [Using Azure Blob storage with HDInsight](hdinsight-hadoop-use-blob-storage.md).\n\n##<a id=\"nextsteps\"></a><a id=\"options\"></a> Creation methods\n\nIn this article, you have learned basic information about creating a Linux-based HDInsight cluster. Use the table below to find specific information on how to create a cluster using a method that best suits your needs:\n\n| Use this to create a cluster... | Using a web browser... | Using a command-line | Using the REST API | Using an SDK | From Linux, Mac OS X, or Unix | From Windows |\n| ------------------------------- |:----------------------:|:--------------------:|:------------------:|:------------:|:-----------------------------:|:------------:|\n| [Azure preview portal](hdinsight-hadoop-create-linux-clusters-portal.md) | ✔     | &nbsp; | &nbsp; | &nbsp; | ✔      | ✔ |\n| [Azure CLI](hdinsight-hadoop-create-linux-clusters-azure-cli.md)         | &nbsp; | ✔     | &nbsp; | &nbsp; | ✔      | ✔ |\n| [Azure PowerShell](hdinsight-hadoop-create-linux-clusters-azure-powershell.md) | &nbsp; | ✔     | &nbsp; | &nbsp; | &nbsp; | ✔ |\n| [cURL](hdinsight-hadoop-create-linux-clusters-curl-rest.md) | &nbsp; | ✔     | ✔ | &nbsp; | ✔      | ✔ |\n| [.NET SDK](hdinsight-hadoop-create-linux-clusters-dotnet-sdk.md) | &nbsp; | &nbsp; | &nbsp; | ✔ | ✔      | ✔ |\n\n\n[hdinsight-use-mapreduce]: hdinsight-use-mapreduce.md\n[hdinsight-use-hive]: hdinsight-use-hive.md\n[hdinsight-use-pig]: hdinsight-use-pig.md\n[hdinsight-upload-data]: hdinsight-upload-data.md\n[hdinsight-sdk-documentation]: http://msdn.microsoft.com/library/dn479185.aspx\n\n\n[hdinsight-customize-cluster]: hdinsight-hadoop-customize-cluster.md\n[hdinsight-get-started]: hdinsight-get-started.md\n[hdinsight-admin-powershell]: hdinsight-administer-use-powershell.md\n\n[hdinsight-submit-jobs]: hdinsight-submit-hadoop-jobs-programmatically.md\n[hdinsight-powershell-reference]: https://msdn.microsoft.com/library/dn858087.aspx\n\n[azure-management-portal]: https://manage.windowsazure.com/\n\n[azure-command-line-tools]: ../xplat-cli/\n[azure-create-storageaccount]: ../storage/storage-create-storage-account.md\n\n[azure-purchase-options]: http://azure.microsoft.com/pricing/purchase-options/\n[azure-member-offers]: http://azure.microsoft.com/pricing/member-offers/\n[azure-free-trial]: http://azure.microsoft.com/pricing/free-trial/\n[hdi-remote]: http://azure.microsoft.com/documentation/articles/hdinsight-administer-use-management-portal/#rdp\n\n\n[Powershell-install-configure]: ../install-configure-powershell/\n\n[image-hdi-customcreatecluster]: ./media/hdinsight-get-started/HDI.CustomCreateCluster.png\n[image-hdi-customcreatecluster-clusteruser]: ./media/hdinsight-get-started/HDI.CustomCreateCluster.ClusterUser.png\n[image-hdi-customcreatecluster-storageaccount]: ./media/hdinsight-get-started/HDI.CustomCreateCluster.StorageAccount.png\n[image-hdi-customcreatecluster-addonstorage]: ./media/hdinsight-get-started/HDI.CustomCreateCluster.AddOnStorage.png\n\n[azure-preview-portal]: https://portal.azure.com\n\n\n[image-cli-account-download-import]: ./media/hdinsight-hadoop-provision-linux-clusters/HDI.CLIAccountDownloadImport.png\n[image-cli-clustercreation]: ./media/hdinsight-hadoop-provision-linux-clusters/HDI.CLIClusterCreation.png\n[image-cli-clustercreation-config]: ./media/hdinsight-hadoop-provision-linux-clusters/HDI.CLIClusterCreationConfig.png\n[image-cli-clusterlisting]: ./media/hdinsight-hadoop-provision-linux-clusters/HDI.CLIListClusters.png \"List and show clusters\"\n\n[image-hdi-ps-provision]: ./media/hdinsight-hadoop-provision-linux-clusters/HDI.ps.provision.png\n[image-hdi-ps-config-provision]: ./media/hdinsight-hadoop-provision-linux-clusters/HDI.ps.config.provision.png\n\n[img-hdi-cluster]: ./media/hdinsight-hadoop-provision-linux-clusters/HDI.Cluster.png\n\n  [89e2276a]: /documentation/articles/hdinsight-use-sqoop/ \"Use Sqoop with HDInsight\"\n"
}