<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="it-it">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Tips for using Hadoop on Linux-based HDInsight | Microsoft Azure</source>
          <target state="new">Tips for using Hadoop on Linux-based HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Get implementation tips for using Linux-based HDInsight (Hadoop) clusters on a familiar Linux environment running in the Azure cloud.</source>
          <target state="new">Get implementation tips for using Linux-based HDInsight (Hadoop) clusters on a familiar Linux environment running in the Azure cloud.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Information about using HDInsight on Linux</source>
          <target state="new">Information about using HDInsight on Linux</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Linux-based Azure HDInsight clusters provide Hadoop on a familiar Linux environment, running in the Azure cloud.</source>
          <target state="new">Linux-based Azure HDInsight clusters provide Hadoop on a familiar Linux environment, running in the Azure cloud.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>For most things, it should work exactly as any other Hadoop-on-Linux installation.</source>
          <target state="new">For most things, it should work exactly as any other Hadoop-on-Linux installation.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>This document calls out specific differences that you should be aware of.</source>
          <target state="new">This document calls out specific differences that you should be aware of.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Domain names</source>
          <target state="new">Domain names</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>The fully qualified domain name (FQDN) to use when connecting to the cluster from the internet is <bpt id="p1">**</bpt>&amp;lt;clustername&gt;.azurehdinsight.net<ept id="p1">**</ept><ph id="ph2" /> or (for SSH only) <bpt id="p2">**</bpt>&amp;lt;clustername-ssh&gt;.azurehdinsight.net<ept id="p2">**</ept>.</source>
          <target state="new">The fully qualified domain name (FQDN) to use when connecting to the cluster from the internet is <bpt id="p1">**</bpt>&amp;lt;clustername&gt;.azurehdinsight.net<ept id="p1">**</ept><ph id="ph2" /> or (for SSH only) <bpt id="p2">**</bpt>&amp;lt;clustername-ssh&gt;.azurehdinsight.net<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Internally, each node in the cluster has a name that is assigned during cluster configuration.</source>
          <target state="new">Internally, each node in the cluster has a name that is assigned during cluster configuration.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>To find the cluster names, you can visit the <bpt id="p3">__</bpt>Hosts<ept id="p3">__</ept><ph id="ph3" /> page on the Ambari Web UI, or use the following to return a list of hosts from the Ambari REST API using <bpt id="p4">[</bpt>cURL<ept id="p4">](http://curl.haxx.se/)</ept><ph id="ph4" /> and <bpt id="p5">[</bpt>jq<ept id="p5">](https://stedolan.github.io/jq/)</ept>:</source>
          <target state="new">To find the cluster names, you can visit the <bpt id="p3">__</bpt>Hosts<ept id="p3">__</ept><ph id="ph3" /> page on the Ambari Web UI, or use the following to return a list of hosts from the Ambari REST API using <bpt id="p4">[</bpt>cURL<ept id="p4">](http://curl.haxx.se/)</ept><ph id="ph4" /> and <bpt id="p5">[</bpt>jq<ept id="p5">](https://stedolan.github.io/jq/)</ept>:</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Replace <bpt id="p6">__</bpt>PASSWORD<ept id="p6">__</ept><ph id="ph5" /> with the password of the admin account, and <bpt id="p7">__</bpt>CLUSTERNAME<ept id="p7">__</ept><ph id="ph6" /> with the name of your cluster.</source>
          <target state="new">Replace <bpt id="p6">__</bpt>PASSWORD<ept id="p6">__</ept><ph id="ph5" /> with the password of the admin account, and <bpt id="p7">__</bpt>CLUSTERNAME<ept id="p7">__</ept><ph id="ph6" /> with the name of your cluster.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>This will return a JSON document that contains a list of the hosts in the cluster, then jq pulls out the <ph id="ph7">`host_name`</ph><ph id="ph8" /> element value for each host in the cluster.</source>
          <target state="new">This will return a JSON document that contains a list of the hosts in the cluster, then jq pulls out the <ph id="ph7">`host_name`</ph><ph id="ph8" /> element value for each host in the cluster.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>If you need to find the name of the node for a specific service, you can query Ambari for that component.</source>
          <target state="new">If you need to find the name of the node for a specific service, you can query Ambari for that component.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>For example, to find the hosts for the HDFS name node, use the following.</source>
          <target state="new">For example, to find the hosts for the HDFS name node, use the following.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>This returns a JSON document describing the service, and then jq pulls out only the <ph id="ph9">`host_name`</ph><ph id="ph10" /> value for the hosts.</source>
          <target state="new">This returns a JSON document describing the service, and then jq pulls out only the <ph id="ph9">`host_name`</ph><ph id="ph10" /> value for the hosts.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Remote access to services</source>
          <target state="new">Remote access to services</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source><bpt id="p8">**</bpt>Ambari (web)<ept id="p8">**</ept><ph id="ph11" /> - https://&amp;lt;clustername&gt;.azurehdinsight.net</source>
          <target state="new"><bpt id="p8">**</bpt>Ambari (web)<ept id="p8">**</ept><ph id="ph11" /> - https://&amp;lt;clustername&gt;.azurehdinsight.net</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Authenticate by using the cluster administrator user and password, and then log in to Ambari.</source>
          <target state="new">Authenticate by using the cluster administrator user and password, and then log in to Ambari.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>This also uses the cluster administrator user and password.</source>
          <target state="new">This also uses the cluster administrator user and password.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</source>
          <target state="new">Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source><ph id="ph12">[AZURE.IMPORTANT]</ph><ph id="ph13" /> While Ambari for your cluster is accessible directly over the Internet, some functionality relies on accessing nodes by the internal domain name used by the cluster.</source>
          <target state="new"><ph id="ph12">[AZURE.IMPORTANT]</ph><ph id="ph13" /> While Ambari for your cluster is accessible directly over the Internet, some functionality relies on accessing nodes by the internal domain name used by the cluster.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Since this is an internal domain name, and not public, you will receive "server not found" errors when trying to access some features over the Internet.</source>
          <target state="new">Since this is an internal domain name, and not public, you will receive "server not found" errors when trying to access some features over the Internet.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>To use the full functionality of the Ambari web UI, use an SSH tunnel to proxy web traffic to the cluster head node.</source>
          <target state="new">To use the full functionality of the Ambari web UI, use an SSH tunnel to proxy web traffic to the cluster head node.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>See <bpt id="p9">[</bpt>Use SSH Tunneling to access Ambari web UI, ResourceManager, JobHistory, NameNode, Oozie, and other web UI's<ept id="p9">](hdinsight-linux-ambari-ssh-tunnel.md)</ept></source>
          <target state="new">See <bpt id="p9">[</bpt>Use SSH Tunneling to access Ambari web UI, ResourceManager, JobHistory, NameNode, Oozie, and other web UI's<ept id="p9">](hdinsight-linux-ambari-ssh-tunnel.md)</ept></target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source><bpt id="p10">**</bpt>Ambari (REST)<ept id="p10">**</ept><ph id="ph14" /> - https://&amp;lt;clustername&gt;.azurehdinsight.net/ambari</source>
          <target state="new"><bpt id="p10">**</bpt>Ambari (REST)<ept id="p10">**</ept><ph id="ph14" /> - https://&amp;lt;clustername&gt;.azurehdinsight.net/ambari</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source><ph id="ph15">[AZURE.NOTE]</ph><ph id="ph16" /> Authenticate by using the cluster administrator user and password.</source>
          <target state="new"><ph id="ph15">[AZURE.NOTE]</ph><ph id="ph16" /> Authenticate by using the cluster administrator user and password.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</source>
          <target state="new">Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source><bpt id="p11">**</bpt>WebHCat (Templeton)<ept id="p11">**</ept><ph id="ph17" /> - https://&amp;lt;clustername&gt;.azurehdinsight.net/templeton</source>
          <target state="new"><bpt id="p11">**</bpt>WebHCat (Templeton)<ept id="p11">**</ept><ph id="ph17" /> - https://&amp;lt;clustername&gt;.azurehdinsight.net/templeton</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source><ph id="ph18">[AZURE.NOTE]</ph><ph id="ph19" /> Authenticate by using the cluster administrator user and password.</source>
          <target state="new"><ph id="ph18">[AZURE.NOTE]</ph><ph id="ph19" /> Authenticate by using the cluster administrator user and password.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</source>
          <target state="new">Authentication is plaintext - always use HTTPS to help ensure that the connection is secure.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><bpt id="p12">**</bpt>SSH<ept id="p12">**</ept><ph id="ph20" /> - &amp;lt;clustername&gt;-ssh.azurehdinsight.net on port 22 or 23.</source>
          <target state="new"><bpt id="p12">**</bpt>SSH<ept id="p12">**</ept><ph id="ph20" /> - &amp;lt;clustername&gt;-ssh.azurehdinsight.net on port 22 or 23.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Port 22 is used to connect to head node 0, while 23 is used to connect to head node 1.</source>
          <target state="new">Port 22 is used to connect to head node 0, while 23 is used to connect to head node 1.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>For more information on the head nodes, see <bpt id="p13">[</bpt>Availability and reliability of Hadoop clusters in HDInsight<ept id="p13">](hdinsight-high-availability-linux.md)</ept>.</source>
          <target state="new">For more information on the head nodes, see <bpt id="p13">[</bpt>Availability and reliability of Hadoop clusters in HDInsight<ept id="p13">](hdinsight-high-availability-linux.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source><ph id="ph21">[AZURE.NOTE]</ph><ph id="ph22" /> You can only access the cluster head nodes through SSH from a client machine.</source>
          <target state="new"><ph id="ph21">[AZURE.NOTE]</ph><ph id="ph22" /> You can only access the cluster head nodes through SSH from a client machine.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Once connected, you can then access the worker nodes by using SSH from the head node.</source>
          <target state="new">Once connected, you can then access the worker nodes by using SSH from the head node.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>File locations</source>
          <target state="new">File locations</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Hadoop-related files can be found on the cluster nodes at <ph id="ph23">`/usr/hdp`</ph>.</source>
          <target state="new">Hadoop-related files can be found on the cluster nodes at <ph id="ph23">`/usr/hdp`</ph>.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>This directory contains the following subdirectories:</source>
          <target state="new">This directory contains the following subdirectories:</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source><bpt id="p14">__</bpt>2.2.4.9-1<ept id="p14">__</ept>: This directory is named for the version of the Hortonworks Data Platform used by HDInsight, so the number on your cluster may be different than the one listed here.</source>
          <target state="new"><bpt id="p14">__</bpt>2.2.4.9-1<ept id="p14">__</ept>: This directory is named for the version of the Hortonworks Data Platform used by HDInsight, so the number on your cluster may be different than the one listed here.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source><bpt id="p15">__</bpt>current<ept id="p15">__</ept>: This directory contains links to directories under the <bpt id="p16">__</bpt>2.2.4.9-1<ept id="p16">__</ept><ph id="ph24" /> directory, and exists so that you don't have to type a version number (that might change,) every time you want to access a file.</source>
          <target state="new"><bpt id="p15">__</bpt>current<ept id="p15">__</ept>: This directory contains links to directories under the <bpt id="p16">__</bpt>2.2.4.9-1<ept id="p16">__</ept><ph id="ph24" /> directory, and exists so that you don't have to type a version number (that might change,) every time you want to access a file.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Example data and JAR files can be found on Hadoop Distributed File System (HDFS) or Azure Blob storage at '/example' or 'wasb:///example'.</source>
          <target state="new">Example data and JAR files can be found on Hadoop Distributed File System (HDFS) or Azure Blob storage at '/example' or 'wasb:///example'.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>HDFS, Azure Blob storage, and storage best practices</source>
          <target state="new">HDFS, Azure Blob storage, and storage best practices</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>In most Hadoop distributions, HDFS is backed by local storage on the machines in the cluster.</source>
          <target state="new">In most Hadoop distributions, HDFS is backed by local storage on the machines in the cluster.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>While this is efficient, it can be costly for a cloud-based solution where you are charged hourly for compute resources.</source>
          <target state="new">While this is efficient, it can be costly for a cloud-based solution where you are charged hourly for compute resources.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>HDInsight uses Azure Blob storage as the default store, which provides the following benefits:</source>
          <target state="new">HDInsight uses Azure Blob storage as the default store, which provides the following benefits:</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Cheap long-term storage</source>
          <target state="new">Cheap long-term storage</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>Accessibility from external services such as websites, file upload/download utilities, various language SDKs, and web browsers</source>
          <target state="new">Accessibility from external services such as websites, file upload/download utilities, various language SDKs, and web browsers</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Since it is the default store for HDInsight, you normally don't have to do anything to use it.</source>
          <target state="new">Since it is the default store for HDInsight, you normally don't have to do anything to use it.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>For example, the following command will list files in the <bpt id="p17">**</bpt>/example/data<ept id="p17">**</ept><ph id="ph25" /> folder, which is stored on Azure Blob storage:</source>
          <target state="new">For example, the following command will list files in the <bpt id="p17">**</bpt>/example/data<ept id="p17">**</ept><ph id="ph25" /> folder, which is stored on Azure Blob storage:</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Some commands may require you to specify that you are using Blob storage.</source>
          <target state="new">Some commands may require you to specify that you are using Blob storage.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>For these, you can prefix the command with <bpt id="p18">**</bpt>WASB://<ept id="p18">**</ept>.</source>
          <target state="new">For these, you can prefix the command with <bpt id="p18">**</bpt>WASB://<ept id="p18">**</ept>.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>HDInsight also allows you to associate multiple Blob storage accounts with a cluster.</source>
          <target state="new">HDInsight also allows you to associate multiple Blob storage accounts with a cluster.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>To access data on a non-default Blob storage account, you can use the format <bpt id="p19">**</bpt>WASB://&amp;lt;container-name&gt;@&amp;lt;account-name&gt;.blob.core.windows.net/<ept id="p19">**</ept>.</source>
          <target state="new">To access data on a non-default Blob storage account, you can use the format <bpt id="p19">**</bpt>WASB://&amp;lt;container-name&gt;@&amp;lt;account-name&gt;.blob.core.windows.net/<ept id="p19">**</ept>.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>For example, the following will list the contents of the <bpt id="p20">**</bpt>/example/data<ept id="p20">**</ept><ph id="ph26" /> directory for the specified container and Blob storage account:</source>
          <target state="new">For example, the following will list the contents of the <bpt id="p20">**</bpt>/example/data<ept id="p20">**</ept><ph id="ph26" /> directory for the specified container and Blob storage account:</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>What Blob storage is the cluster using?</source>
          <target state="new">What Blob storage is the cluster using?</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>During cluster creation, you selected to either use an existing Azure Storage account and container, or create a new one.</source>
          <target state="new">During cluster creation, you selected to either use an existing Azure Storage account and container, or create a new one.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Then, you probably forgot about it.</source>
          <target state="new">Then, you probably forgot about it.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>You can find the default storage account and container by using the Ambari REST API.</source>
          <target state="new">You can find the default storage account and container by using the Ambari REST API.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Use the following command to retrieve HDFS configuration information using curl, and filter it using <bpt id="p21">[</bpt>jq<ept id="p21">](https://stedolan.github.io/jq/)</ept>:</source>
          <target state="new">Use the following command to retrieve HDFS configuration information using curl, and filter it using <bpt id="p21">[</bpt>jq<ept id="p21">](https://stedolan.github.io/jq/)</ept>:</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source><ph id="ph27">[AZURE.NOTE]</ph><ph id="ph28" /> This will return the first configuration applied to the server (<ph id="ph29">`service_config_version=1`</ph>,) which will contain this information.</source>
          <target state="new"><ph id="ph27">[AZURE.NOTE]</ph><ph id="ph28" /> This will return the first configuration applied to the server (<ph id="ph29">`service_config_version=1`</ph>,) which will contain this information.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>If you are retrieving a value that has been modified after cluster creation, you may need to list the configuration versions and retrieve the latest one.</source>
          <target state="new">If you are retrieving a value that has been modified after cluster creation, you may need to list the configuration versions and retrieve the latest one.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>This will return a value similar to the following, where <bpt id="p22">__</bpt>CONTAINER<ept id="p22">__</ept><ph id="ph30" /> is the default container and <bpt id="p23">__</bpt>ACCOUNTNAME<ept id="p23">__</ept><ph id="ph31" /> is the Azure Storage Account name:</source>
          <target state="new">This will return a value similar to the following, where <bpt id="p22">__</bpt>CONTAINER<ept id="p22">__</ept><ph id="ph30" /> is the default container and <bpt id="p23">__</bpt>ACCOUNTNAME<ept id="p23">__</ept><ph id="ph31" /> is the Azure Storage Account name:</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Get the resource group for the Storage Account, use the <bpt id="p24">[</bpt>Azure CLI<ept id="p24">](../xplat-cli-install.md)</ept>.</source>
          <target state="new">Get the resource group for the Storage Account, use the <bpt id="p24">[</bpt>Azure CLI<ept id="p24">](../xplat-cli-install.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>In the following command, replace <bpt id="p25">__</bpt>ACCOUNTNAME<ept id="p25">__</ept><ph id="ph32" /> with the Storage Account name retrieved from Ambari:</source>
          <target state="new">In the following command, replace <bpt id="p25">__</bpt>ACCOUNTNAME<ept id="p25">__</ept><ph id="ph32" /> with the Storage Account name retrieved from Ambari:</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>This will return the resource group name for the account.</source>
          <target state="new">This will return the resource group name for the account.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source><ph id="ph33">[AZURE.NOTE]</ph><ph id="ph34" /> If nothing is returned from this command, you may need to change the Azure CLI to Azure Resource Manager mode and run the command again.</source>
          <target state="new"><ph id="ph33">[AZURE.NOTE]</ph><ph id="ph34" /> If nothing is returned from this command, you may need to change the Azure CLI to Azure Resource Manager mode and run the command again.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>To switch to Azure Resource Manager mode, use the following command.</source>
          <target state="new">To switch to Azure Resource Manager mode, use the following command.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Get the key for the Storage account.</source>
          <target state="new">Get the key for the Storage account.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Replace <bpt id="p26">__</bpt>GROUPNAME<ept id="p26">__</ept><ph id="ph36" /> with the Resource Group from the previous step.</source>
          <target state="new">Replace <bpt id="p26">__</bpt>GROUPNAME<ept id="p26">__</ept><ph id="ph36" /> with the Resource Group from the previous step.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Replace <bpt id="p27">__</bpt>ACCOUNTNAME<ept id="p27">__</ept><ph id="ph37" /> with the Storage Account name:</source>
          <target state="new">Replace <bpt id="p27">__</bpt>ACCOUNTNAME<ept id="p27">__</ept><ph id="ph37" /> with the Storage Account name:</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>This will return the primary key for the account.</source>
          <target state="new">This will return the primary key for the account.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>You can also find the storage information using the Azure Portal:</source>
          <target state="new">You can also find the storage information using the Azure Portal:</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p28">[</bpt>Azure Portal<ept id="p28">](https://portal.azure.com/)</ept>, select your HDInsight cluster.</source>
          <target state="new">In the <bpt id="p28">[</bpt>Azure Portal<ept id="p28">](https://portal.azure.com/)</ept>, select your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>From the <bpt id="p29">__</bpt>Essentials<ept id="p29">__</ept><ph id="ph38" /> section, select <bpt id="p30">__</bpt>All settings<ept id="p30">__</ept>.</source>
          <target state="new">From the <bpt id="p29">__</bpt>Essentials<ept id="p29">__</ept><ph id="ph38" /> section, select <bpt id="p30">__</bpt>All settings<ept id="p30">__</ept>.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>From <bpt id="p31">__</bpt>Settings<ept id="p31">__</ept>, select <bpt id="p32">__</bpt>Azure Storage Keys<ept id="p32">__</ept>.</source>
          <target state="new">From <bpt id="p31">__</bpt>Settings<ept id="p31">__</ept>, select <bpt id="p32">__</bpt>Azure Storage Keys<ept id="p32">__</ept>.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>From <bpt id="p33">__</bpt>Azure Storage Keys<ept id="p33">__</ept>, select one of the storage accounts listed.</source>
          <target state="new">From <bpt id="p33">__</bpt>Azure Storage Keys<ept id="p33">__</ept>, select one of the storage accounts listed.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>This will display information about the storage account.</source>
          <target state="new">This will display information about the storage account.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>Select the key icon.</source>
          <target state="new">Select the key icon.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>This will display keys for this storage account.</source>
          <target state="new">This will display keys for this storage account.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>How do I access Blob storage?</source>
          <target state="new">How do I access Blob storage?</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>Other than through the Hadoop command from the cluster, there are a variety of ways to access blobs:</source>
          <target state="new">Other than through the Hadoop command from the cluster, there are a variety of ways to access blobs:</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source><bpt id="p34">[</bpt>Azure CLI for Mac, Linux and Windows<ept id="p34">](../xplat-cli-install.md)</ept>: Command-Line interface commands for working with Azure.</source>
          <target state="new"><bpt id="p34">[</bpt>Azure CLI for Mac, Linux and Windows<ept id="p34">](../xplat-cli-install.md)</ept>: Command-Line interface commands for working with Azure.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>After installing, use the <ph id="ph39">`azure storage`</ph><ph id="ph40" /> command for help on using storage, or <ph id="ph41">`azure blob`</ph><ph id="ph42" /> for blob-specific commands.</source>
          <target state="new">After installing, use the <ph id="ph39">`azure storage`</ph><ph id="ph40" /> command for help on using storage, or <ph id="ph41">`azure blob`</ph><ph id="ph42" /> for blob-specific commands.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source><bpt id="p35">[</bpt>blobxfer.py<ept id="p35">](https://github.com/Azure/azure-batch-samples/tree/master/Python/Storage)</ept>: A python script for working with blobs in Azure Storage.</source>
          <target state="new"><bpt id="p35">[</bpt>blobxfer.py<ept id="p35">](https://github.com/Azure/azure-batch-samples/tree/master/Python/Storage)</ept>: A python script for working with blobs in Azure Storage.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>A variety of SDKs:</source>
          <target state="new">A variety of SDKs:</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source><bpt id="p36">[</bpt>Java<ept id="p36">](https://github.com/Azure/azure-sdk-for-java)</ept></source>
          <target state="new"><bpt id="p36">[</bpt>Java<ept id="p36">](https://github.com/Azure/azure-sdk-for-java)</ept></target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source><bpt id="p37">[</bpt>Node.js<ept id="p37">](https://github.com/Azure/azure-sdk-for-node)</ept></source>
          <target state="new"><bpt id="p37">[</bpt>Node.js<ept id="p37">](https://github.com/Azure/azure-sdk-for-node)</ept></target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source><bpt id="p38">[</bpt>PHP<ept id="p38">](https://github.com/Azure/azure-sdk-for-php)</ept></source>
          <target state="new"><bpt id="p38">[</bpt>PHP<ept id="p38">](https://github.com/Azure/azure-sdk-for-php)</ept></target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source><bpt id="p39">[</bpt>Python<ept id="p39">](https://github.com/Azure/azure-sdk-for-python)</ept></source>
          <target state="new"><bpt id="p39">[</bpt>Python<ept id="p39">](https://github.com/Azure/azure-sdk-for-python)</ept></target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source><bpt id="p40">[</bpt>Ruby<ept id="p40">](https://github.com/Azure/azure-sdk-for-ruby)</ept></source>
          <target state="new"><bpt id="p40">[</bpt>Ruby<ept id="p40">](https://github.com/Azure/azure-sdk-for-ruby)</ept></target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source><bpt id="p41">[</bpt>.NET<ept id="p41">](https://github.com/Azure/azure-sdk-for-net)</ept></source>
          <target state="new"><bpt id="p41">[</bpt>.NET<ept id="p41">](https://github.com/Azure/azure-sdk-for-net)</ept></target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source><bpt id="p42">[</bpt>Storage REST API<ept id="p42">](https://msdn.microsoft.com/library/azure/dd135733.aspx)</ept></source>
          <target state="new"><bpt id="p42">[</bpt>Storage REST API<ept id="p42">](https://msdn.microsoft.com/library/azure/dd135733.aspx)</ept></target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>Scaling your cluster</source>
          <target state="new">Scaling your cluster</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>The cluster scaling feature allows you to change the number of data nodes used by a cluster that is running in Azure HDInsight without having to delete and re-create the cluster.</source>
          <target state="new">The cluster scaling feature allows you to change the number of data nodes used by a cluster that is running in Azure HDInsight without having to delete and re-create the cluster.</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>You can perform scaling operations while other jobs or processes are running on a cluster.</source>
          <target state="new">You can perform scaling operations while other jobs or processes are running on a cluster.</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>The different cluster types are affected by scaling as follows:</source>
          <target state="new">The different cluster types are affected by scaling as follows:</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source><bpt id="p43">__</bpt>Hadoop<ept id="p43">__</ept>: When scaling down the number of nodes in a cluster, some of the services in the cluster are restarted.</source>
          <target state="new"><bpt id="p43">__</bpt>Hadoop<ept id="p43">__</ept>: When scaling down the number of nodes in a cluster, some of the services in the cluster are restarted.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>This can cause jobs running or pending to fail at the completion of the scaling operation.</source>
          <target state="new">This can cause jobs running or pending to fail at the completion of the scaling operation.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>You can resubmit the jobs once the operation is complete.</source>
          <target state="new">You can resubmit the jobs once the operation is complete.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source><bpt id="p44">__</bpt>HBase<ept id="p44">__</ept>: Regional servers are automatically balanced within a few minutes after completion of the scaling operation.</source>
          <target state="new"><bpt id="p44">__</bpt>HBase<ept id="p44">__</ept>: Regional servers are automatically balanced within a few minutes after completion of the scaling operation.</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>To manually balance regional servers,use the following steps:</source>
          <target state="new">To manually balance regional servers,use the following steps:</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>Connect to the HDInsight cluster using SSH.</source>
          <target state="new">Connect to the HDInsight cluster using SSH.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>For more information on using SSH with HDInsight, see one of the following documents:</source>
          <target state="new">For more information on using SSH with HDInsight, see one of the following documents:</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source><bpt id="p45">[</bpt>Use SSH with HDInsight from Linux, Unix, and Mac OS X<ept id="p45">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept></source>
          <target state="new"><bpt id="p45">[</bpt>Use SSH with HDInsight from Linux, Unix, and Mac OS X<ept id="p45">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept></target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source><bpt id="p46">[</bpt>Use SSH with HDInsight from Windows<ept id="p46">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept></source>
          <target state="new"><bpt id="p46">[</bpt>Use SSH with HDInsight from Windows<ept id="p46">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept></target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>Use the following to start the HBase shell:</source>
          <target state="new">Use the following to start the HBase shell:</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>Once the HBase shell has loaded, use the following to manually balance the regional servers:</source>
          <target state="new">Once the HBase shell has loaded, use the following to manually balance the regional servers:</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source><bpt id="p47">__</bpt>Storm<ept id="p47">__</ept>: You should rebalance any running Storm topologies after a scaling operation has been performed.</source>
          <target state="new"><bpt id="p47">__</bpt>Storm<ept id="p47">__</ept>: You should rebalance any running Storm topologies after a scaling operation has been performed.</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>This allows the topology to readjust parallelism settings based on the new number of nodes in the cluster.</source>
          <target state="new">This allows the topology to readjust parallelism settings based on the new number of nodes in the cluster.</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>To rebalance running topologies, use one of the following options:</source>
          <target state="new">To rebalance running topologies, use one of the following options:</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source><bpt id="p48">__</bpt>SSH<ept id="p48">__</ept>: Connect to the server and use the following command to rebalance a topology:</source>
          <target state="new"><bpt id="p48">__</bpt>SSH<ept id="p48">__</ept>: Connect to the server and use the following command to rebalance a topology:</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>You can also specify parameters to override the parallelism hints originally provided by the topology.</source>
          <target state="new">You can also specify parameters to override the parallelism hints originally provided by the topology.</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>For example, <ph id="ph43">`storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10`</ph><ph id="ph44" /> will reconfigure the topology to 5 worker processes, 3 executors for the blue-spout component, and 10 executors for the yellow-bolt component.</source>
          <target state="new">For example, <ph id="ph43">`storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10`</ph><ph id="ph44" /> will reconfigure the topology to 5 worker processes, 3 executors for the blue-spout component, and 10 executors for the yellow-bolt component.</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source><bpt id="p49">__</bpt>Storm UI<ept id="p49">__</ept>: Use the following steps to rebalance a topology using the Storm UI.</source>
          <target state="new"><bpt id="p49">__</bpt>Storm UI<ept id="p49">__</ept>: Use the following steps to rebalance a topology using the Storm UI.</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>Open <bpt id="p50">__</bpt>https://CLUSTERNAME.azurehdinsight.net/stormui<ept id="p50">__</ept><ph id="ph45" /> in your web browser, where CLUSTERNAME is the name of your Storm cluster.</source>
          <target state="new">Open <bpt id="p50">__</bpt>https://CLUSTERNAME.azurehdinsight.net/stormui<ept id="p50">__</ept><ph id="ph45" /> in your web browser, where CLUSTERNAME is the name of your Storm cluster.</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>If prompted, enter the HDInsight cluster administrator (admin) name and password you specified when creating the cluster.</source>
          <target state="new">If prompted, enter the HDInsight cluster administrator (admin) name and password you specified when creating the cluster.</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>Select the topology you wish to rebalance, then select the <bpt id="p51">__</bpt>Rebalance<ept id="p51">__</ept><ph id="ph46" /> button.</source>
          <target state="new">Select the topology you wish to rebalance, then select the <bpt id="p51">__</bpt>Rebalance<ept id="p51">__</ept><ph id="ph46" /> button.</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>Enter the delay before the rebalance operation is performed.</source>
          <target state="new">Enter the delay before the rebalance operation is performed.</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>For specific information on scaling your HDInsight cluster, see:</source>
          <target state="new">For specific information on scaling your HDInsight cluster, see:</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source><bpt id="p52">[</bpt>Manage Hadoop clusters in HDInsight by using the Azure Portal<ept id="p52">](hdinsight-administer-use-portal-linux.md#scaling)</ept></source>
          <target state="new"><bpt id="p52">[</bpt>Manage Hadoop clusters in HDInsight by using the Azure Portal<ept id="p52">](hdinsight-administer-use-portal-linux.md#scaling)</ept></target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source><bpt id="p53">[</bpt>Manage Hadoop clusters in HDinsight by using Azure PowerShell<ept id="p53">](hdinsight-administer-use-command-line.md#scaling)</ept></source>
          <target state="new"><bpt id="p53">[</bpt>Manage Hadoop clusters in HDinsight by using Azure PowerShell<ept id="p53">](hdinsight-administer-use-command-line.md#scaling)</ept></target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>How do I install Hue (or other Hadoop component)?</source>
          <target state="new">How do I install Hue (or other Hadoop component)?</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>HDInsight is a managed service, which means that nodes in a cluster may be destroyed and reprovisioned automatically by Azure if a problem is detected.</source>
          <target state="new">HDInsight is a managed service, which means that nodes in a cluster may be destroyed and reprovisioned automatically by Azure if a problem is detected.</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>Because of this, it is not recommended to manually install things directly on the cluster nodes.</source>
          <target state="new">Because of this, it is not recommended to manually install things directly on the cluster nodes.</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>Instead, use <bpt id="p54">[</bpt>HDInsight Script Actions<ept id="p54">](hdinsight-hadoop-customize-cluster.md)</ept><ph id="ph47" /> when you need to install the following:</source>
          <target state="new">Instead, use <bpt id="p54">[</bpt>HDInsight Script Actions<ept id="p54">](hdinsight-hadoop-customize-cluster.md)</ept><ph id="ph47" /> when you need to install the following:</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>A service or web site such as Spark or Hue.</source>
          <target state="new">A service or web site such as Spark or Hue.</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>A component that requires configuration changes on multiple nodes in the cluster.</source>
          <target state="new">A component that requires configuration changes on multiple nodes in the cluster.</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>For example, a required environment variable, creating of a logging directory, or creation of a configuration file.</source>
          <target state="new">For example, a required environment variable, creating of a logging directory, or creation of a configuration file.</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>Script Actions are Bash scripts that are ran during cluster provisioning, and can be used to install and configure additional components on the cluster.</source>
          <target state="new">Script Actions are Bash scripts that are ran during cluster provisioning, and can be used to install and configure additional components on the cluster.</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>Example scripts are provided for installing the following components:</source>
          <target state="new">Example scripts are provided for installing the following components:</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source><bpt id="p55">[</bpt>Hue<ept id="p55">](hdinsight-hadoop-hue-linux.md)</ept></source>
          <target state="new"><bpt id="p55">[</bpt>Hue<ept id="p55">](hdinsight-hadoop-hue-linux.md)</ept></target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source><bpt id="p56">[</bpt>Giraph<ept id="p56">](hdinsight-hadoop-giraph-install-linux.md)</ept></source>
          <target state="new"><bpt id="p56">[</bpt>Giraph<ept id="p56">](hdinsight-hadoop-giraph-install-linux.md)</ept></target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source><bpt id="p57">[</bpt>R<ept id="p57">](hdinsight-hadoop-r-scripts-linux.md)</ept></source>
          <target state="new"><bpt id="p57">[</bpt>R<ept id="p57">](hdinsight-hadoop-r-scripts-linux.md)</ept></target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source><bpt id="p58">[</bpt>Solr<ept id="p58">](hdinsight-hadoop-solr-install-linux.md)</ept></source>
          <target state="new"><bpt id="p58">[</bpt>Solr<ept id="p58">](hdinsight-hadoop-solr-install-linux.md)</ept></target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source><bpt id="p59">[</bpt>Spark<ept id="p59">](hdinsight-hadoop-spark-install-linux.md)</ept></source>
          <target state="new"><bpt id="p59">[</bpt>Spark<ept id="p59">](hdinsight-hadoop-spark-install-linux.md)</ept></target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>For information on developing your own Script Actions, see <bpt id="p60">[</bpt>Script Action development with HDInsight<ept id="p60">](hdinsight-hadoop-script-actions-linux.md)</ept>.</source>
          <target state="new">For information on developing your own Script Actions, see <bpt id="p60">[</bpt>Script Action development with HDInsight<ept id="p60">](hdinsight-hadoop-script-actions-linux.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>Jar files</source>
          <target state="new">Jar files</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source>Some Hadoop technologies are provided in self-contained jar files that are contain functions used as part of a MapReduce job, or from inside Pig or Hive.</source>
          <target state="new">Some Hadoop technologies are provided in self-contained jar files that are contain functions used as part of a MapReduce job, or from inside Pig or Hive.</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>While these can be installed using Script Actions, they often don't require any setup and can just be uploaded to the cluster after provisioning and used directly.</source>
          <target state="new">While these can be installed using Script Actions, they often don't require any setup and can just be uploaded to the cluster after provisioning and used directly.</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>If you want to makle sure the component survives reimaging of the cluster, you can store the jar file in WASB.</source>
          <target state="new">If you want to makle sure the component survives reimaging of the cluster, you can store the jar file in WASB.</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>For example, if you want to use the latest version of <bpt id="p61">[</bpt>DataFu<ept id="p61">](http://datafu.incubator.apache.org/)</ept>, you can download a jar containing the project and upload it to the HDInsight cluster.</source>
          <target state="new">For example, if you want to use the latest version of <bpt id="p61">[</bpt>DataFu<ept id="p61">](http://datafu.incubator.apache.org/)</ept>, you can download a jar containing the project and upload it to the HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>Then follow the DataFu documentation on how to use it from Pig or Hive.</source>
          <target state="new">Then follow the DataFu documentation on how to use it from Pig or Hive.</target>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source><ph id="ph48">[AZURE.IMPORTANT]</ph><ph id="ph49" /> Some components that are standalone jar files are provided with HDInsight, but are not in the path.</source>
          <target state="new"><ph id="ph48">[AZURE.IMPORTANT]</ph><ph id="ph49" /> Some components that are standalone jar files are provided with HDInsight, but are not in the path.</target>
        </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>If you are looking for a specific component, you can use the follow to search for it on your cluster:</source>
          <target state="new">If you are looking for a specific component, you can use the follow to search for it on your cluster:</target>
        </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source>This will return the path of any matching jar files.</source>
          <target state="new">This will return the path of any matching jar files.</target>
        </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source>If the cluster already provides a version of a component as a standalone jar file, but you want to use a different version, you can upload a new version of the component to the cluster and try using it in your jobs.</source>
          <target state="new">If the cluster already provides a version of a component as a standalone jar file, but you want to use a different version, you can upload a new version of the component to the cluster and try using it in your jobs.</target>
        </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source><ph id="ph51">[AZURE.WARNING]</ph><ph id="ph52" /> Components provided with the HDInsight cluster are fully supported and Microsoft Support will help to isolate and resolve issues related to these components.</source>
          <target state="new"><ph id="ph51">[AZURE.WARNING]</ph><ph id="ph52" /> Components provided with the HDInsight cluster are fully supported and Microsoft Support will help to isolate and resolve issues related to these components.</target>
        </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>Custom components receive commercially reasonable support to help you to further troubleshoot the issue.</source>
          <target state="new">Custom components receive commercially reasonable support to help you to further troubleshoot the issue.</target>
        </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>This might result in resolving the issue OR asking you to engage available channels for the open source technologies where deep expertise for that technology is found.</source>
          <target state="new">This might result in resolving the issue OR asking you to engage available channels for the open source technologies where deep expertise for that technology is found.</target>
        </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve">
          <source>For example, there are many community sites that can be used, like: <bpt id="p62">[</bpt>MSDN forum for HDInsight<ept id="p62">](https://social.msdn.microsoft.com/Forums/azure/en-US/home?forum=hdinsight)</ept>, <bpt id="p63">[</bpt>http://stackoverflow.com<ept id="p63">](http://stackoverflow.com)</ept>.</source>
          <target state="new">For example, there are many community sites that can be used, like: <bpt id="p62">[</bpt>MSDN forum for HDInsight<ept id="p62">](https://social.msdn.microsoft.com/Forums/azure/en-US/home?forum=hdinsight)</ept>, <bpt id="p63">[</bpt>http://stackoverflow.com<ept id="p63">](http://stackoverflow.com)</ept>.</target>
        </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve">
          <source>Also Apache projects have project sites on <bpt id="p64">[</bpt>http://apache.org<ept id="p64">](http://apache.org)</ept>, for example: <bpt id="p65">[</bpt>Hadoop<ept id="p65">](http://hadoop.apache.org/)</ept>, <bpt id="p66">[</bpt>Spark<ept id="p66">](http://spark.apache.org/)</ept>.</source>
          <target state="new">Also Apache projects have project sites on <bpt id="p64">[</bpt>http://apache.org<ept id="p64">](http://apache.org)</ept>, for example: <bpt id="p65">[</bpt>Hadoop<ept id="p65">](http://hadoop.apache.org/)</ept>, <bpt id="p66">[</bpt>Spark<ept id="p66">](http://spark.apache.org/)</ept>.</target>
        </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve">
          <source><bpt id="p67">[</bpt>Use Hive with HDInsight<ept id="p67">](hdinsight-use-hive.md)</ept></source>
          <target state="new"><bpt id="p67">[</bpt>Use Hive with HDInsight<ept id="p67">](hdinsight-use-hive.md)</ept></target>
        </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve">
          <source><bpt id="p68">[</bpt>Use Pig with HDInsight<ept id="p68">](hdinsight-use-pig.md)</ept></source>
          <target state="new"><bpt id="p68">[</bpt>Use Pig with HDInsight<ept id="p68">](hdinsight-use-pig.md)</ept></target>
        </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source><bpt id="p69">[</bpt>Use MapReduce jobs with HDInsight<ept id="p69">](hdinsight-use-mapreduce.md)</ept></source>
          <target state="new"><bpt id="p69">[</bpt>Use MapReduce jobs with HDInsight<ept id="p69">](hdinsight-use-mapreduce.md)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">dc8c4fc9decec99be4d29570e662decb97039cdd</xliffext:olfilehash>
  </header>
</xliff>