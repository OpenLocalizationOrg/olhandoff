<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" source-language="en-US" target-language="it-it">
    <body>
      <group id="main" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Known issues of Apache Spark in HDInsight | Microsoft Azure</source>
          <target state="new">Known issues of Apache Spark in HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Known issues of Apache Spark in HDInsight.</source>
          <target state="new">Known issues of Apache Spark in HDInsight.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Known issues of Apache Spark in Azure HDInsight (Linux)</source>
          <target state="new">Known issues of Apache Spark in Azure HDInsight (Linux)</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>This document keeps track of all the known issues for the HDInsight Spark public preview.</source>
          <target state="new">This document keeps track of all the known issues for the HDInsight Spark public preview.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Livy leaks interactive session</source>
          <target state="new">Livy leaks interactive session</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Symptom:<ept id="p1">**</ept></source>
          <target state="new"><bpt id="p1">**</bpt>Symptom:<ept id="p1">**</ept></target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>When Livy is restarted with an interactive session (from Ambari or due to headnode 0 virtual machine reboot) still alive, an interactive job session will be leaked.</source>
          <target state="new">When Livy is restarted with an interactive session (from Ambari or due to headnode 0 virtual machine reboot) still alive, an interactive job session will be leaked.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Because of this, new jobs can stuck in the Accepted state, and cannot be started.</source>
          <target state="new">Because of this, new jobs can stuck in the Accepted state, and cannot be started.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source><bpt id="p2">**</bpt>Mitigation:<ept id="p2">**</ept></source>
          <target state="new"><bpt id="p2">**</bpt>Mitigation:<ept id="p2">**</ept></target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Use the following procedure to workaround the issue:</source>
          <target state="new">Use the following procedure to workaround the issue:</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Ssh into headnode.</source>
          <target state="new">Ssh into headnode.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Run the following command to find the application IDs of the interactive jobs started through Livy.</source>
          <target state="new">Run the following command to find the application IDs of the interactive jobs started through Livy.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>The default job names will be Livy if the jobs were started with a Livy interactive session with no explicit names specified, For the Livy session started by Jupyter notebook, the job name will start with remotesparkmagics_*.</source>
          <target state="new">The default job names will be Livy if the jobs were started with a Livy interactive session with no explicit names specified, For the Livy session started by Jupyter notebook, the job name will start with remotesparkmagics_*.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Run the following command to kill those jobs.</source>
          <target state="new">Run the following command to kill those jobs.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>New jobs will start running.</source>
          <target state="new">New jobs will start running.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Spark History Server not started</source>
          <target state="new">Spark History Server not started</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source><bpt id="p3">**</bpt>Symptom:<ept id="p3">**</ept></source>
          <target state="new"><bpt id="p3">**</bpt>Symptom:<ept id="p3">**</ept></target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Spark History Server is not started automatically after a cluster is created.</source>
          <target state="new">Spark History Server is not started automatically after a cluster is created.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p4">**</bpt>Mitigation:<ept id="p4">**</ept></source>
          <target state="new"><bpt id="p4">**</bpt>Mitigation:<ept id="p4">**</ept></target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Manually start the history server from Ambari.</source>
          <target state="new">Manually start the history server from Ambari.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Error while loading a Notebooks larger than 2MB</source>
          <target state="new">Error while loading a Notebooks larger than 2MB</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source><bpt id="p5">**</bpt>Symptom:<ept id="p5">**</ept></source>
          <target state="new"><bpt id="p5">**</bpt>Symptom:<ept id="p5">**</ept></target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>You might see an error <bpt id="p6">**</bpt><ph id="ph2">`Error loading notebook`</ph><ept id="p6">**</ept><ph id="ph3" /> when you load notebooks that are larger than 2MB.</source>
          <target state="new">You might see an error <bpt id="p6">**</bpt><ph id="ph2">`Error loading notebook`</ph><ept id="p6">**</ept><ph id="ph3" /> when you load notebooks that are larger than 2MB.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source><bpt id="p7">**</bpt>Mitigation:<ept id="p7">**</ept></source>
          <target state="new"><bpt id="p7">**</bpt>Mitigation:<ept id="p7">**</ept></target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>If you get this error, it does not mean your data is corrupt or lost.</source>
          <target state="new">If you get this error, it does not mean your data is corrupt or lost.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Your notebooks are still on disk in <ph id="ph4">`/var/lib/jupyter`</ph>, and you can SSH into the cluster to access them.</source>
          <target state="new">Your notebooks are still on disk in <ph id="ph4">`/var/lib/jupyter`</ph>, and you can SSH into the cluster to access them.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>You can copy your notebooks from your cluster to your local machine (using SCP or WinSCP) as a backup to prevent the loss of any important data in the notebook.</source>
          <target state="new">You can copy your notebooks from your cluster to your local machine (using SCP or WinSCP) as a backup to prevent the loss of any important data in the notebook.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>You can then SSH tunnel into your headnode at port 8001 to access Jupyter without going through the gateway.</source>
          <target state="new">You can then SSH tunnel into your headnode at port 8001 to access Jupyter without going through the gateway.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>From there, you can clear the output of your notebook and re-save it to minimize the notebook’s size.</source>
          <target state="new">From there, you can clear the output of your notebook and re-save it to minimize the notebook’s size.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>To prevent this error from happening in the future, you must follow some best practices:</source>
          <target state="new">To prevent this error from happening in the future, you must follow some best practices:</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>It is important to keep the notebook size small.</source>
          <target state="new">It is important to keep the notebook size small.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Any output from your Spark jobs that is sent back to Jupyter is persisted in the notebook.</source>
          <target state="new">Any output from your Spark jobs that is sent back to Jupyter is persisted in the notebook.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>It is a best practice with Jupyter in general to avoid running <ph id="ph5">`.collect()`</ph><ph id="ph6" /> on large RDD’s or dataframes; instead, if you want to peek at an RDD’s contents, consider running <ph id="ph7">`.take()`</ph><ph id="ph8" /> or <ph id="ph9">`.sample()`</ph><ph id="ph10" /> so that your output doesn’t get too big.</source>
          <target state="new">It is a best practice with Jupyter in general to avoid running <ph id="ph5">`.collect()`</ph><ph id="ph6" /> on large RDD’s or dataframes; instead, if you want to peek at an RDD’s contents, consider running <ph id="ph7">`.take()`</ph><ph id="ph8" /> or <ph id="ph9">`.sample()`</ph><ph id="ph10" /> so that your output doesn’t get too big.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Also, when you save a notebook, clear all output cells to reduce the size.</source>
          <target state="new">Also, when you save a notebook, clear all output cells to reduce the size.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Notebook initial startup takes longer than expected</source>
          <target state="new">Notebook initial startup takes longer than expected</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source><bpt id="p8">**</bpt>Symptom:<ept id="p8">**</ept></source>
          <target state="new"><bpt id="p8">**</bpt>Symptom:<ept id="p8">**</ept></target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>First statement in Jupyter notebook using Spark Magic could take more than a minute.</source>
          <target state="new">First statement in Jupyter notebook using Spark Magic could take more than a minute.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source><bpt id="p9">**</bpt>Mitigation:<ept id="p9">**</ept></source>
          <target state="new"><bpt id="p9">**</bpt>Mitigation:<ept id="p9">**</ept></target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>No workaround.</source>
          <target state="new">No workaround.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>It takes a minute sometimes.</source>
          <target state="new">It takes a minute sometimes.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Jupyter notebook timeout in creating the session</source>
          <target state="new">Jupyter notebook timeout in creating the session</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source><bpt id="p10">**</bpt>Symptom:<ept id="p10">**</ept></source>
          <target state="new"><bpt id="p10">**</bpt>Symptom:<ept id="p10">**</ept></target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>When Spark cluster is out of resources, the Spark and Pyspark kernels in the Jupyter notebook will timeout trying to create the session.</source>
          <target state="new">When Spark cluster is out of resources, the Spark and Pyspark kernels in the Jupyter notebook will timeout trying to create the session.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Mitigations:</source>
          <target state="new">Mitigations:</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Free up some resources in your Spark cluster by:</source>
          <target state="new">Free up some resources in your Spark cluster by:</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>Stop other Spark notebooks by going to the Close and Halt menu or clicking Shutdown in the notebook explorer.</source>
          <target state="new">Stop other Spark notebooks by going to the Close and Halt menu or clicking Shutdown in the notebook explorer.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Stop other Spark applications from YARN.</source>
          <target state="new">Stop other Spark applications from YARN.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>Restart the notebook you were trying to start up.</source>
          <target state="new">Restart the notebook you were trying to start up.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Enough resources should be available for you to create a session now.</source>
          <target state="new">Enough resources should be available for you to create a session now.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>Notebook output results formatting issue</source>
          <target state="new">Notebook output results formatting issue</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source><bpt id="p11">**</bpt>Symptom:<ept id="p11">**</ept></source>
          <target state="new"><bpt id="p11">**</bpt>Symptom:<ept id="p11">**</ept></target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>Notebook output results are badly formatted after executing a cell from the Spark and Pyspark Jupyter kernels.</source>
          <target state="new">Notebook output results are badly formatted after executing a cell from the Spark and Pyspark Jupyter kernels.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>This includes successful results from cell executions as well as Spark stacktraces or other errors.</source>
          <target state="new">This includes successful results from cell executions as well as Spark stacktraces or other errors.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source><bpt id="p12">**</bpt>Mitigation:<ept id="p12">**</ept></source>
          <target state="new"><bpt id="p12">**</bpt>Mitigation:<ept id="p12">**</ept></target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>This issue will be addressed in a future release.</source>
          <target state="new">This issue will be addressed in a future release.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Typos in sample notebooks</source>
          <target state="new">Typos in sample notebooks</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source><bpt id="p13">**</bpt>Python notebook 4 (Analyze logs with Spark using a custom library)<ept id="p13">**</ept></source>
          <target state="new"><bpt id="p13">**</bpt>Python notebook 4 (Analyze logs with Spark using a custom library)<ept id="p13">**</ept></target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>"Let us assume you copy it over to wasb:///example/data/iislogparser.py" should be "Let us assume you copy it over to wasb:///HdiSamples/HdiSamples/WebsiteLogSampleData/iislogparser.py".</source>
          <target state="new">"Let us assume you copy it over to wasb:///example/data/iislogparser.py" should be "Let us assume you copy it over to wasb:///HdiSamples/HdiSamples/WebsiteLogSampleData/iislogparser.py".</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source><bpt id="p14">**</bpt>Python notebook 5 (Spark Machine Learning - Predictive analysis on food inspection data using MLLib)<ept id="p14">**</ept></source>
          <target state="new"><bpt id="p14">**</bpt>Python notebook 5 (Spark Machine Learning - Predictive analysis on food inspection data using MLLib)<ept id="p14">**</ept></target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>"A quick visualization can help us reason about the distribution of these outcomes" contains some incorrect code that will not run.</source>
          <target state="new">"A quick visualization can help us reason about the distribution of these outcomes" contains some incorrect code that will not run.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>It should be edited to the following:</source>
          <target state="new">It should be edited to the following:</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source><bpt id="p15">**</bpt>Python notebook 5 (Spark Machine Learning - Predictive analysis on food inspection data using MLLib)<ept id="p15">**</ept></source>
          <target state="new"><bpt id="p15">**</bpt>Python notebook 5 (Spark Machine Learning - Predictive analysis on food inspection data using MLLib)<ept id="p15">**</ept></target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>The final comment notes that the false negative rate and false positive rate are 12.6% and 16.0% respectively.</source>
          <target state="new">The final comment notes that the false negative rate and false positive rate are 12.6% and 16.0% respectively.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>These numbers are inaccurate; run the code to display the pie graph with the true percentages.</source>
          <target state="new">These numbers are inaccurate; run the code to display the pie graph with the true percentages.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source><bpt id="p16">**</bpt>Python notebooks 6 and 7<ept id="p16">**</ept></source>
          <target state="new"><bpt id="p16">**</bpt>Python notebooks 6 and 7<ept id="p16">**</ept></target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>The first cell fails to register the sc.stop() method to be called when the notebook exits.</source>
          <target state="new">The first cell fails to register the sc.stop() method to be called when the notebook exits.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Under certain circumstances this could cause Spark resources to leak.</source>
          <target state="new">Under certain circumstances this could cause Spark resources to leak.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>You can avoid this by making sure to run import atexit; atexit.register(lambda: sc.stop()) in those notebooks before stopping them.</source>
          <target state="new">You can avoid this by making sure to run import atexit; atexit.register(lambda: sc.stop()) in those notebooks before stopping them.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>If you have accidentally leaked resources, then follow the instructions above to kill leaked YARN applications.</source>
          <target state="new">If you have accidentally leaked resources, then follow the instructions above to kill leaked YARN applications.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Cannot customize core/memory configurations</source>
          <target state="new">Cannot customize core/memory configurations</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source><bpt id="p17">**</bpt>Symptom:<ept id="p17">**</ept></source>
          <target state="new"><bpt id="p17">**</bpt>Symptom:<ept id="p17">**</ept></target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>You cannot specify different core/memory configurations than the default from the Spark/Pyspark kernels.</source>
          <target state="new">You cannot specify different core/memory configurations than the default from the Spark/Pyspark kernels.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source><bpt id="p18">**</bpt>Mitigation:<ept id="p18">**</ept></source>
          <target state="new"><bpt id="p18">**</bpt>Mitigation:<ept id="p18">**</ept></target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>This feature is coming.</source>
          <target state="new">This feature is coming.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Permission issue in Spark log directory</source>
          <target state="new">Permission issue in Spark log directory</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source><bpt id="p19">**</bpt>Symptom:<ept id="p19">**</ept></source>
          <target state="new"><bpt id="p19">**</bpt>Symptom:<ept id="p19">**</ept></target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>When hdiuser submits a job with spark-submit, there is an error java.io.FileNotFoundException: /var/log/spark/sparkdriver_hdiuser.log (Permission denied) and the driver log is not written.</source>
          <target state="new">When hdiuser submits a job with spark-submit, there is an error java.io.FileNotFoundException: /var/log/spark/sparkdriver_hdiuser.log (Permission denied) and the driver log is not written.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source><bpt id="p20">**</bpt>Mitigation:<ept id="p20">**</ept></source>
          <target state="new"><bpt id="p20">**</bpt>Mitigation:<ept id="p20">**</ept></target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>Add hdiuser to the Hadoop group.</source>
          <target state="new">Add hdiuser to the Hadoop group.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>Provide 777 permissions on /var/log/spark after cluster creation.</source>
          <target state="new">Provide 777 permissions on /var/log/spark after cluster creation.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>Update the spark log location using Ambari to be a directory with 777 permissions.</source>
          <target state="new">Update the spark log location using Ambari to be a directory with 777 permissions.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>Run spark-submit as sudo.</source>
          <target state="new">Run spark-submit as sudo.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>See also</source>
          <target state="new">See also</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source><bpt id="p21">[</bpt>Overview: Apache Spark on Azure HDInsight (Linux)<ept id="p21">](hdinsight-apache-spark-overview.md)</ept></source>
          <target state="new"><bpt id="p21">[</bpt>Overview: Apache Spark on Azure HDInsight (Linux)<ept id="p21">](hdinsight-apache-spark-overview.md)</ept></target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source><bpt id="p22">[</bpt>Get started: Provision Apache Spark on Azure HDInsight (Linux) and run interactive queries using Spark SQL<ept id="p22">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept></source>
          <target state="new"><bpt id="p22">[</bpt>Get started: Provision Apache Spark on Azure HDInsight (Linux) and run interactive queries using Spark SQL<ept id="p22">](hdinsight-apache-spark-jupyter-spark-sql.md)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">62b6d1e7fce9ed49f1840c0c17f0174f7651268d</xliffext:olfilehash>
  </header>
</xliff>