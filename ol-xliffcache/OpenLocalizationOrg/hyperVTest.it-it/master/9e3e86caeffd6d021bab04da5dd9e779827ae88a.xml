{
  "nodes": [
    {
      "pos": [
        27,
        142
      ],
      "content": "Create a Spark cluster on HDInsight Linux and use Spark SQL from Jupyter for interactive analysis | Microsoft Azure"
    },
    {
      "pos": [
        161,
        322
      ],
      "content": "Step-by-step instructions on how to quickly create an Apache Spark cluster in HDInsight and then use Spark SQL from Jupyter notebooks to run interactive queries."
    },
    {
      "pos": [
        651,
        762
      ],
      "content": "Get started: Create Apache Spark cluster on Azure HDInsight (Linux) and run interactive queries using Spark SQL"
    },
    {
      "pos": [
        764,
        932
      ],
      "content": "Learn how to create an Apache Spark cluster in HDInsight and then use <bpt id=\"p1\">[</bpt>Jupyter<ept id=\"p1\">](https://jupyter.org)</ept><ph id=\"ph2\"/> notebook to run Spark SQL interactive queries on the Spark cluster."
    },
    {
      "pos": [
        937,
        1206
      ],
      "content": "<ph id=\"ph3\">![</ph>Get started using Apache Spark in HDInsight<ph id=\"ph4\">](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.getstartedflow.png  \"Get started using Apache Spark in HDInsight tutorial. Steps illustrated: create a storage account; create a cluster; run Spark SQL statements\")</ph>"
    },
    {
      "pos": [
        1208,
        1226
      ],
      "content": "<bpt id=\"p2\">**</bpt>Prerequisites:<ept id=\"p2\">**</ept>"
    },
    {
      "pos": [
        1230,
        1457
      ],
      "content": "<bpt id=\"p3\">**</bpt>An Azure subscription<ept id=\"p3\">**</ept>. Before you begin this tutorial, you must have an Azure subscription. See <bpt id=\"p4\">[</bpt>Get Azure free trial<ept id=\"p4\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
      "nodes": [
        {
          "content": "<bpt id=\"p3\">**</bpt>An Azure subscription<ept id=\"p3\">**</ept>.",
          "pos": [
            0,
            64
          ]
        },
        {
          "content": "Before you begin this tutorial, you must have an Azure subscription.",
          "pos": [
            65,
            133
          ]
        },
        {
          "content": "See <bpt id=\"p4\">[</bpt>Get Azure free trial<ept id=\"p4\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
          "pos": [
            134,
            303
          ]
        }
      ]
    },
    {
      "pos": [
        1461,
        1680
      ],
      "content": "<bpt id=\"p5\">**</bpt>A Secure Shell (SSH) client<ept id=\"p5\">**</ept>: Linux, Unix, and OS X systems provied an SSH client through the <ph id=\"ph5\">`ssh`</ph><ph id=\"ph6\"/> command. For Windows systems, we recommend <bpt id=\"p6\">[</bpt>PuTTY<ept id=\"p6\">](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html)</ept>.",
      "nodes": [
        {
          "content": "<bpt id=\"p5\">**</bpt>A Secure Shell (SSH) client<ept id=\"p5\">**</ept>: Linux, Unix, and OS X systems provied an SSH client through the <ph id=\"ph5\">`ssh`</ph><ph id=\"ph6\"/> command.",
          "pos": [
            0,
            181
          ]
        },
        {
          "content": "For Windows systems, we recommend <bpt id=\"p6\">[</bpt>PuTTY<ept id=\"p6\">](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html)</ept>.",
          "pos": [
            182,
            327
          ]
        }
      ]
    },
    {
      "pos": [
        1688,
        2253
      ],
      "content": "<bpt id=\"p7\">**</bpt>Secure Shell (SSH) keys (optional)<ept id=\"p7\">**</ept>: You can secure the SSH account used to connect to the cluster using either a password or a public key. Using a password gets you started quickly, and you should use this option if you want to quickly create a cluster and run some test jobs. Using a key is more secure, however it requires additional setup. You might want to use this approach when creating a production cluster. In this article, we use the password approach. For instructions on how to create and use SSH keys with HDInsight, refer to the following articles:",
      "nodes": [
        {
          "content": "<bpt id=\"p7\">**</bpt>Secure Shell (SSH) keys (optional)<ept id=\"p7\">**</ept>: You can secure the SSH account used to connect to the cluster using either a password or a public key.",
          "pos": [
            0,
            180
          ]
        },
        {
          "content": "Using a password gets you started quickly, and you should use this option if you want to quickly create a cluster and run some test jobs.",
          "pos": [
            181,
            318
          ]
        },
        {
          "content": "Using a key is more secure, however it requires additional setup.",
          "pos": [
            319,
            384
          ]
        },
        {
          "content": "You might want to use this approach when creating a production cluster.",
          "pos": [
            385,
            456
          ]
        },
        {
          "content": "In this article, we use the password approach.",
          "pos": [
            457,
            503
          ]
        },
        {
          "content": "For instructions on how to create and use SSH keys with HDInsight, refer to the following articles:",
          "pos": [
            504,
            603
          ]
        }
      ]
    },
    {
      "pos": [
        2262,
        2398
      ],
      "content": "From a Linux computer - <bpt id=\"p8\">[</bpt>Use SSH with Linux-based HDInsight (Hadoop) from Linux, Unix, or OS X<ept id=\"p8\">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept>."
    },
    {
      "pos": [
        2411,
        2539
      ],
      "content": "From a Windows computer - <bpt id=\"p9\">[</bpt>Use SSH with Linux-based HDInsight (Hadoop) from Windows<ept id=\"p9\">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept>."
    },
    {
      "pos": [
        2545,
        2586
      ],
      "content": "Create a Spark cluster on HDInsight Linux"
    },
    {
      "pos": [
        2588,
        2818
      ],
      "content": "In this section, you create an HDInsight version 3.3 cluster, which is based on Spark version 1.5.1. For information about HDInsight versions and their SLAs, see <bpt id=\"p10\">[</bpt>HDInsight component versioning<ept id=\"p10\">](hdinsight-component-versioning.md)</ept>.",
      "nodes": [
        {
          "content": "In this section, you create an HDInsight version 3.3 cluster, which is based on Spark version 1.5.1.",
          "pos": [
            0,
            100
          ]
        },
        {
          "content": "For information about HDInsight versions and their SLAs, see <bpt id=\"p10\">[</bpt>HDInsight component versioning<ept id=\"p10\">](hdinsight-component-versioning.md)</ept>.",
          "pos": [
            101,
            270
          ]
        }
      ]
    },
    {
      "pos": [
        2821,
        3194
      ],
      "content": "<ph id=\"ph7\">[AZURE.NOTE]</ph><ph id=\"ph8\"/> The steps in this article create an Apache Spark cluster in HDInsight by using basic configuration settings. For information about other cluster configuration settings (such as using additional storage, an Azure virtual network, or a metastore for Hive), see <bpt id=\"p11\">[</bpt>Create HDInsight Spark clusters using custom options<ept id=\"p11\">](hdinsight-hadoop-provision-linux-clusters.md)</ept>.",
      "nodes": [
        {
          "content": "<ph id=\"ph7\">[AZURE.NOTE]</ph><ph id=\"ph8\"/> The steps in this article create an Apache Spark cluster in HDInsight by using basic configuration settings.",
          "pos": [
            0,
            153
          ]
        },
        {
          "content": "For information about other cluster configuration settings (such as using additional storage, an Azure virtual network, or a metastore for Hive), see <bpt id=\"p11\">[</bpt>Create HDInsight Spark clusters using custom options<ept id=\"p11\">](hdinsight-hadoop-provision-linux-clusters.md)</ept>.",
          "pos": [
            154,
            445
          ]
        }
      ]
    },
    {
      "pos": [
        3197,
        3226
      ],
      "content": "<bpt id=\"p12\">**</bpt>To create a Spark cluster<ept id=\"p12\">**</ept>"
    },
    {
      "pos": [
        3231,
        3299
      ],
      "content": "Sign in to the <bpt id=\"p13\">[</bpt>Azure preview portal<ept id=\"p13\">](https://ms.portal.azure.com/)</ept>."
    },
    {
      "pos": [
        3304,
        3376
      ],
      "content": "Click <bpt id=\"p14\">**</bpt>NEW<ept id=\"p14\">**</ept>, click <bpt id=\"p15\">**</bpt>Data + Analytics<ept id=\"p15\">**</ept>, and then click <bpt id=\"p16\">**</bpt>HDInsight<ept id=\"p16\">**</ept>."
    },
    {
      "pos": [
        3382,
        3567
      ],
      "content": "<ph id=\"ph9\">![</ph>Creating a new cluster in the Azure preview portal<ph id=\"ph10\">](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.createcluster.1.png \"Creating a new cluster in the Azure preview portal\")</ph>"
    },
    {
      "pos": [
        3572,
        3818
      ],
      "content": "Enter a <bpt id=\"p17\">**</bpt>Cluster Name<ept id=\"p17\">**</ept>, select <bpt id=\"p18\">**</bpt>Hadoop<ept id=\"p18\">**</ept><ph id=\"ph11\"/> for the <bpt id=\"p19\">**</bpt>Cluster Type<ept id=\"p19\">**</ept>, from the <bpt id=\"p20\">**</bpt>Cluster Operating System<ept id=\"p20\">**</ept><ph id=\"ph12\"/> drop-down menu, select <bpt id=\"p21\">**</bpt>Ubuntu<ept id=\"p21\">**</ept>, and then select the version of Spark. A green check appears beside the cluster name if it is available.",
      "nodes": [
        {
          "content": "Enter a <bpt id=\"p17\">**</bpt>Cluster Name<ept id=\"p17\">**</ept>, select <bpt id=\"p18\">**</bpt>Hadoop<ept id=\"p18\">**</ept><ph id=\"ph11\"/> for the <bpt id=\"p19\">**</bpt>Cluster Type<ept id=\"p19\">**</ept>, from the <bpt id=\"p20\">**</bpt>Cluster Operating System<ept id=\"p20\">**</ept><ph id=\"ph12\"/> drop-down menu, select <bpt id=\"p21\">**</bpt>Ubuntu<ept id=\"p21\">**</ept>, and then select the version of Spark.",
          "pos": [
            0,
            410
          ]
        },
        {
          "content": "A green check appears beside the cluster name if it is available.",
          "pos": [
            411,
            476
          ]
        }
      ]
    },
    {
      "pos": [
        3824,
        3963
      ],
      "content": "<ph id=\"ph13\">![</ph>Enter cluster name and type<ph id=\"ph14\">](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.createcluster.2.png \"Enter cluster name and type\")</ph>"
    },
    {
      "pos": [
        3968,
        4097
      ],
      "content": "If you have more than one subscription, click the <bpt id=\"p22\">**</bpt>Subscription<ept id=\"p22\">**</ept><ph id=\"ph15\"/> entry to select the Azure subscription to use for the cluster."
    },
    {
      "pos": [
        4102,
        4362
      ],
      "content": "Click <bpt id=\"p23\">**</bpt>Resource Group<ept id=\"p23\">**</ept><ph id=\"ph16\"/> to see a list of existing resource groups and select where to create the cluster. Or, you can click <bpt id=\"p24\">**</bpt>Create New<ept id=\"p24\">**</ept><ph id=\"ph17\"/> and then enter the name of the new resource group. A green check appears to indicate if the new group name is available.",
      "nodes": [
        {
          "content": "Click <bpt id=\"p23\">**</bpt>Resource Group<ept id=\"p23\">**</ept><ph id=\"ph16\"/> to see a list of existing resource groups and select where to create the cluster.",
          "pos": [
            0,
            161
          ]
        },
        {
          "content": "Or, you can click <bpt id=\"p24\">**</bpt>Create New<ept id=\"p24\">**</ept><ph id=\"ph17\"/> and then enter the name of the new resource group.",
          "pos": [
            162,
            300
          ]
        },
        {
          "content": "A green check appears to indicate if the new group name is available.",
          "pos": [
            301,
            370
          ]
        }
      ]
    },
    {
      "pos": [
        4370,
        4465
      ],
      "content": "<ph id=\"ph18\">[AZURE.NOTE]</ph><ph id=\"ph19\"/> This entry defaults to one of your existing resource groups, if any are available."
    },
    {
      "pos": [
        4470,
        4741
      ],
      "content": "Click <bpt id=\"p25\">**</bpt>Credentials<ept id=\"p25\">**</ept><ph id=\"ph20\"/> and then enter a password for the admin user. You must also enter an <bpt id=\"p26\">**</bpt>SSH Username<ept id=\"p26\">**</ept>. For <bpt id=\"p27\">**</bpt>SSH Authentication Type<ept id=\"p27\">**</ept>, click <bpt id=\"p28\">**</bpt>PASSWORD<ept id=\"p28\">**</ept><ph id=\"ph21\"/> and specify a password for the SSH user. Click <bpt id=\"p29\">**</bpt>Select<ept id=\"p29\">**</ept><ph id=\"ph22\"/> at the bottom to save the credentials configuration.",
      "nodes": [
        {
          "content": "Click <bpt id=\"p25\">**</bpt>Credentials<ept id=\"p25\">**</ept><ph id=\"ph20\"/> and then enter a password for the admin user.",
          "pos": [
            0,
            122
          ]
        },
        {
          "content": "You must also enter an <bpt id=\"p26\">**</bpt>SSH Username<ept id=\"p26\">**</ept>.",
          "pos": [
            123,
            203
          ]
        },
        {
          "content": "For <bpt id=\"p27\">**</bpt>SSH Authentication Type<ept id=\"p27\">**</ept>, click <bpt id=\"p28\">**</bpt>PASSWORD<ept id=\"p28\">**</ept><ph id=\"ph21\"/> and specify a password for the SSH user.",
          "pos": [
            204,
            391
          ]
        },
        {
          "content": "Click <bpt id=\"p29\">**</bpt>Select<ept id=\"p29\">**</ept><ph id=\"ph22\"/> at the bottom to save the credentials configuration.",
          "pos": [
            392,
            516
          ]
        }
      ]
    },
    {
      "pos": [
        4747,
        4886
      ],
      "content": "<ph id=\"ph23\">![</ph>Provide cluster credentials<ph id=\"ph24\">](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.createcluster.3.png \"Provide cluster credentials\")</ph>"
    },
    {
      "pos": [
        4894,
        5308
      ],
      "content": "<ph id=\"ph25\">[AZURE.NOTE]</ph><ph id=\"ph26\"/> SSH is used to remotely access the HDInsight cluster using a command-line. The user name and password you use here is used when connecting to the cluster through SSH. Also, the SSH user name must be unique, as it creates a user account on all the HDInsight cluster nodes. The following are some of the account names reserved for use by services on the cluster, and cannot be used as the SSH user name:",
      "nodes": [
        {
          "content": "<ph id=\"ph25\">[AZURE.NOTE]</ph><ph id=\"ph26\"/> SSH is used to remotely access the HDInsight cluster using a command-line.",
          "pos": [
            0,
            121
          ]
        },
        {
          "content": "The user name and password you use here is used when connecting to the cluster through SSH.",
          "pos": [
            122,
            213
          ]
        },
        {
          "content": "Also, the SSH user name must be unique, as it creates a user account on all the HDInsight cluster nodes.",
          "pos": [
            214,
            318
          ]
        },
        {
          "content": "The following are some of the account names reserved for use by services on the cluster, and cannot be used as the SSH user name:",
          "pos": [
            319,
            448
          ]
        }
      ]
    },
    {
      "pos": [
        5321,
        5462
      ],
      "content": "root, hdiuser, storm, hbase, ubuntu, zookeeper, hdfs, yarn, mapred, hbase, hive, oozie, falcon, sqoop, admin, tez, hcat, hdinsight-zookeeper."
    },
    {
      "pos": [
        5468,
        5552
      ],
      "content": "For more information on using SSH with HDInsight, see one of the following articles:"
    },
    {
      "pos": [
        5560,
        5672
      ],
      "content": "<bpt id=\"p30\">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X<ept id=\"p30\">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept>"
    },
    {
      "pos": [
        5679,
        5781
      ],
      "content": "<bpt id=\"p31\">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id=\"p31\">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept>"
    },
    {
      "pos": [
        5787,
        6300
      ],
      "content": "Click <bpt id=\"p32\">**</bpt>Data Source<ept id=\"p32\">**</ept><ph id=\"ph27\"/> to choose an existing data source for the cluster, or create a new one. When you create a Hadoop cluster in HDInsight, you specify an Azure Storage account. A specific Blob storage container from that account is designated as the default file system, like in the Hadoop distributed file system (HDFS). By default, the HDInsight cluster is created in the same data center as the storage account you specify. For more information, see <bpt id=\"p33\">[</bpt>Use Azure Blob storage with HDInsight<ept id=\"p33\">][hdinsight-storage]</ept>",
      "nodes": [
        {
          "content": "Click <bpt id=\"p32\">**</bpt>Data Source<ept id=\"p32\">**</ept><ph id=\"ph27\"/> to choose an existing data source for the cluster, or create a new one.",
          "pos": [
            0,
            148
          ]
        },
        {
          "content": "When you create a Hadoop cluster in HDInsight, you specify an Azure Storage account.",
          "pos": [
            149,
            233
          ]
        },
        {
          "content": "A specific Blob storage container from that account is designated as the default file system, like in the Hadoop distributed file system (HDFS).",
          "pos": [
            234,
            378
          ]
        },
        {
          "content": "By default, the HDInsight cluster is created in the same data center as the storage account you specify.",
          "pos": [
            379,
            483
          ]
        },
        {
          "content": "For more information, see <bpt id=\"p33\">[</bpt>Use Azure Blob storage with HDInsight<ept id=\"p33\">][hdinsight-storage]</ept>",
          "pos": [
            484,
            608
          ]
        }
      ]
    },
    {
      "pos": [
        6306,
        6441
      ],
      "content": "<ph id=\"ph28\">![</ph>Data source blade<ph id=\"ph29\">](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.createcluster.4.png \"Provide data source configuration\")</ph>"
    },
    {
      "pos": [
        6447,
        6615
      ],
      "content": "Currently you can select an Azure Storage Account as the data source for an HDInsight cluster. Use the following to understand the entries on the <bpt id=\"p34\">**</bpt>Data Source<ept id=\"p34\">**</ept><ph id=\"ph30\"/> blade.",
      "nodes": [
        {
          "content": "Currently you can select an Azure Storage Account as the data source for an HDInsight cluster.",
          "pos": [
            0,
            94
          ]
        },
        {
          "content": "Use the following to understand the entries on the <bpt id=\"p34\">**</bpt>Data Source<ept id=\"p34\">**</ept><ph id=\"ph30\"/> blade.",
          "pos": [
            95,
            223
          ]
        }
      ]
    },
    {
      "pos": [
        6623,
        6871
      ],
      "content": "<bpt id=\"p35\">**</bpt>Selection Method<ept id=\"p35\">**</ept>: Set this to <bpt id=\"p36\">**</bpt>From all subscriptions<ept id=\"p36\">**</ept><ph id=\"ph31\"/> to enable browsing of storage accounts from all your subscriptions. Set this to <bpt id=\"p37\">**</bpt>Access Key<ept id=\"p37\">**</ept><ph id=\"ph32\"/> if you want to enter the <bpt id=\"p38\">**</bpt>Storage Name<ept id=\"p38\">**</ept><ph id=\"ph33\"/> and <bpt id=\"p39\">**</bpt>Access Key<ept id=\"p39\">**</ept><ph id=\"ph34\"/> of an existing storage account.",
      "nodes": [
        {
          "content": "<bpt id=\"p35\">**</bpt>Selection Method<ept id=\"p35\">**</ept>: Set this to <bpt id=\"p36\">**</bpt>From all subscriptions<ept id=\"p36\">**</ept><ph id=\"ph31\"/> to enable browsing of storage accounts from all your subscriptions.",
          "pos": [
            0,
            223
          ]
        },
        {
          "content": "Set this to <bpt id=\"p37\">**</bpt>Access Key<ept id=\"p37\">**</ept><ph id=\"ph32\"/> if you want to enter the <bpt id=\"p38\">**</bpt>Storage Name<ept id=\"p38\">**</ept><ph id=\"ph33\"/> and <bpt id=\"p39\">**</bpt>Access Key<ept id=\"p39\">**</ept><ph id=\"ph34\"/> of an existing storage account.",
          "pos": [
            224,
            508
          ]
        }
      ]
    },
    {
      "pos": [
        6879,
        7216
      ],
      "content": "<bpt id=\"p40\">**</bpt>Select storage account / Create New<ept id=\"p40\">**</ept>: Click <bpt id=\"p41\">**</bpt>Select storage account<ept id=\"p41\">**</ept><ph id=\"ph35\"/> to browse and select an existing storage account you want to associate with the cluster. Or, click <bpt id=\"p42\">**</bpt>Create New<ept id=\"p42\">**</ept><ph id=\"ph36\"/> to create a new storage account. Use the field that appears to enter the name of the storage account. A green check appears if the name is available.",
      "nodes": [
        {
          "content": "<bpt id=\"p40\">**</bpt>Select storage account / Create New<ept id=\"p40\">**</ept>: Click <bpt id=\"p41\">**</bpt>Select storage account<ept id=\"p41\">**</ept><ph id=\"ph35\"/> to browse and select an existing storage account you want to associate with the cluster.",
          "pos": [
            0,
            257
          ]
        },
        {
          "content": "Or, click <bpt id=\"p42\">**</bpt>Create New<ept id=\"p42\">**</ept><ph id=\"ph36\"/> to create a new storage account.",
          "pos": [
            258,
            370
          ]
        },
        {
          "content": "Use the field that appears to enter the name of the storage account.",
          "pos": [
            371,
            439
          ]
        },
        {
          "content": "A green check appears if the name is available.",
          "pos": [
            440,
            487
          ]
        }
      ]
    },
    {
      "pos": [
        7224,
        7499
      ],
      "content": "<bpt id=\"p43\">**</bpt>Choose Default Container<ept id=\"p43\">**</ept>: Use this to enter the name of the default container to use for the cluster. While you can enter any name here, we recommend using the same name as the cluster so that you can easily recognize that the container is used for this specific cluster.",
      "nodes": [
        {
          "content": "<bpt id=\"p43\">**</bpt>Choose Default Container<ept id=\"p43\">**</ept>: Use this to enter the name of the default container to use for the cluster.",
          "pos": [
            0,
            145
          ]
        },
        {
          "content": "While you can enter any name here, we recommend using the same name as the cluster so that you can easily recognize that the container is used for this specific cluster.",
          "pos": [
            146,
            315
          ]
        }
      ]
    },
    {
      "pos": [
        7507,
        7597
      ],
      "content": "<bpt id=\"p44\">**</bpt>Location<ept id=\"p44\">**</ept>: The geographic region that the storage account is in, or will be created in."
    },
    {
      "pos": [
        7609,
        7798
      ],
      "content": "<ph id=\"ph37\">[AZURE.IMPORTANT]</ph><ph id=\"ph38\"/> Selecting the location for the default data source also sets the location of the HDInsight cluster. The cluster and default data source must be located in the same region.",
      "nodes": [
        {
          "content": "<ph id=\"ph37\">[AZURE.IMPORTANT]</ph><ph id=\"ph38\"/> Selecting the location for the default data source also sets the location of the HDInsight cluster.",
          "pos": [
            0,
            151
          ]
        },
        {
          "content": "The cluster and default data source must be located in the same region.",
          "pos": [
            152,
            223
          ]
        }
      ]
    },
    {
      "pos": [
        7804,
        7859
      ],
      "content": "Click <bpt id=\"p45\">**</bpt>Select<ept id=\"p45\">**</ept><ph id=\"ph39\"/> to save the data source configuration."
    },
    {
      "pos": [
        7864,
        8098
      ],
      "content": "Click <bpt id=\"p46\">**</bpt>Node Pricing Tiers<ept id=\"p46\">**</ept><ph id=\"ph40\"/> to display information about the nodes that will be created for this cluster. Set the number of worker nodes that you need for the cluster. The estimated cost of the cluster will be shown within the blade.",
      "nodes": [
        {
          "content": "Click <bpt id=\"p46\">**</bpt>Node Pricing Tiers<ept id=\"p46\">**</ept><ph id=\"ph40\"/> to display information about the nodes that will be created for this cluster.",
          "pos": [
            0,
            161
          ]
        },
        {
          "content": "Set the number of worker nodes that you need for the cluster.",
          "pos": [
            162,
            223
          ]
        },
        {
          "content": "The estimated cost of the cluster will be shown within the blade.",
          "pos": [
            224,
            289
          ]
        }
      ]
    },
    {
      "pos": [
        8104,
        8244
      ],
      "content": "<ph id=\"ph41\">![</ph>Node pricing tiers blade<ph id=\"ph42\">](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.createcluster.5.png \"Specify number of cluster nodes\")</ph>"
    },
    {
      "pos": [
        8250,
        8306
      ],
      "content": "Click <bpt id=\"p47\">**</bpt>Select<ept id=\"p47\">**</ept><ph id=\"ph43\"/> to save the node pricing configuration."
    },
    {
      "pos": [
        8311,
        8645
      ],
      "content": "On the <bpt id=\"p48\">**</bpt>New HDInsight Cluster<ept id=\"p48\">**</ept><ph id=\"ph44\"/> blade, ensure that <bpt id=\"p49\">**</bpt>Pin to Startboard<ept id=\"p49\">**</ept><ph id=\"ph45\"/> is selected, and then click <bpt id=\"p50\">**</bpt>Create<ept id=\"p50\">**</ept>. This creates the cluster and adds a tile for it to the Startboard of your Azure portal. The icon will indicate that the cluster is being created, and will change to display the HDInsight icon once creation has completed.",
      "nodes": [
        {
          "content": "On the <bpt id=\"p48\">**</bpt>New HDInsight Cluster<ept id=\"p48\">**</ept><ph id=\"ph44\"/> blade, ensure that <bpt id=\"p49\">**</bpt>Pin to Startboard<ept id=\"p49\">**</ept><ph id=\"ph45\"/> is selected, and then click <bpt id=\"p50\">**</bpt>Create<ept id=\"p50\">**</ept>.",
          "pos": [
            0,
            263
          ]
        },
        {
          "content": "This creates the cluster and adds a tile for it to the Startboard of your Azure portal.",
          "pos": [
            264,
            351
          ]
        },
        {
          "content": "The icon will indicate that the cluster is being created, and will change to display the HDInsight icon once creation has completed.",
          "pos": [
            352,
            484
          ]
        }
      ]
    },
    {
      "pos": [
        8653,
        8667
      ],
      "content": "While creating"
    },
    {
      "pos": [
        8670,
        8687
      ],
      "content": "creation complete"
    },
    {
      "pos": [
        8747,
        8849
      ],
      "content": "<ph id=\"ph46\">![</ph>Creating indicator on startboard<ph id=\"ph47\">](./media/hdinsight-apache-spark-jupyter-spark-sql/provisioning.png)</ph>"
    },
    {
      "pos": [
        8852,
        8945
      ],
      "content": "<ph id=\"ph48\">![</ph>Provisioned cluster tile<ph id=\"ph49\">](./media/hdinsight-apache-spark-jupyter-spark-sql/provisioned.png)</ph>"
    },
    {
      "pos": [
        8955,
        9169
      ],
      "content": "<ph id=\"ph50\">[AZURE.NOTE]</ph><ph id=\"ph51\"/> It will take some time for the cluster to be created, usually around 15 minutes. Use the tile on the Startboard, or the <bpt id=\"p51\">**</bpt>Notifications<ept id=\"p51\">**</ept><ph id=\"ph52\"/> entry on the left of the page to check on the creation process.",
      "nodes": [
        {
          "content": "<ph id=\"ph50\">[AZURE.NOTE]</ph><ph id=\"ph51\"/> It will take some time for the cluster to be created, usually around 15 minutes.",
          "pos": [
            0,
            127
          ]
        },
        {
          "content": "Use the tile on the Startboard, or the <bpt id=\"p51\">**</bpt>Notifications<ept id=\"p51\">**</ept><ph id=\"ph52\"/> entry on the left of the page to check on the creation process.",
          "pos": [
            128,
            303
          ]
        }
      ]
    },
    {
      "pos": [
        9175,
        9291
      ],
      "content": "Once the creation is complete, click the tile for the Spark cluster from the Startboard to launch the cluster blade."
    },
    {
      "pos": [
        9320,
        9366
      ],
      "content": "Run Spark SQL queries using a Jupyter notebook"
    },
    {
      "pos": [
        9368,
        9461
      ],
      "content": "In this section, you use a Jupyter notebook to run Spark SQL queries against a Spark cluster."
    },
    {
      "pos": [
        9466,
        9707
      ],
      "content": "From the <bpt id=\"p52\">[</bpt>Azure Preview Portal<ept id=\"p52\">](https://portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard). You can also navigate to your cluster under <bpt id=\"p53\">**</bpt>Browse All<ept id=\"p53\">**</ept><ph id=\"ph53\"/> &gt; <bpt id=\"p54\">**</bpt>HDInsight Clusters<ept id=\"p54\">**</ept>.",
      "nodes": [
        {
          "content": "From the <bpt id=\"p52\">[</bpt>Azure Preview Portal<ept id=\"p52\">](https://portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).",
          "pos": [
            0,
            196
          ]
        },
        {
          "content": "You can also navigate to your cluster under <bpt id=\"p53\">**</bpt>Browse All<ept id=\"p53\">**</ept><ph id=\"ph53\"/> &gt; <bpt id=\"p54\">**</bpt>HDInsight Clusters<ept id=\"p54\">**</ept>.",
          "pos": [
            197,
            379
          ]
        }
      ]
    },
    {
      "pos": [
        9715,
        9900
      ],
      "content": "From the Spark cluster blade, click <bpt id=\"p55\">**</bpt>Quick Links<ept id=\"p55\">**</ept>, and then from the <bpt id=\"p56\">**</bpt>Cluster Dashboard<ept id=\"p56\">**</ept><ph id=\"ph54\"/> blade, click <bpt id=\"p57\">**</bpt>Jupyter Notebook<ept id=\"p57\">**</ept>. If prompted, enter the admin credentials for the cluster.",
      "nodes": [
        {
          "content": "From the Spark cluster blade, click <bpt id=\"p55\">**</bpt>Quick Links<ept id=\"p55\">**</ept>, and then from the <bpt id=\"p56\">**</bpt>Cluster Dashboard<ept id=\"p56\">**</ept><ph id=\"ph54\"/> blade, click <bpt id=\"p57\">**</bpt>Jupyter Notebook<ept id=\"p57\">**</ept>.",
          "pos": [
            0,
            262
          ]
        },
        {
          "content": "If prompted, enter the admin credentials for the cluster.",
          "pos": [
            263,
            320
          ]
        }
      ]
    },
    {
      "pos": [
        9908,
        10078
      ],
      "content": "<ph id=\"ph55\">[AZURE.NOTE]</ph><ph id=\"ph56\"/> You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser. Replace <bpt id=\"p58\">__</bpt>CLUSTERNAME<ept id=\"p58\">__</ept><ph id=\"ph57\"/> with the name of your cluster:",
      "nodes": [
        {
          "content": "<ph id=\"ph55\">[AZURE.NOTE]</ph><ph id=\"ph56\"/> You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser.",
          "pos": [
            0,
            149
          ]
        },
        {
          "content": "Replace <bpt id=\"p58\">__</bpt>CLUSTERNAME<ept id=\"p58\">__</ept><ph id=\"ph57\"/> with the name of your cluster:",
          "pos": [
            150,
            259
          ]
        }
      ]
    },
    {
      "pos": [
        10144,
        10209
      ],
      "content": "Create a new notebook. Click <bpt id=\"p59\">**</bpt>New<ept id=\"p59\">**</ept>, and then click <bpt id=\"p60\">**</bpt>Python2<ept id=\"p60\">**</ept>.",
      "nodes": [
        {
          "content": "Create a new notebook.",
          "pos": [
            0,
            22
          ]
        },
        {
          "content": "Click <bpt id=\"p59\">**</bpt>New<ept id=\"p59\">**</ept>, and then click <bpt id=\"p60\">**</bpt>Python2<ept id=\"p60\">**</ept>.",
          "pos": [
            23,
            145
          ]
        }
      ]
    },
    {
      "pos": [
        10215,
        10370
      ],
      "content": "<ph id=\"ph59\">![</ph>Create a new Jupyter notebook<ph id=\"ph60\">](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.note.jupyter.createnotebook.png \"Create a new Jupyter notebook\")</ph>"
    },
    {
      "pos": [
        10375,
        10503
      ],
      "content": "A new notebook is created and opened with the name Untitled.pynb. Click the notebook name at the top, and enter a friendly name.",
      "nodes": [
        {
          "content": "A new notebook is created and opened with the name Untitled.pynb.",
          "pos": [
            0,
            65
          ]
        },
        {
          "content": "Click the notebook name at the top, and enter a friendly name.",
          "pos": [
            66,
            128
          ]
        }
      ]
    },
    {
      "pos": [
        10509,
        10667
      ],
      "content": "<ph id=\"ph61\">![</ph>Provide a name for the notebook<ph id=\"ph62\">](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.note.jupyter.notebook.name.png \"Provide a name for the notebook\")</ph>"
    },
    {
      "pos": [
        10672,
        10823
      ],
      "content": "Import the required modules and create the Spark and SQL contexts. Paste the following code example in an empty cell, and then press <bpt id=\"p61\">**</bpt>SHIFT + ENTER<ept id=\"p61\">**</ept>.",
      "nodes": [
        {
          "content": "Import the required modules and create the Spark and SQL contexts.",
          "pos": [
            0,
            66
          ]
        },
        {
          "content": "Paste the following code example in an empty cell, and then press <bpt id=\"p61\">**</bpt>SHIFT + ENTER<ept id=\"p61\">**</ept>.",
          "pos": [
            67,
            191
          ]
        }
      ]
    },
    {
      "pos": [
        11080,
        11360
      ],
      "content": "Every time you run a job in Jupyter, your web browser window title will show a <bpt id=\"p62\">**</bpt>(Busy)<ept id=\"p62\">**</ept><ph id=\"ph63\"/> status along with the notebook title. You will also see a solid circle next to the <bpt id=\"p63\">**</bpt>Python 2<ept id=\"p63\">**</ept><ph id=\"ph64\"/> text in the top-right corner. After the job is completed, this will change to a hollow circle.",
      "nodes": [
        {
          "content": "Every time you run a job in Jupyter, your web browser window title will show a <bpt id=\"p62\">**</bpt>(Busy)<ept id=\"p62\">**</ept><ph id=\"ph63\"/> status along with the notebook title.",
          "pos": [
            0,
            182
          ]
        },
        {
          "content": "You will also see a solid circle next to the <bpt id=\"p63\">**</bpt>Python 2<ept id=\"p63\">**</ept><ph id=\"ph64\"/> text in the top-right corner.",
          "pos": [
            183,
            325
          ]
        },
        {
          "content": "After the job is completed, this will change to a hollow circle.",
          "pos": [
            326,
            390
          ]
        }
      ]
    },
    {
      "pos": [
        11367,
        11519
      ],
      "content": "<ph id=\"ph65\">![</ph>Status of a Jupyter notebook job<ph id=\"ph66\">](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.jupyter.job.status.png \"Status of a Jupyter notebook job\")</ph>"
    },
    {
      "pos": [
        11524,
        11746
      ],
      "content": "Load sample data into a temporary table. When you create a Spark cluster in HDInsight, the sample data file, <bpt id=\"p64\">**</bpt>hvac.csv<ept id=\"p64\">**</ept>, is copied to the associated storage account under <bpt id=\"p65\">**</bpt>\\HdiSamples\\HdiSamples\\SensorSampleData\\hvac<ept id=\"p65\">**</ept>.",
      "nodes": [
        {
          "content": "Load sample data into a temporary table.",
          "pos": [
            0,
            40
          ]
        },
        {
          "content": "When you create a Spark cluster in HDInsight, the sample data file, <bpt id=\"p64\">**</bpt>hvac.csv<ept id=\"p64\">**</ept>, is copied to the associated storage account under <bpt id=\"p65\">**</bpt>\\HdiSamples\\HdiSamples\\SensorSampleData\\hvac<ept id=\"p65\">**</ept>.",
          "pos": [
            41,
            302
          ]
        }
      ]
    },
    {
      "pos": [
        11752,
        11908
      ],
      "content": "In an empty cell, paste the following code example and press <bpt id=\"p66\">**</bpt>SHIFT + ENTER<ept id=\"p66\">**</ept>. This code example registers the data into a temporary table called <bpt id=\"p67\">**</bpt>hvac<ept id=\"p67\">**</ept>.",
      "nodes": [
        {
          "content": "In an empty cell, paste the following code example and press <bpt id=\"p66\">**</bpt>SHIFT + ENTER<ept id=\"p66\">**</ept>.",
          "pos": [
            0,
            119
          ]
        },
        {
          "content": "This code example registers the data into a temporary table called <bpt id=\"p67\">**</bpt>hvac<ept id=\"p67\">**</ept>.",
          "pos": [
            120,
            236
          ]
        }
      ]
    },
    {
      "pos": [
        12970,
        13044
      ],
      "content": "Once the job is completed successfully, the following output is displayed."
    },
    {
      "pos": [
        13963,
        14189
      ],
      "content": "After you have finished running the application, you should shutdown the notebook to release the resources. To do so, from the <bpt id=\"p68\">**</bpt>File<ept id=\"p68\">**</ept><ph id=\"ph67\"/> menu on the notebook, click <bpt id=\"p69\">**</bpt>Close and Halt<ept id=\"p69\">**</ept>. This will shutdown and close the notebook.",
      "nodes": [
        {
          "content": "After you have finished running the application, you should shutdown the notebook to release the resources.",
          "pos": [
            0,
            107
          ]
        },
        {
          "content": "To do so, from the <bpt id=\"p68\">**</bpt>File<ept id=\"p68\">**</ept><ph id=\"ph67\"/> menu on the notebook, click <bpt id=\"p69\">**</bpt>Close and Halt<ept id=\"p69\">**</ept>.",
          "pos": [
            108,
            278
          ]
        },
        {
          "content": "This will shutdown and close the notebook.",
          "pos": [
            279,
            321
          ]
        }
      ]
    },
    {
      "pos": [
        14217,
        14225
      ],
      "content": "See also"
    },
    {
      "pos": [
        14230,
        14309
      ],
      "content": "<bpt id=\"p70\">[</bpt>Overview: Apache Spark on Azure HDInsight<ept id=\"p70\">](hdinsight-apache-spark-overview.md)</ept>"
    },
    {
      "pos": [
        14315,
        14324
      ],
      "content": "Scenarios"
    },
    {
      "pos": [
        14328,
        14457
      ],
      "content": "<bpt id=\"p71\">[</bpt>Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools<ept id=\"p71\">](hdinsight-apache-spark-use-bi-tools.md)</ept>"
    },
    {
      "pos": [
        14461,
        14626
      ],
      "content": "<bpt id=\"p72\">[</bpt>Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data<ept id=\"p72\">](hdinsight-apache-spark-ipython-notebook-machine-learning.md)</ept>"
    },
    {
      "pos": [
        14630,
        14776
      ],
      "content": "<bpt id=\"p73\">[</bpt>Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results<ept id=\"p73\">](hdinsight-apache-spark-machine-learning-mllib-ipython.md)</ept>"
    },
    {
      "pos": [
        14780,
        14913
      ],
      "content": "<bpt id=\"p74\">[</bpt>Spark Streaming: Use Spark in HDInsight for building real-time streaming applications<ept id=\"p74\">](hdinsight-apache-spark-eventhub-streaming.md)</ept>"
    },
    {
      "pos": [
        14917,
        15027
      ],
      "content": "<bpt id=\"p75\">[</bpt>Website log analysis using Spark in HDInsight<ept id=\"p75\">](hdinsight-apache-spark-custom-library-website-log-analysis.md)</ept>"
    },
    {
      "pos": [
        15033,
        15060
      ],
      "content": "Create and run applications"
    },
    {
      "pos": [
        15064,
        15166
      ],
      "content": "<bpt id=\"p76\">[</bpt>Create a standalone application using Scala<ept id=\"p76\">](hdinsight-apache-spark-create-standalone-application.md)</ept>"
    },
    {
      "pos": [
        15170,
        15266
      ],
      "content": "<bpt id=\"p77\">[</bpt>Run jobs remotely on a Spark cluster using Livy<ept id=\"p77\">](hdinsight-apache-spark-livy-rest-interface.md)</ept>"
    },
    {
      "pos": [
        15272,
        15292
      ],
      "content": "Tools and extensions"
    },
    {
      "pos": [
        15296,
        15435
      ],
      "content": "<bpt id=\"p78\">[</bpt>Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons<ept id=\"p78\">](hdinsight-apache-spark-intellij-tool-plugin.md)</ept>"
    },
    {
      "pos": [
        15439,
        15546
      ],
      "content": "<bpt id=\"p79\">[</bpt>Use Zeppelin notebooks with a Spark cluster on HDInsight<ept id=\"p79\">](hdinsight-apache-spark-use-zeppelin-notebook.md)</ept>"
    },
    {
      "pos": [
        15550,
        15673
      ],
      "content": "<bpt id=\"p80\">[</bpt>Kernels available for Jupyter notebook in Spark cluster for HDInsight<ept id=\"p80\">](hdinsight-apache-spark-jupyter-notebook-kernels.md)</ept>"
    },
    {
      "pos": [
        15679,
        15695
      ],
      "content": "Manage resources"
    },
    {
      "pos": [
        15699,
        15809
      ],
      "content": "<bpt id=\"p81\">[</bpt>Manage resources for the Apache Spark cluster in Azure HDInsight<ept id=\"p81\">](hdinsight-apache-spark-resource-manager.md)</ept>"
    },
    {
      "pos": [
        15815,
        15827
      ],
      "content": "Known issues"
    },
    {
      "pos": [
        15831,
        15928
      ],
      "content": "<bpt id=\"p82\">[</bpt>Known issues of Apache Spark in Azure HDInsight (Linux)<ept id=\"p82\">](hdinsight-apache-spark-known-issues.md)</ept>"
    }
  ],
  "content": "<properties\n    pageTitle=\"Create a Spark cluster on HDInsight Linux and use Spark SQL from Jupyter for interactive analysis | Microsoft Azure\"\n    description=\"Step-by-step instructions on how to quickly create an Apache Spark cluster in HDInsight and then use Spark SQL from Jupyter notebooks to run interactive queries.\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    authors=\"nitinme\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.workload=\"big-data\"\n    ms.tgt_pltfrm=\"na\"\n    ms.devlang=\"na\"\n    ms.topic=\"article\"\n    ms.date=\"02/05/2016\"\n    ms.author=\"nitinme\"/>\n\n\n# Get started: Create Apache Spark cluster on Azure HDInsight (Linux) and run interactive queries using Spark SQL\n\nLearn how to create an Apache Spark cluster in HDInsight and then use [Jupyter](https://jupyter.org) notebook to run Spark SQL interactive queries on the Spark cluster.\n\n   ![Get started using Apache Spark in HDInsight](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.getstartedflow.png  \"Get started using Apache Spark in HDInsight tutorial. Steps illustrated: create a storage account; create a cluster; run Spark SQL statements\")\n\n**Prerequisites:**\n\n- **An Azure subscription**. Before you begin this tutorial, you must have an Azure subscription. See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).\n\n- **A Secure Shell (SSH) client**: Linux, Unix, and OS X systems provied an SSH client through the `ssh` command. For Windows systems, we recommend [PuTTY](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html).\n    \n- **Secure Shell (SSH) keys (optional)**: You can secure the SSH account used to connect to the cluster using either a password or a public key. Using a password gets you started quickly, and you should use this option if you want to quickly create a cluster and run some test jobs. Using a key is more secure, however it requires additional setup. You might want to use this approach when creating a production cluster. In this article, we use the password approach. For instructions on how to create and use SSH keys with HDInsight, refer to the following articles:\n\n    -  From a Linux computer - [Use SSH with Linux-based HDInsight (Hadoop) from Linux, Unix, or OS X](hdinsight-hadoop-linux-use-ssh-unix.md).\n    \n    -  From a Windows computer - [Use SSH with Linux-based HDInsight (Hadoop) from Windows](hdinsight-hadoop-linux-use-ssh-windows.md).\n\n\n## Create a Spark cluster on HDInsight Linux\n\nIn this section, you create an HDInsight version 3.3 cluster, which is based on Spark version 1.5.1. For information about HDInsight versions and their SLAs, see [HDInsight component versioning](hdinsight-component-versioning.md).\n\n>[AZURE.NOTE] The steps in this article create an Apache Spark cluster in HDInsight by using basic configuration settings. For information about other cluster configuration settings (such as using additional storage, an Azure virtual network, or a metastore for Hive), see [Create HDInsight Spark clusters using custom options](hdinsight-hadoop-provision-linux-clusters.md).\n\n\n**To create a Spark cluster**\n\n1. Sign in to the [Azure preview portal](https://ms.portal.azure.com/).\n\n2. Click **NEW**, click **Data + Analytics**, and then click **HDInsight**.\n\n    ![Creating a new cluster in the Azure preview portal](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.createcluster.1.png \"Creating a new cluster in the Azure preview portal\")\n\n3. Enter a **Cluster Name**, select **Hadoop** for the **Cluster Type**, from the **Cluster Operating System** drop-down menu, select **Ubuntu**, and then select the version of Spark. A green check appears beside the cluster name if it is available.\n\n    ![Enter cluster name and type](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.createcluster.2.png \"Enter cluster name and type\")\n\n4. If you have more than one subscription, click the **Subscription** entry to select the Azure subscription to use for the cluster.\n\n5. Click **Resource Group** to see a list of existing resource groups and select where to create the cluster. Or, you can click **Create New** and then enter the name of the new resource group. A green check appears to indicate if the new group name is available.\n\n    > [AZURE.NOTE] This entry defaults to one of your existing resource groups, if any are available.\n\n6. Click **Credentials** and then enter a password for the admin user. You must also enter an **SSH Username**. For **SSH Authentication Type**, click **PASSWORD** and specify a password for the SSH user. Click **Select** at the bottom to save the credentials configuration.\n\n    ![Provide cluster credentials](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.createcluster.3.png \"Provide cluster credentials\")\n\n    > [AZURE.NOTE] SSH is used to remotely access the HDInsight cluster using a command-line. The user name and password you use here is used when connecting to the cluster through SSH. Also, the SSH user name must be unique, as it creates a user account on all the HDInsight cluster nodes. The following are some of the account names reserved for use by services on the cluster, and cannot be used as the SSH user name:\n    >\n    > root, hdiuser, storm, hbase, ubuntu, zookeeper, hdfs, yarn, mapred, hbase, hive, oozie, falcon, sqoop, admin, tez, hcat, hdinsight-zookeeper.\n\n    For more information on using SSH with HDInsight, see one of the following articles:\n\n    * [Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X](hdinsight-hadoop-linux-use-ssh-unix.md)\n    * [Use SSH with Linux-based Hadoop on HDInsight from Windows](hdinsight-hadoop-linux-use-ssh-windows.md)\n\n\n7. Click **Data Source** to choose an existing data source for the cluster, or create a new one. When you create a Hadoop cluster in HDInsight, you specify an Azure Storage account. A specific Blob storage container from that account is designated as the default file system, like in the Hadoop distributed file system (HDFS). By default, the HDInsight cluster is created in the same data center as the storage account you specify. For more information, see [Use Azure Blob storage with HDInsight][hdinsight-storage]\n\n    ![Data source blade](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.createcluster.4.png \"Provide data source configuration\")\n\n    Currently you can select an Azure Storage Account as the data source for an HDInsight cluster. Use the following to understand the entries on the **Data Source** blade.\n\n    - **Selection Method**: Set this to **From all subscriptions** to enable browsing of storage accounts from all your subscriptions. Set this to **Access Key** if you want to enter the **Storage Name** and **Access Key** of an existing storage account.\n\n    - **Select storage account / Create New**: Click **Select storage account** to browse and select an existing storage account you want to associate with the cluster. Or, click **Create New** to create a new storage account. Use the field that appears to enter the name of the storage account. A green check appears if the name is available.\n\n    - **Choose Default Container**: Use this to enter the name of the default container to use for the cluster. While you can enter any name here, we recommend using the same name as the cluster so that you can easily recognize that the container is used for this specific cluster.\n\n    - **Location**: The geographic region that the storage account is in, or will be created in.\n\n        > [AZURE.IMPORTANT] Selecting the location for the default data source also sets the location of the HDInsight cluster. The cluster and default data source must be located in the same region.\n\n    Click **Select** to save the data source configuration.\n\n8. Click **Node Pricing Tiers** to display information about the nodes that will be created for this cluster. Set the number of worker nodes that you need for the cluster. The estimated cost of the cluster will be shown within the blade.\n\n    ![Node pricing tiers blade](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.createcluster.5.png \"Specify number of cluster nodes\")\n\n    Click **Select** to save the node pricing configuration.\n\n9. On the **New HDInsight Cluster** blade, ensure that **Pin to Startboard** is selected, and then click **Create**. This creates the cluster and adds a tile for it to the Startboard of your Azure portal. The icon will indicate that the cluster is being created, and will change to display the HDInsight icon once creation has completed.\n\n    | While creating | creation complete |\n    | ------------------ | --------------------- |\n    | ![Creating indicator on startboard](./media/hdinsight-apache-spark-jupyter-spark-sql/provisioning.png) | ![Provisioned cluster tile](./media/hdinsight-apache-spark-jupyter-spark-sql/provisioned.png) |\n\n    > [AZURE.NOTE] It will take some time for the cluster to be created, usually around 15 minutes. Use the tile on the Startboard, or the **Notifications** entry on the left of the page to check on the creation process.\n\n10. Once the creation is complete, click the tile for the Spark cluster from the Startboard to launch the cluster blade.\n\n\n\n## <a name=\"jupyter\"></a>Run Spark SQL queries using a Jupyter notebook\n\nIn this section, you use a Jupyter notebook to run Spark SQL queries against a Spark cluster.\n\n1. From the [Azure Preview Portal](https://portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard). You can also navigate to your cluster under **Browse All** > **HDInsight Clusters**.   \n\n2. From the Spark cluster blade, click **Quick Links**, and then from the **Cluster Dashboard** blade, click **Jupyter Notebook**. If prompted, enter the admin credentials for the cluster.\n\n    > [AZURE.NOTE] You may also reach the Jupyter Notebook for your cluster by opening the following URL in your browser. Replace __CLUSTERNAME__ with the name of your cluster:\n    >\n    > `https://CLUSTERNAME.azurehdinsight.net/jupyter`\n\n2. Create a new notebook. Click **New**, and then click **Python2**.\n\n    ![Create a new Jupyter notebook](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.note.jupyter.createnotebook.png \"Create a new Jupyter notebook\")\n\n3. A new notebook is created and opened with the name Untitled.pynb. Click the notebook name at the top, and enter a friendly name.\n\n    ![Provide a name for the notebook](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.note.jupyter.notebook.name.png \"Provide a name for the notebook\")\n\n4. Import the required modules and create the Spark and SQL contexts. Paste the following code example in an empty cell, and then press **SHIFT + ENTER**.\n\n        from pyspark import SparkContext\n        from pyspark.sql import SQLContext\n        from pyspark.sql.types import *\n        \n        # Create Spark and SQL contexts\n        sc = SparkContext('yarn-client')\n        sqlContext = SQLContext(sc)\n\n    Every time you run a job in Jupyter, your web browser window title will show a **(Busy)** status along with the notebook title. You will also see a solid circle next to the **Python 2** text in the top-right corner. After the job is completed, this will change to a hollow circle.\n\n     ![Status of a Jupyter notebook job](./media/hdinsight-apache-spark-jupyter-spark-sql/hdispark.jupyter.job.status.png \"Status of a Jupyter notebook job\")\n\n4. Load sample data into a temporary table. When you create a Spark cluster in HDInsight, the sample data file, **hvac.csv**, is copied to the associated storage account under **\\HdiSamples\\HdiSamples\\SensorSampleData\\hvac**.\n\n    In an empty cell, paste the following code example and press **SHIFT + ENTER**. This code example registers the data into a temporary table called **hvac**.\n\n        # Load the data\n        hvacText = sc.textFile(\"wasb:///HdiSamples/HdiSamples/SensorSampleData/hvac/HVAC.csv\")\n        \n        # Create the schema\n        hvacSchema = StructType([StructField(\"date\", StringType(), False),StructField(\"time\", StringType(), False),StructField(\"targettemp\", IntegerType(), False),StructField(\"actualtemp\", IntegerType(), False),StructField(\"buildingID\", StringType(), False)])\n        \n        # Parse the data in hvacText\n        hvac = hvacText.map(lambda s: s.split(\",\")).filter(lambda s: s[0] != \"Date\").map(lambda s:(str(s[0]), str(s[1]), int(s[2]), int(s[3]), str(s[6]) ))\n        \n        # Create a data frame\n        hvacdf = sqlContext.createDataFrame(hvac,hvacSchema)\n        \n        # Register the data fram as a table to run queries against\n        hvacdf.registerTempTable(\"hvac\")\n        \n        # Run queries against the table and display the data\n        data = sqlContext.sql(\"select buildingID, (targettemp - actualtemp) as temp_diff, date from hvac where date = \\\"6/1/13\\\"\")\n        data.show()\n\n5. Once the job is completed successfully, the following output is displayed.\n\n        +----------+---------+------+\n        |buildingID|temp_diff|  date|\n        +----------+---------+------+\n        |         4|        8|6/1/13|\n        |         3|        2|6/1/13|\n        |         7|      -10|6/1/13|\n        |        12|        3|6/1/13|\n        |         7|        9|6/1/13|\n        |         7|        5|6/1/13|\n        |         3|       11|6/1/13|\n        |         8|       -7|6/1/13|\n        |        17|       14|6/1/13|\n        |        16|       -3|6/1/13|\n        |         8|       -8|6/1/13|\n        |         1|       -1|6/1/13|\n        |        12|       11|6/1/13|\n        |         3|       14|6/1/13|\n        |         6|       -4|6/1/13|\n        |         1|        4|6/1/13|\n        |        19|        4|6/1/13|\n        |        19|       12|6/1/13|\n        |         9|       -9|6/1/13|\n        |        15|      -10|6/1/13|\n        +----------+---------+------+\n\n\n6. After you have finished running the application, you should shutdown the notebook to release the resources. To do so, from the **File** menu on the notebook, click **Close and Halt**. This will shutdown and close the notebook.\n\n\n## <a name=\"seealso\"></a>See also\n\n\n* [Overview: Apache Spark on Azure HDInsight](hdinsight-apache-spark-overview.md)\n\n### Scenarios\n\n* [Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools](hdinsight-apache-spark-use-bi-tools.md)\n\n* [Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data](hdinsight-apache-spark-ipython-notebook-machine-learning.md)\n\n* [Spark with Machine Learning: Use Spark in HDInsight to predict food inspection results](hdinsight-apache-spark-machine-learning-mllib-ipython.md)\n\n* [Spark Streaming: Use Spark in HDInsight for building real-time streaming applications](hdinsight-apache-spark-eventhub-streaming.md)\n\n* [Website log analysis using Spark in HDInsight](hdinsight-apache-spark-custom-library-website-log-analysis.md)\n\n### Create and run applications\n\n* [Create a standalone application using Scala](hdinsight-apache-spark-create-standalone-application.md)\n\n* [Run jobs remotely on a Spark cluster using Livy](hdinsight-apache-spark-livy-rest-interface.md)\n\n### Tools and extensions\n\n* [Use HDInsight Tools Plugin for IntelliJ IDEA to create and submit Spark Scala applicatons](hdinsight-apache-spark-intellij-tool-plugin.md)\n\n* [Use Zeppelin notebooks with a Spark cluster on HDInsight](hdinsight-apache-spark-use-zeppelin-notebook.md)\n\n* [Kernels available for Jupyter notebook in Spark cluster for HDInsight](hdinsight-apache-spark-jupyter-notebook-kernels.md)\n\n### Manage resources\n\n* [Manage resources for the Apache Spark cluster in Azure HDInsight](hdinsight-apache-spark-resource-manager.md)\n\n### Known issues\n\n* [Known issues of Apache Spark in Azure HDInsight (Linux)](hdinsight-apache-spark-known-issues.md)\n\n\n[hdinsight-versions]: hdinsight-component-versioning.md\n[hdinsight-upload-data]: hdinsight-upload-data.md\n[hdinsight-storage]: hdinsight-hadoop-use-blob-storage.md\n\n[azure-purchase-options]: http://azure.microsoft.com/pricing/purchase-options/\n[azure-member-offers]: http://azure.microsoft.com/pricing/member-offers/\n[azure-free-trial]: http://azure.microsoft.com/pricing/free-trial/\n[azure-management-portal]: https://manage.windowsazure.com/\n[azure-create-storageaccount]: storage-create-storage-account.md\n"
}