<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="fr-fr">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-48076a9" tool-company="Microsoft" />
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fad8a0839df53f71902361a16627f352424dbda2</xliffext:olfilehash>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">wdg-cpub-test\ndolci2\input-and-devices\define-custom-recognition-constraints.md</xliffext:olfilepath>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
      </xliffext:oltranslationpriority>
      <xliffext:oltranslationtype xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">Human Translation</xliffext:oltranslationtype>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Learn how to define and use custom constraints for speech recognition.</source>
          <target state="new">Learn how to define and use custom constraints for speech recognition.</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Define custom recognition constraints</source>
          <target state="new">Define custom recognition constraints</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Define custom recognition constraints</source>
          <target state="new">Define custom recognition constraints</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>\[ Updated for UWP apps on Windows 10.</source>
          <target state="new">\[ Updated for UWP apps on Windows 10.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>For Windows 8.x articles, see the <bpt id="p1">[</bpt>archive<ept id="p1">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept> \]</source>
          <target state="new">For Windows 8.x articles, see the <bpt id="p1">[</bpt>archive<ept id="p1">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept> \]</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Learn how to define and use custom constraints for speech recognition.</source>
          <target state="new">Learn how to define and use custom constraints for speech recognition.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Important APIs</source>
          <target state="new">Important APIs</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>SpeechRecognitionTopicConstraint</source>
          <target state="new">SpeechRecognitionTopicConstraint</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>SpeechRecognitionListConstraint</source>
          <target state="new">SpeechRecognitionListConstraint</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>SpeechRecognitionGrammarFileConstraint</source>
          <target state="new">SpeechRecognitionGrammarFileConstraint</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Speech recognition requires at least one constraint to define a recognizable vocabulary.</source>
          <target state="new">Speech recognition requires at least one constraint to define a recognizable vocabulary.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>If no constraint is specified, the predefined dictation grammar of Universal Windows apps is used.</source>
          <target state="new">If no constraint is specified, the predefined dictation grammar of Universal Windows apps is used.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Speech recognition<ept id="p1">](speech-recognition.md)</ept>.</source>
          <target state="new">See <bpt id="p1">[</bpt>Speech recognition<ept id="p1">](speech-recognition.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Add constraints</source>
          <target state="new">Add constraints</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognizer.Constraints<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653241)</ept> property to add constraints to a speech recognizer.</source>
          <target state="new">Use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognizer.Constraints<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653241)</ept> property to add constraints to a speech recognizer.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Here, we cover the three kinds of speech recognition constraints used from within an app.</source>
          <target state="new">Here, we cover the three kinds of speech recognition constraints used from within an app.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>(For voice command constraints, see <bpt id="p1">[</bpt>Launch a foreground app with voice commands in Cortana<ept id="p1">](launch-a-foreground-app-with-voice-commands-in-cortana.md)</ept>.)</source>
          <target state="new">(For voice command constraints, see <bpt id="p1">[</bpt>Launch a foreground app with voice commands in Cortana<ept id="p1">](launch-a-foreground-app-with-voice-commands-in-cortana.md)</ept>.)</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognitionTopicConstraint<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631446)</ept>—A constraint based on a predefined grammar (dictation or web search).</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognitionTopicConstraint<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631446)</ept>—A constraint based on a predefined grammar (dictation or web search).</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognitionListConstraint<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631421)</ept>—A constraint based on a list of words or phrases.</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognitionListConstraint<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631421)</ept>—A constraint based on a list of words or phrases.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognitionGrammarFileConstraint<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631412)</ept>—A constraint defined in a Speech Recognition Grammar Specification (SRGS) file.</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognitionGrammarFileConstraint<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631412)</ept>—A constraint defined in a Speech Recognition Grammar Specification (SRGS) file.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Each speech recognizer can have one constraint collection.</source>
          <target state="new">Each speech recognizer can have one constraint collection.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Only these combinations of constraints are valid:</source>
          <target state="new">Only these combinations of constraints are valid:</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>A single-topic constraint, or predefined grammar (dictation or web search).</source>
          <target state="new">A single-topic constraint, or predefined grammar (dictation or web search).</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>No other constraints are allowed.</source>
          <target state="new">No other constraints are allowed.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>A combination of list constraints and/or grammar-file constraints.</source>
          <target state="new">A combination of list constraints and/or grammar-file constraints.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Remember:  <ept id="p1">**</ept>Call the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>SpeechRecognizer.CompileConstraintsAsync<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn653240)</ept> method to compile the constraints before starting the recognition process.</source>
          <target state="new"><bpt id="p1">**</bpt>Remember:  <ept id="p1">**</ept>Call the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>SpeechRecognizer.CompileConstraintsAsync<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn653240)</ept> method to compile the constraints before starting the recognition process.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Specify a web-search grammar (SpeechRecognitionTopicConstraint)</source>
          <target state="new">Specify a web-search grammar (SpeechRecognitionTopicConstraint)</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Topic constraints (dictation or web-search grammar) must be added to the constraints collection of a speech recognizer.</source>
          <target state="new">Topic constraints (dictation or web-search grammar) must be added to the constraints collection of a speech recognizer.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Here, we add a web-search grammar to the constraints collection.</source>
          <target state="new">Here, we add a web-search grammar to the constraints collection.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Specify a programmatic list constraint (SpeechRecognitionListConstraint)</source>
          <target state="new">Specify a programmatic list constraint (SpeechRecognitionListConstraint)</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>List constraints must be added to the constraints collection of a speech recognizer.</source>
          <target state="new">List constraints must be added to the constraints collection of a speech recognizer.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Keep the following points in mind:</source>
          <target state="new">Keep the following points in mind:</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>You can add multiple list constraints to a constraints collection.</source>
          <target state="new">You can add multiple list constraints to a constraints collection.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>You can use any collection that implements <bpt id="p1">**</bpt>IIterable<ph id="ph1">&amp;lt;</ph>String<ph id="ph2">&amp;gt;</ph><ept id="p1">**</ept> for the string values.</source>
          <target state="new">You can use any collection that implements <bpt id="p1">**</bpt>IIterable<ph id="ph1">&amp;lt;</ph>String<ph id="ph2">&amp;gt;</ph><ept id="p1">**</ept> for the string values.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Here, we programmatically specify an array of words as a list constraint and add it to the constraints collection of a speech recognizer.</source>
          <target state="new">Here, we programmatically specify an array of words as a list constraint and add it to the constraints collection of a speech recognizer.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Specify an SRGS grammar constraint (SpeechRecognitionGrammarFileConstraint)</source>
          <target state="new">Specify an SRGS grammar constraint (SpeechRecognitionGrammarFileConstraint)</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>SRGS grammar files must be added to the constraints collection of a speech recognizer.</source>
          <target state="new">SRGS grammar files must be added to the constraints collection of a speech recognizer.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>The SRGS Version 1.0 is the industry-standard markup language for creating XML-format grammars for speech recognition.</source>
          <target state="new">The SRGS Version 1.0 is the industry-standard markup language for creating XML-format grammars for speech recognition.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Although Universal Windows apps provide alternatives to using SRGS for creating speech-recognition grammars, you might find that using SRGS to create grammars produces the best results, particularly for more involved speech recognition scenarios.</source>
          <target state="new">Although Universal Windows apps provide alternatives to using SRGS for creating speech-recognition grammars, you might find that using SRGS to create grammars produces the best results, particularly for more involved speech recognition scenarios.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>SRGS grammars provide a full set of features to help you architect complex voice interaction for your apps.</source>
          <target state="new">SRGS grammars provide a full set of features to help you architect complex voice interaction for your apps.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>For example, with SRGS grammars you can:</source>
          <target state="new">For example, with SRGS grammars you can:</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Specify the order in which words and phrases must be spoken to be recognized.</source>
          <target state="new">Specify the order in which words and phrases must be spoken to be recognized.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>Combine words from multiple lists and phrases to be recognized.</source>
          <target state="new">Combine words from multiple lists and phrases to be recognized.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Link to other grammars.</source>
          <target state="new">Link to other grammars.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Assign a weight to an alternative word or phrase to increase or decrease the likelihood that it will be used to match speech input.</source>
          <target state="new">Assign a weight to an alternative word or phrase to increase or decrease the likelihood that it will be used to match speech input.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Include optional words or phrases.</source>
          <target state="new">Include optional words or phrases.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>Use special rules that help filter out unspecified or unanticipated input, such as random speech that doesn't match the grammar, or background noise.</source>
          <target state="new">Use special rules that help filter out unspecified or unanticipated input, such as random speech that doesn't match the grammar, or background noise.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Use semantics to define what speech recognition means to your app.</source>
          <target state="new">Use semantics to define what speech recognition means to your app.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>Specify pronunciations, either inline in a grammar or via a link to a lexicon.</source>
          <target state="new">Specify pronunciations, either inline in a grammar or via a link to a lexicon.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>For more info about SRGS elements and attributes, see the <bpt id="p1">[</bpt>SRGS Grammar XML Reference<ept id="p1">](http://go.microsoft.com/fwlink/p/?LinkID=269886)</ept> .</source>
          <target state="new">For more info about SRGS elements and attributes, see the <bpt id="p1">[</bpt>SRGS Grammar XML Reference<ept id="p1">](http://go.microsoft.com/fwlink/p/?LinkID=269886)</ept> .</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>To get started creating an SRGS grammar, see <bpt id="p1">[</bpt>How to Create a Basic XML Grammar<ept id="p1">](http://go.microsoft.com/fwlink/p/?LinkID=269887)</ept>.</source>
          <target state="new">To get started creating an SRGS grammar, see <bpt id="p1">[</bpt>How to Create a Basic XML Grammar<ept id="p1">](http://go.microsoft.com/fwlink/p/?LinkID=269887)</ept>.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Keep the following points in mind:</source>
          <target state="new">Keep the following points in mind:</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>You can add multiple grammar-file constraints to a constraints collection.</source>
          <target state="new">You can add multiple grammar-file constraints to a constraints collection.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>Use the .grxml file extension for XML-based grammar documents that conform to SRGS rules.</source>
          <target state="new">Use the .grxml file extension for XML-based grammar documents that conform to SRGS rules.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>This example uses an SRGS grammar defined in a file named srgs.grxml (described later).</source>
          <target state="new">This example uses an SRGS grammar defined in a file named srgs.grxml (described later).</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>In the file properties, the <bpt id="p1">**</bpt>Package Action<ept id="p1">**</ept> is set to <bpt id="p2">**</bpt>Content<ept id="p2">**</ept> with <bpt id="p3">**</bpt>Copy to Output Directory<ept id="p3">**</ept> set to <bpt id="p4">**</bpt>Copy always<ept id="p4">**</ept>:</source>
          <target state="new">In the file properties, the <bpt id="p1">**</bpt>Package Action<ept id="p1">**</ept> is set to <bpt id="p2">**</bpt>Content<ept id="p2">**</ept> with <bpt id="p3">**</bpt>Copy to Output Directory<ept id="p3">**</ept> set to <bpt id="p4">**</bpt>Copy always<ept id="p4">**</ept>:</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>This SRGS file (srgs.grxml) includes semantic interpretation tags.</source>
          <target state="new">This SRGS file (srgs.grxml) includes semantic interpretation tags.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>These tags provide a mechanism for returning grammar match data to your app.</source>
          <target state="new">These tags provide a mechanism for returning grammar match data to your app.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Grammars must conform to the World Wide Web Consortium (W3C) <bpt id="p1">[</bpt>Semantic Interpretation for Speech Recognition (SISR) 1.0<ept id="p1">](http://go.microsoft.com/fwlink/p/?LinkID=201765)</ept> specification.</source>
          <target state="new">Grammars must conform to the World Wide Web Consortium (W3C) <bpt id="p1">[</bpt>Semantic Interpretation for Speech Recognition (SISR) 1.0<ept id="p1">](http://go.microsoft.com/fwlink/p/?LinkID=201765)</ept> specification.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Here, we listen for variants of "yes" and "no".</source>
          <target state="new">Here, we listen for variants of "yes" and "no".</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Manage constraints</source>
          <target state="new">Manage constraints</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>After a constraint collection is loaded for recognition, your app can manage which constraints are enabled for recognition operations by setting the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>IsEnabled<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631402)</ept> property of a constraint to <bpt id="p3">**</bpt>true<ept id="p3">**</ept> or <bpt id="p4">**</bpt>false<ept id="p4">**</ept>.</source>
          <target state="new">After a constraint collection is loaded for recognition, your app can manage which constraints are enabled for recognition operations by setting the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>IsEnabled<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631402)</ept> property of a constraint to <bpt id="p3">**</bpt>true<ept id="p3">**</ept> or <bpt id="p4">**</bpt>false<ept id="p4">**</ept>.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>The default setting is <bpt id="p1">**</bpt>true<ept id="p1">**</ept>.</source>
          <target state="new">The default setting is <bpt id="p1">**</bpt>true<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>It's usually more efficient to load constraints once, enabling and disabling them as needed, rather than to load, unload, and compile constraints for each recognition operation.</source>
          <target state="new">It's usually more efficient to load constraints once, enabling and disabling them as needed, rather than to load, unload, and compile constraints for each recognition operation.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>IsEnabled<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631402)</ept> property, as required.</source>
          <target state="new">Use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>IsEnabled<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631402)</ept> property, as required.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Restricting the number of constraints serves to limit the amount of data that the speech recognizer needs to search and match against the speech input.</source>
          <target state="new">Restricting the number of constraints serves to limit the amount of data that the speech recognizer needs to search and match against the speech input.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>This can improve both the performance and the accuracy of speech recognition.</source>
          <target state="new">This can improve both the performance and the accuracy of speech recognition.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Decide which constraints are enabled based on the phrases that your app can expect in the context of the current recognition operation.</source>
          <target state="new">Decide which constraints are enabled based on the phrases that your app can expect in the context of the current recognition operation.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>For example, if the current app context is to display a color, you probably don't need to enable a constraint that recognizes the names of animals.</source>
          <target state="new">For example, if the current app context is to display a color, you probably don't need to enable a constraint that recognizes the names of animals.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>To prompt the user for what can be spoken, use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognizerUIOptions.AudiblePrompt<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653235)</ept> and <bpt id="p3">[</bpt><bpt id="p4">**</bpt>SpeechRecognizerUIOptions.ExampleText<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn653236)</ept> properties, which are set by means of the <bpt id="p5">[</bpt><bpt id="p6">**</bpt>SpeechRecognizer.UIOptions<ept id="p6">**</ept><ept id="p5">](https://msdn.microsoft.com/library/windows/apps/dn653254)</ept> property.</source>
          <target state="new">To prompt the user for what can be spoken, use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognizerUIOptions.AudiblePrompt<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653235)</ept> and <bpt id="p3">[</bpt><bpt id="p4">**</bpt>SpeechRecognizerUIOptions.ExampleText<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn653236)</ept> properties, which are set by means of the <bpt id="p5">[</bpt><bpt id="p6">**</bpt>SpeechRecognizer.UIOptions<ept id="p6">**</ept><ept id="p5">](https://msdn.microsoft.com/library/windows/apps/dn653254)</ept> property.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Preparing users for what they can say during the recognition operation increases the likelihood that they will speak a phrase that can be matched to an active constraint.</source>
          <target state="new">Preparing users for what they can say during the recognition operation increases the likelihood that they will speak a phrase that can be matched to an active constraint.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>Related articles</source>
          <target state="new">Related articles</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Speech interactions</source>
          <target state="new">Speech interactions</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>Samples</source>
          <target state="new">Samples</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>Speech recognition and speech synthesis sample</source>
          <target state="new">Speech recognition and speech synthesis sample</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>