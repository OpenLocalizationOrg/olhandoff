{
  "nodes": [
    {
      "pos": [
        27,
        114
      ],
      "content": "HBase tutorial: Get started with Linux-based HBase clusters in Hadoop | Microsoft Azure"
    },
    {
      "pos": [
        133,
        281
      ],
      "content": "Follow this HBase tutorial to get started using Apache HBase with Hadoop in HDInsight. Create tables from the HBase shell and query them using Hive.",
      "nodes": [
        {
          "content": "Follow this HBase tutorial to get started using Apache HBase with Hadoop in HDInsight.",
          "pos": [
            0,
            86
          ]
        },
        {
          "content": "Create tables from the HBase shell and query them using Hive.",
          "pos": [
            87,
            148
          ]
        }
      ]
    },
    {
      "pos": [
        656,
        739
      ],
      "content": "HBase tutorial: Get started using Apache HBase with Linux-based Hadoop in HDInsight"
    },
    {
      "pos": [
        820,
        1012
      ],
      "content": "Learn how to create an HBase cluster in HDInsight, create HBase tables, and query tables by using Hive. For general HBase information, see <bpt id=\"p1\">[</bpt>HDInsight HBase overview<ept id=\"p1\">][hdinsight-hbase-overview]</ept>.",
      "nodes": [
        {
          "content": "Learn how to create an HBase cluster in HDInsight, create HBase tables, and query tables by using Hive.",
          "pos": [
            0,
            103
          ]
        },
        {
          "content": "For general HBase information, see <bpt id=\"p1\">[</bpt>HDInsight HBase overview<ept id=\"p1\">][hdinsight-hbase-overview]</ept>.",
          "pos": [
            104,
            230
          ]
        }
      ]
    },
    {
      "pos": [
        1014,
        1191
      ],
      "content": "The information in this document is specific to Linux-based HDInsight clusters. For information on Windows-based clusters, use the tab selector on the top of the page to switch.",
      "nodes": [
        {
          "content": "The information in this document is specific to Linux-based HDInsight clusters.",
          "pos": [
            0,
            79
          ]
        },
        {
          "content": "For information on Windows-based clusters, use the tab selector on the top of the page to switch.",
          "pos": [
            80,
            177
          ]
        }
      ]
    },
    {
      "pos": [
        1196,
        1209
      ],
      "content": "Prerequisites"
    },
    {
      "pos": [
        1211,
        1277
      ],
      "content": "Before you begin this HBase tutorial, you must have the following:"
    },
    {
      "pos": [
        1281,
        1439
      ],
      "content": "<bpt id=\"p2\">**</bpt>An Azure subscription<ept id=\"p2\">**</ept>. See <bpt id=\"p3\">[</bpt>Get Azure free trial<ept id=\"p3\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
      "nodes": [
        {
          "content": "<bpt id=\"p2\">**</bpt>An Azure subscription<ept id=\"p2\">**</ept>.",
          "pos": [
            0,
            64
          ]
        },
        {
          "content": "See <bpt id=\"p3\">[</bpt>Get Azure free trial<ept id=\"p3\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
          "pos": [
            65,
            234
          ]
        }
      ]
    },
    {
      "pos": [
        1442,
        1502
      ],
      "content": "<bpt id=\"p4\">[</bpt>Secure Shell(SSU)<ept id=\"p4\">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept>."
    },
    {
      "pos": [
        1506,
        1548
      ],
      "content": "<bpt id=\"p5\">[</bpt>curl<ept id=\"p5\">](http://curl.haxx.se/download.html)</ept>."
    },
    {
      "pos": [
        1553,
        1573
      ],
      "content": "Create HBase cluster"
    },
    {
      "pos": [
        1575,
        1840
      ],
      "content": "The following procedure use an Azure ARM template to create an HBase cluster. To understand the parameters used in the procedure and other cluster creation methods, see <bpt id=\"p6\">[</bpt>Create Linux-based Hadoop clusters in HDInsight<ept id=\"p6\">](hdinsight-hadoop-provision-linux-clusters.md)</ept>.",
      "nodes": [
        {
          "content": "The following procedure use an Azure ARM template to create an HBase cluster.",
          "pos": [
            0,
            77
          ]
        },
        {
          "content": "To understand the parameters used in the procedure and other cluster creation methods, see <bpt id=\"p6\">[</bpt>Create Linux-based Hadoop clusters in HDInsight<ept id=\"p6\">](hdinsight-hadoop-provision-linux-clusters.md)</ept>.",
          "pos": [
            78,
            303
          ]
        }
      ]
    },
    {
      "pos": [
        1845,
        1971
      ],
      "content": "Click the following image to open an ARM template in the Azure Portal. The ARM template is located in a public blob container.",
      "nodes": [
        {
          "content": "Click the following image to open an ARM template in the Azure Portal.",
          "pos": [
            0,
            70
          ]
        },
        {
          "content": "The ARM template is located in a public blob container.",
          "pos": [
            71,
            126
          ]
        }
      ]
    },
    {
      "pos": [
        2388,
        2439
      ],
      "content": "From the <bpt id=\"p7\">**</bpt>Parameters<ept id=\"p7\">**</ept><ph id=\"ph6\"/> blade, enter the following:"
    },
    {
      "pos": [
        2447,
        2520
      ],
      "content": "<bpt id=\"p8\">**</bpt>ClusterName<ept id=\"p8\">**</ept>: Enter a name for the HBase cluster that you will create."
    },
    {
      "pos": [
        2527,
        2685
      ],
      "content": "<bpt id=\"p9\">**</bpt>ClusterStorageAccountName<ept id=\"p9\">**</ept>: Each cluster has an Azure Blob storage account dependency. After you delete a cluster, the data retains in the storage account.",
      "nodes": [
        {
          "content": "<bpt id=\"p9\">**</bpt>ClusterStorageAccountName<ept id=\"p9\">**</ept>: Each cluster has an Azure Blob storage account dependency.",
          "pos": [
            0,
            127
          ]
        },
        {
          "content": "After you delete a cluster, the data retains in the storage account.",
          "pos": [
            128,
            196
          ]
        }
      ]
    },
    {
      "pos": [
        2692,
        2765
      ],
      "content": "<bpt id=\"p10\">**</bpt>Cluster login name and password<ept id=\"p10\">**</ept>: The default login name is <bpt id=\"p11\">**</bpt>admin<ept id=\"p11\">**</ept>."
    },
    {
      "pos": [
        2772,
        2895
      ],
      "leadings": [
        "",
        "    "
      ],
      "content": "<bpt id=\"p12\">**</bpt>SSH username and password<ept id=\"p12\">**</ept>: The default username is <bpt id=\"p13\">**</bpt>sshuser<ept id=\"p13\">**</ept>.  You can rename it. \n<ph id=\"ph7\"/>Other parameters are optional.",
      "nodes": [
        {
          "content": "<bpt id=\"p12\">**</bpt>SSH username and password<ept id=\"p12\">**</ept>: The default username is <bpt id=\"p13\">**</bpt>sshuser<ept id=\"p13\">**</ept>.",
          "pos": [
            0,
            147
          ]
        },
        {
          "content": "You can rename it.",
          "pos": [
            149,
            167
          ]
        },
        {
          "content": "<ph id=\"ph7\"/>Other parameters are optional.",
          "pos": [
            169,
            213
          ]
        }
      ]
    },
    {
      "pos": [
        2901,
        2937
      ],
      "content": "Click <bpt id=\"p14\">**</bpt>OK<ept id=\"p14\">**</ept><ph id=\"ph8\"/> to save the parameters."
    },
    {
      "pos": [
        2941,
        3189
      ],
      "content": "From the <bpt id=\"p15\">**</bpt>Custom deployment<ept id=\"p15\">**</ept><ph id=\"ph9\"/> blade, click <bpt id=\"p16\">**</bpt>Resource group<ept id=\"p16\">**</ept><ph id=\"ph10\"/> dropdown box, and then click <bpt id=\"p17\">**</bpt>New<ept id=\"p17\">**</ept><ph id=\"ph11\"/> to create a new resource group.  The resource group is a container that groups the cluster, the dependent storage account and other linked resource.",
      "nodes": [
        {
          "content": "From the <bpt id=\"p15\">**</bpt>Custom deployment<ept id=\"p15\">**</ept><ph id=\"ph9\"/> blade, click <bpt id=\"p16\">**</bpt>Resource group<ept id=\"p16\">**</ept><ph id=\"ph10\"/> dropdown box, and then click <bpt id=\"p17\">**</bpt>New<ept id=\"p17\">**</ept><ph id=\"ph11\"/> to create a new resource group.",
          "pos": [
            0,
            295
          ]
        },
        {
          "content": "The resource group is a container that groups the cluster, the dependent storage account and other linked resource.",
          "pos": [
            297,
            412
          ]
        }
      ]
    },
    {
      "pos": [
        3193,
        3242
      ],
      "content": "Click <bpt id=\"p18\">**</bpt>Legal terms<ept id=\"p18\">**</ept>, and then click <bpt id=\"p19\">**</bpt>Create<ept id=\"p19\">**</ept>."
    },
    {
      "pos": [
        3246,
        3317
      ],
      "content": "Click <bpt id=\"p20\">**</bpt>Create<ept id=\"p20\">**</ept>. It takes about around 20 minutes to create a cluster.",
      "nodes": [
        {
          "content": "Click <bpt id=\"p20\">**</bpt>Create<ept id=\"p20\">**</ept>.",
          "pos": [
            0,
            57
          ]
        },
        {
          "content": "It takes about around 20 minutes to create a cluster.",
          "pos": [
            58,
            111
          ]
        }
      ]
    },
    {
      "pos": [
        3321,
        3530
      ],
      "content": "<ph id=\"ph12\">[AZURE.NOTE]</ph><ph id=\"ph13\"/> After an HBase cluster is deleted, you can create another HBase cluster by using the same default blob container. The new cluster will pick up the HBase tables you created in the original cluster.",
      "nodes": [
        {
          "content": "<ph id=\"ph12\">[AZURE.NOTE]</ph><ph id=\"ph13\"/> After an HBase cluster is deleted, you can create another HBase cluster by using the same default blob container.",
          "pos": [
            0,
            160
          ]
        },
        {
          "content": "The new cluster will pick up the HBase tables you created in the original cluster.",
          "pos": [
            161,
            243
          ]
        }
      ]
    },
    {
      "pos": [
        3535,
        3564
      ],
      "content": "Create tables and insert data"
    },
    {
      "pos": [
        3566,
        3972
      ],
      "content": "You can use SSH to connect to HBase clusters and use HBase Shell to create HBase tables, insert data and query data. For information on using SSH from Linux, Unix, OS X and Windows, see <bpt id=\"p21\">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X<ept id=\"p21\">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept><ph id=\"ph14\"/> and <bpt id=\"p22\">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id=\"p22\">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept>.",
      "nodes": [
        {
          "content": "You can use SSH to connect to HBase clusters and use HBase Shell to create HBase tables, insert data and query data.",
          "pos": [
            0,
            116
          ]
        },
        {
          "content": "For information on using SSH from Linux, Unix, OS X and Windows, see <bpt id=\"p21\">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X<ept id=\"p21\">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept><ph id=\"ph14\"/> and <bpt id=\"p22\">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id=\"p22\">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept>.",
          "pos": [
            117,
            501
          ]
        }
      ]
    },
    {
      "pos": [
        3976,
        4028
      ],
      "content": "For most people, data appears in the tabular format:"
    },
    {
      "pos": [
        4030,
        4092
      ],
      "content": "<ph id=\"ph15\">![</ph>hdinsight hbase tabular data<ph id=\"ph16\">][img-hbase-sample-data-tabular]</ph>"
    },
    {
      "pos": [
        4094,
        4168
      ],
      "content": "In HBase which is an implementation of BigTable, the same data looks like:"
    },
    {
      "pos": [
        4170,
        4234
      ],
      "content": "<ph id=\"ph17\">![</ph>hdinsight hbase bigtable data<ph id=\"ph18\">][img-hbase-sample-data-bigtable]</ph>"
    },
    {
      "pos": [
        4236,
        4296
      ],
      "content": "It will make more sense after you finish the next procedure."
    },
    {
      "pos": [
        4301,
        4327
      ],
      "content": "<bpt id=\"p23\">**</bpt>To use the HBase shell<ept id=\"p23\">**</ept>"
    },
    {
      "pos": [
        4332,
        4368
      ],
      "content": "From SSH, run the following command:"
    },
    {
      "pos": [
        4394,
        4435
      ],
      "content": "Create an HBase with two column families:"
    },
    {
      "pos": [
        4501,
        4518
      ],
      "content": "Insert some data:"
    },
    {
      "pos": [
        4815,
        4863
      ],
      "content": "<ph id=\"ph19\">![</ph>hdinsight hadoop hbase shell<ph id=\"ph20\">][img-hbase-shell]</ph>"
    },
    {
      "pos": [
        4868,
        4884
      ],
      "content": "Get a single row"
    },
    {
      "pos": [
        4922,
        5008
      ],
      "content": "You will see the same results as using the scan command because there is only one row."
    },
    {
      "pos": [
        5014,
        5201
      ],
      "content": "For more information about the HBase table schema, see <bpt id=\"p24\">[</bpt>Introduction to HBase Schema Design<ept id=\"p24\">][hbase-schema]</ept>. For more HBase commands, see <bpt id=\"p25\">[</bpt>Apache HBase reference guide<ept id=\"p25\">][hbase-quick-start]</ept>.",
      "nodes": [
        {
          "content": "For more information about the HBase table schema, see <bpt id=\"p24\">[</bpt>Introduction to HBase Schema Design<ept id=\"p24\">][hbase-schema]</ept>.",
          "pos": [
            0,
            147
          ]
        },
        {
          "content": "For more HBase commands, see <bpt id=\"p25\">[</bpt>Apache HBase reference guide<ept id=\"p25\">][hbase-quick-start]</ept>.",
          "pos": [
            148,
            267
          ]
        }
      ]
    },
    {
      "pos": [
        5206,
        5220
      ],
      "content": "Exit the shell"
    },
    {
      "pos": [
        5236,
        5287
      ],
      "content": "<bpt id=\"p26\">**</bpt>To bulk load data into the contacts HBase table<ept id=\"p26\">**</ept>"
    },
    {
      "pos": [
        5289,
        5441
      ],
      "content": "HBase includes several methods of loading data into tables.  For more information, see <bpt id=\"p27\">[</bpt>Bulk loading<ept id=\"p27\">](http://hbase.apache.org/book.html#arch.bulk.load)</ept>.",
      "nodes": [
        {
          "content": "HBase includes several methods of loading data into tables.",
          "pos": [
            0,
            59
          ]
        },
        {
          "content": "For more information, see <bpt id=\"p27\">[</bpt>Bulk loading<ept id=\"p27\">](http://hbase.apache.org/book.html#arch.bulk.load)</ept>.",
          "pos": [
            61,
            192
          ]
        }
      ]
    },
    {
      "pos": [
        5444,
        5617
      ],
      "content": "A sample data file has been uploaded to a public blob container, <bpt id=\"p28\">*</bpt>wasb://hbasecontacts@hditutorialdata.blob.core.windows.net/contacts.txt<ept id=\"p28\">*</ept>.  The content of the data file is:",
      "nodes": [
        {
          "content": "A sample data file has been uploaded to a public blob container, <bpt id=\"p28\">*</bpt>wasb://hbasecontacts@hditutorialdata.blob.core.windows.net/contacts.txt<ept id=\"p28\">*</ept>.",
          "pos": [
            0,
            179
          ]
        },
        {
          "content": "The content of the data file is:",
          "pos": [
            181,
            213
          ]
        }
      ]
    },
    {
      "pos": [
        6392,
        6572
      ],
      "content": "You can create a text file and upload the file to your own storage account if you want. For the instructions, see <bpt id=\"p29\">[</bpt>Upload data for Hadoop jobs in HDInsight<ept id=\"p29\">][hdinsight-upload-data]</ept>.",
      "nodes": [
        {
          "content": "You can create a text file and upload the file to your own storage account if you want.",
          "pos": [
            0,
            87
          ]
        },
        {
          "content": "For the instructions, see <bpt id=\"p29\">[</bpt>Upload data for Hadoop jobs in HDInsight<ept id=\"p29\">][hdinsight-upload-data]</ept>.",
          "pos": [
            88,
            220
          ]
        }
      ]
    },
    {
      "pos": [
        6576,
        6673
      ],
      "content": "<ph id=\"ph21\">[AZURE.NOTE]</ph><ph id=\"ph22\"/> This procedure uses the Contacts HBase table you have created in the last procedure."
    },
    {
      "pos": [
        6678,
        6879
      ],
      "content": "From SSH, run the following command to transform the data file to StoreFiles and store at a relative path specified by Dimporttsv.bulk.output:.  If you are in HBase Shell, use the exit command to exit.",
      "nodes": [
        {
          "content": "From SSH, run the following command to transform the data file to StoreFiles and store at a relative path specified by Dimporttsv.bulk.output:.",
          "pos": [
            0,
            143
          ]
        },
        {
          "content": "If you are in HBase Shell, use the exit command to exit.",
          "pos": [
            145,
            201
          ]
        }
      ]
    },
    {
      "pos": [
        7180,
        7284
      ],
      "content": "Run the following command to upload the data from  /example/data/storeDataFileOutput to the HBase table:"
    },
    {
      "pos": [
        7403,
        7484
      ],
      "content": "You can open the HBase shell, and use the scan command to list the table content."
    },
    {
      "pos": [
        7491,
        7514
      ],
      "content": "Use Hive to query HBase"
    },
    {
      "pos": [
        7516,
        7679
      ],
      "content": "You can query data in HBase tables by using Hive. This section creates a Hive table that maps to the HBase table and uses it to query the data in your HBase table.",
      "nodes": [
        {
          "content": "You can query data in HBase tables by using Hive.",
          "pos": [
            0,
            49
          ]
        },
        {
          "content": "This section creates a Hive table that maps to the HBase table and uses it to query the data in your HBase table.",
          "pos": [
            50,
            163
          ]
        }
      ]
    },
    {
      "pos": [
        7684,
        7776
      ],
      "content": "Open <bpt id=\"p30\">**</bpt>PuTTY<ept id=\"p30\">**</ept>, and connect to the cluster.  See the instructions in the previous procedure.",
      "nodes": [
        {
          "content": "Open <bpt id=\"p30\">**</bpt>PuTTY<ept id=\"p30\">**</ept>, and connect to the cluster.",
          "pos": [
            0,
            83
          ]
        },
        {
          "content": "See the instructions in the previous procedure.",
          "pos": [
            85,
            132
          ]
        }
      ]
    },
    {
      "pos": [
        7780,
        7800
      ],
      "content": "Open the Hive shell."
    },
    {
      "pos": [
        7817,
        8044
      ],
      "content": "Run the following HiveQL script  to create an Hive Table that maps to the HBase table. Make sure that you have created the sample table referenced earlier in this tutorial by using the HBase shell before you run this statement.",
      "nodes": [
        {
          "content": "Run the following HiveQL script  to create an Hive Table that maps to the HBase table.",
          "pos": [
            0,
            86
          ]
        },
        {
          "content": "Make sure that you have created the sample table referenced earlier in this tutorial by using the HBase shell before you run this statement.",
          "pos": [
            87,
            227
          ]
        }
      ]
    },
    {
      "pos": [
        8429,
        8514
      ],
      "content": "Run the following HiveQL script . The Hive query queries the data in the HBase table:",
      "nodes": [
        {
          "content": "Run the following HiveQL script .",
          "pos": [
            0,
            33
          ]
        },
        {
          "content": "The Hive query queries the data in the HBase table:",
          "pos": [
            34,
            85
          ]
        }
      ]
    },
    {
      "pos": [
        8564,
        8594
      ],
      "content": "Use HBase REST APIs using Curl"
    },
    {
      "pos": [
        8598,
        8913
      ],
      "content": "<ph id=\"ph23\">[AZURE.NOTE]</ph><ph id=\"ph24\"/> When using Curl or any other REST communication with WebHCat, you must authenticate the requests by providing the user name and password for the HDInsight cluster administrator. You must also use the cluster name as part of the Uniform Resource Identifier (URI) used to send the requests to the server.",
      "nodes": [
        {
          "content": "<ph id=\"ph23\">[AZURE.NOTE]</ph><ph id=\"ph24\"/> When using Curl or any other REST communication with WebHCat, you must authenticate the requests by providing the user name and password for the HDInsight cluster administrator.",
          "pos": [
            0,
            224
          ]
        },
        {
          "content": "You must also use the cluster name as part of the Uniform Resource Identifier (URI) used to send the requests to the server.",
          "pos": [
            225,
            349
          ]
        }
      ]
    },
    {
      "pos": [
        8918,
        9138
      ],
      "content": "For the commands in this section, replace <bpt id=\"p31\">**</bpt>USERNAME<ept id=\"p31\">**</ept><ph id=\"ph25\"/> with the user to authenticate to the cluster, and replace <bpt id=\"p32\">**</bpt>PASSWORD<ept id=\"p32\">**</ept><ph id=\"ph26\"/> with the password for the user account. Replace <bpt id=\"p33\">**</bpt>CLUSTERNAME<ept id=\"p33\">**</ept><ph id=\"ph27\"/> with the name of your cluster.",
      "nodes": [
        {
          "content": "For the commands in this section, replace <bpt id=\"p31\">**</bpt>USERNAME<ept id=\"p31\">**</ept><ph id=\"ph25\"/> with the user to authenticate to the cluster, and replace <bpt id=\"p32\">**</bpt>PASSWORD<ept id=\"p32\">**</ept><ph id=\"ph26\"/> with the password for the user account.",
          "pos": [
            0,
            275
          ]
        },
        {
          "content": "Replace <bpt id=\"p33\">**</bpt>CLUSTERNAME<ept id=\"p33\">**</ept><ph id=\"ph27\"/> with the name of your cluster.",
          "pos": [
            276,
            385
          ]
        }
      ]
    },
    {
      "pos": [
        9143,
        9383
      ],
      "content": "The REST API is secured via <bpt id=\"p34\">[</bpt>basic authentication<ept id=\"p34\">](http://en.wikipedia.org/wiki/Basic_access_authentication)</ept>. You should always make requests by using Secure HTTP (HTTPS) to help ensure that your credentials are securely sent to the server.",
      "nodes": [
        {
          "content": "The REST API is secured via <bpt id=\"p34\">[</bpt>basic authentication<ept id=\"p34\">](http://en.wikipedia.org/wiki/Basic_access_authentication)</ept>.",
          "pos": [
            0,
            149
          ]
        },
        {
          "content": "You should always make requests by using Secure HTTP (HTTPS) to help ensure that your credentials are securely sent to the server.",
          "pos": [
            150,
            280
          ]
        }
      ]
    },
    {
      "pos": [
        9388,
        9492
      ],
      "content": "From a command line, use the following command to verify that you can connect to your HDInsight cluster:"
    },
    {
      "pos": [
        9601,
        9656
      ],
      "content": "You should receive a response similar to the following:"
    },
    {
      "pos": [
        9662,
        9692
      ],
      "content": "{\"status\":\"ok\",\"version\":\"v1\"}"
    },
    {
      "pos": [
        9696,
        9747
      ],
      "content": "The parameters used in this command are as follows:"
    },
    {
      "pos": [
        9882,
        9943
      ],
      "content": "Use the following command to list the exisiting HBase tables:"
    },
    {
      "pos": [
        10042,
        10120
      ],
      "content": "Use the following command to create a new HBase table wit two column families:"
    },
    {
      "pos": [
        10402,
        10444
      ],
      "content": "The schema is provided in the JSon format."
    },
    {
      "pos": [
        10449,
        10495
      ],
      "content": "Use the following command to insert some data:"
    },
    {
      "pos": [
        10780,
        10819
      ],
      "content": "Use the following command to get a row:"
    },
    {
      "pos": [
        10971,
        10991
      ],
      "content": "Check cluster status"
    },
    {
      "pos": [
        10993,
        11131
      ],
      "content": "HBase in HDInsight ships with a Web UI for monitoring clusters. Using the Web UI, you can request statistics or information about regions.",
      "nodes": [
        {
          "content": "HBase in HDInsight ships with a Web UI for monitoring clusters.",
          "pos": [
            0,
            63
          ]
        },
        {
          "content": "Using the Web UI, you can request statistics or information about regions.",
          "pos": [
            64,
            138
          ]
        }
      ]
    },
    {
      "pos": [
        11133,
        11482
      ],
      "content": "SSH can also be used to tunnel local requests, such as web requests, to the HDInsight cluster. The request will then be routed to the requested resource as if it had originated on the HDInsight cluster head node. For more information, see <bpt id=\"p35\">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id=\"p35\">](hdinsight-hadoop-linux-use-ssh-windows.md#tunnel)</ept>.",
      "nodes": [
        {
          "content": "SSH can also be used to tunnel local requests, such as web requests, to the HDInsight cluster.",
          "pos": [
            0,
            94
          ]
        },
        {
          "content": "The request will then be routed to the requested resource as if it had originated on the HDInsight cluster head node.",
          "pos": [
            95,
            212
          ]
        },
        {
          "content": "For more information, see <bpt id=\"p35\">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id=\"p35\">](hdinsight-hadoop-linux-use-ssh-windows.md#tunnel)</ept>.",
          "pos": [
            213,
            389
          ]
        }
      ]
    },
    {
      "pos": [
        11484,
        11525
      ],
      "content": "<bpt id=\"p36\">**</bpt>To establish an SSH tunneling session<ept id=\"p36\">**</ept>"
    },
    {
      "pos": [
        11530,
        11545
      ],
      "content": "Open <bpt id=\"p37\">**</bpt>PuTTY<ept id=\"p37\">**</ept>."
    },
    {
      "pos": [
        11551,
        11746
      ],
      "content": "If you provided an SSH key when you created your user account during the creation process, you must perform the following step to select the private key to use when authenticating to the cluster:"
    },
    {
      "pos": [
        11752,
        11911
      ],
      "content": "In <bpt id=\"p38\">**</bpt>Category<ept id=\"p38\">**</ept>, expand <bpt id=\"p39\">**</bpt>Connection<ept id=\"p39\">**</ept>, expand <bpt id=\"p40\">**</bpt>SSH<ept id=\"p40\">**</ept>, and select <bpt id=\"p41\">**</bpt>Auth<ept id=\"p41\">**</ept>. Finally, click <bpt id=\"p42\">**</bpt>Browse<ept id=\"p42\">**</ept><ph id=\"ph28\"/> and select the .ppk file that contains your private key.",
      "nodes": [
        {
          "content": "In <bpt id=\"p38\">**</bpt>Category<ept id=\"p38\">**</ept>, expand <bpt id=\"p39\">**</bpt>Connection<ept id=\"p39\">**</ept>, expand <bpt id=\"p40\">**</bpt>SSH<ept id=\"p40\">**</ept>, and select <bpt id=\"p41\">**</bpt>Auth<ept id=\"p41\">**</ept>.",
          "pos": [
            0,
            236
          ]
        },
        {
          "content": "Finally, click <bpt id=\"p42\">**</bpt>Browse<ept id=\"p42\">**</ept><ph id=\"ph28\"/> and select the .ppk file that contains your private key.",
          "pos": [
            237,
            374
          ]
        }
      ]
    },
    {
      "pos": [
        11916,
        11951
      ],
      "content": "In <bpt id=\"p43\">**</bpt>Category<ept id=\"p43\">**</ept>, click <bpt id=\"p44\">**</bpt>Session<ept id=\"p44\">**</ept>."
    },
    {
      "pos": [
        11955,
        12036
      ],
      "content": "From the Basic options for your PuTTY session screen, enter the following values:"
    },
    {
      "pos": [
        12044,
        12260
      ],
      "content": "<bpt id=\"p45\">**</bpt>Host Name<ept id=\"p45\">**</ept>: the SSH address of your HDInsight server in the Host name (or IP address) field. The SSH address is your cluster name, then <bpt id=\"p46\">**</bpt>-ssh.azurehdinsight.net<ept id=\"p46\">**</ept>. For example, <bpt id=\"p47\">*</bpt>mycluster-ssh.azurehdinsight.net<ept id=\"p47\">*</ept>.",
      "nodes": [
        {
          "content": "<bpt id=\"p45\">**</bpt>Host Name<ept id=\"p45\">**</ept>: the SSH address of your HDInsight server in the Host name (or IP address) field.",
          "pos": [
            0,
            135
          ]
        },
        {
          "content": "The SSH address is your cluster name, then <bpt id=\"p46\">**</bpt>-ssh.azurehdinsight.net<ept id=\"p46\">**</ept>.",
          "pos": [
            136,
            247
          ]
        },
        {
          "content": "For example, <bpt id=\"p47\">*</bpt>mycluster-ssh.azurehdinsight.net<ept id=\"p47\">*</ept>.",
          "pos": [
            248,
            336
          ]
        }
      ]
    },
    {
      "pos": [
        12267,
        12319
      ],
      "content": "<bpt id=\"p48\">**</bpt>Port<ept id=\"p48\">**</ept>: 22. The ssh port on the head node 0 is 22.",
      "nodes": [
        {
          "content": "<bpt id=\"p48\">**</bpt>Port<ept id=\"p48\">**</ept>: 22.",
          "pos": [
            0,
            53
          ]
        },
        {
          "content": "The ssh port on the head node 0 is 22.",
          "pos": [
            54,
            92
          ]
        }
      ]
    },
    {
      "pos": [
        12325,
        12446
      ],
      "content": "In the <bpt id=\"p49\">**</bpt>Category<ept id=\"p49\">**</ept><ph id=\"ph29\"/> section to the left of the dialog, expand <bpt id=\"p50\">**</bpt>Connection<ept id=\"p50\">**</ept>, expand <bpt id=\"p51\">**</bpt>SSH<ept id=\"p51\">**</ept>, and then click <bpt id=\"p52\">**</bpt>Tunnels<ept id=\"p52\">**</ept>."
    },
    {
      "pos": [
        12450,
        12536
      ],
      "content": "Provide the following information on the Options controlling SSH port forwarding form:"
    },
    {
      "pos": [
        12544,
        12629
      ],
      "content": "<bpt id=\"p53\">**</bpt>Source port<ept id=\"p53\">**</ept><ph id=\"ph30\"/> - The port on the client that you wish to forward. For example, 9876.",
      "nodes": [
        {
          "content": "<bpt id=\"p53\">**</bpt>Source port<ept id=\"p53\">**</ept><ph id=\"ph30\"/> - The port on the client that you wish to forward.",
          "pos": [
            0,
            121
          ]
        },
        {
          "content": "For example, 9876.",
          "pos": [
            122,
            140
          ]
        }
      ]
    },
    {
      "pos": [
        12636,
        12686
      ],
      "content": "<bpt id=\"p54\">**</bpt>Dynamic<ept id=\"p54\">**</ept><ph id=\"ph31\"/> - Enables dynamic SOCKS proxy routing."
    },
    {
      "pos": [
        12690,
        12724
      ],
      "content": "Click <bpt id=\"p55\">**</bpt>Add<ept id=\"p55\">**</ept><ph id=\"ph32\"/> to add the settings."
    },
    {
      "pos": [
        12728,
        12797
      ],
      "content": "Click <bpt id=\"p56\">**</bpt>Open<ept id=\"p56\">**</ept><ph id=\"ph33\"/> at the bottom of the dialog to open an SSH connection."
    },
    {
      "pos": [
        12801,
        12915
      ],
      "content": "When prompted, log in to the server using a SSH account. This will establish an SSH session and enable the tunnel.",
      "nodes": [
        {
          "content": "When prompted, log in to the server using a SSH account.",
          "pos": [
            0,
            56
          ]
        },
        {
          "content": "This will establish an SSH session and enable the tunnel.",
          "pos": [
            57,
            114
          ]
        }
      ]
    },
    {
      "pos": [
        12917,
        12968
      ],
      "content": "<bpt id=\"p57\">**</bpt>To find the FQDN of the zookeepers using Ambari<ept id=\"p57\">**</ept>"
    },
    {
      "pos": [
        12973,
        13025
      ],
      "content": "Browse to https://<ph id=\"ph34\">&lt;ClusterName&gt;</ph>.azurehdinsight.net/."
    },
    {
      "pos": [
        13029,
        13079
      ],
      "content": "Enter your cluster user account credentials twice."
    },
    {
      "pos": [
        13083,
        13123
      ],
      "content": "From the left menu, click <bpt id=\"p58\">**</bpt>zookeeper<ept id=\"p58\">**</ept>."
    },
    {
      "pos": [
        13127,
        13199
      ],
      "content": "Click one of the three <bpt id=\"p59\">**</bpt>ZooKeeper Server<ept id=\"p59\">**</ept><ph id=\"ph35\"/> links from the Summary list."
    },
    {
      "pos": [
        13203,
        13297
      ],
      "content": "Copy <bpt id=\"p60\">**</bpt>Hostname<ept id=\"p60\">**</ept>. For example, zk0-CLUSTERNAME.xxxxxxxxxxxxxxxxxxxx.cx.internal.cloudapp.net.",
      "nodes": [
        {
          "content": "Copy <bpt id=\"p60\">**</bpt>Hostname<ept id=\"p60\">**</ept>.",
          "pos": [
            0,
            58
          ]
        },
        {
          "content": "For example, zk0-CLUSTERNAME.xxxxxxxxxxxxxxxxxxxx.cx.internal.cloudapp.net.",
          "pos": [
            59,
            134
          ]
        }
      ]
    },
    {
      "pos": [
        13299,
        13367
      ],
      "content": "<bpt id=\"p61\">**</bpt>To configure a client program (Firefox) and check cluster status<ept id=\"p61\">**</ept>"
    },
    {
      "pos": [
        13372,
        13385
      ],
      "content": "Open Firefox."
    },
    {
      "pos": [
        13389,
        13420
      ],
      "content": "Click the <bpt id=\"p62\">**</bpt>Open Menu<ept id=\"p62\">**</ept><ph id=\"ph36\"/> button."
    },
    {
      "pos": [
        13424,
        13442
      ],
      "content": "Click <bpt id=\"p63\">**</bpt>Options<ept id=\"p63\">**</ept>."
    },
    {
      "pos": [
        13446,
        13513
      ],
      "content": "Click <bpt id=\"p64\">**</bpt>Advanced<ept id=\"p64\">**</ept>, click <bpt id=\"p65\">**</bpt>Network<ept id=\"p65\">**</ept>, and then click <bpt id=\"p66\">**</bpt>Settings<ept id=\"p66\">**</ept>."
    },
    {
      "pos": [
        13517,
        13555
      ],
      "content": "Select <bpt id=\"p67\">**</bpt>Manual proxy configuration<ept id=\"p67\">**</ept>."
    },
    {
      "pos": [
        13559,
        13586
      ],
      "content": "Enter the following values:"
    },
    {
      "pos": [
        13594,
        13619
      ],
      "content": "<bpt id=\"p68\">**</bpt>Socks Host<ept id=\"p68\">**</ept>: localhost"
    },
    {
      "pos": [
        13626,
        13717
      ],
      "content": "<bpt id=\"p69\">**</bpt>Port<ept id=\"p69\">**</ept>: Use the same port you configured in the Putty SSH tunnelling.  For example, 9876.",
      "nodes": [
        {
          "content": "<bpt id=\"p69\">**</bpt>Port<ept id=\"p69\">**</ept>: Use the same port you configured in the Putty SSH tunnelling.",
          "pos": [
            0,
            111
          ]
        },
        {
          "content": "For example, 9876.",
          "pos": [
            113,
            131
          ]
        }
      ]
    },
    {
      "pos": [
        13724,
        13748
      ],
      "content": "<bpt id=\"p70\">**</bpt>SOCKS v5<ept id=\"p70\">**</ept>: (selected)"
    },
    {
      "pos": [
        13755,
        13781
      ],
      "content": "<bpt id=\"p71\">**</bpt>Remote DNS<ept id=\"p71\">**</ept>: (selected)"
    },
    {
      "pos": [
        13785,
        13818
      ],
      "content": "Click <bpt id=\"p72\">**</bpt>OK<ept id=\"p72\">**</ept><ph id=\"ph37\"/> to save the changes."
    },
    {
      "pos": [
        13822,
        13883
      ],
      "content": "Browse to http://<ph id=\"ph38\">&lt;TheFQDN of a ZooKeeper&gt;</ph>:60010/master-status"
    },
    {
      "pos": [
        13885,
        14005
      ],
      "content": "In a high availability cluster, you will find a link to the current active HBase master node that is hosting the Web UI."
    },
    {
      "pos": [
        14012,
        14023
      ],
      "content": "Next steps?"
    },
    {
      "pos": [
        14024,
        14344
      ],
      "content": "In this HBase tutorial for HDInsight, you learned how to create an HBase cluster and how to create tables and view the data in those tables from the HBase shell. You also learned how use a Hive query on data in HBase tables and how to use the HBase C# REST APIs to create an HBase table and retrieve data from the table.",
      "nodes": [
        {
          "content": "In this HBase tutorial for HDInsight, you learned how to create an HBase cluster and how to create tables and view the data in those tables from the HBase shell.",
          "pos": [
            0,
            161
          ]
        },
        {
          "content": "You also learned how use a Hive query on data in HBase tables and how to use the HBase C# REST APIs to create an HBase table and retrieve data from the table.",
          "pos": [
            162,
            320
          ]
        }
      ]
    },
    {
      "pos": [
        14346,
        14365
      ],
      "content": "To learn more, see:"
    },
    {
      "pos": [
        14369,
        14596
      ],
      "content": "<bpt id=\"p73\">[</bpt>HDInsight HBase overview<ept id=\"p73\">][hdinsight-hbase-overview]</ept>:\nHBase is an Apache, open-source, NoSQL database built on Hadoop that provides random access and strong consistency for large amounts of unstructured and semistructured data."
    }
  ],
  "content": "<properties\n    pageTitle=\"HBase tutorial: Get started with Linux-based HBase clusters in Hadoop | Microsoft Azure\"\n    description=\"Follow this HBase tutorial to get started using Apache HBase with Hadoop in HDInsight. Create tables from the HBase shell and query them using Hive.\"\n    keywords=\"apache hbase,hbase,hbase shell,hbase tutorial\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    authors=\"mumian\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.workload=\"big-data\"\n    ms.tgt_pltfrm=\"na\"\n    ms.devlang=\"na\"\n    ms.topic=\"get-started-article\"\n    ms.date=\"02/04/2016\"\n    ms.author=\"jgao\"/>\n\n\n\n# HBase tutorial: Get started using Apache HBase with Linux-based Hadoop in HDInsight \n\n[AZURE.INCLUDE [hbase-selector](../../includes/hdinsight-hbase-selector.md)]\n\nLearn how to create an HBase cluster in HDInsight, create HBase tables, and query tables by using Hive. For general HBase information, see [HDInsight HBase overview][hdinsight-hbase-overview].\n\nThe information in this document is specific to Linux-based HDInsight clusters. For information on Windows-based clusters, use the tab selector on the top of the page to switch.\n\n###Prerequisites\n\nBefore you begin this HBase tutorial, you must have the following:\n\n- **An Azure subscription**. See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).\n- [Secure Shell(SSU)](hdinsight-hadoop-linux-use-ssh-unix.md). \n- [curl](http://curl.haxx.se/download.html).\n\n## Create HBase cluster\n\nThe following procedure use an Azure ARM template to create an HBase cluster. To understand the parameters used in the procedure and other cluster creation methods, see [Create Linux-based Hadoop clusters in HDInsight](hdinsight-hadoop-provision-linux-clusters.md).\n\n1. Click the following image to open an ARM template in the Azure Portal. The ARM template is located in a public blob container. \n\n    <a href=\"https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fhditutorialdata.blob.core.windows.net%2Farmtemplates%2FHbase.json\" target=\"_blank\"><img src=\"https://acom.azurecomcdn.net/80C57D/cdn/mediahandler/docarticles/dpsmedia-prod/azure.microsoft.com/en-us/documentation/articles/hdinsight-hbase-tutorial-get-started-linux/20160201111850/deploy-to-azure.png\" alt=\"Deploy to Azure\"></a>\n\n2. From the **Parameters** blade, enter the following:\n\n    - **ClusterName**: Enter a name for the HBase cluster that you will create.\n    - **ClusterStorageAccountName**: Each cluster has an Azure Blob storage account dependency. After you delete a cluster, the data retains in the storage account.\n    - **Cluster login name and password**: The default login name is **admin**.\n    - **SSH username and password**: The default username is **sshuser**.  You can rename it. \n    Other parameters are optional.  \n3. Click **OK** to save the parameters.\n4. From the **Custom deployment** blade, click **Resource group** dropdown box, and then click **New** to create a new resource group.  The resource group is a container that groups the cluster, the dependent storage account and other linked resource.\n5. Click **Legal terms**, and then click **Create**.\n6. Click **Create**. It takes about around 20 minutes to create a cluster.\n\n\n>[AZURE.NOTE] After an HBase cluster is deleted, you can create another HBase cluster by using the same default blob container. The new cluster will pick up the HBase tables you created in the original cluster.\n\n## Create tables and insert data\n\nYou can use SSH to connect to HBase clusters and use HBase Shell to create HBase tables, insert data and query data. For information on using SSH from Linux, Unix, OS X and Windows, see [Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X](hdinsight-hadoop-linux-use-ssh-unix.md) and [Use SSH with Linux-based Hadoop on HDInsight from Windows](hdinsight-hadoop-linux-use-ssh-windows.md).\n \n\nFor most people, data appears in the tabular format:\n\n![hdinsight hbase tabular data][img-hbase-sample-data-tabular]\n\nIn HBase which is an implementation of BigTable, the same data looks like:\n\n![hdinsight hbase bigtable data][img-hbase-sample-data-bigtable]\n\nIt will make more sense after you finish the next procedure.  \n\n\n**To use the HBase shell**\n\n1. From SSH, run the following command:\n\n        hbase shell\n\n4. Create an HBase with two column families:\n\n        create 'Contacts', 'Personal', 'Office'\n        list\n5. Insert some data:\n\n        put 'Contacts', '1000', 'Personal:Name', 'John Dole'\n        put 'Contacts', '1000', 'Personal:Phone', '1-425-000-0001'\n        put 'Contacts', '1000', 'Office:Phone', '1-425-000-0002'\n        put 'Contacts', '1000', 'Office:Address', '1111 San Gabriel Dr.'\n        scan 'Contacts'\n\n    ![hdinsight hadoop hbase shell][img-hbase-shell]\n\n6. Get a single row\n\n        get 'Contacts', '1000'\n\n    You will see the same results as using the scan command because there is only one row.\n\n    For more information about the HBase table schema, see [Introduction to HBase Schema Design][hbase-schema]. For more HBase commands, see [Apache HBase reference guide][hbase-quick-start].\n\n6. Exit the shell\n\n        exit\n\n**To bulk load data into the contacts HBase table**\n\nHBase includes several methods of loading data into tables.  For more information, see [Bulk loading](http://hbase.apache.org/book.html#arch.bulk.load).\n\n\nA sample data file has been uploaded to a public blob container, *wasb://hbasecontacts@hditutorialdata.blob.core.windows.net/contacts.txt*.  The content of the data file is:\n\n    8396    Calvin Raji     230-555-0191    230-555-0191    5415 San Gabriel Dr.\n    16600   Karen Wu        646-555-0113    230-555-0192    9265 La Paz\n    4324    Karl Xie        508-555-0163    230-555-0193    4912 La Vuelta\n    16891   Jonn Jackson    674-555-0110    230-555-0194    40 Ellis St.\n    3273    Miguel Miller   397-555-0155    230-555-0195    6696 Anchor Drive\n    3588    Osa Agbonile    592-555-0152    230-555-0196    1873 Lion Circle\n    10272   Julia Lee       870-555-0110    230-555-0197    3148 Rose Street\n    4868    Jose Hayes      599-555-0171    230-555-0198    793 Crawford Street\n    4761    Caleb Alexander 670-555-0141    230-555-0199    4775 Kentucky Dr.\n    16443   Terry Chander   998-555-0171    230-555-0200    771 Northridge Drive\n\nYou can create a text file and upload the file to your own storage account if you want. For the instructions, see [Upload data for Hadoop jobs in HDInsight][hdinsight-upload-data].\n\n> [AZURE.NOTE] This procedure uses the Contacts HBase table you have created in the last procedure.\n\n1. From SSH, run the following command to transform the data file to StoreFiles and store at a relative path specified by Dimporttsv.bulk.output:.  If you are in HBase Shell, use the exit command to exit.\n\n        hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.columns=\"HBASE_ROW_KEY,Personal:Name, Personal:Phone, Office:Phone, Office:Address\" -Dimporttsv.bulk.output=\"/example/data/storeDataFileOutput\" Contacts wasb://hbasecontacts@hditutorialdata.blob.core.windows.net/contacts.txt\n\n4. Run the following command to upload the data from  /example/data/storeDataFileOutput to the HBase table:\n\n        hbase org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles /example/data/storeDataFileOutput Contacts\n\n5. You can open the HBase shell, and use the scan command to list the table content.\n\n\n\n## Use Hive to query HBase\n\nYou can query data in HBase tables by using Hive. This section creates a Hive table that maps to the HBase table and uses it to query the data in your HBase table.\n\n1. Open **PuTTY**, and connect to the cluster.  See the instructions in the previous procedure.\n2. Open the Hive shell.\n\n       hive\n3. Run the following HiveQL script  to create an Hive Table that maps to the HBase table. Make sure that you have created the sample table referenced earlier in this tutorial by using the HBase shell before you run this statement.\n\n        CREATE EXTERNAL TABLE hbasecontacts(rowkey STRING, name STRING, homephone STRING, officephone STRING, officeaddress STRING)\n        STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'\n        WITH SERDEPROPERTIES ('hbase.columns.mapping' = ':key,Personal:Name,Personal:Phone,Office:Phone,Office:Address')\n        TBLPROPERTIES ('hbase.table.name' = 'Contacts');\n\n2. Run the following HiveQL script . The Hive query queries the data in the HBase table:\n\n        SELECT count(*) FROM hbasecontacts;\n\n## Use HBase REST APIs using Curl\n\n> [AZURE.NOTE] When using Curl or any other REST communication with WebHCat, you must authenticate the requests by providing the user name and password for the HDInsight cluster administrator. You must also use the cluster name as part of the Uniform Resource Identifier (URI) used to send the requests to the server.\n>\n> For the commands in this section, replace **USERNAME** with the user to authenticate to the cluster, and replace **PASSWORD** with the password for the user account. Replace **CLUSTERNAME** with the name of your cluster.\n>\n> The REST API is secured via [basic authentication](http://en.wikipedia.org/wiki/Basic_access_authentication). You should always make requests by using Secure HTTP (HTTPS) to help ensure that your credentials are securely sent to the server.\n\n1. From a command line, use the following command to verify that you can connect to your HDInsight cluster:\n\n        curl -u <UserName>:<Password> -G https://<ClusterName>.azurehdinsight.net/templeton/v1/status\n\n    You should receive a response similar to the following:\n\n    {\"status\":\"ok\",\"version\":\"v1\"}\n\n  The parameters used in this command are as follows:\n\n    * **-u** - The user name and password used to authenticate the request.\n    * **-G** - Indicates that this is a GET request.\n\n2. Use the following command to list the exisiting HBase tables:\n\n        curl -u <UserName>:<Password> -G https://<ClusterName>.azurehdinsight.net/hbaserest/\n\n3. Use the following command to create a new HBase table wit two column families:\n\n        curl -u <UserName>:<Password> -v -X PUT \"https://<ClusterName>.azurehdinsight.net/hbaserest/Contacts1/schema\" -H \"Accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"@name\\\":\\\"test\\\",\\\"ColumnSchema\\\":[{\\\"name\\\":\\\"Personal\\\"},{\\\"name\\\":\\\"Office\\\"}]}\"\n\n    The schema is provided in the JSon format.\n\n4. Use the following command to insert some data:\n\n        curl -u <UserName>:<Password> -v -X PUT \"https://<ClusterName>.azurehdinsight.net/hbaserest/Contacts1/schema\" -H \"Accept: application/json\" -H \"Content-Type: application/json\" -d \"{\\\"Row\\\":{\\\"key\\\":\\\"1000\\\",\\\"Cell\\\":{\\\"column\\\":\\\"Personal:Name\\\", \\\"$\\\":\\\"John Dole\\\"}}}\"\n\n5. Use the following command to get a row:\n\n        curl -u <UserName>:<Password> -v -X GET \"https://<ClusterName>.azurehdinsight.net/hbaserest/Contacts1/1000\" -H \"Accept: application/json\"\n\n## Check cluster status\n\nHBase in HDInsight ships with a Web UI for monitoring clusters. Using the Web UI, you can request statistics or information about regions.\n\nSSH can also be used to tunnel local requests, such as web requests, to the HDInsight cluster. The request will then be routed to the requested resource as if it had originated on the HDInsight cluster head node. For more information, see [Use SSH with Linux-based Hadoop on HDInsight from Windows](hdinsight-hadoop-linux-use-ssh-windows.md#tunnel).\n\n**To establish an SSH tunneling session**\n\n1. Open **PuTTY**.  \n2. If you provided an SSH key when you created your user account during the creation process, you must perform the following step to select the private key to use when authenticating to the cluster:\n\n    In **Category**, expand **Connection**, expand **SSH**, and select **Auth**. Finally, click **Browse** and select the .ppk file that contains your private key.\n\n3. In **Category**, click **Session**.\n4. From the Basic options for your PuTTY session screen, enter the following values:\n\n    - **Host Name**: the SSH address of your HDInsight server in the Host name (or IP address) field. The SSH address is your cluster name, then **-ssh.azurehdinsight.net**. For example, *mycluster-ssh.azurehdinsight.net*.\n    - **Port**: 22. The ssh port on the head node 0 is 22.  \n5. In the **Category** section to the left of the dialog, expand **Connection**, expand **SSH**, and then click **Tunnels**.\n6. Provide the following information on the Options controlling SSH port forwarding form:\n\n    - **Source port** - The port on the client that you wish to forward. For example, 9876.\n    - **Dynamic** - Enables dynamic SOCKS proxy routing.\n7. Click **Add** to add the settings.\n8. Click **Open** at the bottom of the dialog to open an SSH connection.\n9. When prompted, log in to the server using a SSH account. This will establish an SSH session and enable the tunnel.\n\n**To find the FQDN of the zookeepers using Ambari**\n\n1. Browse to https://<ClusterName>.azurehdinsight.net/.\n2. Enter your cluster user account credentials twice.\n3. From the left menu, click **zookeeper**.\n4. Click one of the three **ZooKeeper Server** links from the Summary list.\n5. Copy **Hostname**. For example, zk0-CLUSTERNAME.xxxxxxxxxxxxxxxxxxxx.cx.internal.cloudapp.net.\n\n**To configure a client program (Firefox) and check cluster status**\n\n1. Open Firefox.\n2. Click the **Open Menu** button.\n3. Click **Options**.\n4. Click **Advanced**, click **Network**, and then click **Settings**.\n5. Select **Manual proxy configuration**.\n6. Enter the following values:\n\n    - **Socks Host**: localhost\n    - **Port**: Use the same port you configured in the Putty SSH tunnelling.  For example, 9876.\n    - **SOCKS v5**: (selected)\n    - **Remote DNS**: (selected)\n7. Click **OK** to save the changes.\n8. Browse to http://<TheFQDN of a ZooKeeper>:60010/master-status\n\nIn a high availability cluster, you will find a link to the current active HBase master node that is hosting the Web UI.\n\n\n\n## Next steps?\nIn this HBase tutorial for HDInsight, you learned how to create an HBase cluster and how to create tables and view the data in those tables from the HBase shell. You also learned how use a Hive query on data in HBase tables and how to use the HBase C# REST APIs to create an HBase table and retrieve data from the table.\n\nTo learn more, see:\n\n- [HDInsight HBase overview][hdinsight-hbase-overview]:\nHBase is an Apache, open-source, NoSQL database built on Hadoop that provides random access and strong consistency for large amounts of unstructured and semistructured data.\n\n\n[hdinsight-manage-portal]: hdinsight-administer-use-management-portal.md\n[hdinsight-upload-data]: hdinsight-upload-data.md\n[hbase-reference]: http://hbase.apache.org/book.html#importtsv\n[hbase-schema]: http://0b4af6cdc2f0c5998459-c0245c5c937c5dedcca3f1764ecc9b2f.r43.cf2.rackcdn.com/9353-login1210_khurana.pdf\n[hbase-quick-start]: http://hbase.apache.org/book.html#quickstart\n\n\n\n\n\n[hdinsight-hbase-overview]: hdinsight-hbase-overview.md\n[hdinsight-hbase-provision-vnet]: hdinsight-hbase-provision-vnet.md\n[hdinsight-versions]: hdinsight-component-versioning.md\n[hbase-twitter-sentiment]: hdinsight-hbase-analyze-twitter-sentiment.md\n[azure-purchase-options]: http://azure.microsoft.com/pricing/purchase-options/\n[azure-member-offers]: http://azure.microsoft.com/pricing/member-offers/\n[azure-free-trial]: http://azure.microsoft.com/pricing/free-trial/\n[azure-portal]: https://portal.azure.com/\n[azure-create-storageaccount]: http://azure.microsoft.com/documentation/articles/storage-create-storage-account/\n\n[img-hdinsight-hbase-cluster-quick-create]: ./media/hdinsight-hbase-tutorial-get-started-linux/hdinsight-hbase-quick-create.png\n[img-hdinsight-hbase-hive-editor]: ./media/hdinsight-hbase-tutorial-get-started-linux/hdinsight-hbase-hive-editor.png\n[img-hdinsight-hbase-file-browser]: ./media/hdinsight-hbase-tutorial-get-started-linux/hdinsight-hbase-file-browser.png\n[img-hbase-shell]: ./media/hdinsight-hbase-tutorial-get-started-linux/hdinsight-hbase-shell.png\n[img-hbase-sample-data-tabular]: ./media/hdinsight-hbase-tutorial-get-started-linux/hdinsight-hbase-contacts-tabular.png\n[img-hbase-sample-data-bigtable]: ./media/hdinsight-hbase-tutorial-get-started-linux/hdinsight-hbase-contacts-bigtable.png\n"
}