{
  "nodes": [
    {
      "pos": [
        27,
        93
      ],
      "content": "Linux tutorial: Get started with Hadoop and Hive | Microsoft Azure"
    },
    {
      "pos": [
        112,
        245
      ],
      "content": "Follow this Linux tutorial to get started using Hadoop in HDInsight. Learn how to provision Linux clusters, and query data with Hive.",
      "nodes": [
        {
          "content": "Follow this Linux tutorial to get started using Hadoop in HDInsight.",
          "pos": [
            0,
            68
          ]
        },
        {
          "content": "Learn how to provision Linux clusters, and query data with Hive.",
          "pos": [
            69,
            133
          ]
        }
      ]
    },
    {
      "pos": [
        574,
        640
      ],
      "content": "Hadoop tutorial: Get started using Linux-based Hadoop in HDInsight"
    },
    {
      "pos": [
        644,
        660
      ],
      "content": "[AZURE.SELECTOR]"
    },
    {
      "pos": [
        663,
        722
      ],
      "content": "<bpt id=\"p1\">[</bpt>Windows<ept id=\"p1\">](hdinsight-hadoop-tutorial-get-started-windows.md)</ept>"
    },
    {
      "pos": [
        725,
        780
      ],
      "content": "<bpt id=\"p2\">[</bpt>Linux<ept id=\"p2\">](hdinsight-hadoop-linux-tutorial-get-started.md)</ept>"
    },
    {
      "pos": [
        782,
        886
      ],
      "content": "Learn how to create Linux-based Hadoop clusters in HDInsight, and use Ambari Hive View to run Hive jobs."
    },
    {
      "pos": [
        888,
        1362
      ],
      "content": "If you are new to Hadoop and big data, you can read more about the terms: <bpt id=\"p3\">[</bpt>Apache Hadoop<ept id=\"p3\">](http://go.microsoft.com/fwlink/?LinkId=510084)</ept>, <bpt id=\"p4\">[</bpt>MapReduce<ept id=\"p4\">](http://go.microsoft.com/fwlink/?LinkId=510086)</ept>, <bpt id=\"p5\">[</bpt>Hadoop Distributed File System (HDFS)<ept id=\"p5\">](http://go.microsoft.com/fwlink/?LinkId=510087)</ept>, and <bpt id=\"p6\">[</bpt>Hive<ept id=\"p6\">](http://go.microsoft.com/fwlink/?LinkId=510085)</ept>. To understand how HDInsight enables Hadoop in Azure, see <bpt id=\"p7\">[</bpt>Introduction to Hadoop in HDInsight<ept id=\"p7\">](hdinsight-hadoop-introduction.md)</ept>.",
      "nodes": [
        {
          "content": "If you are new to Hadoop and big data, you can read more about the terms: <bpt id=\"p3\">[</bpt>Apache Hadoop<ept id=\"p3\">](http://go.microsoft.com/fwlink/?LinkId=510084)</ept>, <bpt id=\"p4\">[</bpt>MapReduce<ept id=\"p4\">](http://go.microsoft.com/fwlink/?LinkId=510086)</ept>, <bpt id=\"p5\">[</bpt>Hadoop Distributed File System (HDFS)<ept id=\"p5\">](http://go.microsoft.com/fwlink/?LinkId=510087)</ept>, and <bpt id=\"p6\">[</bpt>Hive<ept id=\"p6\">](http://go.microsoft.com/fwlink/?LinkId=510085)</ept>.",
          "pos": [
            0,
            496
          ]
        },
        {
          "content": "To understand how HDInsight enables Hadoop in Azure, see <bpt id=\"p7\">[</bpt>Introduction to Hadoop in HDInsight<ept id=\"p7\">](hdinsight-hadoop-introduction.md)</ept>.",
          "pos": [
            497,
            664
          ]
        }
      ]
    },
    {
      "pos": [
        1368,
        1381
      ],
      "content": "Prerequisites"
    },
    {
      "pos": [
        1383,
        1429
      ],
      "content": "Before you begin this tutorial, you must have:"
    },
    {
      "pos": [
        1433,
        1588
      ],
      "content": "<bpt id=\"p8\">**</bpt>Azure subscription<ept id=\"p8\">**</ept>: See <bpt id=\"p9\">[</bpt>Get Azure free trial<ept id=\"p9\">](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>."
    },
    {
      "pos": [
        1593,
        1607
      ],
      "content": "Create cluster"
    },
    {
      "pos": [
        1609,
        2257
      ],
      "content": "Most of Hadoop jobs are batch jobs. You create a cluster and run some jobs. In this section, you will create a Linux-based Hadoop cluster in HDInsight using <bpt id=\"p10\">[</bpt>Azure ARM template<ept id=\"p10\">](../resource-group-template-deploy.md)</ept>. The Azure ARM template experience is not required for following this tutorial. For other cluster creation methods and understanding the settings, see <bpt id=\"p11\">[</bpt>Create HDInsight clusters<ept id=\"p11\">](hdinsight-hadoop-provision-linux-clusters.md)</ept>. For more information about using ARM template to create Hadoop clusters in HDInsight, see <bpt id=\"p12\">[</bpt>Create Hadoop clusters in HDInsight using ARM templates<ept id=\"p12\">](hdinsight-hadoop-create-windows-clusters-arm-templates.md)</ept>",
      "nodes": [
        {
          "content": "Most of Hadoop jobs are batch jobs.",
          "pos": [
            0,
            35
          ]
        },
        {
          "content": "You create a cluster and run some jobs.",
          "pos": [
            36,
            75
          ]
        },
        {
          "content": "In this section, you will create a Linux-based Hadoop cluster in HDInsight using <bpt id=\"p10\">[</bpt>Azure ARM template<ept id=\"p10\">](../resource-group-template-deploy.md)</ept>.",
          "pos": [
            76,
            256
          ]
        },
        {
          "content": "The Azure ARM template experience is not required for following this tutorial.",
          "pos": [
            257,
            335
          ]
        },
        {
          "content": "For other cluster creation methods and understanding the settings, see <bpt id=\"p11\">[</bpt>Create HDInsight clusters<ept id=\"p11\">](hdinsight-hadoop-provision-linux-clusters.md)</ept>.",
          "pos": [
            336,
            521
          ]
        },
        {
          "content": "For more information about using ARM template to create Hadoop clusters in HDInsight, see <bpt id=\"p12\">[</bpt>Create Hadoop clusters in HDInsight using ARM templates<ept id=\"p12\">](hdinsight-hadoop-create-windows-clusters-arm-templates.md)</ept>",
          "pos": [
            522,
            768
          ]
        }
      ]
    },
    {
      "pos": [
        2262,
        2388
      ],
      "content": "Click the following image to open an ARM template in the Azure Portal. The ARM template is located in a public blob container.",
      "nodes": [
        {
          "content": "Click the following image to open an ARM template in the Azure Portal.",
          "pos": [
            0,
            70
          ]
        },
        {
          "content": "The ARM template is located in a public blob container.",
          "pos": [
            71,
            126
          ]
        }
      ]
    },
    {
      "pos": [
        2846,
        2897
      ],
      "content": "From the <bpt id=\"p13\">**</bpt>Parameters<ept id=\"p13\">**</ept><ph id=\"ph5\"/> blade, enter the following:"
    },
    {
      "pos": [
        2905,
        2979
      ],
      "content": "<bpt id=\"p14\">**</bpt>ClusterName<ept id=\"p14\">**</ept>: Enter a name for the Hadoop cluster that you will create."
    },
    {
      "pos": [
        2986,
        3144
      ],
      "content": "<bpt id=\"p15\">**</bpt>ClusterStorageAccountName<ept id=\"p15\">**</ept>: Each cluster has an Azure Blob storage account dependency. After you delete a cluster, the data retains in the storage account.",
      "nodes": [
        {
          "content": "<bpt id=\"p15\">**</bpt>ClusterStorageAccountName<ept id=\"p15\">**</ept>: Each cluster has an Azure Blob storage account dependency.",
          "pos": [
            0,
            129
          ]
        },
        {
          "content": "After you delete a cluster, the data retains in the storage account.",
          "pos": [
            130,
            198
          ]
        }
      ]
    },
    {
      "pos": [
        3151,
        3224
      ],
      "content": "<bpt id=\"p16\">**</bpt>Cluster login name and password<ept id=\"p16\">**</ept>: The default login name is <bpt id=\"p17\">**</bpt>admin<ept id=\"p17\">**</ept>."
    },
    {
      "pos": [
        3231,
        3386
      ],
      "leadings": [
        "",
        "    "
      ],
      "content": "<bpt id=\"p18\">**</bpt>SSH username and password<ept id=\"p18\">**</ept>: The default username is <bpt id=\"p19\">**</bpt>sshuser<ept id=\"p19\">**</ept>.  You can rename it. \n<ph id=\"ph6\"/>Other parameters are optional. You can leave them as they are.",
      "nodes": [
        {
          "content": "<bpt id=\"p18\">**</bpt>SSH username and password<ept id=\"p18\">**</ept>: The default username is <bpt id=\"p19\">**</bpt>sshuser<ept id=\"p19\">**</ept>.",
          "pos": [
            0,
            147
          ]
        },
        {
          "content": "You can rename it.",
          "pos": [
            149,
            167
          ]
        },
        {
          "content": "<ph id=\"ph6\"/>Other parameters are optional.",
          "pos": [
            169,
            213
          ]
        },
        {
          "content": "You can leave them as they are.",
          "pos": [
            214,
            245
          ]
        }
      ]
    },
    {
      "pos": [
        3392,
        3428
      ],
      "content": "Click <bpt id=\"p20\">**</bpt>OK<ept id=\"p20\">**</ept><ph id=\"ph7\"/> to save the parameters."
    },
    {
      "pos": [
        3432,
        3680
      ],
      "content": "From the <bpt id=\"p21\">**</bpt>Custom deployment<ept id=\"p21\">**</ept><ph id=\"ph8\"/> blade, click <bpt id=\"p22\">**</bpt>Resource group<ept id=\"p22\">**</ept><ph id=\"ph9\"/> dropdown box, and then click <bpt id=\"p23\">**</bpt>New<ept id=\"p23\">**</ept><ph id=\"ph10\"/> to create a new resource group.  The resource group is a container that groups the cluster, the dependent storage account and other linked resource.",
      "nodes": [
        {
          "content": "From the <bpt id=\"p21\">**</bpt>Custom deployment<ept id=\"p21\">**</ept><ph id=\"ph8\"/> blade, click <bpt id=\"p22\">**</bpt>Resource group<ept id=\"p22\">**</ept><ph id=\"ph9\"/> dropdown box, and then click <bpt id=\"p23\">**</bpt>New<ept id=\"p23\">**</ept><ph id=\"ph10\"/> to create a new resource group.",
          "pos": [
            0,
            294
          ]
        },
        {
          "content": "The resource group is a container that groups the cluster, the dependent storage account and other linked resource.",
          "pos": [
            296,
            411
          ]
        }
      ]
    },
    {
      "pos": [
        3684,
        3733
      ],
      "content": "Click <bpt id=\"p24\">**</bpt>Legal terms<ept id=\"p24\">**</ept>, and then click <bpt id=\"p25\">**</bpt>Create<ept id=\"p25\">**</ept>."
    },
    {
      "pos": [
        3737,
        3977
      ],
      "content": "Click <bpt id=\"p26\">**</bpt>Create<ept id=\"p26\">**</ept>. You will see a new tile titled <bpt id=\"p27\">**</bpt>Submitting deployment for Template deployment<ept id=\"p27\">**</ept>. It takes about around 20 minutes to create a cluster. Once the cluster is created, you can click the cluster blade in the portal to open it.",
      "nodes": [
        {
          "content": "Click <bpt id=\"p26\">**</bpt>Create<ept id=\"p26\">**</ept>.",
          "pos": [
            0,
            57
          ]
        },
        {
          "content": "You will see a new tile titled <bpt id=\"p27\">**</bpt>Submitting deployment for Template deployment<ept id=\"p27\">**</ept>.",
          "pos": [
            58,
            179
          ]
        },
        {
          "content": "It takes about around 20 minutes to create a cluster.",
          "pos": [
            180,
            233
          ]
        },
        {
          "content": "Once the cluster is created, you can click the cluster blade in the portal to open it.",
          "pos": [
            234,
            320
          ]
        }
      ]
    },
    {
      "pos": [
        3979,
        4565
      ],
      "content": "After you complete the tutorial, you might want to delete the cluster. With HDInsight, your data is stored in Azure Storage, so you can safely delete a cluster when it is not in use. You are also charged for an HDInsight cluster, even when it is not in use. Since the charges for the cluster are many times more than the charges for storage, it makes economic sense to delete clusters when they are not in use. For the instructions of deleting a cluster, see <bpt id=\"p28\">[</bpt>Manage Hadoop clusters in HDInsight by using the Azure Portal<ept id=\"p28\">](hdinsight-administer-use-management-portal.md#delete-clusters)</ept>.",
      "nodes": [
        {
          "content": "After you complete the tutorial, you might want to delete the cluster.",
          "pos": [
            0,
            70
          ]
        },
        {
          "content": "With HDInsight, your data is stored in Azure Storage, so you can safely delete a cluster when it is not in use.",
          "pos": [
            71,
            182
          ]
        },
        {
          "content": "You are also charged for an HDInsight cluster, even when it is not in use.",
          "pos": [
            183,
            257
          ]
        },
        {
          "content": "Since the charges for the cluster are many times more than the charges for storage, it makes economic sense to delete clusters when they are not in use.",
          "pos": [
            258,
            410
          ]
        },
        {
          "content": "For the instructions of deleting a cluster, see <bpt id=\"p28\">[</bpt>Manage Hadoop clusters in HDInsight by using the Azure Portal<ept id=\"p28\">](hdinsight-administer-use-management-portal.md#delete-clusters)</ept>.",
          "pos": [
            411,
            626
          ]
        }
      ]
    },
    {
      "pos": [
        4570,
        4586
      ],
      "content": "Run Hive queries"
    },
    {
      "pos": [
        4588,
        4898
      ],
      "content": "<bpt id=\"p29\">[</bpt>Ambari<ept id=\"p29\">](hdinsight-hadoop-manage-ambari.md)</ept><ph id=\"ph11\"/> Views provide several utilities through a web page. One of the utilities is Hive view. In this section, you'll use the Hive view to run Hive queries on your HDInsight cluster. For other methods to run Hive queries, see <bpt id=\"p30\">[</bpt>Use Hive in HDInsight<ept id=\"p30\">](hdinsight-use-hive.md)</ept>.",
      "nodes": [
        {
          "content": "<bpt id=\"p29\">[</bpt>Ambari<ept id=\"p29\">](hdinsight-hadoop-manage-ambari.md)</ept><ph id=\"ph11\"/> Views provide several utilities through a web page.",
          "pos": [
            0,
            150
          ]
        },
        {
          "content": "One of the utilities is Hive view.",
          "pos": [
            151,
            185
          ]
        },
        {
          "content": "In this section, you'll use the Hive view to run Hive queries on your HDInsight cluster.",
          "pos": [
            186,
            274
          ]
        },
        {
          "content": "For other methods to run Hive queries, see <bpt id=\"p30\">[</bpt>Use Hive in HDInsight<ept id=\"p30\">](hdinsight-use-hive.md)</ept>.",
          "pos": [
            275,
            405
          ]
        }
      ]
    },
    {
      "pos": [
        4903,
        5052
      ],
      "content": "Browse to  <bpt id=\"p31\">**</bpt>https://&amp;lt;ClusterName&gt;.azurehdinsight.net<ept id=\"p31\">**</ept>, where &amp;lt;ClusterName&gt; is the cluster you created in the previous section to open Ambari."
    },
    {
      "pos": [
        5056,
        5173
      ],
      "content": "Enter the Hadoop username and password that you specified in the previous section. The default username is <bpt id=\"p32\">**</bpt>admin<ept id=\"p32\">**</ept>.",
      "nodes": [
        {
          "content": "Enter the Hadoop username and password that you specified in the previous section.",
          "pos": [
            0,
            82
          ]
        },
        {
          "content": "The default username is <bpt id=\"p32\">**</bpt>admin<ept id=\"p32\">**</ept>.",
          "pos": [
            83,
            157
          ]
        }
      ]
    },
    {
      "pos": [
        5177,
        5233
      ],
      "content": "Open <bpt id=\"p33\">**</bpt>Hive View<ept id=\"p33\">**</ept><ph id=\"ph12\"/> as shown in the following screenshot:"
    },
    {
      "pos": [
        5239,
        5337
      ],
      "content": "<ph id=\"ph13\">![</ph>Selecting ambari views<ph id=\"ph14\">](./media/hdinsight-hadoop-linux-tutorial-get-started/selecthiveview.png)</ph>."
    },
    {
      "pos": [
        5341,
        5443
      ],
      "content": "In the <bpt id=\"p34\">__</bpt>Query Editor<ept id=\"p34\">__</ept><ph id=\"ph15\"/> section of the page, paste the following HiveQL statements into the worksheet:"
    },
    {
      "pos": [
        5469,
        5601
      ],
      "content": "Click <bpt id=\"p35\">__</bpt>Execute<ept id=\"p35\">__</ept>. A <bpt id=\"p36\">__</bpt>Query Process Results<ept id=\"p36\">__</ept><ph id=\"ph16\"/> section should appear beneath the Query Editor and display information about the job.",
      "nodes": [
        {
          "content": "Click <bpt id=\"p35\">__</bpt>Execute<ept id=\"p35\">__</ept>.",
          "pos": [
            0,
            58
          ]
        },
        {
          "content": "A <bpt id=\"p36\">__</bpt>Query Process Results<ept id=\"p36\">__</ept><ph id=\"ph16\"/> section should appear beneath the Query Editor and display information about the job.",
          "pos": [
            59,
            227
          ]
        }
      ]
    },
    {
      "pos": [
        5608,
        5831
      ],
      "content": "Once the query has finished, The <bpt id=\"p37\">__</bpt>Query Process Results<ept id=\"p37\">__</ept><ph id=\"ph17\"/> section will display the results of the operation. You shall see one table called <bpt id=\"p38\">**</bpt>hivesampletable<ept id=\"p38\">**</ept>. This sample Hive table comes with all the HDInsight clusters.",
      "nodes": [
        {
          "content": "Once the query has finished, The <bpt id=\"p37\">__</bpt>Query Process Results<ept id=\"p37\">__</ept><ph id=\"ph17\"/> section will display the results of the operation.",
          "pos": [
            0,
            164
          ]
        },
        {
          "content": "You shall see one table called <bpt id=\"p38\">**</bpt>hivesampletable<ept id=\"p38\">**</ept>.",
          "pos": [
            165,
            256
          ]
        },
        {
          "content": "This sample Hive table comes with all the HDInsight clusters.",
          "pos": [
            257,
            318
          ]
        }
      ]
    },
    {
      "pos": [
        5843,
        6047
      ],
      "content": "<ph id=\"ph18\">[AZURE.TIP]</ph><ph id=\"ph19\"/> Note the <bpt id=\"p39\">__</bpt>Save results<ept id=\"p39\">__</ept><ph id=\"ph20\"/> dropdown in the upper left of the <bpt id=\"p40\">__</bpt>Query Process Results<ept id=\"p40\">__</ept><ph id=\"ph21\"/> section; you can use this to either download the results, or save them to HDInsight storage as a CSV file."
    },
    {
      "pos": [
        6051,
        6103
      ],
      "content": "Repeat step 4 and step 5 to run the following query:"
    },
    {
      "pos": [
        6145,
        6545
      ],
      "content": "After you have completed a Hive job, you can <bpt id=\"p41\">[</bpt>export the results to Azure SQL database or SQL Server database<ept id=\"p41\">](hdinsight-use-sqoop-mac-linux.md)</ept>, you can also <bpt id=\"p42\">[</bpt>visualize the results using Excel<ept id=\"p42\">](hdinsight-connect-excel-power-query.md)</ept>. For more information about using Hive in HDInsight, see <bpt id=\"p43\">[</bpt>Use Hive and HiveQL with Hadoop in HDInsight to analyze a sample Apache log4j file<ept id=\"p43\">](hdinsight-use-hive.md)</ept>.",
      "nodes": [
        {
          "content": "After you have completed a Hive job, you can <bpt id=\"p41\">[</bpt>export the results to Azure SQL database or SQL Server database<ept id=\"p41\">](hdinsight-use-sqoop-mac-linux.md)</ept>, you can also <bpt id=\"p42\">[</bpt>visualize the results using Excel<ept id=\"p42\">](hdinsight-connect-excel-power-query.md)</ept>.",
          "pos": [
            0,
            315
          ]
        },
        {
          "content": "For more information about using Hive in HDInsight, see <bpt id=\"p43\">[</bpt>Use Hive and HiveQL with Hadoop in HDInsight to analyze a sample Apache log4j file<ept id=\"p43\">](hdinsight-use-hive.md)</ept>.",
          "pos": [
            316,
            520
          ]
        }
      ]
    },
    {
      "pos": [
        6550,
        6560
      ],
      "content": "Next steps"
    },
    {
      "pos": [
        6562,
        6704
      ],
      "content": "In this tutorial, you have learned how to create a Linux-based HDInsight cluster using an ARM template, and how to perform basic Hive queries."
    },
    {
      "pos": [
        6706,
        6775
      ],
      "content": "To learn more about analyzing data with HDInsight, see the following:"
    },
    {
      "pos": [
        6779,
        6934
      ],
      "content": "To learn more about using Hive with HDInsight, including how to perform Hive queries from Visual Studio, see <bpt id=\"p44\">[</bpt>Use Hive with HDInsight<ept id=\"p44\">][hdinsight-use-hive]</ept>."
    },
    {
      "pos": [
        6938,
        7041
      ],
      "content": "To learn about Pig, a language used to transform data, see <bpt id=\"p45\">[</bpt>Use Pig with HDInsight<ept id=\"p45\">][hdinsight-use-pig]</ept>."
    },
    {
      "pos": [
        7045,
        7184
      ],
      "content": "To learn about MapReduce, a way to write programs that process data on Hadoop, see <bpt id=\"p46\">[</bpt>Use MapReduce with HDInsight<ept id=\"p46\">][hdinsight-use-mapreduce]</ept>."
    },
    {
      "pos": [
        7188,
        7395
      ],
      "content": "To learn about using the HDInsight Tools for Visual Studio to analyze data on HDInsight, see <bpt id=\"p47\">[</bpt>Get started using Visual Studio Hadoop tools for HDInsight<ept id=\"p47\">](hdinsight-hadoop-visual-studio-tools-get-started.md)</ept>."
    },
    {
      "pos": [
        7397,
        7556
      ],
      "content": "If you're ready to start working with your own data and need to know more about how HDInsight stores data or how to get data into HDInsight, see the following:"
    },
    {
      "pos": [
        7560,
        7700
      ],
      "content": "For information on how HDInsight uses Azure blob storage, see <bpt id=\"p48\">[</bpt>Use Azure Blob storage with HDInsight<ept id=\"p48\">](hdinsight-hadoop-use-blob-storage.md)</ept>."
    },
    {
      "pos": [
        7704,
        7810
      ],
      "content": "For information on how to upload data to HDInsight, see <bpt id=\"p49\">[</bpt>Upload data to HDInsight<ept id=\"p49\">][hdinsight-upload-data]</ept>."
    },
    {
      "pos": [
        7812,
        7907
      ],
      "content": "If you'd like to learn more about creating or managing an HDInsight cluster, see the following:"
    },
    {
      "pos": [
        7911,
        8051
      ],
      "content": "To learn about managing your Linux-based HDInsight cluster, see <bpt id=\"p50\">[</bpt>Manage HDInsight clusters using Ambari<ept id=\"p50\">](hdinsight-hadoop-manage-ambari.md)</ept>."
    },
    {
      "pos": [
        8055,
        8239
      ],
      "content": "To learn more about the options you can select when creating an HDInsight cluster, see <bpt id=\"p51\">[</bpt>Creating HDInsight on Linux using custom options<ept id=\"p51\">](hdinsight-hadoop-provision-linux-clusters.md)</ept>."
    },
    {
      "pos": [
        8243,
        8457
      ],
      "content": "If you are familiar with Linux, and Hadoop, but want to know specifics about Hadoop on the HDInsight, see <bpt id=\"p52\">[</bpt>Working with HDInsight on Linux<ept id=\"p52\">](hdinsight-hadoop-linux-information.md)</ept>. This provides information such as:",
      "nodes": [
        {
          "content": "If you are familiar with Linux, and Hadoop, but want to know specifics about Hadoop on the HDInsight, see <bpt id=\"p52\">[</bpt>Working with HDInsight on Linux<ept id=\"p52\">](hdinsight-hadoop-linux-information.md)</ept>.",
          "pos": [
            0,
            219
          ]
        },
        {
          "content": "This provides information such as:",
          "pos": [
            220,
            254
          ]
        }
      ]
    },
    {
      "pos": [
        8465,
        8532
      ],
      "content": "URLs for services hosted on the cluster, such as Ambari and WebHCat"
    },
    {
      "pos": [
        8539,
        8605
      ],
      "content": "The location of Hadoop files and examples on the local file system"
    },
    {
      "pos": [
        8612,
        8685
      ],
      "content": "The use of Azure Storage (WASB) instead of HDFS as the default data store"
    }
  ],
  "content": "<properties\n    pageTitle=\"Linux tutorial: Get started with Hadoop and Hive | Microsoft Azure\"\n    description=\"Follow this Linux tutorial to get started using Hadoop in HDInsight. Learn how to provision Linux clusters, and query data with Hive.\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    authors=\"mumian\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.devlang=\"na\"\n    ms.topic=\"hero-article\"\n    ms.tgt_pltfrm=\"na\"\n    ms.workload=\"big-data\"\n    ms.date=\"02/11/2016\"\n    ms.author=\"jgao\"/>\n\n# Hadoop tutorial: Get started using Linux-based Hadoop in HDInsight\n\n> [AZURE.SELECTOR]\n- [Windows](hdinsight-hadoop-tutorial-get-started-windows.md)\n- [Linux](hdinsight-hadoop-linux-tutorial-get-started.md)\n\nLearn how to create Linux-based Hadoop clusters in HDInsight, and use Ambari Hive View to run Hive jobs.\n\nIf you are new to Hadoop and big data, you can read more about the terms: [Apache Hadoop](http://go.microsoft.com/fwlink/?LinkId=510084), [MapReduce](http://go.microsoft.com/fwlink/?LinkId=510086), [Hadoop Distributed File System (HDFS)](http://go.microsoft.com/fwlink/?LinkId=510087), and [Hive](http://go.microsoft.com/fwlink/?LinkId=510085). To understand how HDInsight enables Hadoop in Azure, see [Introduction to Hadoop in HDInsight](hdinsight-hadoop-introduction.md).\n\n### Prerequisites\n\nBefore you begin this tutorial, you must have:\n\n- **Azure subscription**: See [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).\n\n## Create cluster\n\nMost of Hadoop jobs are batch jobs. You create a cluster and run some jobs. In this section, you will create a Linux-based Hadoop cluster in HDInsight using [Azure ARM template](../resource-group-template-deploy.md). The Azure ARM template experience is not required for following this tutorial. For other cluster creation methods and understanding the settings, see [Create HDInsight clusters](hdinsight-hadoop-provision-linux-clusters.md). For more information about using ARM template to create Hadoop clusters in HDInsight, see [Create Hadoop clusters in HDInsight using ARM templates](hdinsight-hadoop-create-windows-clusters-arm-templates.md)\n\n1. Click the following image to open an ARM template in the Azure Portal. The ARM template is located in a public blob container. \n\n    <a href=\"https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fhditutorialdata.blob.core.windows.net%2Farmtemplates%2Fcreate-linux-based-hadoop-cluster-in-hdinsight.json\" target=\"_blank\"><img src=\"https://acom.azurecomcdn.net/80C57D/cdn/mediahandler/docarticles/dpsmedia-prod/azure.microsoft.com/en-us/documentation/articles/hdinsight-hbase-tutorial-get-started-linux/20160201111850/deploy-to-azure.png\" alt=\"Deploy to Azure\"></a>\n\n2. From the **Parameters** blade, enter the following:\n\n    - **ClusterName**: Enter a name for the Hadoop cluster that you will create.\n    - **ClusterStorageAccountName**: Each cluster has an Azure Blob storage account dependency. After you delete a cluster, the data retains in the storage account.\n    - **Cluster login name and password**: The default login name is **admin**.\n    - **SSH username and password**: The default username is **sshuser**.  You can rename it. \n    Other parameters are optional. You can leave them as they are.  \n3. Click **OK** to save the parameters.\n4. From the **Custom deployment** blade, click **Resource group** dropdown box, and then click **New** to create a new resource group.  The resource group is a container that groups the cluster, the dependent storage account and other linked resource.\n5. Click **Legal terms**, and then click **Create**.\n6. Click **Create**. You will see a new tile titled **Submitting deployment for Template deployment**. It takes about around 20 minutes to create a cluster. Once the cluster is created, you can click the cluster blade in the portal to open it.\n\nAfter you complete the tutorial, you might want to delete the cluster. With HDInsight, your data is stored in Azure Storage, so you can safely delete a cluster when it is not in use. You are also charged for an HDInsight cluster, even when it is not in use. Since the charges for the cluster are many times more than the charges for storage, it makes economic sense to delete clusters when they are not in use. For the instructions of deleting a cluster, see [Manage Hadoop clusters in HDInsight by using the Azure Portal](hdinsight-administer-use-management-portal.md#delete-clusters).\n\n\n##Run Hive queries\n\n[Ambari](hdinsight-hadoop-manage-ambari.md) Views provide several utilities through a web page. One of the utilities is Hive view. In this section, you'll use the Hive view to run Hive queries on your HDInsight cluster. For other methods to run Hive queries, see [Use Hive in HDInsight](hdinsight-use-hive.md).\n\n1. Browse to  **https://&lt;ClusterName>.azurehdinsight.net**, where &lt;ClusterName> is the cluster you created in the previous section to open Ambari.\n2. Enter the Hadoop username and password that you specified in the previous section. The default username is **admin**.\n3. Open **Hive View** as shown in the following screenshot:\n\n    ![Selecting ambari views](./media/hdinsight-hadoop-linux-tutorial-get-started/selecthiveview.png).\n4. In the __Query Editor__ section of the page, paste the following HiveQL statements into the worksheet:\n\n        SHOW tables;\n5. Click __Execute__. A __Query Process Results__ section should appear beneath the Query Editor and display information about the job. \n\n    Once the query has finished, The __Query Process Results__ section will display the results of the operation. You shall see one table called **hivesampletable**. This sample Hive table comes with all the HDInsight clusters.\n    \n    > [AZURE.TIP] Note the __Save results__ dropdown in the upper left of the __Query Process Results__ section; you can use this to either download the results, or save them to HDInsight storage as a CSV file.\n6. Repeat step 4 and step 5 to run the following query:\n\n        SELECT * FROM hivesampletable;\n\nAfter you have completed a Hive job, you can [export the results to Azure SQL database or SQL Server database](hdinsight-use-sqoop-mac-linux.md), you can also [visualize the results using Excel](hdinsight-connect-excel-power-query.md). For more information about using Hive in HDInsight, see [Use Hive and HiveQL with Hadoop in HDInsight to analyze a sample Apache log4j file](hdinsight-use-hive.md).\n\n## Next steps\n\nIn this tutorial, you have learned how to create a Linux-based HDInsight cluster using an ARM template, and how to perform basic Hive queries.\n\nTo learn more about analyzing data with HDInsight, see the following:\n\n- To learn more about using Hive with HDInsight, including how to perform Hive queries from Visual Studio, see [Use Hive with HDInsight][hdinsight-use-hive].\n\n- To learn about Pig, a language used to transform data, see [Use Pig with HDInsight][hdinsight-use-pig].\n\n- To learn about MapReduce, a way to write programs that process data on Hadoop, see [Use MapReduce with HDInsight][hdinsight-use-mapreduce].\n\n- To learn about using the HDInsight Tools for Visual Studio to analyze data on HDInsight, see [Get started using Visual Studio Hadoop tools for HDInsight](hdinsight-hadoop-visual-studio-tools-get-started.md).\n\nIf you're ready to start working with your own data and need to know more about how HDInsight stores data or how to get data into HDInsight, see the following:\n\n- For information on how HDInsight uses Azure blob storage, see [Use Azure Blob storage with HDInsight](hdinsight-hadoop-use-blob-storage.md).\n\n- For information on how to upload data to HDInsight, see [Upload data to HDInsight][hdinsight-upload-data].\n\nIf you'd like to learn more about creating or managing an HDInsight cluster, see the following:\n\n- To learn about managing your Linux-based HDInsight cluster, see [Manage HDInsight clusters using Ambari](hdinsight-hadoop-manage-ambari.md).\n\n- To learn more about the options you can select when creating an HDInsight cluster, see [Creating HDInsight on Linux using custom options](hdinsight-hadoop-provision-linux-clusters.md).\n\n- If you are familiar with Linux, and Hadoop, but want to know specifics about Hadoop on the HDInsight, see [Working with HDInsight on Linux](hdinsight-hadoop-linux-information.md). This provides information such as:\n\n    * URLs for services hosted on the cluster, such as Ambari and WebHCat\n    * The location of Hadoop files and examples on the local file system\n    * The use of Azure Storage (WASB) instead of HDFS as the default data store\n\n\n[1]: ../HDInsight/hdinsight-hadoop-visual-studio-tools-get-started.md\n\n[hdinsight-provision]: hdinsight-provision-clusters.md\n[hdinsight-admin-powershell]: hdinsight-administer-use-powershell.md\n[hdinsight-upload-data]: hdinsight-upload-data.md\n[hdinsight-use-mapreduce]: hdinsight-use-mapreduce.md\n[hdinsight-use-hive]: hdinsight-use-hive.md\n[hdinsight-use-pig]: hdinsight-use-pig.md\n\n[powershell-download]: http://go.microsoft.com/fwlink/p/?linkid=320376&clcid=0x409\n[powershell-install-configure]: powershell-install-configure.md\n[powershell-open]: powershell-install-configure.md#Install\n\n[img-hdi-dashboard]: ./media/hdinsight-hadoop-tutorial-get-started-windows/HDI.dashboard.png\n[img-hdi-dashboard-query-select]: ./media/hdinsight-hadoop-tutorial-get-started-windows/HDI.dashboard.query.select.png\n[img-hdi-dashboard-query-select-result]: ./media/hdinsight-hadoop-tutorial-get-started-windows/HDI.dashboard.query.select.result.png\n[img-hdi-dashboard-query-select-result-output]: ./media/hdinsight-hadoop-tutorial-get-started-windows/HDI.dashboard.query.select.result.output.png\n[img-hdi-dashboard-query-browse-output]: ./media/hdinsight-hadoop-tutorial-get-started-windows/HDI.dashboard.query.browse.output.png\n[image-hdi-clusterstatus]: ./media/hdinsight-hadoop-tutorial-get-started-windows/HDI.ClusterStatus.png\n[image-hdi-gettingstarted-powerquery-importdata]: ./media/hdinsight-hadoop-tutorial-get-started-windows/HDI.GettingStarted.PowerQuery.ImportData.png\n[image-hdi-gettingstarted-powerquery-importdata2]: ./media/hdinsight-hadoop-tutorial-get-started-windows/HDI.GettingStarted.PowerQuery.ImportData2.png\n"
}