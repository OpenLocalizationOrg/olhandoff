{
  "nodes": [
    {
      "pos": [
        23,
        55
      ],
      "content": "Use DataFu with Pig on HDInsight"
    },
    {
      "pos": [
        70,
        191
      ],
      "content": "DataFu is a collection of libraries for use with Hadoop. Learn how you can use DataFu with Pig on your HDInsight cluster.",
      "nodes": [
        {
          "content": "DataFu is a collection of libraries for use with Hadoop.",
          "pos": [
            0,
            56
          ]
        },
        {
          "content": "Learn how you can use DataFu with Pig on your HDInsight cluster.",
          "pos": [
            57,
            121
          ]
        }
      ]
    },
    {
      "pos": [
        448,
        480
      ],
      "content": "Use DataFu with pig on HDInsight"
    },
    {
      "pos": [
        482,
        689
      ],
      "content": "DataFu is a collection of Open Source libraries for use with Hadoop. In this document, you will learn how to use DataFu on your HDInsight cluster, and how to use DataFu User Defined Functions (UDF) with Pig.",
      "nodes": [
        {
          "content": "DataFu is a collection of Open Source libraries for use with Hadoop.",
          "pos": [
            0,
            68
          ]
        },
        {
          "content": "In this document, you will learn how to use DataFu on your HDInsight cluster, and how to use DataFu User Defined Functions (UDF) with Pig.",
          "pos": [
            69,
            207
          ]
        }
      ]
    },
    {
      "pos": [
        693,
        706
      ],
      "content": "Prerequisites"
    },
    {
      "pos": [
        710,
        732
      ],
      "content": "An Azure subscription."
    },
    {
      "pos": [
        736,
        787
      ],
      "content": "An Azure HDInsight cluster (Linux or Windows based)"
    },
    {
      "pos": [
        791,
        862
      ],
      "content": "A basic familiarity with <bpt id=\"p1\">[</bpt>using Pig on HDInsight<ept id=\"p1\">](hdinsight-use-pig.md)</ept>"
    },
    {
      "pos": [
        866,
        905
      ],
      "content": "Install DataFu on Linux-based HDInsight"
    },
    {
      "pos": [
        909,
        1043
      ],
      "content": "<ph id=\"ph2\">[AZURE.NOTE]</ph><ph id=\"ph3\"/> DataFu is pre-installed on Windows-based HDInsight clusters. If you are using a Windows-based cluster, skip this section.",
      "nodes": [
        {
          "content": "<ph id=\"ph2\">[AZURE.NOTE]</ph><ph id=\"ph3\"/> DataFu is pre-installed on Windows-based HDInsight clusters.",
          "pos": [
            0,
            105
          ]
        },
        {
          "content": "If you are using a Windows-based cluster, skip this section.",
          "pos": [
            106,
            166
          ]
        }
      ]
    },
    {
      "pos": [
        1045,
        1175
      ],
      "content": "DataFu can be downloaded and installed from the Maven repository. Use the following steps to add DataFu to your HDInsight cluster:",
      "nodes": [
        {
          "content": "DataFu can be downloaded and installed from the Maven repository.",
          "pos": [
            0,
            65
          ]
        },
        {
          "content": "Use the following steps to add DataFu to your HDInsight cluster:",
          "pos": [
            66,
            130
          ]
        }
      ]
    },
    {
      "pos": [
        1180,
        1322
      ],
      "content": "Connect to your Linux-based HDInsight cluster using SSH. For more information on using SSH with HDInsight, see one of the following documents:",
      "nodes": [
        {
          "content": "Connect to your Linux-based HDInsight cluster using SSH.",
          "pos": [
            0,
            56
          ]
        },
        {
          "content": "For more information on using SSH with HDInsight, see one of the following documents:",
          "pos": [
            57,
            142
          ]
        }
      ]
    },
    {
      "pos": [
        1330,
        1443
      ],
      "content": "<bpt id=\"p2\">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Linux, OS X, and Unix<ept id=\"p2\">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept>"
    },
    {
      "pos": [
        1450,
        1549
      ],
      "content": "<bpt id=\"p3\">[</bpt>Use SSH with Linux-based Hadoop on HDInsight from Windows<ept id=\"p3\">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept>"
    },
    {
      "pos": [
        1558,
        1707
      ],
      "content": "Use the following command to download the DataFu jar file using the wget utility, or copy and paste the link into your browser to begin the download."
    },
    {
      "pos": [
        1808,
        2014
      ],
      "content": "Next, upload the file to default storage for your HDInsight cluster. This makes the file available to all nodes in the cluster, and the file will stay in storage even if you delete and recreate the cluster.",
      "nodes": [
        {
          "content": "Next, upload the file to default storage for your HDInsight cluster.",
          "pos": [
            0,
            68
          ]
        },
        {
          "content": "This makes the file available to all nodes in the cluster, and the file will stay in storage even if you delete and recreate the cluster.",
          "pos": [
            69,
            206
          ]
        }
      ]
    },
    {
      "pos": [
        2080,
        2275
      ],
      "content": "<ph id=\"ph4\">[AZURE.NOTE]</ph><ph id=\"ph5\"/> The above example stores the jar in <ph id=\"ph6\">`wasb:///example/jars`</ph><ph id=\"ph7\"/> since this directory already exists on the cluster storage. You can use any location you wish on HDInsight cluster storage.",
      "nodes": [
        {
          "content": "<ph id=\"ph4\">[AZURE.NOTE]</ph><ph id=\"ph5\"/> The above example stores the jar in <ph id=\"ph6\">`wasb:///example/jars`</ph><ph id=\"ph7\"/> since this directory already exists on the cluster storage.",
          "pos": [
            0,
            195
          ]
        },
        {
          "content": "You can use any location you wish on HDInsight cluster storage.",
          "pos": [
            196,
            259
          ]
        }
      ]
    },
    {
      "pos": [
        2279,
        2298
      ],
      "content": "Use DataFu With Pig"
    },
    {
      "pos": [
        2300,
        2579
      ],
      "content": "The steps in this section assume that you are familiar with using Pig on HDInsight, and only provide the Pig Latin statements, not the steps on how to use them with the cluster. For more information on using Pig with HDInsight, see <bpt id=\"p4\">[</bpt>Use Pig with HDInsight<ept id=\"p4\">](hdinsight-use-pig.md)</ept>.",
      "nodes": [
        {
          "content": "The steps in this section assume that you are familiar with using Pig on HDInsight, and only provide the Pig Latin statements, not the steps on how to use them with the cluster.",
          "pos": [
            0,
            177
          ]
        },
        {
          "content": "For more information on using Pig with HDInsight, see <bpt id=\"p4\">[</bpt>Use Pig with HDInsight<ept id=\"p4\">](hdinsight-use-pig.md)</ept>.",
          "pos": [
            178,
            317
          ]
        }
      ]
    },
    {
      "pos": [
        2583,
        2741
      ],
      "content": "<ph id=\"ph8\">[AZURE.IMPORTANT]</ph><ph id=\"ph9\"/> When using DataFu from Pig on a Linux-based HDInsight cluster, you must first register the jar file using the following Pig Latin statement:"
    },
    {
      "pos": [
        2803,
        2871
      ],
      "content": "DataFu is registered by default on Windows-based HDInsight clusters."
    },
    {
      "pos": [
        2873,
        2940
      ],
      "content": "You will usually define an alias for DataFu functions. For example:",
      "nodes": [
        {
          "content": "You will usually define an alias for DataFu functions.",
          "pos": [
            0,
            54
          ]
        },
        {
          "content": "For example:",
          "pos": [
            55,
            67
          ]
        }
      ]
    },
    {
      "pos": [
        2985,
        3214
      ],
      "content": "This defines an alias named <ph id=\"ph11\">`SHA`</ph><ph id=\"ph12\"/> for the SHA hashing function. You can then use this in a Pig Latin script to generate a hash for the input data. For example, the following replaces the names in the input data with a hash value:",
      "nodes": [
        {
          "content": "This defines an alias named <ph id=\"ph11\">`SHA`</ph><ph id=\"ph12\"/> for the SHA hashing function.",
          "pos": [
            0,
            97
          ]
        },
        {
          "content": "You can then use this in a Pig Latin script to generate a hash for the input data.",
          "pos": [
            98,
            180
          ]
        },
        {
          "content": "For example, the following replaces the names in the input data with a hash value:",
          "pos": [
            181,
            263
          ]
        }
      ]
    },
    {
      "pos": [
        3432,
        3478
      ],
      "content": "If this is used with the following input data:"
    },
    {
      "pos": [
        3716,
        3754
      ],
      "content": "It will generate the following output:"
    },
    {
      "pos": [
        4529,
        4539
      ],
      "content": "Next steps"
    },
    {
      "pos": [
        4541,
        4608
      ],
      "content": "For more information on DataFu or Pig, see the following documents:"
    },
    {
      "pos": [
        4612,
        4697
      ],
      "content": "<bpt id=\"p5\">[</bpt>Apache DataFu Pig Guide<ept id=\"p5\">](http://datafu.incubator.apache.org/docs/datafu/guide.html)</ept>."
    },
    {
      "pos": [
        4701,
        4747
      ],
      "content": "<bpt id=\"p6\">[</bpt>Use Pig with HDInsight<ept id=\"p6\">](hdinsight-use-pig.md)</ept>"
    }
  ],
  "content": "<properties\npageTitle=\"Use DataFu with Pig on HDInsight\"\ndescription=\"DataFu is a collection of libraries for use with Hadoop. Learn how you can use DataFu with Pig on your HDInsight cluster.\"\nservices=\"hdinsight\"\ndocumentationCenter=\"\"\nauthors=\"Blackmist\"\nmanager=\"paulettm\"\neditor=\"cgronlun\"/>\n\n<tags\nms.service=\"hdinsight\"\nms.devlang=\"na\"\nms.topic=\"article\"\nms.tgt_pltfrm=\"na\"\nms.workload=\"big-data\"\nms.date=\"01/08/2016\"\nms.author=\"larryfr\"/>\n\n#Use DataFu with pig on HDInsight\n\nDataFu is a collection of Open Source libraries for use with Hadoop. In this document, you will learn how to use DataFu on your HDInsight cluster, and how to use DataFu User Defined Functions (UDF) with Pig.\n\n##Prerequisites\n\n* An Azure subscription.\n\n* An Azure HDInsight cluster (Linux or Windows based)\n\n* A basic familiarity with [using Pig on HDInsight](hdinsight-use-pig.md)\n\n##Install DataFu on Linux-based HDInsight\n\n> [AZURE.NOTE] DataFu is pre-installed on Windows-based HDInsight clusters. If you are using a Windows-based cluster, skip this section.\n\nDataFu can be downloaded and installed from the Maven repository. Use the following steps to add DataFu to your HDInsight cluster:\n\n1. Connect to your Linux-based HDInsight cluster using SSH. For more information on using SSH with HDInsight, see one of the following documents:\n\n    * [Use SSH with Linux-based Hadoop on HDInsight from Linux, OS X, and Unix](hdinsight-hadoop-linux-use-ssh-unix.md)\n    * [Use SSH with Linux-based Hadoop on HDInsight from Windows](hdinsight-hadoop-linux-use-ssh-unix.md)\n    \n2. Use the following command to download the DataFu jar file using the wget utility, or copy and paste the link into your browser to begin the download.\n\n        wget http://central.maven.org/maven2/com/linkedin/datafu/datafu/1.2.0/datafu-1.2.0.jar\n\n3. Next, upload the file to default storage for your HDInsight cluster. This makes the file available to all nodes in the cluster, and the file will stay in storage even if you delete and recreate the cluster.\n\n        hdfs dfs -put datafu-1.2.0.jar /example/jars\n    \n    > [AZURE.NOTE] The above example stores the jar in `wasb:///example/jars` since this directory already exists on the cluster storage. You can use any location you wish on HDInsight cluster storage.\n\n##Use DataFu With Pig\n\nThe steps in this section assume that you are familiar with using Pig on HDInsight, and only provide the Pig Latin statements, not the steps on how to use them with the cluster. For more information on using Pig with HDInsight, see [Use Pig with HDInsight](hdinsight-use-pig.md).\n\n> [AZURE.IMPORTANT] When using DataFu from Pig on a Linux-based HDInsight cluster, you must first register the jar file using the following Pig Latin statement:\n>\n> ```register wasb:///example/jars/datafu-1.2.0.jar```\n>\n> DataFu is registered by default on Windows-based HDInsight clusters.\n\nYou will usually define an alias for DataFu functions. For example:\n\n    DEFINE SHA datafu.pig.hash.SHA();\n    \nThis defines an alias named `SHA` for the SHA hashing function. You can then use this in a Pig Latin script to generate a hash for the input data. For example, the following replaces the names in the input data with a hash value:\n\n    raw = LOAD '/data/raw/' USING PigStorage(',') AS  \n        (name:chararray, \n        int1:int, \n        int2:int,\n        int3:int); \n    mask = FOREACH raw GENERATE SHA(name), int1, int2, int3; \n    DUMP mask;\n\nIf this is used with the following input data:\n\n    Lana Zemljaric,5,9,1\n    Qiong Zhong,9,3,6\n    Sandor Harsanyi,0,7,3\n    Roko Petkovic,2,6,2\n    Tibor Rozsa,8,0,0\n    Lea Hrastovsek,6,3,6\n    Regina Toth,2,1,2\n    Eva Makay,8,9,2\n    Shi Liao,4,6,0\n    Tjasa Zemljaric,0,2,5\n    \nIt will generate the following output:\n\n    (c1a743b0f34d349cfc2ce00ef98369bdc3dba1565fec92b4159a9cd5de186347,5,9,1)\n    (713d030d621ab69aa3737c8ea37a2c7c724a01cd0657a370e103d8cdecac6f99,9,3,6)\n    (7a5f5abdd281f68168199319d98a1a662535f988d1443b3a3c497010937bac89,0,7,3)\n    (a94818e93807e12079c4b35f8f3c8c8ef8e8acd1954e7f0476bc1a3a86fc96a9,2,6,2)\n    (894ead4f48af91df7e088241218a23157bede7c52115272e417e95c046d48902,8,0,0)\n    (6f99f163af3448fda672087db306f363e27a98a9e49c1f274a0860e303f8aec4,6,3,6)\n    (a03de92a28be3c6a984c7a153fa9ed81c0413f76a9401955b5f7e04a5dd0ab9f,2,1,2)\n    (6ceab977c8fb48d9ad0dc413e6bc646cabd89f22e7ab97a6b0133f3d225c6013,8,9,2)\n    (fa9c436469096ff1bd297e182831f460501b826272ae97e921f5f6e3f54747e8,4,6,0)\n    (bc22db7c238b86c37af79a62c78f61a304b35143f6087eb99c34040325865654,0,2,5)\n\n##Next steps\n\nFor more information on DataFu or Pig, see the following documents:\n\n* [Apache DataFu Pig Guide](http://datafu.incubator.apache.org/docs/datafu/guide.html).\n\n* [Use Pig with HDInsight](hdinsight-use-pig.md)\n"
}