{"nodes":[{"content":"Create and display a basic mesh","pos":[27,58]},{"content":"3-D Universal Windows Platform (UWP) games typically use polygons to represent objects and surfaces in the game.","pos":[72,184]},{"content":"Create and display a basic mesh","pos":[241,272]},{"content":"Updated for UWP apps on Windows 10.","pos":[278,313]},{"content":"For Windows 8.x articles, see the <bpt id=\"p1\">[</bpt>archive<ept id=\"p1\">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept>","pos":[314,406]},{"content":"3-D Universal Windows Platform (UWP) games typically use polygons to represent objects and surfaces in the game.","pos":[411,523]},{"content":"The lists of vertices that comprise the structure of these polygonal objects and surfaces are called meshes.","pos":[524,632]},{"content":"Here, we create a basic mesh for a cube object and provide it to the shader pipeline for rendering and display.","pos":[633,744]},{"content":"<bpt id=\"p1\">**</bpt>Important<ept id=\"p1\">**</ept>   The example code included here uses types (such as DirectX::XMFLOAT3 and DirectX::XMFLOAT4X4) and inline methods declared in DirectXMath.h.","pos":[748,903]},{"content":"If you're cutting and pasting this code, <ph id=\"ph1\">\\#</ph>include <ph id=\"ph2\">&amp;lt;</ph>DirectXMath.h<ph id=\"ph3\">&amp;gt;</ph> in your project.","pos":[904,993]},{"content":"What you need to know","pos":[1001,1022]},{"content":"Technologies","pos":[1029,1041]},{"content":"Direct3D","pos":[1048,1056]},{"content":"Prerequisites","pos":[1124,1137]},{"content":"Basic knowledge of linear algebra and 3-D coordinate systems","pos":[1143,1203]},{"content":"A Visual Studio 2015 Direct3D template","pos":[1208,1246]},{"content":"Instructions","pos":[1251,1263]},{"content":"Step 1: Construct the mesh for the model","pos":[1269,1309]},{"content":"In most games, the mesh for a game object is loaded from a file that contains the specific vertex data.","pos":[1311,1414]},{"content":"The ordering of these vertices is app-dependent, but they are usually serialized as strips or fans.","pos":[1415,1514]},{"content":"Vertex data can come from any software source, or it can be created manually.","pos":[1515,1592]},{"content":"It's up to your game to interpret the data in a way that the vertex shader can effectively process it.","pos":[1593,1695]},{"content":"In our example, we use a simple mesh for a cube.","pos":[1697,1745]},{"content":"The cube, like any object mesh at this stage in the pipeline, is represented using its own coordinate system.","pos":[1746,1855]},{"content":"The vertex shader takes its coordinates and, by applying the transformation matrices you provide, returns the final 2-D view projection in a homogeneous coordinate system.","pos":[1856,2027]},{"content":"Define the mesh for a cube.","pos":[2029,2056]},{"content":"(Or load it from a file.","pos":[2057,2081]},{"content":"It's your call!)","pos":[2082,2098]},{"content":"The cube's coordinate system places the center of the cube at the origin, with the y-axis running top to bottom using a left-handed coordinate system.","pos":[2865,3015]},{"content":"Coordinate values are expressed as 32-bit floating values between -1 and 1.","pos":[3016,3091]},{"content":"In each bracketed pairing, the second DirectX::XMFLOAT3 value group specifies the color associated with the vertex as an RGB value.","pos":[3093,3224]},{"content":"For example, the first vertex at (-0.5, 0.5, -0.5) has a full green color (the G value is set to 1.0, and the \"R\" and \"B\" values are set to 0).","pos":[3225,3368]},{"content":"Therefore, you have 8 vertices, each with a specific color.","pos":[3370,3429]},{"content":"Each vertex/color pairing is the complete data for a vertex in our example.","pos":[3430,3505]},{"content":"When you specify our vertex buffer, you must keep this specific layout in mind.","pos":[3506,3585]},{"content":"We provide this input layout to the vertex shader so it can understand your vertex data.","pos":[3586,3674]},{"content":"Step 2: Set up the input layout","pos":[3680,3711]},{"content":"Now, you have the vertices in memory.","pos":[3713,3750]},{"content":"But, your graphics device has its own memory, and you use Direct3D to access it.","pos":[3751,3831]},{"content":"To get your vertex data into the graphics device for processing, you need to clear the way, as it were: you must declare how the vertex data is laid out so that the graphics device can interpret it when it gets it from your game.","pos":[3832,4061]},{"content":"To do that, you use <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ID3D11InputLayout<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ff476575)</ept>.","pos":[4062,4167]},{"content":"Declare and set the input layout for the vertex buffer.","pos":[4169,4224]},{"content":"In this code, you specify a layout for the vertices, specifically, what data each element in the vertex list contains.","pos":[4766,4884]},{"content":"Here, in <bpt id=\"p1\">**</bpt>basicVertexLayoutDesc<ept id=\"p1\">**</ept>, you specify two data components:","pos":[4885,4953]},{"content":"<bpt id=\"p1\">**</bpt>POSITION<ept id=\"p1\">**</ept>: This is an HLSL semantic for position data provided to a shader.","pos":[4959,5037]},{"content":"In this code, it's a DirectX::XMFLOAT3, or more specifically, a structure with 3 32-bit floating point values that correspond to a 3D coordinate (x, y, z).","pos":[5038,5193]},{"content":"You could also use a float4 if you are supplying the homogeneous \"w\" coordinate, and in that case, you specify DXGI<ph id=\"ph1\">\\_</ph>FORMAT<ph id=\"ph2\">\\_</ph>R32G32B32A32<ph id=\"ph3\">\\_</ph>FLOAT.","pos":[5194,5339]},{"content":"Whether you use a DirectX::XMFLOAT3 or a float4 is up to the specific needs of your game.","pos":[5340,5429]},{"content":"Just make sure that the vertex data for your mesh corresponds correctly to the format you use!","pos":[5430,5524]},{"content":"Each coordinate value is expressed as a floating point value between -1 and 1, in the object's coordinate space.","pos":[5530,5642]},{"content":"When the vertex shader completes, the transformed vertex is in the homogeneous (perspective corrected) view projection space.","pos":[5643,5768]},{"content":"\"But the enumeration value indicates RGB, not XYZ!\"","pos":[5774,5825]},{"content":"you smartly note.","pos":[5826,5843]},{"content":"Good eye!","pos":[5844,5853]},{"content":"In both the cases of color data and coordinate data, you typically use 3 or 4 component values, so why not use the same format for both?","pos":[5854,5990]},{"content":"The HLSL semantic, not the format name, indicates how the shader treats the data.","pos":[5991,6072]},{"content":"<bpt id=\"p1\">**</bpt>COLOR<ept id=\"p1\">**</ept>: This is an HLSL semantic for color data.","pos":[6078,6129]},{"content":"Like <bpt id=\"p1\">**</bpt>POSITION<ept id=\"p1\">**</ept>, it consists of 3 32-bit floating point values (DirectX::XMFLOAT3).","pos":[6130,6215]},{"content":"Each value contains a color component: red (r), blue (b), or green (g), expressed as a floating number between 0 and 1.","pos":[6216,6335]},{"content":"<bpt id=\"p1\">**</bpt>COLOR<ept id=\"p1\">**</ept> values are typically returned as a 4-component RGBA value at the end of the shader pipeline.","pos":[6341,6443]},{"content":"For this example, you will be setting the \"A\" alpha value to 1.0 (maximum opacity) in the shader pipeline for all pixels.","pos":[6444,6565]},{"content":"For a complete list of formats, see <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>DXGI<ph id=\"ph1\">\\_</ph>FORMAT<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/bb173059)</ept>.","pos":[6567,6683]},{"content":"For a complete list of HLSL semantics, see <bpt id=\"p1\">[</bpt>Semantics<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/bb509647)</ept>.","pos":[6684,6800]},{"content":"Call <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ID3D11Device::CreateInputLayout<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ff476512)</ept> and create the input layout on the Direct3D device.","pos":[6802,6957]},{"content":"Now, you need to create a buffer that can actually hold the data!","pos":[6958,7023]},{"content":"Step 3: Populate the vertex buffers","pos":[7029,7064]},{"content":"Vertex buffers contain the list of vertices for each triangle in the mesh.","pos":[7066,7140]},{"content":"Every vertex must be unique in this list.","pos":[7141,7182]},{"content":"In our example, you have 8 vertices for the cube.","pos":[7183,7232]},{"content":"The vertex shader runs on the graphics device and reads from the vertex buffer, and it interprets the data based on the input layout you specified in the previous step.","pos":[7233,7401]},{"content":"In the next example, you provide a description and a subresource for the buffer, which tell Direct3D a number of things about the physical mapping of the vertex data and how to treat it in memory on the graphics device.","pos":[7403,7622]},{"content":"This is necessary because you use a generic <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ID3D11Buffer<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ff476351)</ept>, which could contain anything!","pos":[7623,7777]},{"content":"The <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>D3D11<ph id=\"ph1\">\\_</ph>BUFFER<ph id=\"ph2\">\\_</ph>DESC<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ff476092)</ept> and <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>D3D11<ph id=\"ph3\">\\_</ph>SUBRESOURCE<ph id=\"ph4\">\\_</ph>DATA<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/desktop/ff476220)</ept> structures are supplied to ensure that Direct3D understands the physical memory layout of the buffer, including the size of each vertex element in the buffer as well as the maximum size of the vertex list.","pos":[7778,8170]},{"content":"You can also control access to the buffer memory here and how it is traversed, but that's a bit beyond the scope of this tutorial.","pos":[8171,8301]},{"content":"After you configure the buffer, you call <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ID3D11Device::CreateBuffer<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ff476501)</ept> to actually create it.","pos":[8303,8460]},{"content":"Obviously, if you have more than one object, create buffers for each unique model.","pos":[8461,8543]},{"content":"Declare and create the vertex buffer.","pos":[8545,8582]},{"content":"Vertices loaded.","pos":[9252,9268]},{"content":"But what's the order of processing these vertices?","pos":[9269,9319]},{"content":"That's handled when you provide a list of indices to the vertices—the ordering of these indices is the order in which the vertex shader processes them.","pos":[9320,9471]},{"content":"Step 4: Populate the index buffers","pos":[9477,9511]},{"content":"Now, you provide a list of the indices for each of the vertices.","pos":[9513,9577]},{"content":"These indices correspond to the position of the vertex in the vertex buffer, starting with 0.","pos":[9578,9671]},{"content":"To help you visualize this, consider that each unique vertex in your mesh has a unique number assigned to it, like an ID.","pos":[9672,9793]},{"content":"This ID is the integer position of the vertex in the vertex buffer.","pos":[9794,9861]},{"content":"a cube with eight numbered vertices","pos":[9865,9900]},{"content":"In our example cube, you have 8 vertices, which create 6 quads for the sides.","pos":[9927,10004]},{"content":"You split the quads into triangles, for a total of 12 triangles that use our 8 vertices.","pos":[10005,10093]},{"content":"At 3 vertices per triangle, you have 36 entries in our index buffer.","pos":[10094,10162]},{"content":"In our example, this index pattern is known as a triangle list, and you indicate it to Direct3D as a <bpt id=\"p1\">**</bpt>D3D11<ph id=\"ph1\">\\_</ph>PRIMITIVE<ph id=\"ph2\">\\_</ph>TOPOLOGY<ph id=\"ph3\">\\_</ph>TRIANGLELIST<ept id=\"p1\">**</ept> when you set the primitive topology.","pos":[10163,10345]},{"content":"This is probably the most inefficient way to list indices, as there are many redundancies when triangles share points and sides.","pos":[10347,10475]},{"content":"For example, when a triangle shares a side in a rhombus shape, you list 6 indices for the four vertices, like this:","pos":[10476,10591]},{"content":"order of indices when constructing a rhombus","pos":[10595,10639]},{"content":"Triangle 1: <ph id=\"ph1\">\\[</ph>0, 1, 2","pos":[10676,10697]},{"content":"Triangle 2: <ph id=\"ph1\">\\[</ph>0, 2, 3","pos":[10704,10725]},{"content":"In a strip or fan topology, you order the vertices in a way that eliminates many redundant sides during traversal (such as the side from index 0 to index 2 in the image.) For large meshes, this dramatically reduces the number of times the vertex shader is run, and improves performance significantly.","pos":[10729,11029]},{"content":"However, we'll keep it simple and stick with the triangle list.","pos":[11030,11093]},{"content":"Declare the indices for the vertex buffer as a simple triangle list topology.","pos":[11095,11172]},{"content":"Thirty six index elements in the buffer is very redundant when you only have 8 vertices!","pos":[11380,11468]},{"content":"If you choose to eliminate some of the redundancies and use a different vertex list type, such as a strip or a fan, you must specify that type when you provide a specific <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>D3D11<ph id=\"ph1\">\\_</ph>PRIMITIVE<ph id=\"ph2\">\\_</ph>TOPOLOGY<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ff476189)</ept> value to the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>ID3D11DeviceContext::IASetPrimitiveTopology<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/desktop/ff476455)</ept> method.","pos":[11469,11865]},{"pos":[11867,12015],"content":"For more information about different index list techniques, see <bpt id=\"p1\">[</bpt>Primitive Topologies<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/bb205124)</ept>."},{"content":"Step 5: Create a constant buffer for your transformation matrices","pos":[12021,12086]},{"content":"Before you can start processing vertices, you need to provide the transformation matrices that will be applied (multiplied) to each vertex when it runs.","pos":[12088,12240]},{"content":"For most 3-D games, there are three of them:","pos":[12241,12285]},{"content":"The 4x4 matrix that transforms from the object (model) coordinate system to the overall world coordinate system.","pos":[12291,12403]},{"content":"The 4x4 matrix that transforms from the world coordinate system to the camera (view) coordinate system.","pos":[12408,12511]},{"content":"The 4x4 matrix that transforms from the camera coordinate system to the 2-D view projection coordinate system.","pos":[12516,12626]},{"content":"These matrices are passed to the shader in a <bpt id=\"p1\">*</bpt>constant buffer<ept id=\"p1\">*</ept>.","pos":[12628,12691]},{"content":"A constant buffer is a region of memory that remains constant throughout the execution of the next pass of the shader pipeline, and which can be directly accessed by the shaders from your HLSL code.","pos":[12692,12890]},{"content":"You define each constant buffer two times: first in your game's C++ code, and (at least) one time in the C-like HLSL syntax for your shader code.","pos":[12891,13036]},{"content":"The two declarations must directly correspond in terms of types and data alignment.","pos":[13037,13120]},{"content":"It's easy to introduce hard to find errors when the shader uses the HLSL declaration to interpret data declared in C++, and the types don't match or the alignment of data is off!","pos":[13121,13299]},{"content":"Constant buffers don't get changed by the HLSL.","pos":[13301,13348]},{"content":"You can change them when your game updates specific data.","pos":[13349,13406]},{"content":"Often, game devs create 4 classes of constant buffers: one type for updates per frame; one type for updates per model/object; one type for updates per game state refresh; and one type for data that never changes through the lifetime of the game.","pos":[13407,13652]},{"content":"In this example, we just have one that never changes: the DirectX::XMFLOAT4X4 data for the three matrices.","pos":[13654,13760]},{"content":"<bpt id=\"p1\">**</bpt>Note<ept id=\"p1\">**</ept>   The example code presented here uses column-major matrices.","pos":[13764,13834]},{"content":"You can use row-major matrices instead by using the <bpt id=\"p1\">**</bpt>row<ph id=\"ph1\">\\_</ph>major<ept id=\"p1\">**</ept> keyword in HLSL, and ensuring your source matrix data is also row-major.","pos":[13835,13974]},{"content":"DirectXMath uses row-major matrices and can be used directly with HLSL matrices defined with the <bpt id=\"p1\">**</bpt>row<ph id=\"ph1\">\\_</ph>major<ept id=\"p1\">**</ept> keyword.","pos":[13975,14095]},{"content":"Declare and create a constant buffer for the three matrices you use to transform each vertex.","pos":[14100,14193]},{"content":"<bpt id=\"p1\">**</bpt>Note<ept id=\"p1\">**</ept>  You usually declare the projection matrix when you set up device specific resources, because the results of multiplication with it must match the current 2-D viewport size parameters (which often correspond with the pixel height and width of the display).","pos":[15750,16015]},{"content":"If those change, you must scale the x- and y-coordinate values accordingly.","pos":[16016,16091]},{"pos":[16988,17161],"content":"While you're here, set the vertex and index buffers on the<bpt id=\"p1\">[</bpt>ID3D11DeviceContext<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/ff476149)</ept>, plus the topology you're using."},{"content":"All right!","pos":[17702,17712]},{"content":"Input assembly complete.","pos":[17713,17737]},{"content":"Everything's in place for rendering.","pos":[17738,17774]},{"content":"Let's get that vertex shader going.","pos":[17775,17810]},{"content":"Step 6: Process the mesh with the vertex shader","pos":[17816,17863]},{"content":"Now that you have a vertex buffer with the vertices that define your mesh, and the index buffer that defines the order in which the vertices are processed, you send them to the vertex shader.","pos":[17865,18056]},{"content":"The vertex shader code, expressed as compiled high-level shader language, runs one time for each vertex in the vertex buffer, allowing you to perform your per-vertex transforms.","pos":[18057,18234]},{"content":"The final result is typically a 2-D projection.","pos":[18235,18282]},{"content":"(Did you load your vertex shader?","pos":[18284,18317]},{"content":"If not, review <bpt id=\"p1\">[</bpt>How to load resources in your DirectX game<ept id=\"p1\">](load-a-game-asset.md)</ept>.)","pos":[18318,18401]},{"content":"Here, you create the vertex shader...","pos":[18403,18440]},{"content":"...and set the constant buffers.","pos":[18620,18652]},{"content":"Here's the vertex shader code that handles the transformation from object coordinates to world coordinates and then to the 2-D view projection coordinate system.","pos":[18800,18961]},{"content":"You also apply some simple per-vertex lighting to make things pretty.","pos":[18962,19031]},{"content":"This goes in your vertex shader's HLSL file (SimplerVertexShader.hlsl, in this example).","pos":[19032,19120]},{"content":"See that <bpt id=\"p1\">**</bpt>cbuffer<ept id=\"p1\">**</ept> at the top?","pos":[19917,19949]},{"content":"That's the HLSL analogue to the same constant buffer we declared in our C++ code previously.","pos":[19950,20042]},{"content":"And the <bpt id=\"p1\">**</bpt>VertexShaderInputstruct<ept id=\"p1\">**</ept>?","pos":[20043,20079]},{"content":"Why, that looks just like your input layout and vertex data declaration!","pos":[20080,20152]},{"content":"It's important that the constant buffer and vertex data declarations in your C++ code match the declarations in your HLSL code—and that includes signs, types, and data alignment.","pos":[20153,20331]},{"content":"<bpt id=\"p1\">**</bpt>PixelShaderInput<ept id=\"p1\">**</ept> specifies the layout of the data that is returned by the vertex shader's main function.","pos":[20333,20441]},{"content":"When you finish processing a vertex, you'll return a vertex position in the 2-D projection space and a color used for per-vertex lighting.","pos":[20442,20580]},{"content":"The graphics card uses data output by the shader to calculate the \"fragments\" (possible pixels) that must be colored when the pixel shader is run in the next stage of the pipeline.","pos":[20581,20761]},{"content":"Step 7: Passing the mesh through the pixel shader","pos":[20767,20816]},{"content":"Typically, at this stage in the graphics pipeline, you perform per-pixel operations on the visible projected surfaces of your objects.","pos":[20818,20952]},{"content":"(People like textures.) For the purposes of sample, though, you simply pass it through this stage.","pos":[20953,21051]},{"content":"First, let's create an instance of the pixel shader.","pos":[21053,21105]},{"content":"The pixel shader runs for every pixel in the 2-D projection of your scene, assigning a color to that pixel.","pos":[21106,21213]},{"content":"In this case, we pass the color for the pixel returned by the vertex shader straight through.","pos":[21214,21307]},{"content":"Set the pixel shader.","pos":[21309,21330]},{"content":"Define a passthrough pixel shader in HLSL.","pos":[21414,21456]},{"content":"Put this code in an HLSL file separate from the vertex shader HLSL (such as SimplePixelShader.hlsl).","pos":[21682,21782]},{"content":"This code is run one time for every visible pixel in your viewport (an in-memory representation of the portion of the screen you are drawing to), which, in this case, maps to the entire screen.","pos":[21783,21976]},{"content":"Now, your graphics pipeline is completely defined!","pos":[21977,22027]},{"content":"Step 8: Rasterizing and displaying the mesh","pos":[22033,22076]},{"content":"Let's run the pipeline.","pos":[22078,22101]},{"content":"This is easy: call <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ID3D11DeviceContext::DrawIndexed<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/bb173565)</ept>.","pos":[22102,22221]},{"content":"Draw that cube!","pos":[22223,22238]},{"content":"Inside the graphics card, each vertex is processed in the order specified in your index buffer.","pos":[22348,22443]},{"content":"After your code has executed the vertex shader and the 2-D fragments are defined, the pixel shader is invoked and the triangles colored.","pos":[22444,22580]},{"content":"Now, put the cube on the screen.","pos":[22582,22614]},{"content":"Present that frame buffer to the display.","pos":[22616,22657]},{"content":"And you're done!","pos":[22953,22969]},{"content":"For a scene full of models, use multiple vertex and index buffers, and you might even have different shaders for different model types.","pos":[22970,23105]},{"content":"Remember that each model has its own coordinate system, and you need to transform them to the shared world coordinate system using the matrices you defined in the constant buffer.","pos":[23106,23285]},{"content":"Remarks","pos":[23290,23297]},{"content":"This topic covers creating and displaying simple geometry that you create yourself.","pos":[23299,23382]},{"content":"For more info about loading more complex geometry from a file and converting it to the sample-specific vertex buffer object (.vbo) format, see <bpt id=\"p1\">[</bpt>How to load resources in your DirectX game<ept id=\"p1\">](load-a-game-asset.md)</ept>.","pos":[23383,23593]},{"content":"Note","pos":[23599,23603]},{"content":"This article is for Windows 10 developers writing Universal Windows Platform (UWP) apps.","pos":[23608,23696]},{"content":"If you’re developing for Windows 8.x or Windows Phone 8.x, see the <bpt id=\"p1\">[</bpt>archived documentation<ept id=\"p1\">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept>.","pos":[23697,23838]},{"content":"Related topics","pos":[23846,23860]},{"content":"How to load resources in your DirectX game","pos":[23866,23908]}],"content":"---\nauthor: mtoepke\ntitle: Create and display a basic mesh\ndescription: 3-D Universal Windows Platform (UWP) games typically use polygons to represent objects and surfaces in the game.\nms.assetid: bfe0ed5b-63d8-935b-a25b-378b36982b7d\n---\n\n# Create and display a basic mesh\n\n\n\\[ Updated for UWP apps on Windows 10. For Windows 8.x articles, see the [archive](http://go.microsoft.com/fwlink/p/?linkid=619132) \\]\n\n3-D Universal Windows Platform (UWP) games typically use polygons to represent objects and surfaces in the game. The lists of vertices that comprise the structure of these polygonal objects and surfaces are called meshes. Here, we create a basic mesh for a cube object and provide it to the shader pipeline for rendering and display.\n\n> **Important**   The example code included here uses types (such as DirectX::XMFLOAT3 and DirectX::XMFLOAT4X4) and inline methods declared in DirectXMath.h. If you're cutting and pasting this code, \\#include &lt;DirectXMath.h&gt; in your project.\n\n \n\n## What you need to know\n\n\n### Technologies\n\n-   [Direct3D](https://msdn.microsoft.com/library/windows/desktop/hh769064)\n\n### Prerequisites\n\n-   Basic knowledge of linear algebra and 3-D coordinate systems\n-   A Visual Studio 2015 Direct3D template\n\n## Instructions\n\n### Step 1: Construct the mesh for the model\n\nIn most games, the mesh for a game object is loaded from a file that contains the specific vertex data. The ordering of these vertices is app-dependent, but they are usually serialized as strips or fans. Vertex data can come from any software source, or it can be created manually. It's up to your game to interpret the data in a way that the vertex shader can effectively process it.\n\nIn our example, we use a simple mesh for a cube. The cube, like any object mesh at this stage in the pipeline, is represented using its own coordinate system. The vertex shader takes its coordinates and, by applying the transformation matrices you provide, returns the final 2-D view projection in a homogeneous coordinate system.\n\nDefine the mesh for a cube. (Or load it from a file. It's your call!)\n\n```cpp\nSimpleCubeVertex cubeVertices[] =\n{\n    { DirectX::XMFLOAT3(-0.5f, 0.5f, -0.5f), DirectX::XMFLOAT3(0.0f, 1.0f, 0.0f) }, // +Y (top face)\n    { DirectX::XMFLOAT3( 0.5f, 0.5f, -0.5f), DirectX::XMFLOAT3(1.0f, 1.0f, 0.0f) },\n    { DirectX::XMFLOAT3( 0.5f, 0.5f,  0.5f), DirectX::XMFLOAT3(1.0f, 1.0f, 1.0f) },\n    { DirectX::XMFLOAT3(-0.5f, 0.5f,  0.5f), DirectX::XMFLOAT3(0.0f, 1.0f, 1.0f) },\n\n    { DirectX::XMFLOAT3(-0.5f, -0.5f,  0.5f), DirectX::XMFLOAT3(0.0f, 0.0f, 1.0f) }, // -Y (bottom face)\n    { DirectX::XMFLOAT3( 0.5f, -0.5f,  0.5f), DirectX::XMFLOAT3(1.0f, 0.0f, 1.0f) },\n    { DirectX::XMFLOAT3( 0.5f, -0.5f, -0.5f), DirectX::XMFLOAT3(1.0f, 0.0f, 0.0f) },\n    { DirectX::XMFLOAT3(-0.5f, -0.5f, -0.5f), DirectX::XMFLOAT3(0.0f, 0.0f, 0.0f) },\n};\n```\n\nThe cube's coordinate system places the center of the cube at the origin, with the y-axis running top to bottom using a left-handed coordinate system. Coordinate values are expressed as 32-bit floating values between -1 and 1.\n\nIn each bracketed pairing, the second DirectX::XMFLOAT3 value group specifies the color associated with the vertex as an RGB value. For example, the first vertex at (-0.5, 0.5, -0.5) has a full green color (the G value is set to 1.0, and the \"R\" and \"B\" values are set to 0).\n\nTherefore, you have 8 vertices, each with a specific color. Each vertex/color pairing is the complete data for a vertex in our example. When you specify our vertex buffer, you must keep this specific layout in mind. We provide this input layout to the vertex shader so it can understand your vertex data.\n\n### Step 2: Set up the input layout\n\nNow, you have the vertices in memory. But, your graphics device has its own memory, and you use Direct3D to access it. To get your vertex data into the graphics device for processing, you need to clear the way, as it were: you must declare how the vertex data is laid out so that the graphics device can interpret it when it gets it from your game. To do that, you use [**ID3D11InputLayout**](https://msdn.microsoft.com/library/windows/desktop/ff476575).\n\nDeclare and set the input layout for the vertex buffer.\n\n```cpp\nconst D3D11_INPUT_ELEMENT_DESC basicVertexLayoutDesc[] =\n{\n    { \"POSITION\", 0, DXGI_FORMAT_R32G32B32_FLOAT, 0,  0, D3D11_INPUT_PER_VERTEX_DATA, 0 },\n    { \"COLOR\",    0, DXGI_FORMAT_R32G32B32_FLOAT, 0, 12, D3D11_INPUT_PER_VERTEX_DATA, 0 },\n};\n\nComPtr<ID3D11InputLayout> inputLayout;\nm_d3dDevice->CreateInputLayout(\n                basicVertexLayoutDesc,\n                ARRAYSIZE(basicVertexLayoutDesc),\n                vertexShaderBytecode->Data,\n                vertexShaderBytecode->Length,\n                &inputLayout)\n);\n```\n\nIn this code, you specify a layout for the vertices, specifically, what data each element in the vertex list contains. Here, in **basicVertexLayoutDesc**, you specify two data components:\n\n-   **POSITION**: This is an HLSL semantic for position data provided to a shader. In this code, it's a DirectX::XMFLOAT3, or more specifically, a structure with 3 32-bit floating point values that correspond to a 3D coordinate (x, y, z). You could also use a float4 if you are supplying the homogeneous \"w\" coordinate, and in that case, you specify DXGI\\_FORMAT\\_R32G32B32A32\\_FLOAT. Whether you use a DirectX::XMFLOAT3 or a float4 is up to the specific needs of your game. Just make sure that the vertex data for your mesh corresponds correctly to the format you use!\n\n    Each coordinate value is expressed as a floating point value between -1 and 1, in the object's coordinate space. When the vertex shader completes, the transformed vertex is in the homogeneous (perspective corrected) view projection space.\n\n    \"But the enumeration value indicates RGB, not XYZ!\" you smartly note. Good eye! In both the cases of color data and coordinate data, you typically use 3 or 4 component values, so why not use the same format for both? The HLSL semantic, not the format name, indicates how the shader treats the data.\n\n-   **COLOR**: This is an HLSL semantic for color data. Like **POSITION**, it consists of 3 32-bit floating point values (DirectX::XMFLOAT3). Each value contains a color component: red (r), blue (b), or green (g), expressed as a floating number between 0 and 1.\n\n    **COLOR** values are typically returned as a 4-component RGBA value at the end of the shader pipeline. For this example, you will be setting the \"A\" alpha value to 1.0 (maximum opacity) in the shader pipeline for all pixels.\n\nFor a complete list of formats, see [**DXGI\\_FORMAT**](https://msdn.microsoft.com/library/windows/desktop/bb173059). For a complete list of HLSL semantics, see [Semantics](https://msdn.microsoft.com/library/windows/desktop/bb509647).\n\nCall [**ID3D11Device::CreateInputLayout**](https://msdn.microsoft.com/library/windows/desktop/ff476512) and create the input layout on the Direct3D device. Now, you need to create a buffer that can actually hold the data!\n\n### Step 3: Populate the vertex buffers\n\nVertex buffers contain the list of vertices for each triangle in the mesh. Every vertex must be unique in this list. In our example, you have 8 vertices for the cube. The vertex shader runs on the graphics device and reads from the vertex buffer, and it interprets the data based on the input layout you specified in the previous step.\n\nIn the next example, you provide a description and a subresource for the buffer, which tell Direct3D a number of things about the physical mapping of the vertex data and how to treat it in memory on the graphics device. This is necessary because you use a generic [**ID3D11Buffer**](https://msdn.microsoft.com/library/windows/desktop/ff476351), which could contain anything! The [**D3D11\\_BUFFER\\_DESC**](https://msdn.microsoft.com/library/windows/desktop/ff476092) and [**D3D11\\_SUBRESOURCE\\_DATA**](https://msdn.microsoft.com/library/windows/desktop/ff476220) structures are supplied to ensure that Direct3D understands the physical memory layout of the buffer, including the size of each vertex element in the buffer as well as the maximum size of the vertex list. You can also control access to the buffer memory here and how it is traversed, but that's a bit beyond the scope of this tutorial.\n\nAfter you configure the buffer, you call [**ID3D11Device::CreateBuffer**](https://msdn.microsoft.com/library/windows/desktop/ff476501) to actually create it. Obviously, if you have more than one object, create buffers for each unique model.\n\nDeclare and create the vertex buffer.\n\n```cpp\nD3D11_BUFFER_DESC vertexBufferDesc = {0};\nvertexBufferDesc.ByteWidth = sizeof(SimpleCubeVertex) * ARRAYSIZE(cubeVertices);\nvertexBufferDesc.Usage = D3D11_USAGE_DEFAULT;\nvertexBufferDesc.BindFlags = D3D11_BIND_VERTEX_BUFFER;\nvertexBufferDesc.CPUAccessFlags = 0;\nvertexBufferDesc.MiscFlags = 0;\nvertexBufferDesc.StructureByteStride = 0;\n\nD3D11_SUBRESOURCE_DATA vertexBufferData;\nvertexBufferData.pSysMem = cubeVertices;\nvertexBufferData.SysMemPitch = 0;\nvertexBufferData.SysMemSlicePitch = 0;\n\nComPtr<ID3D11Buffer> vertexBuffer;\nm_d3dDevice->CreateBuffer(\n                &vertexBufferDesc,\n                &vertexBufferData,\n                &vertexBuffer);\n```\n\nVertices loaded. But what's the order of processing these vertices? That's handled when you provide a list of indices to the vertices—the ordering of these indices is the order in which the vertex shader processes them.\n\n### Step 4: Populate the index buffers\n\nNow, you provide a list of the indices for each of the vertices. These indices correspond to the position of the vertex in the vertex buffer, starting with 0. To help you visualize this, consider that each unique vertex in your mesh has a unique number assigned to it, like an ID. This ID is the integer position of the vertex in the vertex buffer.\n\n![a cube with eight numbered vertices](images/cube-mesh-1.png)\n\nIn our example cube, you have 8 vertices, which create 6 quads for the sides. You split the quads into triangles, for a total of 12 triangles that use our 8 vertices. At 3 vertices per triangle, you have 36 entries in our index buffer. In our example, this index pattern is known as a triangle list, and you indicate it to Direct3D as a **D3D11\\_PRIMITIVE\\_TOPOLOGY\\_TRIANGLELIST** when you set the primitive topology.\n\nThis is probably the most inefficient way to list indices, as there are many redundancies when triangles share points and sides. For example, when a triangle shares a side in a rhombus shape, you list 6 indices for the four vertices, like this:\n\n![order of indices when constructing a rhombus](images/rhombus-surface-1.png)\n\n-   Triangle 1: \\[0, 1, 2\\]\n-   Triangle 2: \\[0, 2, 3\\]\n\nIn a strip or fan topology, you order the vertices in a way that eliminates many redundant sides during traversal (such as the side from index 0 to index 2 in the image.) For large meshes, this dramatically reduces the number of times the vertex shader is run, and improves performance significantly. However, we'll keep it simple and stick with the triangle list.\n\nDeclare the indices for the vertex buffer as a simple triangle list topology.\n\n```cpp\nunsigned short cubeIndices[] =\n{   0, 1, 2,\n    0, 2, 3,\n\n    4, 5, 6,\n    4, 6, 7,\n\n    3, 2, 5,\n    3, 5, 4,\n\n    2, 1, 6,\n    2, 6, 5,\n\n    1, 7, 6,\n    1, 0, 7,\n\n    0, 3, 4,\n    0, 4, 7 };\n```\n\nThirty six index elements in the buffer is very redundant when you only have 8 vertices! If you choose to eliminate some of the redundancies and use a different vertex list type, such as a strip or a fan, you must specify that type when you provide a specific [**D3D11\\_PRIMITIVE\\_TOPOLOGY**](https://msdn.microsoft.com/library/windows/desktop/ff476189) value to the [**ID3D11DeviceContext::IASetPrimitiveTopology**](https://msdn.microsoft.com/library/windows/desktop/ff476455) method.\n\nFor more information about different index list techniques, see [Primitive Topologies](https://msdn.microsoft.com/library/windows/desktop/bb205124).\n\n### Step 5: Create a constant buffer for your transformation matrices\n\nBefore you can start processing vertices, you need to provide the transformation matrices that will be applied (multiplied) to each vertex when it runs. For most 3-D games, there are three of them:\n\n-   The 4x4 matrix that transforms from the object (model) coordinate system to the overall world coordinate system.\n-   The 4x4 matrix that transforms from the world coordinate system to the camera (view) coordinate system.\n-   The 4x4 matrix that transforms from the camera coordinate system to the 2-D view projection coordinate system.\n\nThese matrices are passed to the shader in a *constant buffer*. A constant buffer is a region of memory that remains constant throughout the execution of the next pass of the shader pipeline, and which can be directly accessed by the shaders from your HLSL code. You define each constant buffer two times: first in your game's C++ code, and (at least) one time in the C-like HLSL syntax for your shader code. The two declarations must directly correspond in terms of types and data alignment. It's easy to introduce hard to find errors when the shader uses the HLSL declaration to interpret data declared in C++, and the types don't match or the alignment of data is off!\n\nConstant buffers don't get changed by the HLSL. You can change them when your game updates specific data. Often, game devs create 4 classes of constant buffers: one type for updates per frame; one type for updates per model/object; one type for updates per game state refresh; and one type for data that never changes through the lifetime of the game.\n\nIn this example, we just have one that never changes: the DirectX::XMFLOAT4X4 data for the three matrices.\n\n> **Note**   The example code presented here uses column-major matrices. You can use row-major matrices instead by using the **row\\_major** keyword in HLSL, and ensuring your source matrix data is also row-major. DirectXMath uses row-major matrices and can be used directly with HLSL matrices defined with the **row\\_major** keyword.\n\n \n\nDeclare and create a constant buffer for the three matrices you use to transform each vertex.\n\n```cpp\nstruct ConstantBuffer\n{\n    DirectX::XMFLOAT4X4 model;\n    DirectX::XMFLOAT4X4 view;\n    DirectX::XMFLOAT4X4 projection;\n};\nComPtr<ID3D11Buffer> m_constantBuffer;\nConstantBuffer m_constantBufferData;\n\n// ...\n\n// Create a constant buffer for passing model, view, and projection matrices\n// to the vertex shader.  This allows us to rotate the cube and apply\n// a perspective projection to it.\n\nD3D11_BUFFER_DESC constantBufferDesc = {0};\nconstantBufferDesc.ByteWidth = sizeof(m_constantBufferData);\nconstantBufferDesc.Usage = D3D11_USAGE_DEFAULT;\nconstantBufferDesc.BindFlags = D3D11_BIND_CONSTANT_BUFFER;\nconstantBufferDesc.CPUAccessFlags = 0;\nconstantBufferDesc.MiscFlags = 0;\nconstantBufferDesc.StructureByteStride = 0;\nm_d3dDevice->CreateBuffer(\n                &constantBufferDesc,\n                nullptr,\n                &m_constantBuffer\n             );\n\nm_constantBufferData.model = DirectX::XMFLOAT4X4( // Identity matrix, since you are not animating the object\n            1.0f, 0.0f, 0.0f, 0.0f,\n            0.0f, 1.0f, 0.0f, 0.0f,\n            0.0f, 0.0f, 1.0f, 0.0f,\n            0.0f, 0.0f, 0.0f, 1.0f);\n\n);\n// Specify the view (camera) transform corresponding to a camera position of\n// X = 0, Y = 1, Z = 2.  \n\nm_constantBufferData.view = DirectX::XMFLOAT4X4(\n            -1.00000000f, 0.00000000f,  0.00000000f,  0.00000000f,\n             0.00000000f, 0.89442718f,  0.44721359f,  0.00000000f,\n             0.00000000f, 0.44721359f, -0.89442718f, -2.23606800f,\n             0.00000000f, 0.00000000f,  0.00000000f,  1.00000000f);\n```\n\n> **Note**  You usually declare the projection matrix when you set up device specific resources, because the results of multiplication with it must match the current 2-D viewport size parameters (which often correspond with the pixel height and width of the display). If those change, you must scale the x- and y-coordinate values accordingly.\n\n \n\n```cpp\n// Finally, update the constant buffer perspective projection parameters\n// to account for the size of the application window.  In this sample,\n// the parameters are fixed to a 70-degree field of view, with a depth\n// range of 0.01 to 100.  \n\nfloat xScale = 1.42814801f;\nfloat yScale = 1.42814801f;\nif (backBufferDesc.Width > backBufferDesc.Height)\n{\n    xScale = yScale *\n                static_cast<float>(backBufferDesc.Height) /\n                static_cast<float>(backBufferDesc.Width);\n}\nelse\n{\n    yScale = xScale *\n                static_cast<float>(backBufferDesc.Width) /\n                static_cast<float>(backBufferDesc.Height);\n}\nm_constantBufferData.projection = DirectX::XMFLOAT4X4(\n            xScale, 0.0f,    0.0f,  0.0f,\n            0.0f,   yScale,  0.0f,  0.0f,\n            0.0f,   0.0f,   -1.0f, -0.01f,\n            0.0f,   0.0f,   -1.0f,  0.0f\n            );\n```\n\nWhile you're here, set the vertex and index buffers on the[ID3D11DeviceContext](https://msdn.microsoft.com/library/windows/desktop/ff476149), plus the topology you're using.\n\n```cpp\n// Set the vertex and index buffers, and specify the way they define geometry.\nUINT stride = sizeof(SimpleCubeVertex);\nUINT offset = 0;\nm_d3dDeviceContext->IASetVertexBuffers(\n                0,\n                1,\n                vertexBuffer.GetAddressOf(),\n                &stride,\n                &offset);\n\nm_d3dDeviceContext->IASetIndexBuffer(\n                indexBuffer.Get(),\n                DXGI_FORMAT_R16_UINT,\n                0);\n\n m_d3dDeviceContext->IASetPrimitiveTopology(D3D11_PRIMITIVE_TOPOLOGY_TRIANGLELIST);\n```\n\nAll right! Input assembly complete. Everything's in place for rendering. Let's get that vertex shader going.\n\n### Step 6: Process the mesh with the vertex shader\n\nNow that you have a vertex buffer with the vertices that define your mesh, and the index buffer that defines the order in which the vertices are processed, you send them to the vertex shader. The vertex shader code, expressed as compiled high-level shader language, runs one time for each vertex in the vertex buffer, allowing you to perform your per-vertex transforms. The final result is typically a 2-D projection.\n\n(Did you load your vertex shader? If not, review [How to load resources in your DirectX game](load-a-game-asset.md).)\n\nHere, you create the vertex shader...\n\n``` syntax\n// Set the vertex and pixel shader stage state.\nm_d3dDeviceContext->VSSetShader(\n                vertexShader.Get(),\n                nullptr,\n                0);\n```\n\n...and set the constant buffers.\n\n``` syntax\nm_d3dDeviceContext->VSSetConstantBuffers(\n                0,\n                1,\n                m_constantBuffer.GetAddressOf());\n```\n\nHere's the vertex shader code that handles the transformation from object coordinates to world coordinates and then to the 2-D view projection coordinate system. You also apply some simple per-vertex lighting to make things pretty. This goes in your vertex shader's HLSL file (SimplerVertexShader.hlsl, in this example).\n\n``` syntax\ncbuffer simpleConstantBuffer : register( b0 )\n{\n    matrix model;\n    matrix view;\n    matrix projection;\n};\n\nstruct VertexShaderInput\n{\n    DirectX::XMFLOAT3 pos : POSITION;\n    DirectX::XMFLOAT3 color : COLOR;\n};\n\nstruct PixelShaderInput\n{\n    float4 pos : SV_POSITION;\n    float4 color : COLOR;\n};\n\nPixelShaderInput SimpleVertexShader(VertexShaderInput input)\n{\n    PixelShaderInput vertexShaderOutput;\n    float4 pos = float4(input.pos, 1.0f);\n\n    // Transform the vertex position into projection space.\n    pos = mul(pos, model);\n    pos = mul(pos, view);\n    pos = mul(pos, projection);\n    vertexShaderOutput.pos = pos;\n\n    // Pass the vertex color through to the pixel shader.\n    vertexShaderOutput.color = float4(input.color, 1.0f);\n\n    return vertexShaderOutput;\n}\n```\n\nSee that **cbuffer** at the top? That's the HLSL analogue to the same constant buffer we declared in our C++ code previously. And the **VertexShaderInputstruct**? Why, that looks just like your input layout and vertex data declaration! It's important that the constant buffer and vertex data declarations in your C++ code match the declarations in your HLSL code—and that includes signs, types, and data alignment.\n\n**PixelShaderInput** specifies the layout of the data that is returned by the vertex shader's main function. When you finish processing a vertex, you'll return a vertex position in the 2-D projection space and a color used for per-vertex lighting. The graphics card uses data output by the shader to calculate the \"fragments\" (possible pixels) that must be colored when the pixel shader is run in the next stage of the pipeline.\n\n### Step 7: Passing the mesh through the pixel shader\n\nTypically, at this stage in the graphics pipeline, you perform per-pixel operations on the visible projected surfaces of your objects. (People like textures.) For the purposes of sample, though, you simply pass it through this stage.\n\nFirst, let's create an instance of the pixel shader. The pixel shader runs for every pixel in the 2-D projection of your scene, assigning a color to that pixel. In this case, we pass the color for the pixel returned by the vertex shader straight through.\n\nSet the pixel shader.\n\n``` syntax\nm_d3dDeviceContext->PSSetShader( pixelShader.Get(), nullptr, 0 );\n```\n\nDefine a passthrough pixel shader in HLSL.\n\n``` syntax\nstruct PixelShaderInput\n{\n    float4 pos : SV_POSITION;\n};\n\nfloat4 SimplePixelShader(PixelShaderInput input) : SV_TARGET\n{\n    // Draw the entire triangle yellow.\n    return float4(1.0f, 1.0f, 0.0f, 1.0f);\n}\n```\n\nPut this code in an HLSL file separate from the vertex shader HLSL (such as SimplePixelShader.hlsl). This code is run one time for every visible pixel in your viewport (an in-memory representation of the portion of the screen you are drawing to), which, in this case, maps to the entire screen. Now, your graphics pipeline is completely defined!\n\n### Step 8: Rasterizing and displaying the mesh\n\nLet's run the pipeline. This is easy: call [**ID3D11DeviceContext::DrawIndexed**](https://msdn.microsoft.com/library/windows/desktop/bb173565).\n\nDraw that cube!\n\n```cpp\n// Draw the cube.\nm_d3dDeviceContext->DrawIndexed( ARRAYSIZE(cubeIndices), 0, 0 );\n            \n```\n\nInside the graphics card, each vertex is processed in the order specified in your index buffer. After your code has executed the vertex shader and the 2-D fragments are defined, the pixel shader is invoked and the triangles colored.\n\nNow, put the cube on the screen.\n\nPresent that frame buffer to the display.\n\n```cpp\n// Present the rendered image to the window.  Because the maximum frame latency is set to 1,\n// the render loop is generally  throttled to the screen refresh rate, typically around\n// 60 Hz, by sleeping the app on Present until the screen is refreshed.\n\nm_swapChain->Present(1, 0);\n```\n\nAnd you're done! For a scene full of models, use multiple vertex and index buffers, and you might even have different shaders for different model types. Remember that each model has its own coordinate system, and you need to transform them to the shared world coordinate system using the matrices you defined in the constant buffer.\n\n## Remarks\n\nThis topic covers creating and displaying simple geometry that you create yourself. For more info about loading more complex geometry from a file and converting it to the sample-specific vertex buffer object (.vbo) format, see [How to load resources in your DirectX game](load-a-game-asset.md).\n\n> **Note**  \nThis article is for Windows 10 developers writing Universal Windows Platform (UWP) apps. If you’re developing for Windows 8.x or Windows Phone 8.x, see the [archived documentation](http://go.microsoft.com/fwlink/p/?linkid=619132).\n\n \n\n## Related topics\n\n\n* [How to load resources in your DirectX game](load-a-game-asset.md)\n\n \n\n \n\n\n\n\n"}