<?xml version="1.0" encoding="utf-8"?>
<xliff xmlns:mda="urn:oasis:names:tc:xliff:metadata:2.0" srcLang="en-US" trgLang="zh-cn" version="2.0" xml:space="default" xmlns="urn:oasis:names:tc:xliff:document:2.0">
  <file id="1">
    <mda:metadata>
      <mda:metaGroup>
        <mda:meta type="oltranslationpriority">
        </mda:meta>
      </mda:metaGroup>
    </mda:metadata>
    <mda:metadata>
      <mda:metaGroup>
        <mda:meta type="olfilepath">windows-apps-src\input-and-devices\specify-the-speech-recognizer-language.md</mda:meta>
      </mda:metaGroup>
    </mda:metadata>
    <mda:metadata>
      <mda:metaGroup>
        <mda:meta type="olfilehash">24393ef52d72aa08f9aab2d541e65ccb5f2aceed</mda:meta>
      </mda:metaGroup>
    </mda:metadata>
    <mda:metadata>
      <mda:metaGroup>
        <mda:meta type="tool-id">mdxliff</mda:meta>
        <mda:meta type="tool-name">mdxliff</mda:meta>
        <mda:meta type="tool-version">1.0-781aacf</mda:meta>
        <mda:meta type="tool-company">Microsoft</mda:meta>
      </mda:metaGroup>
    </mda:metadata>
    <group id="content">
      <unit id="101">
        <segment state="initial">
          <source>Learn how to select an installed language to use for speech recognition.</source>
          <target>Learn how to select an installed language to use for speech recognition.</target>
        </segment>
      </unit>
      <unit id="102">
        <segment state="initial">
          <source>Specify the speech recognizer language</source>
          <target>Specify the speech recognizer language</target>
        </segment>
      </unit>
      <unit id="103">
        <segment state="initial">
          <source>Specify the speech recognizer language</source>
          <target>Specify the speech recognizer language</target>
        </segment>
      </unit>
      <unit id="104">
        <segment state="initial">
          <source>Learn how to select an installed language to use for speech recognition.</source>
          <target>Learn how to select an installed language to use for speech recognition.</target>
        </segment>
      </unit>
      <unit id="105">
        <segment state="initial">
          <source>Important APIs</source>
          <target>Important APIs</target>
        </segment>
      </unit>
      <unit id="106">
        <segment state="initial">
          <source>SupportedTopicLanguages</source>
          <target>SupportedTopicLanguages</target>
        </segment>
      </unit>
      <unit id="107">
        <segment state="initial">
          <source>SupportedGrammarLanguages</source>
          <target>SupportedGrammarLanguages</target>
        </segment>
      </unit>
      <unit id="108">
        <segment state="initial">
          <source>Language</source>
          <target>Language</target>
        </segment>
      </unit>
      <unit id="109">
        <segment state="initial">
          <source>Here, we enumerate the languages installed on a system, identify which is the default language, and select a different language for recognition.</source>
          <target>Here, we enumerate the languages installed on a system, identify which is the default language, and select a different language for recognition.</target>
        </segment>
      </unit>
      <unit id="110">
        <segment state="initial">
          <source>Prerequisites:</source>
          <target>Prerequisites:</target>
        </segment>
      </unit>
      <unit id="111">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](speech-recognition.md)</data>
        </originalData>
        <segment state="initial">
          <source>This topic builds on <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Speech recognition</pc>.</source>
          <target>This topic builds on <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Speech recognition</pc>.</target>
        </segment>
      </unit>
      <unit id="112">
        <segment state="initial">
          <source>You should have a basic understanding of speech recognition and recognition constraints.</source>
          <target>You should have a basic understanding of speech recognition and recognition constraints.</target>
        </segment>
      </unit>
      <unit id="113">
        <segment state="initial">
          <source>If you're new to developing Universal Windows Platform (UWP) apps, have a look through these topics to get familiar with the technologies discussed here.</source>
          <target>If you're new to developing Universal Windows Platform (UWP) apps, have a look through these topics to get familiar with the technologies discussed here.</target>
        </segment>
      </unit>
      <unit id="114">
        <segment state="initial">
          <source>Create your first app</source>
          <target>Create your first app</target>
        </segment>
      </unit>
      <unit id="115">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/mt185584)</data>
        </originalData>
        <segment state="initial">
          <source>Learn about events with <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Events and routed events overview</pc></source>
          <target>Learn about events with <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Events and routed events overview</pc></target>
        </segment>
      </unit>
      <unit id="116">
        <segment state="initial">
          <source>User experience guidelines:</source>
          <target>User experience guidelines:</target>
        </segment>
      </unit>
      <unit id="117">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn596121)</data>
        </originalData>
        <segment state="initial">
          <source>For helpful tips about designing a useful and engaging speech-enabled app, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Speech design guidelines</pc> .</source>
          <target>For helpful tips about designing a useful and engaging speech-enabled app, see <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Speech design guidelines</pc> .</target>
        </segment>
      </unit>
      <unit id="118">
        <segment state="initial">
          <source>Identify the default language</source>
          <target>Identify the default language</target>
        </segment>
      </unit>
      <unit id="119">
        <segment state="initial">
          <source>A speech recognizer uses the system speech language as its default recognition language.</source>
          <target>A speech recognizer uses the system speech language as its default recognition language.</target>
        </segment>
      </unit>
      <unit id="120">
        <originalData>
          <data id="id1">&amp;gt;</data>
          <data id="id2">&amp;gt;</data>
          <data id="id3">&amp;gt;</data>
        </originalData>
        <segment state="initial">
          <source>This language is set by the user on the device Settings <ph dataRef="id1" id="ph1" /> System <ph dataRef="id2" id="ph2" /> Speech <ph dataRef="id3" id="ph3" /> Speech Language screen.</source>
          <target>This language is set by the user on the device Settings <ph dataRef="id1" id="ph1" /> System <ph dataRef="id2" id="ph2" /> Speech <ph dataRef="id3" id="ph3" /> Speech Language screen.</target>
        </segment>
      </unit>
      <unit id="121">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn653252)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source>We identify the default language by checking the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SystemSpeechLanguage</pc></pc> static property.</source>
          <target>We identify the default language by checking the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SystemSpeechLanguage</pc></pc> static property.</target>
        </segment>
      </unit>
      <unit id="122">
        <segment state="initial">
          <source>Confirm an installed language</source>
          <target>Confirm an installed language</target>
        </segment>
      </unit>
      <unit id="123">
        <segment state="initial">
          <source>Installed languages can vary between devices.</source>
          <target>Installed languages can vary between devices.</target>
        </segment>
      </unit>
      <unit id="124">
        <segment state="initial">
          <source>You should verify the existence of a language if you depend on it for a particular constraint.</source>
          <target>You should verify the existence of a language if you depend on it for a particular constraint.</target>
        </segment>
      </unit>
      <unit id="125">
        <originalData>
          <data id="id1">**</data>
          <data id="id2">**</data>
        </originalData>
        <segment state="initial">
          <source>
            <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>  A reboot is required after a new language pack is installed.</source>
          <target>
            <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Note</pc>  A reboot is required after a new language pack is installed.</target>
        </segment>
      </unit>
      <unit id="126">
        <originalData>
          <data id="id1">\_</data>
          <data id="id2">\_</data>
        </originalData>
        <segment state="initial">
          <source>An exception with error code SPERR<ph dataRef="id1" id="ph1" />NOT<ph dataRef="id2" id="ph2" />FOUND (0x8004503a) is raised if the specified language is not supported or has not finished installing.</source>
          <target>An exception with error code SPERR<ph dataRef="id1" id="ph1" />NOT<ph dataRef="id2" id="ph2" />FOUND (0x8004503a) is raised if the specified language is not supported or has not finished installing.</target>
        </segment>
      </unit>
      <unit id="127">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn653226)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source>Determine the supported languages on a device by checking one of two static properties of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognizer</pc></pc> class:</source>
          <target>Determine the supported languages on a device by checking one of two static properties of the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognizer</pc></pc> class:</target>
        </segment>
      </unit>
      <unit id="128">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn653251)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/br206804)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source>
            <pc dataRefEnd="id2" dataRefStart="id1" id="p1">
              <pc dataRefEnd="id4" dataRefStart="id3" id="p2">SupportedTopicLanguages</pc>
            </pc>—The collection of <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">Language</pc></pc> objects used with predefined dictation and web search grammars.</source>
          <target>
            <pc dataRefEnd="id2" dataRefStart="id1" id="p1">
              <pc dataRefEnd="id4" dataRefStart="id3" id="p2">SupportedTopicLanguages</pc>
            </pc>—The collection of <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">Language</pc></pc> objects used with predefined dictation and web search grammars.</target>
        </segment>
      </unit>
      <unit id="129">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn653250)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/br206804)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source>
            <pc dataRefEnd="id2" dataRefStart="id1" id="p1">
              <pc dataRefEnd="id4" dataRefStart="id3" id="p2">SupportedGrammarLanguages</pc>
            </pc>—The collection of <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">Language</pc></pc> objects used with a list constraint or a Speech Recognition Grammar Specification (SRGS) file.</source>
          <target>
            <pc dataRefEnd="id2" dataRefStart="id1" id="p1">
              <pc dataRefEnd="id4" dataRefStart="id3" id="p2">SupportedGrammarLanguages</pc>
            </pc>—The collection of <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">Language</pc></pc> objects used with a list constraint or a Speech Recognition Grammar Specification (SRGS) file.</target>
        </segment>
      </unit>
      <unit id="130">
        <segment state="initial">
          <source>Specify a language</source>
          <target>Specify a language</target>
        </segment>
      </unit>
      <unit id="131">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/br206804)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn653226)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
        </originalData>
        <segment state="initial">
          <source>To specify a language, pass a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Language</pc></pc> object in the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">SpeechRecognizer</pc></pc> constructor.</source>
          <target>To specify a language, pass a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">Language</pc></pc> object in the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">SpeechRecognizer</pc></pc> constructor.</target>
        </segment>
      </unit>
      <unit id="132">
        <segment state="initial">
          <source>Here, we specify "en-US" as the recognition language.</source>
          <target>Here, we specify "en-US" as the recognition language.</target>
        </segment>
      </unit>
      <unit id="133">
        <segment state="initial">
          <source>Remarks</source>
          <target>Remarks</target>
        </segment>
      </unit>
      <unit id="134">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631446)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn653241)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
          <data id="id9">[</data>
          <data id="id10">](https://msdn.microsoft.com/library/windows/apps/dn653226)</data>
          <data id="id11">**</data>
          <data id="id12">**</data>
          <data id="id13">[</data>
          <data id="id14">](https://msdn.microsoft.com/library/windows/apps/dn653240)</data>
          <data id="id15">**</data>
          <data id="id16">**</data>
        </originalData>
        <segment state="initial">
          <source>A topic constraint can be configured by adding a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognitionTopicConstraint</pc></pc> to the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">Constraints</pc></pc> collection of the <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">SpeechRecognizer</pc></pc> and then calling <pc dataRefEnd="id14" dataRefStart="id13" id="p7"><pc dataRefEnd="id16" dataRefStart="id15" id="p8">CompileConstraintsAsync</pc></pc>.</source>
          <target>A topic constraint can be configured by adding a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognitionTopicConstraint</pc></pc> to the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">Constraints</pc></pc> collection of the <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">SpeechRecognizer</pc></pc> and then calling <pc dataRefEnd="id14" dataRefStart="id13" id="p7"><pc dataRefEnd="id16" dataRefStart="id15" id="p8">CompileConstraintsAsync</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="135">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631433)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">**</data>
          <data id="id6">**</data>
        </originalData>
        <segment state="initial">
          <source>A <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognitionResultStatus</pc></pc> of <pc dataRefEnd="id6" dataRefStart="id5" id="p3">TopicLanguageNotSupported</pc> is returned if the recognizer is not initialized with a supported topic language.</source>
          <target>A <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognitionResultStatus</pc></pc> of <pc dataRefEnd="id6" dataRefStart="id5" id="p3">TopicLanguageNotSupported</pc> is returned if the recognizer is not initialized with a supported topic language.</target>
        </segment>
      </unit>
      <unit id="136">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631421)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn653241)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
          <data id="id9">[</data>
          <data id="id10">](https://msdn.microsoft.com/library/windows/apps/dn653226)</data>
          <data id="id11">**</data>
          <data id="id12">**</data>
          <data id="id13">[</data>
          <data id="id14">](https://msdn.microsoft.com/library/windows/apps/dn653240)</data>
          <data id="id15">**</data>
          <data id="id16">**</data>
        </originalData>
        <segment state="initial">
          <source>A list constraint is configured by adding a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognitionListConstraint</pc></pc> to the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">Constraints</pc></pc> collection of the <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">SpeechRecognizer</pc></pc> and then calling <pc dataRefEnd="id14" dataRefStart="id13" id="p7"><pc dataRefEnd="id16" dataRefStart="id15" id="p8">CompileConstraintsAsync</pc></pc>.</source>
          <target>A list constraint is configured by adding a <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognitionListConstraint</pc></pc> to the <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">Constraints</pc></pc> collection of the <pc dataRefEnd="id10" dataRefStart="id9" id="p5"><pc dataRefEnd="id12" dataRefStart="id11" id="p6">SpeechRecognizer</pc></pc> and then calling <pc dataRefEnd="id14" dataRefStart="id13" id="p7"><pc dataRefEnd="id16" dataRefStart="id15" id="p8">CompileConstraintsAsync</pc></pc>.</target>
        </segment>
      </unit>
      <unit id="137">
        <segment state="initial">
          <source>You cannot specify the language of a custom list directly.</source>
          <target>You cannot specify the language of a custom list directly.</target>
        </segment>
      </unit>
      <unit id="138">
        <segment state="initial">
          <source>Instead, the list will be processed using the language of the recognizer.</source>
          <target>Instead, the list will be processed using the language of the recognizer.</target>
        </segment>
      </unit>
      <unit id="139">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn631412)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
        </originalData>
        <segment state="initial">
          <source>An SRGS grammar is an open-standard XML format represented by the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognitionGrammarFileConstraint</pc></pc> class.</source>
          <target>An SRGS grammar is an open-standard XML format represented by the <pc dataRefEnd="id2" dataRefStart="id1" id="p1"><pc dataRefEnd="id4" dataRefStart="id3" id="p2">SpeechRecognitionGrammarFileConstraint</pc></pc> class.</target>
        </segment>
      </unit>
      <unit id="140">
        <segment state="initial">
          <source>Unlike custom lists, you can specify the language of the grammar in the SRGS markup.</source>
          <target>Unlike custom lists, you can specify the language of the grammar in the SRGS markup.</target>
        </segment>
      </unit>
      <unit id="141">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn653240)</data>
          <data id="id3">**</data>
          <data id="id4">**</data>
          <data id="id5">[</data>
          <data id="id6">](https://msdn.microsoft.com/library/windows/apps/dn631433)</data>
          <data id="id7">**</data>
          <data id="id8">**</data>
          <data id="id9">**</data>
          <data id="id10">**</data>
        </originalData>
        <segment state="initial">
          <source>
            <pc dataRefEnd="id2" dataRefStart="id1" id="p1">
              <pc dataRefEnd="id4" dataRefStart="id3" id="p2">CompileConstraintsAsync</pc>
            </pc> fails with a <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">SpeechRecognitionResultStatus</pc></pc> of <pc dataRefEnd="id10" dataRefStart="id9" id="p5">TopicLanguageNotSupported</pc> if the recognizer is not initialized to the same language as the SRGS markup.</source>
          <target>
            <pc dataRefEnd="id2" dataRefStart="id1" id="p1">
              <pc dataRefEnd="id4" dataRefStart="id3" id="p2">CompileConstraintsAsync</pc>
            </pc> fails with a <pc dataRefEnd="id6" dataRefStart="id5" id="p3"><pc dataRefEnd="id8" dataRefStart="id7" id="p4">SpeechRecognitionResultStatus</pc></pc> of <pc dataRefEnd="id10" dataRefStart="id9" id="p5">TopicLanguageNotSupported</pc> if the recognizer is not initialized to the same language as the SRGS markup.</target>
        </segment>
      </unit>
      <unit id="142">
        <segment state="initial">
          <source>Related articles</source>
          <target>Related articles</target>
        </segment>
      </unit>
      <unit id="143">
        <segment state="initial">
          <source>Developers</source>
          <target>Developers</target>
        </segment>
      </unit>
      <unit id="144">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](speech-interactions.md)</data>
          <data id="id3">
          </data>
          <data id="id4">**</data>
          <data id="id5">**</data>
        </originalData>
        <segment state="initial">
          <source>
            <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Speech interactions</pc>
            <ph dataRef="id3" id="ph1" />
            <pc dataRefEnd="id5" dataRefStart="id4" id="p2">Designers</pc>
          </source>
          <target>
            <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Speech interactions</pc>
            <ph dataRef="id3" id="ph1" />
            <pc dataRefEnd="id5" dataRefStart="id4" id="p2">Designers</pc>
          </target>
        </segment>
      </unit>
      <unit id="145">
        <originalData>
          <data id="id1">[</data>
          <data id="id2">](https://msdn.microsoft.com/library/windows/apps/dn596121)</data>
          <data id="id3">
          </data>
          <data id="id4">**</data>
          <data id="id5">**</data>
        </originalData>
        <segment state="initial">
          <source>
            <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Speech design guidelines</pc>
            <ph dataRef="id3" id="ph1" />
            <pc dataRefEnd="id5" dataRefStart="id4" id="p2">Samples</pc>
          </source>
          <target>
            <pc dataRefEnd="id2" dataRefStart="id1" id="p1">Speech design guidelines</pc>
            <ph dataRef="id3" id="ph1" />
            <pc dataRefEnd="id5" dataRefStart="id4" id="p2">Samples</pc>
          </target>
        </segment>
      </unit>
      <unit id="146">
        <segment state="initial">
          <source>Speech recognition and speech synthesis sample</source>
          <target>Speech recognition and speech synthesis sample</target>
        </segment>
      </unit>
    </group>
  </file>
</xliff>