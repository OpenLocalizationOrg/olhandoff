{"nodes":[{"content":"In addition to using voice commands within Cortana to access system features, you can also extend Cortana with features and functionality from a background app using voice commands that specify an action or command to execute within the app.","pos":[47,288]},{"content":"Launch a background app with voice commands in Cortana","pos":[296,350]},{"content":"Activate a background app with voice commands through Cortana","pos":[459,520]},{"content":"In addition to using voice commands within <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> to access system features, you can also extend <bpt id=\"p2\">**</bpt>Cortana<ept id=\"p2\">**</ept> with features and functionality from your app (as a background task) using voice commands that specify an action or command to execute.","pos":[522,771]},{"content":"When an app handles a voice command in the background, it does not take focus.","pos":[772,850]},{"content":"Instead, it returns all feedback and results through the <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> canvas and the <bpt id=\"p2\">**</bpt>Cortana<ept id=\"p2\">**</ept> voice.","pos":[851,953]},{"content":"Important APIs","pos":[957,971]},{"content":"Windows.ApplicationModel.VoiceCommands","pos":[982,1020]},{"content":"VCD elements and attributes v1.2","pos":[1089,1121]},{"content":"Apps can be activated to the foreground (the app takes focus) or activated in the background (<bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> retains focus), depending on the complexity of the interaction.","pos":[1186,1355]},{"content":"For example, voice commands that require additional context or user input (such as sending a message to a specific contact) are best handled in a foreground app, while basic commands (such as listing upcoming trips) can be handled in <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> through a background app.","pos":[1356,1627]},{"pos":[1629,1827],"content":"If you want to activate an app to the foreground using voice commands, see <bpt id=\"p1\">[</bpt>Activate a foreground app with voice commands through Cortana<ept id=\"p1\">](launch-a-foreground-app-with-voice-commands-in-cortana.md)</ept>."},{"pos":[1831,2005],"content":"**Note**  \nA voice command is a single utterance with a specific intent, defined in a Voice Command Definition (VCD) file, directed at an installed app through **Cortana**.","leadings":["","> "],"nodes":[{"content":"Note","pos":[2,6]},{"content":"A voice command is a single utterance with a specific intent, defined in a Voice Command Definition (VCD) file, directed at an installed app through <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept>.","pos":[11,172]}]},{"content":"A VCD file defines one or more voice commands, each with a unique intent.","pos":[2009,2082]},{"content":"A voice command definition can vary in complexity.","pos":[2086,2136]},{"content":"It can support anything from a single, constrained utterance to a collection of more flexible, natural language utterances, all denoting the same intent.","pos":[2137,2290]},{"pos":[2292,2492],"content":"To demonstrate background app features, we'll use a trip planning and management app named <bpt id=\"p1\">**</bpt>Adventure Works<ept id=\"p1\">**</ept> from the <bpt id=\"p2\">[</bpt>Cortana voice command sample<ept id=\"p2\">](http://go.microsoft.com/fwlink/p/?LinkID=619899)</ept>."},{"pos":[2494,2583],"content":"Here's an overview of the <bpt id=\"p1\">**</bpt>Adventure Works<ept id=\"p1\">**</ept> app integrated with the <bpt id=\"p2\">**</bpt>Cortana<ept id=\"p2\">**</ept> canvas."},{"content":"cortana canvas overview","pos":[2587,2610]},{"pos":[2643,2772],"content":"To view an <bpt id=\"p1\">**</bpt>Adventure Works<ept id=\"p1\">**</ept> trip without <bpt id=\"p2\">**</bpt>Cortana<ept id=\"p2\">**</ept>, a user would launch the app and navigate to the <bpt id=\"p3\">**</bpt>Upcoming trips<ept id=\"p3\">**</ept> page."},{"content":"Using voice commands through <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> to launch your app in the background, the user can instead just say, \"Adventure Works, when is my trip to Las Vegas?\".","pos":[2774,2933]},{"content":"Your app handles the command and <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> displays results along with your app icon and other app info, if provided.","pos":[2934,3053]},{"content":"Here's an example of a basic trip query and <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> result screen that both shows and speaks \"Your next trip to Las Vegas is on Friday July 31st, 2015\".","pos":[3054,3210]},{"content":"a basic query and result screen using the adventure works app in the background","pos":[3214,3293]},{"pos":[3337,3496],"content":"These are the basic steps to add voice-command functionality and extend <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> with background functionality from your app using speech or keyboard input:"},{"pos":[3502,3673],"content":"Create an app service (see <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Windows.ApplicationModel.AppService<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn921731)</ept>) that <bpt id=\"p3\">**</bpt>Cortana<ept id=\"p3\">**</ept> invokes in the background."},{"content":"Create a VCD file.","pos":[3678,3696]},{"content":"This is an XML document that defines all the spoken commands that the user can say to initiate actions or invoke commands when activating your app.","pos":[3697,3844]},{"content":"See <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VCD elements and attributes v1.2<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn706593)</ept>.","pos":[3845,3946]},{"content":"Register the command sets in the VCD file when the app is launched.","pos":[3951,4018]},{"content":"Handle the background activation of the app service and the execution of the voice command.","pos":[4023,4114]},{"pos":[4119,4202],"content":"Display and speak the appropriate feedback to the voice command within <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept>."},{"content":"Prerequisites:","pos":[4206,4220]},{"content":"If you're new to developing Universal Windows Platform (UWP) apps, have a look through these topics to get familiar with the technologies discussed here.","pos":[4226,4379]},{"content":"Create your first app","pos":[4386,4407]},{"pos":[4471,4588],"content":"Learn about events with <bpt id=\"p1\">[</bpt>Events and routed events overview<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/mt185584)</ept>"},{"content":"User experience guidelines:","pos":[4592,4619]},{"pos":[4625,4933],"content":"See <bpt id=\"p1\">[</bpt>Cortana design guidelines<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974233)</ept> for info about how to integrate your app with <bpt id=\"p2\">**</bpt>Cortana<ept id=\"p2\">**</ept> and <bpt id=\"p3\">[</bpt>Speech design guidelines<ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn596121)</ept> for helpful tips on designing a useful and engaging speech-enabled app."},{"pos":[5178,5239],"content":"Create a new solution with a primary project in Visual Studio"},{"content":"Launch Microsoft Visual Studio 2015.","pos":[5246,5282]},{"content":"The Visual Studio 2015 Start page appears.","pos":[5288,5330]},{"pos":[5336,5387],"content":"On the <bpt id=\"p1\">**</bpt>File<ept id=\"p1\">**</ept> menu, select <bpt id=\"p2\">**</bpt>New<ept id=\"p2\">**</ept><ph id=\"ph1\"> &gt; </ph><bpt id=\"p3\">**</bpt>Project<ept id=\"p3\">**</ept>."},{"content":"The <bpt id=\"p1\">**</bpt>New Project<ept id=\"p1\">**</ept> dialog appears.","pos":[5393,5428]},{"content":"The left pane of the dialog lets you select the type of templates to display.","pos":[5429,5506]},{"content":"In the left pane, expand <bpt id=\"p1\">**</bpt>Installed &gt; Templates &gt; Visual C<ph id=\"ph1\">\\#</ph> &gt; Windows<ept id=\"p1\">**</ept>, then pick the <bpt id=\"p2\">**</bpt>Universal<ept id=\"p2\">**</ept> template group.","pos":[5512,5630]},{"content":"The dialog's center pane displays a list of project templates for Universal Windows Platform (UWP) apps.","pos":[5631,5735]},{"pos":[5740,5814],"content":"In the center pane, select the <bpt id=\"p1\">**</bpt>Blank App (Universal Windows)<ept id=\"p1\">**</ept> template."},{"content":"The <bpt id=\"p1\">**</bpt>Blank App<ept id=\"p1\">**</ept> template creates a minimal UWP app that compiles and runs, but contains no user-interface controls or data.","pos":[5820,5945]},{"content":"You add controls to the app over the course of this tutorial.","pos":[5946,6007]},{"content":"In the <bpt id=\"p1\">**</bpt>Name<ept id=\"p1\">**</ept> text box, type your project name.","pos":[6013,6062]},{"content":"For this example, we use \"AdventureWorks\".","pos":[6063,6105]},{"pos":[6110,6145],"content":"Click <bpt id=\"p1\">**</bpt>OK<ept id=\"p1\">**</ept> to create the project."},{"pos":[6151,6241],"content":"Microsoft Visual Studio creates your project and displays it in the <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>."},{"pos":[6520,6593],"content":"Add image assets to  primary project and specify them in the app manifest"},{"content":"UWP apps can automatically select the most appropriate images based on specific settings and device capabilities (high contrast, effective pixels, locale, and so on).","pos":[6601,6767]},{"content":"All you need to do is provide the images and ensure you use the appropriate naming convention and folder organization within the app project for the different resource versions.","pos":[6768,6945]},{"content":"If you don't provide the recommended resource versions, accessibility, localization, and image quality can suffer, depending on the user's preferences, abilities, device type, and location.","pos":[6946,7135]},{"pos":[7137,7348],"content":"For more detail on image resources for high contrast and scale factors, see <bpt id=\"p1\">[</bpt>Guidelines for tile and icon assets<ept id=\"p1\">](https://msdn.microsoft.com/windows/uwp/controls-and-patterns/tiles-and-notifications-app-assets)</ept>."},{"content":"You name resources using qualifiers.","pos":[7350,7386]},{"content":"Resource qualifiers are folder and filename modifiers that identify the context in which a particular version of a resource should be used.","pos":[7387,7526]},{"content":"The standard naming convention is <ph id=\"ph1\">`foldername/qualifiername-value[_qualifiername-value]/filename.qualifiername-value[_qualifiername-value].ext`</ph>.","pos":[7528,7672]},{"content":"For example, <ph id=\"ph1\">`images/en-US/logo.scale-100_contrast-white.png`</ph>, which can be referred to in code using just the root folder and the filename: <ph id=\"ph2\">`images/logo.png`</ph>.","pos":[7673,7832]},{"content":"See <bpt id=\"p1\">[</bpt>How to name resources using qualifiers<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/xaml/hh965324.aspx)</ept>.","pos":[7833,7946]},{"content":"We recommend that you mark the default language on string resource files (such as <ph id=\"ph1\">`en-US\\resources.resw`</ph>) and the default scale factor on images (such as <ph id=\"ph2\">`logo.scale-100.png`</ph>), even if you do not currently plan to provide localized or multiple resolution resources.","pos":[7948,8213]},{"content":"However, at a minimum, we recommend that you provide assets for 100, 200, and 400 scale factors.","pos":[8214,8310]},{"content":"*Important","pos":[8314,8324]},{"pos":[8328,8463],"content":"The app icon used in the title area of the <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> canvas is the Square44x44Logo icon specified in the \"Package.appxmanifest\" file."},{"content":"You can also specify an icon for each entry in the content area of the <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> canvas.","pos":[8468,8558]},{"content":"Valid image sizes for the results icons are:","pos":[8559,8603]},{"content":"68w x 68h","pos":[8609,8618]},{"content":"68w x 92h","pos":[8624,8633]},{"content":"280w x 140h","pos":[8639,8650]},{"content":"The content tile is not validated until a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VoiceCommandResponse<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974182)</ept> is passed to the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>VoiceCommandServiceConnection<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn974204)</ept>.","pos":[8653,8891]},{"content":"If you pass a <bpt id=\"p1\">**</bpt>VoiceCommandResponse<ept id=\"p1\">**</ept> object to <bpt id=\"p2\">**</bpt>Cortana<ept id=\"p2\">**</ept> that contains a content tile with an image that does not adhere to these size ratios, an exception can occur.","pos":[8892,9062]},{"content":"In this example from the <bpt id=\"p1\">**</bpt>Adventure Works<ept id=\"p1\">**</ept> app (VoiceCommandService<ph id=\"ph1\">\\\\</ph>AdventureWorksVoiceCommandService.cs), we specify a simple grey square (\"GreyTile.png\") on the <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>VoiceCommandContentTile<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn974168)</ept> using the <bpt id=\"p4\">[</bpt><bpt id=\"p5\">**</bpt>TitleWith68x68IconAndText<ept id=\"p5\">**</ept><ept id=\"p4\">](https://msdn.microsoft.com/library/windows/apps/dn974169)</ept> tile template.","pos":[9065,9433]},{"content":"The logo variants are located in VoiceCommandService<ph id=\"ph1\">\\\\</ph>Images, and are retrieved using the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>GetFileFromApplicationUriAsync<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/hh701741)</ept> method.","pos":[9434,9626]},{"pos":[10090,10119],"content":"Create an app service project"},{"content":"Right-click your Solution name, select <bpt id=\"p1\">**</bpt>New &gt; Project<ept id=\"p1\">**</ept>.","pos":[10135,10196]},{"content":"Under <bpt id=\"p1\">**</bpt>Installed &gt; Templates &gt; Visual C# &gt; Windows &gt; Universal<ept id=\"p1\">**</ept>, select <bpt id=\"p2\">**</bpt>Windows Runtime Component<ept id=\"p2\">**</ept>.","pos":[10216,10324]},{"content":"This is the component that implements the app service (<bpt id=\"p1\">**</bpt><bpt id=\"p2\">[</bpt>Windows.ApplicationModel.AppService<ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn921731)</ept><ept id=\"p1\">**</ept>).","pos":[10325,10481]},{"content":"Type a name for the project (for example, \"VoiceCommandService\") and click <bpt id=\"p1\">**</bpt>OK<ept id=\"p1\">**</ept>.","pos":[10501,10587]},{"content":"In <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>, select the \"VoiceCommandService\" project and rename the \"Class1.cs\" file generated by Visual Studio.","pos":[10607,10737]},{"content":"For the <bpt id=\"p1\">**</bpt>Adventure Works<ept id=\"p1\">**</ept> example we use \"AdventureWorksVoiceCommandService.cs\".","pos":[10738,10820]},{"content":"Click <bpt id=\"p1\">**</bpt>Yes<ept id=\"p1\">**</ept> when asked if you want to rename all occurrences of \"Class1.cs\".","pos":[10840,10922]},{"content":"In the \"AdventureWorksVoiceCommandService.cs\" file:","pos":[10943,11006]},{"content":"Add the following using directive.","pos":[11027,11062]},{"content":"When you create a new project, the project name is used as the default root namespace in all files.","pos":[11128,11228]},{"content":"Rename the namespace to nest the app service code under the primary project.","pos":[11229,11305]},{"content":"For example, <ph id=\"ph1\">`namespace AdventureWorks.VoiceCommands`</ph>.","pos":[11306,11360]},{"content":"Right click the app service project name in Solution Explorer and select <bpt id=\"p1\">**</bpt>Properties<ept id=\"p1\">**</ept>.","pos":[11375,11464]},{"content":"On the <bpt id=\"p1\">**</bpt>Library<ept id=\"p1\">**</ept> tab, update the <bpt id=\"p2\">**</bpt>Default namespace<ept id=\"p2\">**</ept> field with this same value (for this example, \"AdventureWorks.VoiceCommands\").","pos":[11479,11615]},{"content":"Create a new class that implements the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IBackgroundTask<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br224794)</ept> interface.","pos":[11630,11760]},{"content":"This class requires a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Run<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br224811)</ept> method, which is the entry point when Cortana recognizes the voice command.","pos":[11761,11926]},{"content":"Here's a basic background task class from the <bpt id=\"p1\">**</bpt>Adventure Works<ept id=\"p1\">**</ept> app.","pos":[11966,12036]},{"content":"We'll fill in more detail later.","pos":[12037,12069]},{"pos":[12072,12208],"content":"**Note**    \nThe background task class itself, and all other classes in the background task project, need to be sealed public classes.","leadings":["","> "],"nodes":[{"content":"Note","pos":[2,6]},{"content":"The background task class itself, and all other classes in the background task project, need to be sealed public classes.","pos":[13,134]}]},{"content":"Declare your background task as an <bpt id=\"p1\">**</bpt>AppService<ept id=\"p1\">**</ept> in the app manifest.","pos":[14138,14212]},{"content":"In <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>, right click the \"Package.appxmanifest\" file and select <bpt id=\"p2\">**</bpt>View Code<ept id=\"p2\">**</ept>.","pos":[14244,14347]},{"content":"Find the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Application<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn934738)</ept> element.","pos":[14376,14477]},{"content":"Add an <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Extensions<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn934720)</ept> element to the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>Application<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn934738)</ept> element.","pos":[14505,14694]},{"content":"Add a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>uap:Extension<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn986788)</ept> element to the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>Extensions<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn934720)</ept> element.","pos":[14722,14912]},{"content":"Add a <bpt id=\"p1\">**</bpt>Category<ept id=\"p1\">**</ept> attribute to the <bpt id=\"p2\">**</bpt>uap:Extension<ept id=\"p2\">**</ept> element and set the value of the <bpt id=\"p3\">**</bpt>Category<ept id=\"p3\">**</ept> attribute to \"windows.appService\".","pos":[14939,15073]},{"content":"Add an <bpt id=\"p1\">**</bpt>EntryPoint<ept id=\"p1\">**</ept> attribute to the <bpt id=\"p2\">**</bpt>uap:Extension<ept id=\"p2\">**</ept> element and set the value of the <bpt id=\"p3\">**</bpt>EntryPoint<ept id=\"p3\">**</ept> attribute to the name of the class that implements <bpt id=\"p4\">[</bpt><bpt id=\"p5\">**</bpt>IBackgroundTask<ept id=\"p5\">**</ept><ept id=\"p4\">](https://msdn.microsoft.com/library/windows/apps/br224794)</ept>, in this case \"AdventureWorks.VoiceCommands.AdventureWorksVoiceCommandService\".","pos":[15101,15424]},{"content":"Add a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>uap:AppService<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn934779)</ept> element to the <bpt id=\"p3\">**</bpt>uap:Extension<ept id=\"p3\">**</ept> element.","pos":[15452,15586]},{"content":"Add a <bpt id=\"p1\">**</bpt>Name<ept id=\"p1\">**</ept> attribute to the <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>uap:AppService<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn934779)</ept> element and set the value of the <bpt id=\"p4\">**</bpt>Name<ept id=\"p4\">**</ept> attribute to a name for the app service, in this case \"AdventureWorksVoiceCommandService\".","pos":[15614,15865]},{"content":"Add a second <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>uap:Extension<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn986788)</ept> element to <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>Extensions<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn934720)</ept>.","pos":[15893,16078]},{"content":"Add a <bpt id=\"p1\">**</bpt>Category<ept id=\"p1\">**</ept> attribute to this <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>uap:Extension<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn986788)</ept> element and set the value of the <bpt id=\"p4\">**</bpt>Category<ept id=\"p4\">**</ept> attribute to \"windows.personalAssistantLaunch\".","pos":[16106,16322]},{"content":"Here's the manifest from the Adventure Works app:","pos":[16381,16430]},{"content":"Add this app service project as a reference in the primary project.","pos":[16896,16967]},{"content":"Right click <bpt id=\"p1\">**</bpt>References<ept id=\"p1\">**</ept>.","pos":[17000,17035]},{"content":"Select <bpt id=\"p1\">**</bpt>Add Reference...<ept id=\"p1\">**</ept>","pos":[17064,17099]},{"content":"In the <bpt id=\"p1\">**</bpt>Reference Manager<ept id=\"p1\">**</ept> dialog, expand <bpt id=\"p2\">**</bpt>Projects<ept id=\"p2\">**</ept> and select the app service project.","pos":[17128,17228]},{"content":"Click OK.","pos":[17257,17274]},{"pos":[17428,17445],"content":"Create a VCD file"},{"content":"In Visual Studio, right-click your primary project name, select <bpt id=\"p1\">**</bpt>Add &gt; New Item<ept id=\"p1\">**</ept>.","pos":[17451,17534]},{"content":"Add an <bpt id=\"p1\">**</bpt>XML File<ept id=\"p1\">**</ept>.","pos":[17535,17555]},{"pos":[17559,17716],"content":"Type a name for the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VCD<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn706593)</ept> file (for this example, \"AdventureWorksCommands.xml\"), and click Add."},{"pos":[17721,17831],"content":"In <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>, select the <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>VCD<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn706593)</ept> file."},{"pos":[17836,17966],"content":"In the <bpt id=\"p1\">**</bpt>Properties<ept id=\"p1\">**</ept> window, set <bpt id=\"p2\">**</bpt>Build action<ept id=\"p2\">**</ept> to <bpt id=\"p3\">**</bpt>Content<ept id=\"p3\">**</ept>, and then set <bpt id=\"p4\">**</bpt>Copy to output directory<ept id=\"p4\">**</ept> to <bpt id=\"p5\">**</bpt>Copy if newer<ept id=\"p5\">**</ept>."},{"pos":[18079,18096],"content":"Edit the VCD file"},{"pos":[18101,18222],"content":"Add a <bpt id=\"p1\">**</bpt>VoiceCommands<ept id=\"p1\">**</ept> element with an <bpt id=\"p2\">**</bpt>xmlns<ept id=\"p2\">**</ept> attribute pointing to <ph id=\"ph1\">`http://schemas.microsoft.com/voicecommands/1.2`</ph>."},{"pos":[18227,18415],"content":"For each language supported by your app, create a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>CommandSet<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn722331)</ept> element that contains the voice commands supported by your app."},{"content":"You can declare multiple <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>CommandSet<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn722331)</ept> elements, each with a different <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>xml:lang<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn722331)</ept> attribute so your app to be used in different markets.","pos":[18419,18678]},{"content":"For example, an app for the United States might have a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>CommandSet<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn722331)</ept> for English and a <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>CommandSet<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn722331)</ept> for Spanish.","pos":[18679,18914]},{"content":"Caution","pos":[18923,18930]},{"content":"To activate an app and initiate an action using a voice command, the app must register a VCD file that contains a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>CommandSet<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn722331)</ept> with a language that matches the speech language selected by the user for their device.","pos":[18937,19213]},{"content":"The speech language is located in <bpt id=\"p1\">**</bpt>Settings &gt; System &gt; Speech &gt; Speech Language<ept id=\"p1\">**</ept>.","pos":[19214,19297]},{"pos":[19302,19365],"content":"Add a <bpt id=\"p1\">**</bpt>Command<ept id=\"p1\">**</ept> element for each command you want to support."},{"pos":[19369,19503],"content":"Each <bpt id=\"p1\">**</bpt>Command<ept id=\"p1\">**</ept> declared in a <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>VCD<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn706593)</ept> file must include this information:"},{"pos":[19509,19598],"content":"A <bpt id=\"p1\">**</bpt>Name<ept id=\"p1\">**</ept> attribute that your application uses to identify the voice command at runtime."},{"content":"An <bpt id=\"p1\">**</bpt>Example<ept id=\"p1\">**</ept> element that contains a phrase describing how a user can invoke the command.","pos":[19604,19695]},{"content":"<bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> shows this example when the user says \"What can I say?\", \"Help\", or they tap <bpt id=\"p2\">**</bpt>See more<ept id=\"p2\">**</ept>.","pos":[19696,19798]},{"content":"A <bpt id=\"p1\">**</bpt>ListenFor<ept id=\"p1\">**</ept> element that contains the words or phrases that your app recognizes as a command.","pos":[19809,19906]},{"content":"Each <bpt id=\"p1\">**</bpt>ListenFor<ept id=\"p1\">**</ept> element can contain references to one or more <bpt id=\"p2\">**</bpt>PhraseList<ept id=\"p2\">**</ept> elements that contain specific words relevant to the command.","pos":[19907,20048]},{"content":"Note","pos":[20055,20059]},{"content":"<bpt id=\"p1\">  **</bpt>ListenFor<ept id=\"p1\">**</ept> elements cannot be programmatically modified.","pos":[20064,20125]},{"content":"However, <bpt id=\"p1\">**</bpt>PhraseList<ept id=\"p1\">**</ept> elements associated with <bpt id=\"p2\">**</bpt>ListenFor<ept id=\"p2\">**</ept> elements can be programmatically modified.","pos":[20126,20231]},{"content":"Applications should modify the content of the <bpt id=\"p1\">**</bpt>PhraseList<ept id=\"p1\">**</ept> at runtime based on the data set generated as the user uses the app.","pos":[20232,20361]},{"content":"See <bpt id=\"p1\">[</bpt>Dynamically modify Voice Command Definition (VCD) phrase lists<ept id=\"p1\">](dynamically-modify-voice-command-definition--vcd--phrase-lists.md)</ept>.","pos":[20362,20498]},{"pos":[20506,20620],"content":"A <bpt id=\"p1\">**</bpt>Feedback<ept id=\"p1\">**</ept> element that contains the text for <bpt id=\"p2\">**</bpt>Cortana<ept id=\"p2\">**</ept> to display and speak as the application is launched."},{"content":"A <bpt id=\"p1\">**</bpt>Navigate<ept id=\"p1\">**</ept> element indicates that the voice command activates the app to the foreground.","pos":[20622,20714]},{"content":"In this example, the <ph id=\"ph1\">```showTripToDestination```</ph> command is a foreground task.","pos":[20715,20793]},{"content":"A <bpt id=\"p1\">**</bpt>VoiceCommandService<ept id=\"p1\">**</ept> element indicates that the voice command activates the app in the background.","pos":[20795,20898]},{"content":"The value of the <bpt id=\"p1\">**</bpt>Target<ept id=\"p1\">**</ept> attribute of this element should match the value of the <bpt id=\"p2\">**</bpt>Name<ept id=\"p2\">**</ept> attribute of the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>uap:AppService<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn934779)</ept> element in the package.appxmanifest file.","pos":[20899,21129]},{"content":"In this example, the <ph id=\"ph1\">```whenIsTripToDestination```</ph> and <ph id=\"ph2\">```cancelTripToDestination```</ph> commands are background tasks that specify the name of the app service as \"AdventureWorksVoiceCommandService\".","pos":[21130,21325]},{"pos":[21327,21459],"content":"For more detail, see the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VCD elements and attributes v1.2<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn706593)</ept> reference."},{"pos":[21461,21628],"content":"Here's a portion of the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VCD<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn706593)</ept> file that defines the en-us voice commands for the <bpt id=\"p3\">**</bpt>Adventure Works<ept id=\"p3\">**</ept> app."},{"pos":[23589,23613],"content":"Install the VCD commands"},{"content":"Your app must run once to install the VCD.","pos":[23615,23657]},{"content":"Note","pos":[23665,23669]},{"content":"Voice command data is not preserved across app installations.","pos":[23674,23735]},{"content":"To ensure the voice command data for your app remains intact, consider initializing your VCD file each time your app is launched or activated, or maintain a setting that indicates if the VCD is currently installed.","pos":[23736,23950]},{"content":"In the \"app.xaml.cs\" file:","pos":[23952,23978]},{"content":"Add the following using directive:","pos":[23983,24017]},{"content":"Mark the \"OnLaunched\" method with the async modifier.","pos":[24060,24113]},{"pos":[24202,24471],"content":"Call <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>InstallCommandDefinitionsFromStorageFileAsync<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn708205)</ept> in the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>OnLaunched<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br242335)</ept> handler to register the voice commands that the system should recognize."},{"pos":[24475,24607],"content":"In the Adventure Works sample, we first define a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>StorageFile<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br227171)</ept> object."},{"pos":[24612,24762],"content":"We then call <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>GetFileAsync<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br227272)</ept> to initialize it with our \"AdventureWorksCommands.xml\" file."},{"pos":[24766,24982],"content":"This <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>StorageFile<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br227171)</ept> object is then passed to <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>InstallCommandDefinitionsFromStorageFileAsync<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn708205)</ept>."},{"pos":[25853,25870],"content":"Handle activation"},{"content":"Specify how your app responds to subsequent voice command activations (after it has been launched at least once and the voice command sets have been installed).","pos":[25872,26032]},{"content":"Confirm that your app was activated by a voice command.","pos":[26038,26093]},{"pos":[26099,26457],"content":"Override the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Application.OnActivated<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br242330)</ept> event and check whether <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>IActivatedEventArgs<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br224727)</ept>.<bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>Kind<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/br224728)</ept> is <bpt id=\"p7\">[</bpt><bpt id=\"p8\">**</bpt>VoiceCommand<ept id=\"p8\">**</ept><ept id=\"p7\">](https://msdn.microsoft.com/library/windows/apps/br224693)</ept>."},{"content":"Determine the name of the command and what was spoken.","pos":[26463,26517]},{"pos":[26523,26934],"content":"Get a reference to a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VoiceCommandActivatedEventArgs<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn609755)</ept> object from the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>IActivatedEventArgs<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br224727)</ept> and query the <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>Result<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/dn609758)</ept> property for a <bpt id=\"p7\">[</bpt><bpt id=\"p8\">**</bpt>SpeechRecognitionResult<ept id=\"p8\">**</ept><ept id=\"p7\">](https://msdn.microsoft.com/library/windows/apps/dn631432)</ept> object."},{"pos":[26940,27235],"content":"To determine what the user said, check the value of <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Text<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn631441)</ept> or the semantic properties of the recognized phrase in the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>SpeechRecognitionSemanticInterpretation<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn631443)</ept> dictionary."},{"content":"Take the appropriate action in your app, such as navigating to the desired page.","pos":[27241,27321]},{"content":"For this example, we refer back to the VCD in Step 3: Edit the VCD file.","pos":[27323,27395]},{"content":"Once we get the speech-recognition result for the voice command, we get the command name from the first value in the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>RulePath<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn631438)</ept> array.","pos":[27397,27593]},{"content":"As the VCD file defined more than one possible voice command, we need to compare the value against the command names in the VCD and take the appropriate action.","pos":[27594,27754]},{"content":"The most common action an application can take is to navigate to a page with content relevant to the context of the voice command.","pos":[27756,27886]},{"content":"For this example, we navigate to a <bpt id=\"p1\">**</bpt>TripPage<ept id=\"p1\">**</ept> page and pass in the value of the voice command, how the command was input, and the recognized \"destination\" phrase (if applicable).","pos":[27887,28067]},{"content":"Alternatively, the app could send a navigation parameter to the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SpeechRecognitionResult<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn631432)</ept> when navigating to the page.","pos":[28068,28248]},{"content":"You can find out whether the voice command that launched your app was actually spoken, or whether it was typed in as text, from the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SpeechRecognitionSemanticInterpretation.Properties<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn631445)</ept> dictionary using the <bpt id=\"p3\">**</bpt>commandMode<ept id=\"p3\">**</ept> key.","pos":[28250,28538]},{"content":"The value of that key will be either \"voice\" or \"text\".","pos":[28539,28594]},{"content":"If the value of the key is \"voice\", consider using speech synthesis (<bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Windows.Media.SpeechSynthesis<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn278951)</ept>) in your app to provide the user with spoken feedback.","pos":[28595,28812]},{"content":"Use the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SpeechRecognitionSemanticInterpretation.Properties<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn631445)</ept> to find out the content spoken in the <bpt id=\"p3\">**</bpt>PhraseList<ept id=\"p3\">**</ept> or <bpt id=\"p4\">**</bpt>PhraseTopic<ept id=\"p4\">**</ept> constraints of a <bpt id=\"p5\">**</bpt>ListenFor<ept id=\"p5\">**</ept> element.","pos":[28814,29048]},{"content":"The dictionary key is the value of the <bpt id=\"p1\">**</bpt>Label<ept id=\"p1\">**</ept> attribute of the <bpt id=\"p2\">**</bpt>PhraseList<ept id=\"p2\">**</ept> or <bpt id=\"p3\">**</bpt>PhraseTopic<ept id=\"p3\">**</ept> element.","pos":[29049,29157]},{"content":"Here, we show how to access the value of <bpt id=\"p1\">**</bpt>{destination}<ept id=\"p1\">**</ept> phrase.","pos":[29158,29224]},{"pos":[35054,35097],"content":"Handle the voice command in the app service"},{"content":"Process the voice command in the app service.","pos":[35100,35145]},{"content":"Add the following using directives to your voice command service file, \"AdventureWorksVoiceCommandService.cs\" for this example.","pos":[35152,35279]},{"content":"Take a service deferral so your app service is not terminated while handling the voice command.","pos":[35435,35530]},{"content":"Confirm that your background task is running as an app service activated by a voice command.","pos":[35535,35627]},{"pos":[35637,35877],"content":"Cast the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IBackgroundTaskInstance.TriggerDetails<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br224802)</ept> to <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>Windows.ApplicationModel.AppService.AppServiceTriggerDetails<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn921727)</ept>."},{"pos":[35886,36071],"content":"Check that <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IBackgroundTaskInstance.TriggerDetails.Name<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br224807)</ept> is the name of the app service in the \"Package.appxmanifest\" file."},{"pos":[36077,36335],"content":"Use <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IBackgroundTaskInstance.TriggerDetails<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br224802)</ept> to create a <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>VoiceCommandServiceConnection<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn974204)</ept> to <bpt id=\"p5\">**</bpt>Cortana<ept id=\"p5\">**</ept> to retrieve the voice command."},{"pos":[36340,36632],"content":"Register an event handler for <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VoiceCommandServiceConnection<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974204)</ept>.<bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>VoiceCommandCompleted<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn706584)</ept> to receive notification when the app service is closed due to a user cancellation."},{"pos":[36637,36852],"content":"Register an event handler for the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IBackgroundTaskInstance.Canceled<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br224798)</ept> to receive notification when the app service is closed due to an unexpected failure."},{"content":"Determine the name of the command and what was spoken.","pos":[36857,36911]},{"pos":[36921,37134],"content":"Use the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VoiceCommand<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974162)</ept>.<bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>CommandName<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn706589)</ept> property to determine the name of the voice command."},{"pos":[37143,37438],"content":"To determine what the user said, check the value of <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Text<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn631441)</ept> or the semantic properties of the recognized phrase in the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>SpeechRecognitionSemanticInterpretation<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/dn631443)</ept> dictionary."},{"content":"Take the appropriate action in your app service.","pos":[37444,37492]},{"pos":[37497,37566],"content":"Display and speak the feedback to the voice command with <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept>."},{"content":"Determine the strings that you want <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> to display and speak to the user in response to the voice command and create a <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>VoiceCommandResponse<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn974182)</ept> object.","pos":[37576,37795]},{"content":"For guidance on how to select the feedback strings that <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> shows and speaks, see <bpt id=\"p2\">[</bpt>Cortana design guidelines<ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn974233)</ept>.","pos":[37796,37972]},{"pos":[37981,38371],"content":"Use the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>VoiceCommandServiceConnection<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn974204)</ept> instance to report progress or completion to <bpt id=\"p3\">**</bpt>Cortana<ept id=\"p3\">**</ept> by calling <bpt id=\"p4\">[</bpt><bpt id=\"p5\">**</bpt>ReportProgressAsync<ept id=\"p5\">**</ept><ept id=\"p4\">](https://msdn.microsoft.com/library/windows/apps/dn706579)</ept> or <bpt id=\"p6\">[</bpt><bpt id=\"p7\">**</bpt>ReportSuccessAsync<ept id=\"p7\">**</ept><ept id=\"p6\">](https://msdn.microsoft.com/library/windows/apps/dn706580)</ept> with the <bpt id=\"p8\">**</bpt>VoiceCommandServiceConnection<ept id=\"p8\">**</ept> object."},{"content":"For this example, we refer back to the VCD in Step 3: Edit the VCD file.","pos":[38377,38449]},{"content":"Once activated, the app service has .5 seconds to call <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ReportSuccessAsync<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/dn706580)</ept>.","pos":[43063,43201]},{"content":"<bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> uses the data provided by the app to show and say the feedback specified in the VCD file.","pos":[43202,43303]},{"content":"If the app takes longer than .5 seconds to make the call, <bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> inserts a hand-off screen, as shown here.","pos":[43304,43415]},{"content":"<bpt id=\"p1\">**</bpt>Cortana<ept id=\"p1\">**</ept> displays the hand-off screen until the application calls <bpt id=\"p2\">**</bpt>ReportSuccessAsync<ept id=\"p2\">**</ept>, or for up to 5 seconds.","pos":[43416,43532]},{"content":"If the app service doesnâ€™t call <bpt id=\"p1\">**</bpt>ReportSuccessAsync<ept id=\"p1\">**</ept>, or any of the <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>VoiceCommandServiceConnection<ept id=\"p3\">**</ept><ept id=\"p2\">](https://msdn.microsoft.com/library/windows/apps/dn974204)</ept> methods that provide <bpt id=\"p4\">**</bpt>Cortana<ept id=\"p4\">**</ept> with information, the user receives an error message and the app service is cancelled.","pos":[43533,43816]},{"content":"a basic query with progress and result screens using the adventure works app in the background","pos":[43820,43914]},{"pos":[44003,44019],"content":"Related articles"},{"content":"Developers","pos":[44024,44034]},{"content":"Cortana interactions","pos":[44040,44060]},{"content":"Define custom recognition constraints","pos":[44090,44127]},{"content":"Interact with a background app in Cortana","pos":[44174,44215]},{"content":"VCD elements and attributes v1.2","pos":[44268,44300]},{"content":"Quickstart: Using file or image resources","pos":[44365,44406]},{"content":"How to name resources using qualifiers","pos":[44474,44512]},{"content":"Designers","pos":[44580,44589]},{"content":"Cortana design guidelines","pos":[44595,44620]},{"content":"Speech design guidelines","pos":[44683,44707]},{"content":"Responsive design 101 for UWP apps","pos":[44770,44804]},{"content":"Guidelines for tile and icon assets","pos":[44867,44902]},{"content":"Samples","pos":[44965,44972]},{"content":"Cortana voice command sample","pos":[44978,45006]}],"content":"---\nauthor: Karl-Bridge-Microsoft\nDescription: In addition to using voice commands within Cortana to access system features, you can also extend Cortana with features and functionality from a background app using voice commands that specify an action or command to execute within the app.\ntitle: Launch a background app with voice commands in Cortana\nms.assetid: DF5B530C-57DD-4CA5-B3BE-1A0B3695C9C6\nlabel: Launch a background app\ntemplate: detail.hbs\n---\n\n# Activate a background app with voice commands through Cortana\n\nIn addition to using voice commands within **Cortana** to access system features, you can also extend **Cortana** with features and functionality from your app (as a background task) using voice commands that specify an action or command to execute. When an app handles a voice command in the background, it does not take focus. Instead, it returns all feedback and results through the **Cortana** canvas and the **Cortana** voice.\n\n**Important APIs**\n\n-   [**Windows.ApplicationModel.VoiceCommands**](https://msdn.microsoft.com/library/windows/apps/dn706594)\n-   [**VCD elements and attributes v1.2**](https://msdn.microsoft.com/library/windows/apps/dn706593)\n\n\n\nApps can be activated to the foreground (the app takes focus) or activated in the background (**Cortana** retains focus), depending on the complexity of the interaction. For example, voice commands that require additional context or user input (such as sending a message to a specific contact) are best handled in a foreground app, while basic commands (such as listing upcoming trips) can be handled in **Cortana** through a background app.\n\nIf you want to activate an app to the foreground using voice commands, see [Activate a foreground app with voice commands through Cortana](launch-a-foreground-app-with-voice-commands-in-cortana.md).\n\n> **Note**  \n> A voice command is a single utterance with a specific intent, defined in a Voice Command Definition (VCD) file, directed at an installed app through **Cortana**.\n\n> A VCD file defines one or more voice commands, each with a unique intent.\n\n> A voice command definition can vary in complexity. It can support anything from a single, constrained utterance to a collection of more flexible, natural language utterances, all denoting the same intent.\n\nTo demonstrate background app features, we'll use a trip planning and management app named **Adventure Works** from the [Cortana voice command sample](http://go.microsoft.com/fwlink/p/?LinkID=619899).\n\nHere's an overview of the **Adventure Works** app integrated with the **Cortana** canvas.\n\n![cortana canvas overview ](images/cortana-overview.png)\n\nTo view an **Adventure Works** trip without **Cortana**, a user would launch the app and navigate to the **Upcoming trips** page.\n\nUsing voice commands through **Cortana** to launch your app in the background, the user can instead just say, \"Adventure Works, when is my trip to Las Vegas?\". Your app handles the command and **Cortana** displays results along with your app icon and other app info, if provided. Here's an example of a basic trip query and **Cortana** result screen that both shows and speaks \"Your next trip to Las Vegas is on Friday July 31st, 2015\".\n\n![a basic query and result screen using the adventure works app in the background](images/cortana-backgroundapp-result.png)\n\nThese are the basic steps to add voice-command functionality and extend **Cortana** with background functionality from your app using speech or keyboard input:\n\n1.  Create an app service (see [**Windows.ApplicationModel.AppService**](https://msdn.microsoft.com/library/windows/apps/dn921731)) that **Cortana** invokes in the background.\n2.  Create a VCD file. This is an XML document that defines all the spoken commands that the user can say to initiate actions or invoke commands when activating your app. See [**VCD elements and attributes v1.2**](https://msdn.microsoft.com/library/windows/apps/dn706593).\n3.  Register the command sets in the VCD file when the app is launched.\n4.  Handle the background activation of the app service and the execution of the voice command.\n5.  Display and speak the appropriate feedback to the voice command within **Cortana**.\n\n**Prerequisites:  **\n\nIf you're new to developing Universal Windows Platform (UWP) apps, have a look through these topics to get familiar with the technologies discussed here.\n\n-   [Create your first app](https://msdn.microsoft.com/library/windows/apps/bg124288)\n-   Learn about events with [Events and routed events overview](https://msdn.microsoft.com/library/windows/apps/mt185584)\n\n**User experience guidelines:  **\n\nSee [Cortana design guidelines](https://msdn.microsoft.com/library/windows/apps/dn974233) for info about how to integrate your app with **Cortana** and [Speech design guidelines](https://msdn.microsoft.com/library/windows/apps/dn596121) for helpful tips on designing a useful and engaging speech-enabled app.\n\n## <span id=\"Create_a_new_solution_with_a_primary_project_in_Visual_Studio\"></span><span id=\"create_a_new_solution_with_a_primary_project_in_visual_studio\"></span><span id=\"CREATE_A_NEW_SOLUTION_WITH_A_PRIMARY_PROJECT_IN_VISUAL_STUDIO\"></span>Create a new solution with a primary project in Visual Studio\n\n\n1.  Launch Microsoft Visual Studio 2015.\n\n    The Visual Studio 2015 Start page appears.\n\n2.  On the **File** menu, select **New** > **Project**.\n\n    The **New Project** dialog appears. The left pane of the dialog lets you select the type of templates to display.\n\n3.  In the left pane, expand **Installed > Templates > Visual C\\# > Windows**, then pick the **Universal** template group. The dialog's center pane displays a list of project templates for Universal Windows Platform (UWP) apps.\n4.  In the center pane, select the **Blank App (Universal Windows)** template.\n\n    The **Blank App** template creates a minimal UWP app that compiles and runs, but contains no user-interface controls or data. You add controls to the app over the course of this tutorial.\n\n5.  In the **Name** text box, type your project name. For this example, we use \"AdventureWorks\".\n6.  Click **OK** to create the project.\n\n    Microsoft Visual Studio creates your project and displays it in the **Solution Explorer**.\n\n\n## <span id=\"Add_image_assets_to_primary_project_and_specify_them_in_the_app_manifest\"></span><span id=\"add_image_assets_to_primary_project_and_specify_them_in_the_app_manifest\"></span><span id=\"ADD_IMAGE_ASSETS_TO_PRIMARY_PROJECT_AND_SPECIFY_THEM_IN_THE_APP_MANIFEST\"></span>Add image assets to  primary project and specify them in the app manifest\n      \nUWP apps can automatically select the most appropriate images based on specific settings and device capabilities (high contrast, effective pixels, locale, and so on). All you need to do is provide the images and ensure you use the appropriate naming convention and folder organization within the app project for the different resource versions. If you don't provide the recommended resource versions, accessibility, localization, and image quality can suffer, depending on the user's preferences, abilities, device type, and location.\n\nFor more detail on image resources for high contrast and scale factors, see [Guidelines for tile and icon assets](https://msdn.microsoft.com/windows/uwp/controls-and-patterns/tiles-and-notifications-app-assets).\n\nYou name resources using qualifiers. Resource qualifiers are folder and filename modifiers that identify the context in which a particular version of a resource should be used.\n\nThe standard naming convention is `foldername/qualifiername-value[_qualifiername-value]/filename.qualifiername-value[_qualifiername-value].ext`. For example, `images/en-US/logo.scale-100_contrast-white.png`, which can be referred to in code using just the root folder and the filename: `images/logo.png`. See [How to name resources using qualifiers](https://msdn.microsoft.com/library/windows/apps/xaml/hh965324.aspx).\n\nWe recommend that you mark the default language on string resource files (such as `en-US\\resources.resw`) and the default scale factor on images (such as `logo.scale-100.png`), even if you do not currently plan to provide localized or multiple resolution resources. However, at a minimum, we recommend that you provide assets for 100, 200, and 400 scale factors.\n\n> *Important\n\n> The app icon used in the title area of the **Cortana** canvas is the Square44x44Logo icon specified in the \"Package.appxmanifest\" file. \n\n> You can also specify an icon for each entry in the content area of the **Cortana** canvas. Valid image sizes for the results icons are:\n\n> - 68w x 68h \n> - 68w x 92h \n> - 280w x 140h \n\nThe content tile is not validated until a [**VoiceCommandResponse**](https://msdn.microsoft.com/library/windows/apps/dn974182) is passed to the [**VoiceCommandServiceConnection**](https://msdn.microsoft.com/library/windows/apps/dn974204). If you pass a **VoiceCommandResponse** object to **Cortana** that contains a content tile with an image that does not adhere to these size ratios, an exception can occur. \n\nIn this example from the **Adventure Works** app (VoiceCommandService\\\\AdventureWorksVoiceCommandService.cs), we specify a simple grey square (\"GreyTile.png\") on the [**VoiceCommandContentTile**](https://msdn.microsoft.com/library/windows/apps/dn974168) using the [**TitleWith68x68IconAndText**](https://msdn.microsoft.com/library/windows/apps/dn974169) tile template. The logo variants are located in VoiceCommandService\\\\Images, and are retrieved using the [**GetFileFromApplicationUriAsync**](https://msdn.microsoft.com/library/windows/apps/hh701741) method.\n\n```CSharp\nvar destinationTile = new VoiceCommandContentTile();\n\ndestinationTile.ContentTileType = \n  VoiceCommandContentTileType.TitleWith68x68IconAndText;\ndestinationTile.Image = \n  await StorageFile.GetFileFromApplicationUriAsync(\n    new Uri(\"ms-appx:///AdventureWorks.VoiceCommands/Images/GreyTile.png\"));\n```\n\n## <span id=\"Create_an_app_service_project\"></span><span id=\"create_an_app_service_project\"></span><span id=\"CREATE_AN_APP_SERVICE_PROJECT\"></span>Create an app service project\n\n<ol>\n    <li>\n    Right-click your Solution name, select **New > Project**.\n    </li>\n    <li>\n    Under **Installed > Templates > Visual C# > Windows > Universal**, select **Windows Runtime Component**. This is the component that implements the app service (**[Windows.ApplicationModel.AppService](https://msdn.microsoft.com/library/windows/apps/dn921731)**).\n    </li>\n    <li>\n    Type a name for the project (for example, \"VoiceCommandService\") and click **OK**.\n    </li>\n    <li>\n    In **Solution Explorer**, select the \"VoiceCommandService\" project and rename the \"Class1.cs\" file generated by Visual Studio. For the **Adventure Works** example we use \"AdventureWorksVoiceCommandService.cs\".\n    </li>\n    <li>\n    Click **Yes** when asked if you want to rename all occurrences of \"Class1.cs\". \n    </li>\n    <li>\n    In the \"AdventureWorksVoiceCommandService.cs\" file:\n        <ol type=\"i\">\n <li>\n Add the following using directive.  \n ```using Windows.ApplicationModel.Background;```\n </li>\n <li>\n When you create a new project, the project name is used as the default root namespace in all files. Rename the namespace to nest the app service code under the primary project. For example, `namespace AdventureWorks.VoiceCommands`. \n </li>\n <li>\n Right click the app service project name in Solution Explorer and select **Properties**. \n </li>\n <li>\n On the **Library** tab, update the **Default namespace** field with this same value (for this example, \"AdventureWorks.VoiceCommands\"). \n </li>\n <li>\n Create a new class that implements the [**IBackgroundTask**](https://msdn.microsoft.com/library/windows/apps/br224794) interface. This class requires a [**Run**](https://msdn.microsoft.com/library/windows/apps/br224811) method, which is the entry point when Cortana recognizes the voice command. \n </li>\n        </ol>\n    </li>\n</ol>\n\nHere's a basic background task class from the **Adventure Works** app. We'll fill in more detail later.\n> **Note**    \n> The background task class itself, and all other classes in the background task project, need to be sealed public classes.\n \n``` csharp\nnamespace AdventureWorks.VoiceCommands\n{\n    ...\n    \n    /// <summary>\n    /// The VoiceCommandService implements the entry point for all voice commands.\n    /// The individual commands supported are described in the VCD xml file. \n    /// The service entry point is defined in the appxmanifest.\n    /// </summary>\n    public sealed class AdventureWorksVoiceCommandService : IBackgroundTask\n    {\n        ...\n        \n        /// <summary>\n        /// The background task entrypoint. \n        /// \n        /// Background tasks must respond to activation by Cortana within 0.5 seconds, and must \n        /// report progress to Cortana every 5 seconds (unless Cortana is waiting for user\n        /// input). There is no execution time limit on the background task managed by Cortana,\n        /// but developers should use plmdebug (https://msdn.microsoft.com/library/windows/hardware/jj680085%28v=vs.85%29.aspx)\n        /// on the Cortana app package in order to prevent Cortana timing out the task during\n        /// debugging.\n        /// \n        /// The Cortana UI is dismissed if Cortana loses focus. \n        /// The background task is also dismissed even if being debugged. \n        /// Use of Remote Debugging is recommended in order to debug background task behaviors. \n        /// Open the project properties for the app package (not the background task project), \n        /// and enable Debug -> \"Do not launch, but debug my code when it starts\". \n        /// Alternatively, add a long initial progress screen, and attach to the background task process while it executes.\n        /// </summary>\n        /// <param name=\"taskInstance\">Connection to the hosting background service process.</param>\n        public void Run(IBackgroundTaskInstance taskInstance)\n        {\n        \n          //\n          // TODO: Insert code \n          //\n          //\n        \n    }        \n  }\n}\n```\n\n<ol start=\"7\">\n    <li>\n    Declare your background task as an **AppService** in the app manifest.\n    <ol type=\"i\">\n        <li>\n        In **Solution Explorer**, right click the \"Package.appxmanifest\" file and select **View Code**. \n        </li>\n        <li>\n        Find the [**Application**](https://msdn.microsoft.com/library/windows/apps/dn934738) element.\n        </li>\n        <li>\n        Add an [**Extensions**](https://msdn.microsoft.com/library/windows/apps/dn934720) element to the [**Application**](https://msdn.microsoft.com/library/windows/apps/dn934738) element.\n        </li>\n        <li>\n        Add a [**uap:Extension**](https://msdn.microsoft.com/library/windows/apps/dn986788) element to the [**Extensions**](https://msdn.microsoft.com/library/windows/apps/dn934720) element.\n        </li>\n        <li>Add a **Category** attribute to the **uap:Extension** element and set the value of the **Category** attribute to \"windows.appService\".\n        </li>\n        <li>\n        Add an **EntryPoint** attribute to the **uap:Extension** element and set the value of the **EntryPoint** attribute to the name of the class that implements [**IBackgroundTask**](https://msdn.microsoft.com/library/windows/apps/br224794), in this case \"AdventureWorks.VoiceCommands.AdventureWorksVoiceCommandService\".\n        </li>\n        <li>\n        Add a [**uap:AppService**](https://msdn.microsoft.com/library/windows/apps/dn934779) element to the **uap:Extension** element.\n        </li>\n        <li>\n        Add a **Name** attribute to the [**uap:AppService**](https://msdn.microsoft.com/library/windows/apps/dn934779) element and set the value of the **Name** attribute to a name for the app service, in this case \"AdventureWorksVoiceCommandService\".\n        </li>\n        <li>\n        Add a second [**uap:Extension**](https://msdn.microsoft.com/library/windows/apps/dn986788) element to [**Extensions**](https://msdn.microsoft.com/library/windows/apps/dn934720).\n        </li>\n        <li>\n        Add a **Category** attribute to this [**uap:Extension**](https://msdn.microsoft.com/library/windows/apps/dn986788) element and set the value of the **Category** attribute to \"windows.personalAssistantLaunch\".\n        </li>\n    </li> \n    </ol>\n    </li>    \n</ol>  \n\nHere's the manifest from the Adventure Works app:\n```xml\n<Package>\n  <Applications>\n    <Application>\n\n      <Extensions>\n        <uap:Extension Category=\"windows.appService\" \n          EntryPoint=\"CortanaBack1.VoiceCommands.CortanaBack1VoiceCommandService\">\n          <uap:AppService Name=\"CortanaBack1VoiceCommandService\"/>\n        </uap:Extension>\n        <uap:Extension Category=\"windows.personalAssistantLaunch\"/>\n      </Extensions>\n\n    <Application>\n  <Applications>\n</Package>\n```\n\n<ol start=\"8\">\n    <li>\n    Add this app service project as a reference in the primary project. \n    <ol type=\"i\">\n        <li>\n        Right click **References**. \n        </li>\n        <li>\n        Select **Add Reference...** \n        </li>\n        <li>\n        In the **Reference Manager** dialog, expand **Projects** and select the app service project. \n        </li>\n        <li>\n        Click OK. \n        </li>\n    </ol>\n    </li>\n</ol>\n\n## <span id=\"Create_a_VCD_file\"></span><span id=\"create_a_vcd_file\"></span><span id=\"CREATE_A_VCD_FILE\"></span>Create a VCD file\n\n\n1. In Visual Studio, right-click your primary project name, select **Add > New Item**. Add an **XML File**.\n2. Type a name for the [**VCD**](https://msdn.microsoft.com/library/windows/apps/dn706593) file (for this example, \"AdventureWorksCommands.xml\"), and click Add. \n3. In **Solution Explorer**, select the [**VCD**](https://msdn.microsoft.com/library/windows/apps/dn706593) file.\n4.  In the **Properties** window, set **Build action** to **Content**, and then set **Copy to output directory** to **Copy if newer**.\n\n## <span id=\"Edit_the_VCD_file\"></span><span id=\"edit_the_vcd_file\"></span><span id=\"EDIT_THE_VCD_FILE\"></span>Edit the VCD file\n\n1. Add a **VoiceCommands** element with an **xmlns** attribute pointing to `http://schemas.microsoft.com/voicecommands/1.2`.\n\n2. For each language supported by your app, create a [**CommandSet**](https://msdn.microsoft.com/library/windows/apps/dn722331) element that contains the voice commands supported by your app.\n\n  You can declare multiple [**CommandSet**](https://msdn.microsoft.com/library/windows/apps/dn722331) elements, each with a different [**xml:lang**](https://msdn.microsoft.com/library/windows/apps/dn722331) attribute so your app to be used in different markets. For example, an app for the United States might have a [**CommandSet**](https://msdn.microsoft.com/library/windows/apps/dn722331) for English and a [**CommandSet**](https://msdn.microsoft.com/library/windows/apps/dn722331) for Spanish.\n\n  >  **Caution**  \n  To activate an app and initiate an action using a voice command, the app must register a VCD file that contains a [**CommandSet**](https://msdn.microsoft.com/library/windows/apps/dn722331) with a language that matches the speech language selected by the user for their device. The speech language is located in **Settings > System > Speech > Speech Language**.\n\n3. Add a **Command** element for each command you want to support.\n\n  Each **Command** declared in a [**VCD**](https://msdn.microsoft.com/library/windows/apps/dn706593) file must include this information:\n\n  - A **Name** attribute that your application uses to identify the voice command at runtime. \n  - An **Example** element that contains a phrase describing how a user can invoke the command. **Cortana** shows this example when the user says \"What can I say?\", \"Help\", or they tap **See more**.    \n  -   A **ListenFor** element that contains the words or phrases that your app recognizes as a command. Each **ListenFor** element can contain references to one or more **PhraseList** elements that contain specific words relevant to the command.\n  > **Note**  \n  **ListenFor** elements cannot be programmatically modified. However, **PhraseList** elements associated with **ListenFor** elements can be programmatically modified. Applications should modify the content of the **PhraseList** at runtime based on the data set generated as the user uses the app. See [Dynamically modify Voice Command Definition (VCD) phrase lists](dynamically-modify-voice-command-definition--vcd--phrase-lists.md).\n\n  -   A **Feedback** element that contains the text for **Cortana** to display and speak as the application is launched.\n\nA **Navigate** element indicates that the voice command activates the app to the foreground. In this example, the ```showTripToDestination``` command is a foreground task.\n\nA **VoiceCommandService** element indicates that the voice command activates the app in the background. The value of the **Target** attribute of this element should match the value of the **Name** attribute of the [**uap:AppService**](https://msdn.microsoft.com/library/windows/apps/dn934779) element in the package.appxmanifest file. In this example, the ```whenIsTripToDestination``` and ```cancelTripToDestination``` commands are background tasks that specify the name of the app service as \"AdventureWorksVoiceCommandService\".\n\nFor more detail, see the [**VCD elements and attributes v1.2**](https://msdn.microsoft.com/library/windows/apps/dn706593) reference.\n\nHere's a portion of the [**VCD**](https://msdn.microsoft.com/library/windows/apps/dn706593) file that defines the en-us voice commands for the **Adventure Works** app.\n\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n<VoiceCommands xmlns=\"http://schemas.microsoft.com/voicecommands/1.2\">\n  <CommandSet xml:lang=\"en-us\" Name=\"AdventureWorksCommandSet_en-us\">\n    <AppName> Adventure Works </AppName>\n    <Example> Show trip to London </Example>\n\n    <Command Name=\"showTripToDestination\">\n      <Example> Show trip to London </Example>\n      <ListenFor RequireAppName=\"BeforeOrAfterPhrase\"> show [my] trip to {destination} </ListenFor>\n      <ListenFor RequireAppName=\"ExplicitlySpecified\"> show [my] {builtin:AppName} trip to {destination} </ListenFor>\n      <Feedback> Showing trip to {destination} </Feedback>\n      <Navigate />\n    </Command>\n\n    <Command Name=\"whenIsTripToDestination\">\n      <Example> When is my trip to Las Vegas?</Example>\n      <ListenFor RequireAppName=\"BeforeOrAfterPhrase\"> when is [my] trip to {destination}</ListenFor>\n      <ListenFor RequireAppName=\"ExplicitlySpecified\"> when is [my] {builtin:AppName} trip to {destination} </ListenFor>\n      <Feedback> Looking for trip to {destination}</Feedback>\n      <VoiceCommandService Target=\"AdventureWorksVoiceCommandService\"/>\n    </Command>\n    \n    <Command Name=\"cancelTripToDestination\">\n      <Example> Cancel my trip to Las Vegas </Example>\n      <ListenFor RequireAppName=\"BeforeOrAfterPhrase\"> cancel [my] trip to {destination}</ListenFor>\n      <ListenFor RequireAppName=\"ExplicitlySpecified\"> cancel [my] {builtin:AppName} trip to {destination} </ListenFor>\n      <Feedback> Cancelling trip to {destination}</Feedback>\n      <VoiceCommandService Target=\"AdventureWorksVoiceCommandService\"/>\n    </Command>\n\n    <PhraseList Label=\"destination\">\n      <Item>London</Item>\n      <Item>Las Vegas</Item>\n      <Item>Melbourne</Item>\n      <Item>Yosemite National Park</Item>\n    </PhraseList>\n  </CommandSet>\n```\n\n## <span id=\"Install_the_VCD_commands\"></span><span id=\"install_the_vcd_commands\"></span><span id=\"INSTALL_THE_VCD_COMMANDS\"></span>Install the VCD commands\n\nYour app must run once to install the VCD. \n\n>  **Note**  \nVoice command data is not preserved across app installations. To ensure the voice command data for your app remains intact, consider initializing your VCD file each time your app is launched or activated, or maintain a setting that indicates if the VCD is currently installed.\n\nIn the \"app.xaml.cs\" file:\n\n1. Add the following using directive:  \n```csharp\nusing Windows.Storage;\n```\n2. Mark the \"OnLaunched\" method with the async modifier.  \n```csharp\nprotected async override void OnLaunched(LaunchActivatedEventArgs e)\n```\n3. Call [**InstallCommandDefinitionsFromStorageFileAsync**](https://msdn.microsoft.com/library/windows/apps/dn708205) in the [**OnLaunched**](https://msdn.microsoft.com/library/windows/apps/br242335) handler to register the voice commands that the system should recognize.\n\n  In the Adventure Works sample, we first define a [**StorageFile**](https://msdn.microsoft.com/library/windows/apps/br227171) object. \n\n  We then call [**GetFileAsync**](https://msdn.microsoft.com/library/windows/apps/br227272) to initialize it with our \"AdventureWorksCommands.xml\" file.\n\n  This [**StorageFile**](https://msdn.microsoft.com/library/windows/apps/br227171) object is then passed to [**InstallCommandDefinitionsFromStorageFileAsync**](https://msdn.microsoft.com/library/windows/apps/dn708205).    \n```CSharp\ntry\n{\n  // Install the main VCD. \n  StorageFile vcdStorageFile = \n    await Package.Current.InstalledLocation.GetFileAsync(\n      @\"AdventureWorksCommands.xml\");\n\n  await Windows.ApplicationModel.VoiceCommands.VoiceCommandDefinitionManager.\n    InstallCommandDefinitionsFromStorageFileAsync(vcdStorageFile);\n\n  // Update phrase list.\n  ViewModel.ViewModelLocator locator = App.Current.Resources[\"ViewModelLocator\"] as ViewModel.ViewModelLocator;\n  if(locator != null)\n  {\n     await locator.TripViewModel.UpdateDestinationPhraseList();\n  }\n}\ncatch (Exception ex)\n{\n  System.Diagnostics.Debug.WriteLine(\"Installing Voice Commands Failed: \" + ex.ToString());\n}\n```\n\n## <span id=\"Handle_activation_and_execute_voice_commands\"></span><span id=\"handle_activation_and_execute_voice_commands\"></span><span id=\"HANDLE_ACTIVATION_AND_EXECUTE_VOICE_COMMANDS\"></span>Handle activation\n\nSpecify how your app responds to subsequent voice command activations (after it has been launched at least once and the voice command sets have been installed).\n\n1.  Confirm that your app was activated by a voice command.\n\n    Override the [**Application.OnActivated**](https://msdn.microsoft.com/library/windows/apps/br242330) event and check whether [**IActivatedEventArgs**](https://msdn.microsoft.com/library/windows/apps/br224727).[**Kind**](https://msdn.microsoft.com/library/windows/apps/br224728) is [**VoiceCommand**](https://msdn.microsoft.com/library/windows/apps/br224693).\n\n2.  Determine the name of the command and what was spoken.\n\n    Get a reference to a [**VoiceCommandActivatedEventArgs**](https://msdn.microsoft.com/library/windows/apps/dn609755) object from the [**IActivatedEventArgs**](https://msdn.microsoft.com/library/windows/apps/br224727) and query the [**Result**](https://msdn.microsoft.com/library/windows/apps/dn609758) property for a [**SpeechRecognitionResult**](https://msdn.microsoft.com/library/windows/apps/dn631432) object.\n\n    To determine what the user said, check the value of [**Text**](https://msdn.microsoft.com/library/windows/apps/dn631441) or the semantic properties of the recognized phrase in the [**SpeechRecognitionSemanticInterpretation**](https://msdn.microsoft.com/library/windows/apps/dn631443) dictionary.\n\n3.  Take the appropriate action in your app, such as navigating to the desired page.\n\nFor this example, we refer back to the VCD in Step 3: Edit the VCD file.\n\nOnce we get the speech-recognition result for the voice command, we get the command name from the first value in the [**RulePath**](https://msdn.microsoft.com/library/windows/apps/dn631438) array. As the VCD file defined more than one possible voice command, we need to compare the value against the command names in the VCD and take the appropriate action.\n\nThe most common action an application can take is to navigate to a page with content relevant to the context of the voice command. For this example, we navigate to a **TripPage** page and pass in the value of the voice command, how the command was input, and the recognized \"destination\" phrase (if applicable). Alternatively, the app could send a navigation parameter to the [**SpeechRecognitionResult**](https://msdn.microsoft.com/library/windows/apps/dn631432) when navigating to the page.\n\nYou can find out whether the voice command that launched your app was actually spoken, or whether it was typed in as text, from the [**SpeechRecognitionSemanticInterpretation.Properties**](https://msdn.microsoft.com/library/windows/apps/dn631445) dictionary using the **commandMode** key. The value of that key will be either \"voice\" or \"text\". If the value of the key is \"voice\", consider using speech synthesis ([**Windows.Media.SpeechSynthesis**](https://msdn.microsoft.com/library/windows/apps/dn278951)) in your app to provide the user with spoken feedback.\n\nUse the [**SpeechRecognitionSemanticInterpretation.Properties**](https://msdn.microsoft.com/library/windows/apps/dn631445) to find out the content spoken in the **PhraseList** or **PhraseTopic** constraints of a **ListenFor** element. The dictionary key is the value of the **Label** attribute of the **PhraseList** or **PhraseTopic** element. Here, we show how to access the value of **{destination}** phrase.\n\n``` csharp\n/// <summary>\n/// Entry point for an application activated by some means other than normal launching. \n/// This includes voice commands, URI, share target from another app, and so on. \n/// \n/// NOTE:\n/// A previous version of the VCD file might remain in place \n/// if you modify it and update the app through the store. \n/// Activations might include commands from older versions of your VCD. \n/// Try to handle these commands gracefully.\n/// </summary>\n/// <param name=\"args\">Details about the activation method.</param>\nprotected override void OnActivated(IActivatedEventArgs args)\n{\n    base.OnActivated(args);\n\n    Type navigationToPageType;\n    ViewModel.TripVoiceCommand? navigationCommand = null;\n\n    // Voice command activation.\n    if (args.Kind == ActivationKind.VoiceCommand)\n    {\n        // Event args can represent many different activation types. \n        // Cast it so we can get the parameters we care about out.\n        var commandArgs = args as VoiceCommandActivatedEventArgs;\n\n        Windows.Media.SpeechRecognition.SpeechRecognitionResult speechRecognitionResult = commandArgs.Result;\n\n        // Get the name of the voice command and the text spoken. \n        // See VoiceCommands.xml for supported voice commands.\n        string voiceCommandName = speechRecognitionResult.RulePath[0];\n        string textSpoken = speechRecognitionResult.Text;\n\n        // commandMode indicates whether the command was entered using speech or text.\n        // Apps should respect text mode by providing silent (text) feedback.\n        string commandMode = this.SemanticInterpretation(\"commandMode\", speechRecognitionResult);\n        \n        switch (voiceCommandName)\n        {\n            case \"showTripToDestination\":\n                // Access the value of {destination} in the voice command.\n                string destination = this.SemanticInterpretation(\"destination\", speechRecognitionResult);\n\n                // Create a navigation command object to pass to the page. \n                navigationCommand = new ViewModel.TripVoiceCommand(\n                    voiceCommandName,\n                    commandMode,\n                    textSpoken,\n                    destination);\n\n                // Set the page to navigate to for this voice command.\n                navigationToPageType = typeof(View.TripDetails);\n                break;\n            default:\n                // If we can't determine what page to launch, go to the default entry point.\n                navigationToPageType = typeof(View.TripListView);\n                break;\n        }\n    }\n    // Protocol activation occurs when a card is clicked within Cortana (using a background task).\n    else if (args.Kind == ActivationKind.Protocol)\n    {\n        // Extract the launch context. In this case, we're just using the destination from the phrase set (passed\n        // along in the background task inside Cortana), which makes no attempt to be unique. A unique id or \n        // identifier is ideal for more complex scenarios. We let the destination page check if the \n        // destination trip still exists, and navigate back to the trip list if it doesn't.\n        var commandArgs = args as ProtocolActivatedEventArgs;\n        Windows.Foundation.WwwFormUrlDecoder decoder = new Windows.Foundation.WwwFormUrlDecoder(commandArgs.Uri.Query);\n        var destination = decoder.GetFirstValueByName(\"LaunchContext\");\n\n        navigationCommand = new ViewModel.TripVoiceCommand(\n                                \"protocolLaunch\",\n                                \"text\",\n                                \"destination\",\n                                destination);\n\n        navigationToPageType = typeof(View.TripDetails);\n    }\n    else\n    {\n        // If we were launched via any other mechanism, fall back to the main page view.\n        // Otherwise, we'll hang at a splash screen.\n        navigationToPageType = typeof(View.TripListView);\n    }\n\n    // Repeat the same basic initialization as OnLaunched() above, taking into account whether\n    // or not the app is already active.\n    Frame rootFrame = Window.Current.Content as Frame;\n\n    // Do not repeat app initialization when the Window already has content,\n    // just ensure that the window is active.\n    if (rootFrame == null)\n    {\n        // Create a frame to act as the navigation context and navigate to the first page.\n        rootFrame = new Frame();\n        App.NavigationService = new NavigationService(rootFrame);\n\n        rootFrame.NavigationFailed += OnNavigationFailed;\n\n        // Place the frame in the current window.\n        Window.Current.Content = rootFrame;\n    }\n\n    // Since we're expecting to always show a details page, navigate even if \n    // a content frame is in place (unlike OnLaunched).\n    // Navigate to either the main trip list page, or if a valid voice command\n    // was provided, to the details page for that trip.\n    rootFrame.Navigate(navigationToPageType, navigationCommand);\n\n    // Ensure the current window is active\n    Window.Current.Activate();\n}\n\n/// <summary>\n/// Returns the semantic interpretation of a speech result. \n/// Returns null if there is no interpretation for that key.\n/// </summary>\n/// <param name=\"interpretationKey\">The interpretation key.</param>\n/// <param name=\"speechRecognitionResult\">The speech recognition result to get the semantic interpretation from.</param>\n/// <returns></returns>\nprivate string SemanticInterpretation(string interpretationKey, SpeechRecognitionResult speechRecognitionResult)\n{\n  return speechRecognitionResult.SemanticInterpretation.Properties[interpretationKey].FirstOrDefault();\n}\n```\n\n## <span id=\"Handle_the_voice_command_in_the_app_service\"></span><span id=\"handle_the_voice_command_in_the_app_service\"></span><span id=\"HANDLE_THE_VOICE_COMMAND_IN_THE_APP_SERVICE\"></span>Handle the voice command in the app service\n\n\nProcess the voice command in the app service.\n\n\n1.  Add the following using directives to your voice command service file, \"AdventureWorksVoiceCommandService.cs\" for this example.\n```csharp\nusing Windows.ApplicationModel.VoiceCommands;\nusing Windows.ApplicationModel.Resources.Core;\nusing Windows.ApplicationModel.AppService;\n```\n\n2.  Take a service deferral so your app service is not terminated while handling the voice command.\n3.  Confirm that your background task is running as an app service activated by a voice command.\n\n    1.  Cast the [**IBackgroundTaskInstance.TriggerDetails**](https://msdn.microsoft.com/library/windows/apps/br224802) to [**Windows.ApplicationModel.AppService.AppServiceTriggerDetails**](https://msdn.microsoft.com/library/windows/apps/dn921727).\n    2.  Check that [**IBackgroundTaskInstance.TriggerDetails.Name**](https://msdn.microsoft.com/library/windows/apps/br224807) is the name of the app service in the \"Package.appxmanifest\" file.\n\n4.  Use [**IBackgroundTaskInstance.TriggerDetails**](https://msdn.microsoft.com/library/windows/apps/br224802) to create a [**VoiceCommandServiceConnection**](https://msdn.microsoft.com/library/windows/apps/dn974204) to **Cortana** to retrieve the voice command.\n5.  Register an event handler for [**VoiceCommandServiceConnection**](https://msdn.microsoft.com/library/windows/apps/dn974204).[**VoiceCommandCompleted**](https://msdn.microsoft.com/library/windows/apps/dn706584) to receive notification when the app service is closed due to a user cancellation.\n6.  Register an event handler for the [**IBackgroundTaskInstance.Canceled**](https://msdn.microsoft.com/library/windows/apps/br224798) to receive notification when the app service is closed due to an unexpected failure.\n7.  Determine the name of the command and what was spoken.\n\n    1.  Use the [**VoiceCommand**](https://msdn.microsoft.com/library/windows/apps/dn974162).[**CommandName**](https://msdn.microsoft.com/library/windows/apps/dn706589) property to determine the name of the voice command.\n    2.  To determine what the user said, check the value of [**Text**](https://msdn.microsoft.com/library/windows/apps/dn631441) or the semantic properties of the recognized phrase in the [**SpeechRecognitionSemanticInterpretation**](https://msdn.microsoft.com/library/windows/apps/dn631443) dictionary.\n\n7.  Take the appropriate action in your app service.\n8.  Display and speak the feedback to the voice command with **Cortana**.\n\n    1.  Determine the strings that you want **Cortana** to display and speak to the user in response to the voice command and create a [**VoiceCommandResponse**](https://msdn.microsoft.com/library/windows/apps/dn974182) object. For guidance on how to select the feedback strings that **Cortana** shows and speaks, see [Cortana design guidelines](https://msdn.microsoft.com/library/windows/apps/dn974233).\n    2.  Use the [**VoiceCommandServiceConnection**](https://msdn.microsoft.com/library/windows/apps/dn974204) instance to report progress or completion to **Cortana** by calling [**ReportProgressAsync**](https://msdn.microsoft.com/library/windows/apps/dn706579) or [**ReportSuccessAsync**](https://msdn.microsoft.com/library/windows/apps/dn706580) with the **VoiceCommandServiceConnection** object.\n\n    For this example, we refer back to the VCD in Step 3: Edit the VCD file.\n\n```csharp\npublic sealed class VoiceCommandService : IBackgroundTask\n    {\n      private BackgroundTaskDeferral serviceDeferral;\n      VoiceCommandServiceConnection voiceServiceConnection;\n\n      public async void Run(IBackgroundTaskInstance taskInstance)\n      {\n      //Take a service deferral so the service isn&#39;t terminated.\n        this.serviceDeferral = taskInstance.GetDeferral();\n\n        taskInstance.Canceled += OnTaskCanceled;\n\n        var triggerDetails = \n          taskInstance.TriggerDetails as AppServiceTriggerDetails;\n\n        if (triggerDetails != null &amp;&amp; \n          triggerDetails.Name == \"AdventureWorksVoiceServiceEndpoint\")\n        {\n          try\n          {\n voiceServiceConnection = \n   VoiceCommandServiceConnection.FromAppServiceTriggerDetails(\n     triggerDetails);\n\n voiceServiceConnection.VoiceCommandCompleted += \n   VoiceCommandCompleted;\n\n VoiceCommand voiceCommand = await\n voiceServiceConnection.GetVoiceCommandAsync();\n\n switch (voiceCommand.CommandName)\n {\n   case \"whenIsTripToDestination\":\n   {\n     var destination = \n       voiceCommand.Properties[\"destination\"][0];\n     SendCompletionMessageForDestination(destination);\n     break;\n   }\n\n   // As a last resort, launch the app in the foreground.\n   default:\n     LaunchAppInForeground();\n     break;\n }\n          }\n          finally\n          {\n if (this.serviceDeferral != null)\n {\n   // Complete the service deferral.\n   this.serviceDeferral.Complete();\n }\n          }\n        }\n      }\n\n      private void VoiceCommandCompleted(\n        VoiceCommandServiceConnection sender, \n        VoiceCommandCompletedEventArgs args)\n      {\n        if (this.serviceDeferral != null)\n        {\n          // Insert your code here.\n          // Complete the service deferral.\n          this.serviceDeferral.Complete();\n        }\n      }\n\n      private async void SendCompletionMessageForDestination(\n        string destination)\n      {\n        // Take action and determine when the next trip to destination\n        // Insert code here.\n        \n        // Replace the hardcoded strings used here with strings \n        // appropriate for your application.\n\n        // First, create the VoiceCommandUserMessage with the strings \n        // that Cortana will show and speak.\n        var userMessage = new VoiceCommandUserMessage();\n        userMessage.DisplayMessage = \"Hereâ€™s your trip.\";\n        userMessage.SpokenMessage = \"Your trip to Vegas is on August 3rd.\";\n\n        // Optionally, present visual information about the answer.\n        // For this example, create a VoiceCommandContentTile with an \n        // icon and a string.\n        var destinationsContentTiles = new List<VoiceCommandContentTile>();\n\n        var destinationTile = new VoiceCommandContentTile();\n        destinationTile.ContentTileType = \n          VoiceCommandContentTileType.TitleWith68x68IconAndText;\n        // The user can tap on the visual content to launch the app. \n        // Pass in a launch argument to enable the app to deep link to a \n        // page relevant to the item displayed on the content tile.\n        destinationTile.AppLaunchArgument = \n          string.Format(\"destination={0}â€, â€œLas Vegas\");\n        destinationTile.Title = \"Las Vegas\";\n        destinationTile.TextLine1 = \"August 3rd 2015\";\n        destinationsContentTiles.Add(destinationTile);\n\n        // Create the VoiceCommandResponse from the userMessage and list    \n        // of content tiles.\n        var response = \n          VoiceCommandResponse.CreateResponse(\n userMessage, destinationsContentTiles);\n\n        // Cortana will present a â€œGo to app_nameâ€ link that the user \n        // can tap to launch the app. \n        // Pass in a launch to enable the app to deep link to a page \n        // relevant to the voice command.\n        response.AppLaunchArgument = \n          string.Format(\"destination={0}â€, â€œLas Vegas\");\n        \n        // Ask Cortana to display the user message and content tile and \n        // also speak the user message.\n        await voiceServiceConnection.ReportSuccessAsync(response);\n      }\n\n      private async void LaunchAppInForeground()\n      {\n        var userMessage = new VoiceCommandUserMessage();\n        userMessage.SpokenMessage = \"Launching Adventure Works\";\n\n        var response = VoiceCommandResponse.CreateResponse(userMessage);\n\n        // When launching the app in the foreground, pass an app \n        // specific launch parameter to indicate what page to show.\n        response.AppLaunchArgument = \"showAllTrips=true\";\n\n        await voiceServiceConnection.RequestAppLaunchAsync(response);\n      }\n    }\n```\n\nOnce activated, the app service has .5 seconds to call [**ReportSuccessAsync**](https://msdn.microsoft.com/library/windows/apps/dn706580). **Cortana** uses the data provided by the app to show and say the feedback specified in the VCD file. If the app takes longer than .5 seconds to make the call, **Cortana** inserts a hand-off screen, as shown here. **Cortana** displays the hand-off screen until the application calls **ReportSuccessAsync**, or for up to 5 seconds. If the app service doesnâ€™t call **ReportSuccessAsync**, or any of the [**VoiceCommandServiceConnection**](https://msdn.microsoft.com/library/windows/apps/dn974204) methods that provide **Cortana** with information, the user receives an error message and the app service is cancelled.\n\n![a basic query with progress and result screens using the adventure works app in the background](images/cortana-backgroundapp-progress-result.png)\n\n## <span id=\"related_topics\"></span>Related articles\n\n\n**Developers**\n* [Cortana interactions](cortana-interactions.md)\n* [Define custom recognition constraints](define-custom-recognition-constraints.md)\n* [Interact with a background app in Cortana](interact-with-a-background-app-in-cortana.md)\n* [**VCD elements and attributes v1.2**](https://msdn.microsoft.com/library/windows/apps/dn706593)\n* [Quickstart: Using file or image resources](https://msdn.microsoft.com/library/windows/apps/xaml/hh965325)\n* [How to name resources using qualifiers](https://msdn.microsoft.com/library/windows/apps/xaml/hh965324)\n\n**Designers**\n* [Cortana design guidelines](https://msdn.microsoft.com/library/windows/apps/dn974233)\n* [Speech design guidelines](https://msdn.microsoft.com/library/windows/apps/dn596121)\n* [Responsive design 101 for UWP apps](https://msdn.microsoft.com/library/windows/apps/dn958435)\n* [Guidelines for tile and icon assets](https://msdn.microsoft.com/library/windows/apps/mt412102)\n\n**Samples**\n* [Cortana voice command sample](http://go.microsoft.com/fwlink/p/?LinkID=619899)\n \n\n \n\n\n\n\n"}