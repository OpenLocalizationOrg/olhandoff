{"nodes":[{"content":"Create Universal Windows Platform (UWP) apps with intuitive and distinctive user interaction experiences that are optimized for touch but are functionally consistent across input devices.","pos":[47,234]},{"content":"Touch interactions","pos":[242,260]},{"content":"Touch interactions","pos":[364,382]},{"content":"Design your app with the expectation that touch will be the primary input method of your users.","pos":[385,480]},{"content":"If you use UWP controls, support for touchpad, mouse, and pen/stylus requires no additional programming, because UWP apps provide this for free.","pos":[481,625]},{"content":"However, keep in mind that a UI optimized for touch is not always superior to a traditional UI.","pos":[627,722]},{"content":"Both provide advantages and disadvantages that are unique to a technology and application.","pos":[723,813]},{"content":"In the move to a touch-first UI, it is important to understand the core differences between touch (including touchpad), pen/stylus, mouse, and keyboard input.","pos":[814,972]},{"content":"Important APIs","pos":[976,990]},{"content":"Windows.UI.Xaml.Input","pos":[1001,1022]},{"content":"Windows.UI.Core","pos":[1091,1106]},{"content":"Windows.Devices.Input","pos":[1175,1196]},{"content":"Many devices have multi-touch screens that support using one or more fingers (or touch contacts) as input.","pos":[1261,1367]},{"content":"The touch contacts, and their movement, are interpreted as touch gestures and manipulations to support various user interactions.","pos":[1368,1497]},{"content":"The Universal Windows Platform (UWP) includes a number of different mechanisms for handling touch input, enabling you to create an immersive experience that your users can explore with confidence.","pos":[1499,1695]},{"content":"Here, we cover the basics of using touch input in a UWP app.","pos":[1696,1756]},{"content":"Touch interactions require three things:","pos":[1758,1798]},{"content":"A touch-sensitive display.","pos":[1804,1830]},{"content":"The direct contact (or proximity to, if the display has proximity sensors and supports hover detection) of one or more fingers on that display.","pos":[1835,1978]},{"content":"Movement of the touch contacts (or lack thereof, based on a time threshold).","pos":[1983,2059]},{"content":"The input data provided by the touch sensor can be:","pos":[2061,2112]},{"content":"Interpreted as a physical gesture for direct manipulation of one or more UI elements (such as panning, rotating, resizing, or moving).","pos":[2118,2252]},{"content":"In contrast, interacting with an element through its properties window, dialog box, or other UI affordance is considered indirect manipulation.","pos":[2253,2396]},{"content":"Recognized as an alternative input method, such as mouse or pen.","pos":[2401,2465]},{"content":"Used to complement or modify aspects of other input methods, such as smudging an ink stroke drawn with a pen.","pos":[2470,2579]},{"content":"Touch input typically involves the direct manipulation of an element on the screen.","pos":[2581,2664]},{"content":"The element responds immediately to any touch contact within its hit test area, and reacts appropriately to any subsequent movement of the touch contacts, including removal.","pos":[2665,2838]},{"content":"Custom touch gestures and interactions should be designed carefully.","pos":[2840,2908]},{"content":"They should be intuitive, responsive, and discoverable, and they should let users explore your app with confidence.","pos":[2909,3024]},{"content":"Ensure that app functionality is exposed consistently across every supported input device type.","pos":[3026,3121]},{"content":"If necessary, use some form of indirect input mode, such as text input for keyboard interactions, or UI affordances for mouse and pen.","pos":[3122,3256]},{"content":"Remember that traditional input devices (such as mouse and keyboard), are familiar and appealing to many users.","pos":[3258,3369]},{"content":"They can offer speed, accuracy, and tactile feedback that touch might not.","pos":[3370,3444]},{"content":"Providing unique and distinctive interaction experiences for all input devices will support the widest range of capabilities and preferences, appeal to the broadest possible audience, and attract more customers to your app.","pos":[3446,3669]},{"content":"Compare touch interaction requirements","pos":[3674,3712]},{"content":"The following table shows some of the differences between input devices that you should consider when you design touch-optimized UWP apps.","pos":[3714,3852]},{"content":"Factor","pos":[3877,3883]},{"content":"Touch interactions","pos":[3892,3910]},{"content":"Mouse, keyboard, pen/stylus interactions","pos":[3919,3959]},{"content":"Touchpad","pos":[3968,3976]},{"content":"Precision","pos":[4007,4016]},{"content":"The contact area of a fingertip is greater than a single x-y coordinate, which increases the chances of unintended command activations.","pos":[4025,4160]},{"content":"The mouse and pen/stylus supply a precise x-y coordinate.","pos":[4169,4226]},{"content":"Same as mouse.","pos":[4235,4249]},{"content":"The shape  of the contact area changes throughout the movement.","pos":[4268,4331]},{"content":"Mouse movements and pen/stylus strokes supply precise x-y coordinates.","pos":[4342,4412]},{"content":"Keyboard focus is explicit.","pos":[4413,4440]},{"content":"Same as mouse.","pos":[4449,4463]},{"content":"There is no mouse cursor to assist with targeting.","pos":[4482,4532]},{"content":"The mouse cursor, pen/stylus cursor, and keyboard focus all assist with targeting.","pos":[4541,4623]},{"content":"Same as mouse.","pos":[4632,4646]},{"content":"Human anatomy","pos":[4677,4690]},{"content":"Fingertip movements are imprecise, because a straight-line motion with one or more fingers is difficult.","pos":[4699,4803]},{"content":"This is due to the curvature of hand joints and the number of joints involved in the motion.","pos":[4804,4896]},{"content":"It's easier to perform a straight-line motion with the mouse or pen/stylus because the hand that controls them travels a shorter physical distance than the cursor on the screen.","pos":[4905,5082]},{"content":"Same as mouse.","pos":[5091,5105]},{"content":"Some areas on the touch surface of a display device can be difficult to reach due to finger posture and the user's grip on the device.","pos":[5124,5258]},{"content":"The mouse and pen/stylus can reach any part of the screen while any control should be accessible by the keyboard through tab order.","pos":[5267,5398]},{"content":"Finger posture and grip can be an issue.","pos":[5408,5448]},{"content":"Objects might be obscured by one or more fingertips or the user's hand.","pos":[5467,5538]},{"content":"This is known as occlusion.","pos":[5539,5566]},{"content":"Indirect input devices do not cause  occlusion.","pos":[5575,5622]},{"content":"Same as mouse.","pos":[5631,5645]},{"content":"Object state","pos":[5664,5676]},{"content":"Touch uses a two-state model: the touch surface of a display device  is either touched (on) or not (off).","pos":[5685,5790]},{"content":"There is no hover state that can trigger additional visual feedback.","pos":[5791,5859]},{"content":"A mouse, pen/stylus, and keyboard all expose a three-state model: up (off), down (on), and hover (focus).","pos":[5872,5977]},{"content":"Hover lets users explore and learn through tooltips  associated with UI elements.","pos":[5985,6066]},{"content":"Hover and focus effects  can relay which objects are interactive and also help with targeting.","pos":[6067,6161]},{"content":"Same as mouse.","pos":[6177,6191]},{"content":"Rich interaction","pos":[6222,6238]},{"content":"Supports multi-touch: multiple input points (fingertips) on a touch surface.","pos":[6247,6323]},{"content":"Supports a single input point.","pos":[6332,6362]},{"content":"Same as touch.","pos":[6371,6385]},{"content":"Supports direct manipulation of objects through gestures such as tapping, dragging, sliding, pinching, and rotating.","pos":[6404,6520]},{"content":"No support for direct manipulation as mouse, pen/stylus, and keyboard are indirect input devices.","pos":[6529,6626]},{"content":"Same as mouse.","pos":[6635,6649]},{"content":"Note","pos":[6682,6686]},{"content":"Indirect input has had the benefit of more than 25 years of refinement.","pos":[6691,6762]},{"content":"Features such as hover-triggered tooltips have been designed to solve UI exploration specifically for touchpad, mouse, pen/stylus, and keyboard input.","pos":[6763,6913]},{"content":"UI features like this have been re-designed for the rich experience provided by touch input, without compromising the user experience for these other devices.","pos":[6914,7072]},{"content":"Use touch feedback","pos":[7080,7098]},{"content":"Appropriate visual feedback during interactions with your app helps users recognize, learn, and adapt to how their interactions are interpreted by both the app and Windows 8.","pos":[7100,7274]},{"content":"Visual feedback can indicate successful interactions, relay system status, improve the sense of control, reduce errors, help users understand the system and input device, and encourage interaction.","pos":[7275,7472]},{"content":"Visual feedback is critical when the user relies on touch input for activities that require accuracy and precision based on location.","pos":[7474,7607]},{"content":"Display feedback whenever and wherever touch input is detected, to help the user understand any custom targeting rules that are defined by your app and its controls.","pos":[7608,7773]},{"content":"Targeting","pos":[7779,7788]},{"content":"Targeting is optimized through:","pos":[7790,7821]},{"content":"Touch target sizes","pos":[7827,7845]},{"content":"Clear size guidelines ensure that applications provide a comfortable UI that contains objects and controls that are easy and safe to target.","pos":[7851,7991]},{"content":"Contact geometry","pos":[7997,8013]},{"content":"The entire contact area of the finger determines the most likely target object.","pos":[8019,8098]},{"content":"Scrubbing","pos":[8104,8113]},{"content":"Items within a group are easily re-targeted by dragging the finger between them (for example, radio buttons).","pos":[8119,8228]},{"content":"The current item is activated when the touch is released.","pos":[8229,8286]},{"content":"Rocking","pos":[8292,8299]},{"content":"Densely packed items (for example, hyperlinks) are easily re-targeted by pressing the finger down and, without sliding, rocking it back and forth over the items.","pos":[8305,8466]},{"content":"Due to occlusion, the current item is identified through a tooltip or the status bar and is activated when the touch is released.","pos":[8467,8596]},{"content":"Accuracy","pos":[8601,8609]},{"content":"Design for sloppy interactions by using:","pos":[8611,8651]},{"content":"Snap-points that can make it easier to stop at desired locations when users interact with content.","pos":[8657,8755]},{"content":"Directional \"rails\" that can assist with vertical or horizontal panning, even when the hand moves in a slight arc.","pos":[8760,8874]},{"content":"For more information, see <bpt id=\"p1\">[</bpt>Guidelines for panning<ept id=\"p1\">](guidelines-for-panning.md)</ept>.","pos":[8875,8953]},{"content":"Occlusion","pos":[8958,8967]},{"content":"Finger and hand occlusion is avoided through:","pos":[8969,9014]},{"content":"Size and positioning of UI","pos":[9020,9046]},{"content":"Make UI elements big enough so that they cannot be completely covered by a fingertip contact area.","pos":[9052,9150]},{"content":"Position menus and pop-ups above the contact area whenever possible.","pos":[9156,9224]},{"content":"Tooltips","pos":[9230,9238]},{"content":"Show tooltips when a user maintains finger contact on an object.","pos":[9244,9308]},{"content":"This is useful for describing object functionality.","pos":[9309,9360]},{"content":"The user can drag the fingertip off the object to avoid invoking the tooltip.","pos":[9361,9438]},{"content":"For small objects, offset tooltips so they are not covered by the fingertip contact area.","pos":[9444,9533]},{"content":"This is helpful for targeting.","pos":[9534,9564]},{"content":"Handles for precision","pos":[9570,9591]},{"content":"Where precision is required (for example, text selection), provide selection handles that are offset to improve accuracy.","pos":[9597,9718]},{"content":"For more information, see <bpt id=\"p1\">[</bpt>Guidelines for selecting text and images (Windows Runtime apps)<ept id=\"p1\">](guidelines-for-textselection.md)</ept>.","pos":[9719,9844]},{"content":"Timing","pos":[9849,9855]},{"content":"Avoid timed mode changes in favor of direct manipulation.","pos":[9857,9914]},{"content":"Direct manipulation simulates the direct, real-time physical handling of an object.","pos":[9915,9998]},{"content":"The object responds as the fingers are moved.","pos":[9999,10044]},{"content":"A timed interaction, on the other hand, occurs after a touch interaction.","pos":[10046,10119]},{"content":"Timed interactions typically depend on invisible thresholds like time, distance, or speed to determine what command to perform.","pos":[10120,10247]},{"content":"Timed interactions have no visual feedback until the system performs the action.","pos":[10248,10328]},{"content":"Direct manipulation provides a number of benefits over timed interactions:","pos":[10330,10404]},{"content":"Instant visual feedback during interactions make users feel more engaged, confident, and in control.","pos":[10410,10510]},{"content":"Direct manipulations make it safer to explore a system because they are reversibleâ€”users can easily step back through their actions in a logical and intuitive manner.","pos":[10515,10681]},{"content":"Interactions that directly affect objects and mimic real world interactions are more intuitive, discoverable, and memorable.","pos":[10686,10810]},{"content":"They don't rely on obscure or abstract interactions.","pos":[10811,10863]},{"content":"Timed interactions can be difficult to perform, as users must reach arbitrary and invisible thresholds.","pos":[10868,10971]},{"content":"In addition, the following are strongly recommended:","pos":[10973,11025]},{"content":"Manipulations should not be distinguished by the number of fingers used.","pos":[11031,11103]},{"content":"Interactions should support compound manipulations.","pos":[11108,11159]},{"content":"For example, pinch to zoom while dragging the fingers to pan.","pos":[11160,11221]},{"content":"Interactions should not be distinguished by time.","pos":[11226,11275]},{"content":"The same interaction should have the same outcome regardless of the time taken to perform it.","pos":[11276,11369]},{"content":"Time-based activations introduce mandatory delays for users and detract from both the immersive nature of direct manipulation and the perception of system responsiveness.","pos":[11370,11540]},{"pos":[11546,11690],"content":"<bpt id=\"p1\">**</bpt>Note<ept id=\"p1\">**</ept>  An exception to this is where you use specific timed interactions to assist in learning and exploration (for example, press and hold)."},{"content":"Appropriate descriptions and visual cues have a great effect on the use of advanced interactions.","pos":[11703,11800]},{"pos":[11890,11899],"content":"App views"},{"content":"Tweak the user interaction experience through the pan/scroll and zoom settings of your app views.","pos":[11902,11999]},{"content":"An app view dictates how a user accesses and manipulates your app and its content.","pos":[12000,12082]},{"content":"Views also provide behaviors such as inertia, content boundary bounce, and snap points.","pos":[12083,12170]},{"content":"Pan and scroll settings of the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ScrollViewer<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br209527)</ept> control dictate how users navigate within a single view, when the content of the view doesn't fit within the viewport.","pos":[12172,12398]},{"content":"A single view can be, for example, a page of a magazine or book, the folder structure of a computer, a library of documents, or a photo album.","pos":[12399,12541]},{"content":"Zoom settings apply to both optical zoom (supported by the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ScrollViewer<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br209527)</ept> control) and the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>Semantic Zoom<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/hh702601)</ept> control.","pos":[12543,12782]},{"content":"Semantic Zoom is a touch-optimized technique for presenting and navigating large sets of related data or content within a single view.","pos":[12783,12917]},{"content":"It works by using two distinct modes of classification, or zoom levels.","pos":[12918,12989]},{"content":"This is analogous to panning and scrolling within a single view.","pos":[12990,13054]},{"content":"Panning and scrolling can be used in conjunction with Semantic Zoom.","pos":[13055,13123]},{"content":"Use app views and events to modify the pan/scroll and zoom behaviors.","pos":[13125,13194]},{"content":"This can provide a smoother interaction experience than is possible through the handling of pointer and gesture events.","pos":[13195,13314]},{"pos":[13316,13439],"content":"For more info about app views, see <bpt id=\"p1\">[</bpt>Controls, layouts, and text<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/mt228348)</ept>."},{"pos":[13522,13547],"content":"Custom touch interactions"},{"content":"If you implement your own interaction support, keep in mind that users expect an intuitive experience involving direct interaction with the UI elements in your app.","pos":[13550,13714]},{"content":"We recommend that you model your custom interactions on the platform control libraries to keep things consistent and discoverable.","pos":[13715,13845]},{"content":"The controls in these libraries provide the full user interaction experience, including standard interactions, animated physics effects, visual feedback, and accessibility.","pos":[13846,14018]},{"content":"Create custom interactions only if there is a clear, well-defined requirement and basic interactions don't support your scenario.","pos":[14019,14148]},{"content":"To provide customized touch support, you can handle various <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>UIElement<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208911)</ept> events.","pos":[14150,14291]},{"content":"These events are grouped into three levels of abstraction.","pos":[14292,14350]},{"content":"Static gesture events are triggered after an interaction is complete.","pos":[14356,14425]},{"content":"Gesture events include <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Tapped<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208985)</ept>, <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>DoubleTapped<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br208922)</ept>, <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>RightTapped<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/br208984)</ept>, and <bpt id=\"p7\">[</bpt><bpt id=\"p8\">**</bpt>Holding<ept id=\"p8\">**</ept><ept id=\"p7\">](https://msdn.microsoft.com/library/windows/apps/br208928)</ept>.","pos":[14426,14752]},{"pos":[14758,15164],"content":"You can disable gesture events on specific elements by setting <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IsTapEnabled<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208939)</ept>, <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>IsDoubleTapEnabled<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br208931)</ept>, <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>IsRightTapEnabled<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/br208937)</ept>, and <bpt id=\"p7\">[</bpt><bpt id=\"p8\">**</bpt>IsHoldingEnabled<ept id=\"p8\">**</ept><ept id=\"p7\">](https://msdn.microsoft.com/library/windows/apps/br208935)</ept> to <bpt id=\"p9\">**</bpt>false<ept id=\"p9\">**</ept>."},{"pos":[15170,15484],"content":"Pointer events such as <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>PointerPressed<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208971)</ept> and <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>PointerMoved<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br208970)</ept> provide low-level details for each touch contact, including pointer motion and the ability to distinguish press and release events."},{"content":"A pointer is a generic input type with a unified event mechanism.","pos":[15490,15555]},{"content":"It exposes basic info, such as screen position, on the active input source, which can be touch, touchpad, mouse, or pen.","pos":[15556,15676]},{"content":"Manipulation gesture events, such as <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ManipulationStarted<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208950)</ept>, indicate an ongoing interaction.","pos":[15682,15836]},{"content":"They start firing when the user touches an element and continue until the user lifts their finger(s), or the manipulation is canceled.","pos":[15837,15971]},{"content":"Manipulation events include multi-touch interactions such as zooming, panning, or rotating, and interactions that use inertia and velocity data such as dragging.","pos":[15977,16138]},{"content":"The information provided by the manipulation events doesn't identify the form of the interaction that was performed, but rather includes data such as position, translation delta, and velocity.","pos":[16139,16331]},{"content":"You can use this touch data to determine the type of interaction that should be performed.","pos":[16332,16422]},{"content":"Here is the basic set of touch gestures supported by the UWP.","pos":[16424,16485]},{"content":"Name","pos":[16489,16493]},{"content":"Type","pos":[16506,16510]},{"content":"Description","pos":[16529,16540]},{"content":"Tap","pos":[16751,16754]},{"content":"Static gesture","pos":[16768,16782]},{"content":"One finger touches the screen and lifts up.","pos":[16791,16834]},{"content":"Press and hold","pos":[16882,16896]},{"content":"Static gesture","pos":[16899,16913]},{"content":"One finger touches the screen and stays in place.","pos":[16922,16971]},{"content":"Slide","pos":[17013,17018]},{"content":"Manipulation gesture","pos":[17030,17050]},{"content":"One or more fingers touch the screen and move in the same direction.","pos":[17053,17121]},{"content":"Swipe","pos":[17144,17149]},{"content":"Manipulation gesture","pos":[17161,17181]},{"content":"One or more fingers touch the screen and move a short distance in the same direction.","pos":[17184,17269]},{"content":"Turn","pos":[17275,17279]},{"content":"Manipulation gesture","pos":[17292,17312]},{"content":"Two or more fingers touch the screen and move in a clockwise or counter-clockwise arc.","pos":[17315,17401]},{"content":"Pinch","pos":[17406,17411]},{"content":"Manipulation gesture","pos":[17423,17443]},{"content":"Two or more fingers touch the screen and move closer together.","pos":[17446,17508]},{"content":"Stretch","pos":[17537,17544]},{"content":"Manipulation gesture","pos":[17554,17574]},{"content":"Two or more fingers touch the screen and move farther apart.","pos":[17577,17637]},{"pos":[17932,17946],"content":"Gesture events"},{"pos":[17949,18066],"content":"For details about individual controls, see <bpt id=\"p1\">[</bpt>Controls list<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/mt185406)</ept>."},{"pos":[18149,18163],"content":"Pointer events"},{"content":"Pointer events are raised by a variety of active input sources, including touch, touchpad, pen, and mouse (they replace traditional mouse events.)","pos":[18166,18312]},{"content":"Pointer events are based on a single input point (finger, pen tip, mouse cursor) and do not support velocity-based interactions.","pos":[18314,18442]},{"content":"Here is a list of pointer events and their related event argument.","pos":[18444,18510]},{"content":"Event or class","pos":[18514,18528]},{"content":"Description","pos":[18585,18596]},{"content":"PointerPressed","pos":[18791,18805]},{"content":"Occurs when a single finger touches the screen.","pos":[18881,18928]},{"content":"PointerReleased","pos":[18950,18965]},{"content":"Occurs when that same touch contact is lifted.","pos":[19039,19085]},{"content":"PointerMoved","pos":[19108,19120]},{"content":"Occurs when the pointer is dragged across the screen.","pos":[19200,19253]},{"content":"PointerEntered","pos":[19269,19283]},{"content":"Occurs when a pointer enters the hit test area of an element.","pos":[19359,19420]},{"content":"PointerExited","pos":[19428,19441]},{"content":"Occurs when a pointer exits the hit test area of an element.","pos":[19519,19579]},{"content":"PointerCanceled","pos":[19588,19603]},{"content":"Occurs when a touch contact is abnormally lost.","pos":[19677,19724]},{"content":"PointerCaptureLost","pos":[19746,19764]},{"content":"Occurs when a pointer capture is taken by another element.","pos":[19832,19890]},{"content":"PointerWheelChanged","pos":[19901,19920]},{"content":"Occurs when the delta value of a mouse wheel changes.","pos":[19986,20039]},{"content":"PointerRoutedEventArgs","pos":[20055,20077]},{"content":"Provides data for all pointer events.","pos":[20141,20178]},{"pos":[20209,20616],"content":"The following example shows how to use the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>PointerPressed<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208971)</ept>, <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>PointerReleased<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br208972)</ept>, and <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>PointerExited<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/br208969)</ept> events to handle a tap interaction on a <bpt id=\"p7\">[</bpt><bpt id=\"p8\">**</bpt>Rectangle<ept id=\"p8\">**</ept><ept id=\"p7\">](https://msdn.microsoft.com/library/windows/apps/br243371)</ept> object."},{"pos":[20618,20784],"content":"First, a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Rectangle<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br243371)</ept> named <ph id=\"ph1\">`touchRectangle`</ph> is created in Extensible Application Markup Language (XAML)."},{"pos":[21333,21621],"content":"Next, listeners for the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>PointerPressed<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208971)</ept>, <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>PointerReleased<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br208972)</ept>, and <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>PointerExited<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/br208969)</ept> events are specified."},{"pos":[22815,23412],"content":"Finally, the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>PointerPressed<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208971)</ept> event handler increases the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>Height<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br208718)</ept> and <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>Width<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/br208751)</ept> of the <bpt id=\"p7\">[</bpt><bpt id=\"p8\">**</bpt>Rectangle<ept id=\"p8\">**</ept><ept id=\"p7\">](https://msdn.microsoft.com/library/windows/apps/br243371)</ept>, while the <bpt id=\"p9\">[</bpt><bpt id=\"p10\">**</bpt>PointerReleased<ept id=\"p10\">**</ept><ept id=\"p9\">](https://msdn.microsoft.com/library/windows/apps/br208972)</ept> and <bpt id=\"p11\">[</bpt><bpt id=\"p12\">**</bpt>PointerExited<ept id=\"p12\">**</ept><ept id=\"p11\">](https://msdn.microsoft.com/library/windows/apps/br208969)</ept> event handlers set the <bpt id=\"p13\">**</bpt>Height<ept id=\"p13\">**</ept> and <bpt id=\"p14\">**</bpt>Width<ept id=\"p14\">**</ept> back to their starting values."},{"pos":[26585,26604],"content":"Manipulation events"},{"content":"Use manipulation events if you need to support multiple finger interactions in your app, or interactions that require velocity data.","pos":[26607,26739]},{"content":"You can use manipulation events to detect interactions such as drag, zoom, and hold.","pos":[26741,26825]},{"content":"Here is a list of manipulation events and related event arguments.","pos":[26827,26893]},{"content":"Event or class","pos":[26897,26911]},{"content":"Description","pos":[27008,27019]},{"content":"ManipulationStarting event","pos":[27406,27432]},{"content":"Occurs when the manipulation processor is first created.","pos":[27530,27586]},{"content":"ManipulationStarted event","pos":[27675,27700]},{"pos":[27800,27931],"content":"Occurs when an input device begins a manipulation on the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>UIElement<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208911)</ept>."},{"content":"ManipulationDelta event","pos":[27982,28005]},{"content":"Occurs when the input device changes position during a manipulation.","pos":[28109,28177]},{"content":"ManipulationInertiaStarting event","pos":[28254,28287]},{"pos":[28366,28540],"content":"Occurs when the input device loses contact with the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>UIElement<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208911)</ept> object during a manipulation and inertia begins."},{"content":"ManipulationCompleted event","pos":[28548,28575]},{"pos":[28671,28804],"content":"Occurs when a manipulation and inertia on the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>UIElement<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208911)</ept> are complete."},{"content":"ManipulationStartingRoutedEventArgs","pos":[28853,28888]},{"pos":[28966,29079],"content":"Provides data for the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ManipulationStarting<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208951)</ept> event."},{"content":"ManipulationStartedRoutedEventArgs","pos":[29127,29161]},{"pos":[29241,29353],"content":"Provides data for the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ManipulationStarted<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208950)</ept> event."},{"content":"ManipulationDeltaRoutedEventArgs","pos":[29403,29435]},{"pos":[29519,29629],"content":"Provides data for the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ManipulationDelta<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208946)</ept> event."},{"content":"ManipulationInertiaStartingRoutedEventArgs","pos":[29683,29725]},{"pos":[29789,29909],"content":"Provides data for the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ManipulationInertiaStarting<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208947)</ept> event."},{"content":"ManipulationVelocities","pos":[29943,29965]},{"content":"Describes the speed at which manipulations occur.","pos":[30074,30123]},{"content":"ManipulationCompletedRoutedEventArgs","pos":[30219,30255]},{"pos":[30331,30445],"content":"Provides data for the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ManipulationCompleted<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208945)</ept> event."},{"content":"A gesture consists of a series of manipulation events.","pos":[30490,30544]},{"content":"Each gesture starts with a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ManipulationStarted<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208950)</ept> event, such as when a user touches the screen.","pos":[30545,30702]},{"content":"Next, one or more <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ManipulationDelta<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208946)</ept> events are fired.","pos":[30704,30821]},{"content":"For example, if you touch the screen and then drag your finger across the screen.","pos":[30822,30903]},{"content":"Finally, a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ManipulationCompleted<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208945)</ept> event is raised when the interaction finishes.","pos":[30904,31047]},{"pos":[31049,31200],"content":"<bpt id=\"p1\">**</bpt>Note<ept id=\"p1\">**</ept>  If you don't have a touch-screen monitor, you can test your manipulation event code in the simulator using a mouse and mouse wheel interface."},{"pos":[31205,31476],"content":"The following example shows how to use the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ManipulationDelta<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208946)</ept> events to handle a slide interaction on a <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>Rectangle<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br243371)</ept> and move it across the screen."},{"pos":[31478,31762],"content":"First, a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Rectangle<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br243371)</ept> named <ph id=\"ph1\">`touchRectangle`</ph> is created in XAML with a <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>Height<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br208718)</ept> and <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>Width<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/br208751)</ept> of 200."},{"content":"Next, a global <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>TranslateTransform<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br243027)</ept> named <ph id=\"ph1\">`dragTranslation`</ph> is created for translating the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>Rectangle<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br243371)</ept>.","pos":[32425,32652]},{"content":"A <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ManipulationDelta<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208946)</ept> event listener is specified on the <bpt id=\"p3\">**</bpt>Rectangle<ept id=\"p3\">**</ept>, and <ph id=\"ph1\">`dragTranslation`</ph> is added to the <bpt id=\"p4\">[</bpt><bpt id=\"p5\">**</bpt>RenderTransform<ept id=\"p5\">**</ept><ept id=\"p4\">](https://msdn.microsoft.com/library/windows/apps/br208980)</ept> of the <bpt id=\"p6\">**</bpt>Rectangle<ept id=\"p6\">**</ept>.","pos":[32653,32926]},{"pos":[35014,35414],"content":"Finally, in the <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>ManipulationDelta<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208946)</ept> event handler, the position of the <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>Rectangle<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br243371)</ept> is updated by using the <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>TranslateTransform<ept id=\"p6\">**</ept><ept id=\"p5\">](https://msdn.microsoft.com/library/windows/apps/br243027)</ept> on the <bpt id=\"p7\">[</bpt><bpt id=\"p8\">**</bpt>Delta<ept id=\"p8\">**</ept><ept id=\"p7\">](https://msdn.microsoft.com/library/windows/apps/hh702058)</ept> property."},{"pos":[36763,36776],"content":"Routed events"},{"content":"All of the pointer events, gesture events and manipulation events mentioned here are implemented as <bpt id=\"p1\">*</bpt>routed events<ept id=\"p1\">*</ept>.","pos":[36779,36895]},{"content":"This means that the event can potentially be handled by objects other than the one that originally raised the event.","pos":[36896,37012]},{"content":"Successive parents in an object tree, such as the parent containers of a <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>UIElement<ept id=\"p2\">**</ept><ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/br208911)</ept> or the root <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>Page<ept id=\"p4\">**</ept><ept id=\"p3\">](https://msdn.microsoft.com/library/windows/apps/br227503)</ept> of your app, can choose to handle these events even if the original element does not.","pos":[37013,37326]},{"content":"Conversely, any object that does handle the event can mark the event handled so that it no longer reaches any parent element.","pos":[37327,37452]},{"content":"For more info about the routed event concept and how it affects how you write handlers for routed events, see <bpt id=\"p1\">[</bpt>Events and routed events overview<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/apps/hh758286)</ept>.","pos":[37453,37657]},{"pos":[37761,37775],"content":"Dos and don'ts"},{"content":"Design applications with touch interaction as the primary expected input method.","pos":[37782,37862]},{"content":"Provide visual feedback for interactions of all types (touch, pen, stylus, mouse, etc.)","pos":[37867,37954]},{"content":"Optimize targeting by adjusting touch target size, contact geometry, scrubbing and rocking.","pos":[37959,38050]},{"content":"Optimize accuracy through the use of snap points and directional \"rails\".","pos":[38055,38128]},{"content":"Provide tooltips and handles to help improve touch accuracy for tightly packed UI items.","pos":[38133,38221]},{"content":"Don't use timed interactions whenever possible (example of appropriate use: touch and hold).","pos":[38226,38318]},{"content":"Don't use the number of fingers used to distinguish the manipulation whenever possible.","pos":[38323,38410]},{"pos":[38449,38465],"content":"Related articles"},{"content":"Handle pointer input","pos":[38470,38490]},{"pos":[38519,38582],"content":"<bpt id=\"p1\">[</bpt>Identify input devices<ept id=\"p1\">](identify-input-devices.md)</ept><ph id=\"ph1\">\n</ph><bpt id=\"p2\">**</bpt>Samples<ept id=\"p2\">**</ept>"},{"content":"Basic input sample","pos":[38586,38604]},{"content":"Low latency input sample","pos":[38658,38682]},{"content":"User interaction mode sample","pos":[38736,38764]},{"pos":[38817,38908],"content":"<bpt id=\"p1\">[</bpt>Focus visuals sample<ept id=\"p1\">](http://go.microsoft.com/fwlink/p/?LinkID=619895)</ept><ph id=\"ph1\">\n</ph><bpt id=\"p2\">**</bpt>Archive Samples<ept id=\"p2\">**</ept>"},{"content":"Input: Device capabilities sample","pos":[38912,38945]},{"content":"Input: XAML user input events sample","pos":[38999,39035]},{"content":"XAML scrolling, panning, and zooming sample","pos":[39089,39132]},{"content":"Input: Gestures and manipulations with GestureRecognizer","pos":[39186,39242]}],"content":"---\nauthor: Karl-Bridge-Microsoft\nDescription: Create Universal Windows Platform (UWP) apps with intuitive and distinctive user interaction experiences that are optimized for touch but are functionally consistent across input devices.\ntitle: Touch interactions\nms.assetid: DA6EBC88-EB18-4418-A98A-457EA1DEA88A\nlabel: Touch interactions\ntemplate: detail.hbs\n---\n\n# Touch interactions\n\n\nDesign your app with the expectation that touch will be the primary input method of your users. If you use UWP controls, support for touchpad, mouse, and pen/stylus requires no additional programming, because UWP apps provide this for free.\n\nHowever, keep in mind that a UI optimized for touch is not always superior to a traditional UI. Both provide advantages and disadvantages that are unique to a technology and application. In the move to a touch-first UI, it is important to understand the core differences between touch (including touchpad), pen/stylus, mouse, and keyboard input.\n\n**Important APIs**\n\n-   [**Windows.UI.Xaml.Input**](https://msdn.microsoft.com/library/windows/apps/br227994)\n-   [**Windows.UI.Core**](https://msdn.microsoft.com/library/windows/apps/br208383)\n-   [**Windows.Devices.Input**](https://msdn.microsoft.com/library/windows/apps/br225648)\n\n\n\nMany devices have multi-touch screens that support using one or more fingers (or touch contacts) as input. The touch contacts, and their movement, are interpreted as touch gestures and manipulations to support various user interactions.\n\nThe Universal Windows Platform (UWP) includes a number of different mechanisms for handling touch input, enabling you to create an immersive experience that your users can explore with confidence. Here, we cover the basics of using touch input in a UWP app.\n\nTouch interactions require three things:\n\n-   A touch-sensitive display.\n-   The direct contact (or proximity to, if the display has proximity sensors and supports hover detection) of one or more fingers on that display.\n-   Movement of the touch contacts (or lack thereof, based on a time threshold).\n\nThe input data provided by the touch sensor can be:\n\n-   Interpreted as a physical gesture for direct manipulation of one or more UI elements (such as panning, rotating, resizing, or moving). In contrast, interacting with an element through its properties window, dialog box, or other UI affordance is considered indirect manipulation.\n-   Recognized as an alternative input method, such as mouse or pen.\n-   Used to complement or modify aspects of other input methods, such as smudging an ink stroke drawn with a pen.\n\nTouch input typically involves the direct manipulation of an element on the screen. The element responds immediately to any touch contact within its hit test area, and reacts appropriately to any subsequent movement of the touch contacts, including removal.\n\nCustom touch gestures and interactions should be designed carefully. They should be intuitive, responsive, and discoverable, and they should let users explore your app with confidence.\n\nEnsure that app functionality is exposed consistently across every supported input device type. If necessary, use some form of indirect input mode, such as text input for keyboard interactions, or UI affordances for mouse and pen.\n\nRemember that traditional input devices (such as mouse and keyboard), are familiar and appealing to many users. They can offer speed, accuracy, and tactile feedback that touch might not.\n\nProviding unique and distinctive interaction experiences for all input devices will support the widest range of capabilities and preferences, appeal to the broadest possible audience, and attract more customers to your app.\n\n## Compare touch interaction requirements\n\nThe following table shows some of the differences between input devices that you should consider when you design touch-optimized UWP apps.\n\n<table>\n<tbody><tr><th>Factor</th><th>Touch interactions</th><th>Mouse, keyboard, pen/stylus interactions</th><th>Touchpad</th></tr>\n<tr><td rowspan=\"3\">Precision</td><td>The contact area of a fingertip is greater than a single x-y coordinate, which increases the chances of unintended command activations.</td><td>The mouse and pen/stylus supply a precise x-y coordinate.</td><td>Same as mouse.</td></tr>\n<tr><td>The shape  of the contact area changes throughout the movement.  </td><td>Mouse movements and pen/stylus strokes supply precise x-y coordinates. Keyboard focus is explicit.</td><td>Same as mouse.</td></tr>\n<tr><td>There is no mouse cursor to assist with targeting.</td><td>The mouse cursor, pen/stylus cursor, and keyboard focus all assist with targeting.</td><td>Same as mouse.</td></tr>\n<tr><td rowspan=\"3\">Human anatomy</td><td>Fingertip movements are imprecise, because a straight-line motion with one or more fingers is difficult. This is due to the curvature of hand joints and the number of joints involved in the motion.</td><td>It's easier to perform a straight-line motion with the mouse or pen/stylus because the hand that controls them travels a shorter physical distance than the cursor on the screen.</td><td>Same as mouse.</td></tr>\n<tr><td>Some areas on the touch surface of a display device can be difficult to reach due to finger posture and the user's grip on the device.</td><td>The mouse and pen/stylus can reach any part of the screen while any control should be accessible by the keyboard through tab order. </td><td>Finger posture and grip can be an issue.</td></tr>\n<tr><td>Objects might be obscured by one or more fingertips or the user's hand. This is known as occlusion.</td><td>Indirect input devices do not cause  occlusion.</td><td>Same as mouse.</td></tr>\n<tr><td>Object state</td><td>Touch uses a two-state model: the touch surface of a display device  is either touched (on) or not (off). There is no hover state that can trigger additional visual feedback.</td><td>\n<p>A mouse, pen/stylus, and keyboard all expose a three-state model: up (off), down (on), and hover (focus).</p>\n<p>Hover lets users explore and learn through tooltips  associated with UI elements. Hover and focus effects  can relay which objects are interactive and also help with targeting. \n</p>\n</td><td>Same as mouse.</td></tr>\n<tr><td rowspan=\"2\">Rich interaction</td><td>Supports multi-touch: multiple input points (fingertips) on a touch surface.</td><td>Supports a single input point.</td><td>Same as touch.</td></tr>\n<tr><td>Supports direct manipulation of objects through gestures such as tapping, dragging, sliding, pinching, and rotating.</td><td>No support for direct manipulation as mouse, pen/stylus, and keyboard are indirect input devices.</td><td>Same as mouse.</td></tr>\n</tbody></table>\n\n\n\n**Note**  \nIndirect input has had the benefit of more than 25 years of refinement. Features such as hover-triggered tooltips have been designed to solve UI exploration specifically for touchpad, mouse, pen/stylus, and keyboard input. UI features like this have been re-designed for the rich experience provided by touch input, without compromising the user experience for these other devices.\n\n \n\n## Use touch feedback\n\nAppropriate visual feedback during interactions with your app helps users recognize, learn, and adapt to how their interactions are interpreted by both the app and Windows 8. Visual feedback can indicate successful interactions, relay system status, improve the sense of control, reduce errors, help users understand the system and input device, and encourage interaction.\n\nVisual feedback is critical when the user relies on touch input for activities that require accuracy and precision based on location. Display feedback whenever and wherever touch input is detected, to help the user understand any custom targeting rules that are defined by your app and its controls.\n\n\n## Targeting\n\nTargeting is optimized through:\n\n-   Touch target sizes\n\n    Clear size guidelines ensure that applications provide a comfortable UI that contains objects and controls that are easy and safe to target.\n\n-   Contact geometry\n\n    The entire contact area of the finger determines the most likely target object.\n\n-   Scrubbing\n\n    Items within a group are easily re-targeted by dragging the finger between them (for example, radio buttons). The current item is activated when the touch is released.\n\n-   Rocking\n\n    Densely packed items (for example, hyperlinks) are easily re-targeted by pressing the finger down and, without sliding, rocking it back and forth over the items. Due to occlusion, the current item is identified through a tooltip or the status bar and is activated when the touch is released.\n\n## Accuracy\n\nDesign for sloppy interactions by using:\n\n-   Snap-points that can make it easier to stop at desired locations when users interact with content.\n-   Directional \"rails\" that can assist with vertical or horizontal panning, even when the hand moves in a slight arc. For more information, see [Guidelines for panning](guidelines-for-panning.md).\n\n## Occlusion\n\nFinger and hand occlusion is avoided through:\n\n-   Size and positioning of UI\n\n    Make UI elements big enough so that they cannot be completely covered by a fingertip contact area.\n\n    Position menus and pop-ups above the contact area whenever possible.\n\n-   Tooltips\n\n    Show tooltips when a user maintains finger contact on an object. This is useful for describing object functionality. The user can drag the fingertip off the object to avoid invoking the tooltip.\n\n    For small objects, offset tooltips so they are not covered by the fingertip contact area. This is helpful for targeting.\n\n-   Handles for precision\n\n    Where precision is required (for example, text selection), provide selection handles that are offset to improve accuracy. For more information, see [Guidelines for selecting text and images (Windows Runtime apps)](guidelines-for-textselection.md).\n\n## Timing\n\nAvoid timed mode changes in favor of direct manipulation. Direct manipulation simulates the direct, real-time physical handling of an object. The object responds as the fingers are moved.\n\nA timed interaction, on the other hand, occurs after a touch interaction. Timed interactions typically depend on invisible thresholds like time, distance, or speed to determine what command to perform. Timed interactions have no visual feedback until the system performs the action.\n\nDirect manipulation provides a number of benefits over timed interactions:\n\n-   Instant visual feedback during interactions make users feel more engaged, confident, and in control.\n-   Direct manipulations make it safer to explore a system because they are reversibleâ€”users can easily step back through their actions in a logical and intuitive manner.\n-   Interactions that directly affect objects and mimic real world interactions are more intuitive, discoverable, and memorable. They don't rely on obscure or abstract interactions.\n-   Timed interactions can be difficult to perform, as users must reach arbitrary and invisible thresholds.\n\nIn addition, the following are strongly recommended:\n\n-   Manipulations should not be distinguished by the number of fingers used.\n-   Interactions should support compound manipulations. For example, pinch to zoom while dragging the fingers to pan.\n-   Interactions should not be distinguished by time. The same interaction should have the same outcome regardless of the time taken to perform it. Time-based activations introduce mandatory delays for users and detract from both the immersive nature of direct manipulation and the perception of system responsiveness.\n\n    **Note**  An exception to this is where you use specific timed interactions to assist in learning and exploration (for example, press and hold).\n\n     \n\n-   Appropriate descriptions and visual cues have a great effect on the use of advanced interactions.\n\n\n## <span id=\"App_views\"></span><span id=\"app_views\"></span><span id=\"APP_VIEWS\"></span>App views\n\n\nTweak the user interaction experience through the pan/scroll and zoom settings of your app views. An app view dictates how a user accesses and manipulates your app and its content. Views also provide behaviors such as inertia, content boundary bounce, and snap points.\n\nPan and scroll settings of the [**ScrollViewer**](https://msdn.microsoft.com/library/windows/apps/br209527) control dictate how users navigate within a single view, when the content of the view doesn't fit within the viewport. A single view can be, for example, a page of a magazine or book, the folder structure of a computer, a library of documents, or a photo album.\n\nZoom settings apply to both optical zoom (supported by the [**ScrollViewer**](https://msdn.microsoft.com/library/windows/apps/br209527) control) and the [**Semantic Zoom**](https://msdn.microsoft.com/library/windows/apps/hh702601) control. Semantic Zoom is a touch-optimized technique for presenting and navigating large sets of related data or content within a single view. It works by using two distinct modes of classification, or zoom levels. This is analogous to panning and scrolling within a single view. Panning and scrolling can be used in conjunction with Semantic Zoom.\n\nUse app views and events to modify the pan/scroll and zoom behaviors. This can provide a smoother interaction experience than is possible through the handling of pointer and gesture events.\n\nFor more info about app views, see [Controls, layouts, and text](https://msdn.microsoft.com/library/windows/apps/mt228348).\n\n## <span id=\"intro_to_touch_input\"></span><span id=\"INTRO_TO_TOUCH_INPUT\"></span>Custom touch interactions\n\n\nIf you implement your own interaction support, keep in mind that users expect an intuitive experience involving direct interaction with the UI elements in your app. We recommend that you model your custom interactions on the platform control libraries to keep things consistent and discoverable. The controls in these libraries provide the full user interaction experience, including standard interactions, animated physics effects, visual feedback, and accessibility. Create custom interactions only if there is a clear, well-defined requirement and basic interactions don't support your scenario.\n\nTo provide customized touch support, you can handle various [**UIElement**](https://msdn.microsoft.com/library/windows/apps/br208911) events. These events are grouped into three levels of abstraction.\n\n-   Static gesture events are triggered after an interaction is complete. Gesture events include [**Tapped**](https://msdn.microsoft.com/library/windows/apps/br208985), [**DoubleTapped**](https://msdn.microsoft.com/library/windows/apps/br208922), [**RightTapped**](https://msdn.microsoft.com/library/windows/apps/br208984), and [**Holding**](https://msdn.microsoft.com/library/windows/apps/br208928).\n\n    You can disable gesture events on specific elements by setting [**IsTapEnabled**](https://msdn.microsoft.com/library/windows/apps/br208939), [**IsDoubleTapEnabled**](https://msdn.microsoft.com/library/windows/apps/br208931), [**IsRightTapEnabled**](https://msdn.microsoft.com/library/windows/apps/br208937), and [**IsHoldingEnabled**](https://msdn.microsoft.com/library/windows/apps/br208935) to **false**.\n\n-   Pointer events such as [**PointerPressed**](https://msdn.microsoft.com/library/windows/apps/br208971) and [**PointerMoved**](https://msdn.microsoft.com/library/windows/apps/br208970) provide low-level details for each touch contact, including pointer motion and the ability to distinguish press and release events.\n\n    A pointer is a generic input type with a unified event mechanism. It exposes basic info, such as screen position, on the active input source, which can be touch, touchpad, mouse, or pen.\n\n-   Manipulation gesture events, such as [**ManipulationStarted**](https://msdn.microsoft.com/library/windows/apps/br208950), indicate an ongoing interaction. They start firing when the user touches an element and continue until the user lifts their finger(s), or the manipulation is canceled.\n\n    Manipulation events include multi-touch interactions such as zooming, panning, or rotating, and interactions that use inertia and velocity data such as dragging. The information provided by the manipulation events doesn't identify the form of the interaction that was performed, but rather includes data such as position, translation delta, and velocity. You can use this touch data to determine the type of interaction that should be performed.\n\nHere is the basic set of touch gestures supported by the UWP.\n\n| Name           | Type                 | Description                                                                            |\n|----------------|----------------------|----------------------------------------------------------------------------------------|\n| Tap            | Static gesture       | One finger touches the screen and lifts up.                                            |\n| Press and hold | Static gesture       | One finger touches the screen and stays in place.                                      |\n| Slide          | Manipulation gesture | One or more fingers touch the screen and move in the same direction.                   |\n| Swipe          | Manipulation gesture | One or more fingers touch the screen and move a short distance in the same direction.  |\n| Turn           | Manipulation gesture | Two or more fingers touch the screen and move in a clockwise or counter-clockwise arc. |\n| Pinch          | Manipulation gesture | Two or more fingers touch the screen and move closer together.                         |\n| Stretch        | Manipulation gesture | Two or more fingers touch the screen and move farther apart.                           |\n\n \n\n<!-- mijacobs: Removing for now. We don't have a real page to link to yet. \nFor more info about gestures, manipulations, and interactions, see [Custom user interactions](custom-user-input-portal.md).\n-->\n\n## <span id=\"gestures\"></span><span id=\"GESTURES\"></span>Gesture events\n\n\nFor details about individual controls, see [Controls list](https://msdn.microsoft.com/library/windows/apps/mt185406).\n\n## <span id=\"using_pointer_events\"></span><span id=\"USING_POINTER_EVENTS\"></span>Pointer events\n\n\nPointer events are raised by a variety of active input sources, including touch, touchpad, pen, and mouse (they replace traditional mouse events.)\n\nPointer events are based on a single input point (finger, pen tip, mouse cursor) and do not support velocity-based interactions.\n\nHere is a list of pointer events and their related event argument.\n\n| Event or class                                                       | Description                                                   |\n|----------------------------------------------------------------------|---------------------------------------------------------------|\n| [**PointerPressed**](https://msdn.microsoft.com/library/windows/apps/br208971)             | Occurs when a single finger touches the screen.               |\n| [**PointerReleased**](https://msdn.microsoft.com/library/windows/apps/br208972)           | Occurs when that same touch contact is lifted.                |\n| [**PointerMoved**](https://msdn.microsoft.com/library/windows/apps/br208970)                 | Occurs when the pointer is dragged across the screen.         |\n| [**PointerEntered**](https://msdn.microsoft.com/library/windows/apps/br208968)             | Occurs when a pointer enters the hit test area of an element. |\n| [**PointerExited**](https://msdn.microsoft.com/library/windows/apps/br208969)               | Occurs when a pointer exits the hit test area of an element.  |\n| [**PointerCanceled**](https://msdn.microsoft.com/library/windows/apps/br208964)           | Occurs when a touch contact is abnormally lost.               |\n| [**PointerCaptureLost**](https://msdn.microsoft.com/library/windows/apps/br208965)     | Occurs when a pointer capture is taken by another element.    |\n| [**PointerWheelChanged**](https://msdn.microsoft.com/library/windows/apps/br208973)   | Occurs when the delta value of a mouse wheel changes.         |\n| [**PointerRoutedEventArgs**](https://msdn.microsoft.com/library/windows/apps/hh943076) | Provides data for all pointer events.                         |\n\n \n\nThe following example shows how to use the [**PointerPressed**](https://msdn.microsoft.com/library/windows/apps/br208971), [**PointerReleased**](https://msdn.microsoft.com/library/windows/apps/br208972), and [**PointerExited**](https://msdn.microsoft.com/library/windows/apps/br208969) events to handle a tap interaction on a [**Rectangle**](https://msdn.microsoft.com/library/windows/apps/br243371) object.\n\nFirst, a [**Rectangle**](https://msdn.microsoft.com/library/windows/apps/br243371) named `touchRectangle` is created in Extensible Application Markup Language (XAML).\n\n```XAML\n<Grid Background=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\">\n    <Rectangle Name=\"touchRectangle\"\n           Height=\"100\" Width=\"200\" Fill=\"Blue\" />\n</Grid>\n```\n\n```XAML\n<Grid Background=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\">\n    <Rectangle Name=\"touchRectangle\"\n               Height=\"100\" Width=\"200\" Fill=\"Blue\" />\n</Grid>\n```\n\n```XAML\n<Grid Background=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\">\n    <Rectangle Name=\"touchRectangle\"\n           Height=\"100\" Width=\"200\" Fill=\"Blue\" />\n</Grid>\n```\n\nNext, listeners for the [**PointerPressed**](https://msdn.microsoft.com/library/windows/apps/br208971), [**PointerReleased**](https://msdn.microsoft.com/library/windows/apps/br208972), and [**PointerExited**](https://msdn.microsoft.com/library/windows/apps/br208969) events are specified.\n\n```ManagedCPlusPlus\nMainPage::MainPage()\n{\n    InitializeComponent();\n\n    // Pointer event listeners.\n    touchRectangle->PointerPressed += ref new PointerEventHandler(this, &amp;MainPage::touchRectangle_PointerPressed);\n    touchRectangle->PointerReleased += ref new PointerEventHandler(this, &amp;MainPage::touchRectangle_PointerReleased);\n    touchRectangle->PointerExited += ref new PointerEventHandler(this, &amp;MainPage::touchRectangle_PointerExited);\n}\n```\n\n```CSharp\npublic MainPage()\n{\n    this.InitializeComponent();\n\n    // Pointer event listeners.\n    touchRectangle.PointerPressed += touchRectangle_PointerPressed;\n    touchRectangle.PointerReleased += touchRectangle_PointerReleased;\n    touchRectangle.PointerExited += touchRectangle_PointerExited;\n}\n```\n\n```VisualBasic\nPublic Sub New()\n\n    &#39; This call is required by the designer.\n    InitializeComponent()\n\n    &#39; Pointer event listeners.\n    AddHandler touchRectangle.PointerPressed, AddressOf touchRectangle_PointerPressed\n    AddHandler touchRectangle.PointerReleased, AddressOf Me.touchRectangle_PointerReleased\n    AddHandler touchRectangle.PointerExited, AddressOf touchRectangle_PointerExited\n\nEnd Sub\n```\n\nFinally, the [**PointerPressed**](https://msdn.microsoft.com/library/windows/apps/br208971) event handler increases the [**Height**](https://msdn.microsoft.com/library/windows/apps/br208718) and [**Width**](https://msdn.microsoft.com/library/windows/apps/br208751) of the [**Rectangle**](https://msdn.microsoft.com/library/windows/apps/br243371), while the [**PointerReleased**](https://msdn.microsoft.com/library/windows/apps/br208972) and [**PointerExited**](https://msdn.microsoft.com/library/windows/apps/br208969) event handlers set the **Height** and **Width** back to their starting values.\n\n```ManagedCPlusPlus\n// Handler for pointer exited event.\nvoid MainPage::touchRectangle_PointerExited(Object^ sender, PointerRoutedEventArgs^ e)\n{\n    Rectangle^ rect = (Rectangle^)sender;\n\n    // Pointer moved outside Rectangle hit test area.\n    // Reset the dimensions of the Rectangle.\n    if (nullptr != rect)\n    {\n        rect->Width = 200;\n        rect->Height = 100;\n    }\n}\n\n// Handler for pointer released event.\nvoid MainPage::touchRectangle_PointerReleased(Object^ sender, PointerRoutedEventArgs^ e)\n{\n    Rectangle^ rect = (Rectangle^)sender;\n\n    // Reset the dimensions of the Rectangle.\n    if (nullptr != rect)\n    {\n        rect->Width = 200;\n        rect->Height = 100;\n    }\n}\n\n// Handler for pointer pressed event.\nvoid MainPage::touchRectangle_PointerPressed(Object^ sender, PointerRoutedEventArgs^ e)\n{\n    Rectangle^ rect = (Rectangle^)sender;\n\n    // Change the dimensions of the Rectangle.\n    if (nullptr != rect)\n    {\n        rect->Width = 250;\n        rect->Height = 150;\n    }\n}\n```\n\n```CSharp\n// Handler for pointer exited event.\nprivate void touchRectangle_PointerExited(object sender, PointerRoutedEventArgs e)\n{\n    Rectangle rect = sender as Rectangle;\n\n    // Pointer moved outside Rectangle hit test area.\n    // Reset the dimensions of the Rectangle.\n    if (null != rect)\n    {\n        rect.Width = 200;\n        rect.Height = 100;\n    }\n}\n// Handler for pointer released event.\nprivate void touchRectangle_PointerReleased(object sender, PointerRoutedEventArgs e)\n{\n    Rectangle rect = sender as Rectangle;\n\n    // Reset the dimensions of the Rectangle.\n    if (null != rect)\n    {\n        rect.Width = 200;\n        rect.Height = 100;\n    }\n}\n\n// Handler for pointer pressed event.\nprivate void touchRectangle_PointerPressed(object sender, PointerRoutedEventArgs e)\n{\n    Rectangle rect = sender as Rectangle;\n\n    // Change the dimensions of the Rectangle.\n    if (null != rect)\n    {\n        rect.Width = 250;\n        rect.Height = 150;\n    }\n}\n```\n\n```VisualBasic\n&#39; Handler for pointer exited event.\nPrivate Sub touchRectangle_PointerExited(sender As Object, e As PointerRoutedEventArgs)\n    Dim rect As Rectangle = CType(sender, Rectangle)\n\n    &#39; Pointer moved outside Rectangle hit test area.\n    &#39; Reset the dimensions of the Rectangle.\n    If (rect IsNot Nothing) Then\n        rect.Width = 200\n        rect.Height = 100\n    End If\nEnd Sub\n\n&#39; Handler for pointer released event.\nPrivate Sub touchRectangle_PointerReleased(sender As Object, e As PointerRoutedEventArgs)\n    Dim rect As Rectangle = CType(sender, Rectangle)\n\n    &#39; Reset the dimensions of the Rectangle.\n    If (rect IsNot Nothing) Then\n        rect.Width = 200\n        rect.Height = 100\n    End If\nEnd Sub\n\n&#39; Handler for pointer pressed event.\nPrivate Sub touchRectangle_PointerPressed(sender As Object, e As PointerRoutedEventArgs)\n    Dim rect As Rectangle = CType(sender, Rectangle)\n\n    &#39; Change the dimensions of the Rectangle.\n    If (rect IsNot Nothing) Then\n        rect.Width = 250\n        rect.Height = 150\n    End If\nEnd Sub\n```\n\n## <span id=\"using_manipulation_events\"></span><span id=\"USING_MANIPULATION_EVENTS\"></span>Manipulation events\n\n\nUse manipulation events if you need to support multiple finger interactions in your app, or interactions that require velocity data.\n\nYou can use manipulation events to detect interactions such as drag, zoom, and hold.\n\nHere is a list of manipulation events and related event arguments.\n\n| Event or class                                                                                               | Description                                                                                                                               |\n|--------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------|\n| [**ManipulationStarting event**](https://msdn.microsoft.com/library/windows/apps/br208951)                                   | Occurs when the manipulation processor is first created.                                                                                  |\n| [**ManipulationStarted event**](https://msdn.microsoft.com/library/windows/apps/br208950)                                     | Occurs when an input device begins a manipulation on the [**UIElement**](https://msdn.microsoft.com/library/windows/apps/br208911).                                            |\n| [**ManipulationDelta event**](https://msdn.microsoft.com/library/windows/apps/br208946)                                         | Occurs when the input device changes position during a manipulation.                                                                      |\n| [**ManipulationInertiaStarting event**](https://msdn.microsoft.com/library/windows/apps/hh702425)                | Occurs when the input device loses contact with the [**UIElement**](https://msdn.microsoft.com/library/windows/apps/br208911) object during a manipulation and inertia begins. |\n| [**ManipulationCompleted event**](https://msdn.microsoft.com/library/windows/apps/br208945)                                 | Occurs when a manipulation and inertia on the [**UIElement**](https://msdn.microsoft.com/library/windows/apps/br208911) are complete.                                          |\n| [**ManipulationStartingRoutedEventArgs**](https://msdn.microsoft.com/library/windows/apps/hh702132)               | Provides data for the [**ManipulationStarting**](https://msdn.microsoft.com/library/windows/apps/br208951) event.                                         |\n| [**ManipulationStartedRoutedEventArgs**](https://msdn.microsoft.com/library/windows/apps/hh702101)                 | Provides data for the [**ManipulationStarted**](https://msdn.microsoft.com/library/windows/apps/br208950) event.                                           |\n| [**ManipulationDeltaRoutedEventArgs**](https://msdn.microsoft.com/library/windows/apps/hh702051)                     | Provides data for the [**ManipulationDelta**](https://msdn.microsoft.com/library/windows/apps/br208946) event.                                               |\n| [**ManipulationInertiaStartingRoutedEventArgs**](https://msdn.microsoft.com/library/windows/apps/hh702074) | Provides data for the [**ManipulationInertiaStarting**](https://msdn.microsoft.com/library/windows/apps/br208947) event.                           |\n| [**ManipulationVelocities**](https://msdn.microsoft.com/library/windows/apps/br242032)                                              | Describes the speed at which manipulations occur.                                                                                         |\n| [**ManipulationCompletedRoutedEventArgs**](https://msdn.microsoft.com/library/windows/apps/hh702035)             | Provides data for the [**ManipulationCompleted**](https://msdn.microsoft.com/library/windows/apps/br208945) event.                                       |\n\n \n\nA gesture consists of a series of manipulation events. Each gesture starts with a [**ManipulationStarted**](https://msdn.microsoft.com/library/windows/apps/br208950) event, such as when a user touches the screen.\n\nNext, one or more [**ManipulationDelta**](https://msdn.microsoft.com/library/windows/apps/br208946) events are fired. For example, if you touch the screen and then drag your finger across the screen. Finally, a [**ManipulationCompleted**](https://msdn.microsoft.com/library/windows/apps/br208945) event is raised when the interaction finishes.\n\n**Note**  If you don't have a touch-screen monitor, you can test your manipulation event code in the simulator using a mouse and mouse wheel interface.\n\n \n\nThe following example shows how to use the [**ManipulationDelta**](https://msdn.microsoft.com/library/windows/apps/br208946) events to handle a slide interaction on a [**Rectangle**](https://msdn.microsoft.com/library/windows/apps/br243371) and move it across the screen.\n\nFirst, a [**Rectangle**](https://msdn.microsoft.com/library/windows/apps/br243371) named `touchRectangle` is created in XAML with a [**Height**](https://msdn.microsoft.com/library/windows/apps/br208718) and [**Width**](https://msdn.microsoft.com/library/windows/apps/br208751) of 200.\n\n```XAML\n<Grid Background=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\">\n    <Rectangle Name=\"touchRectangle\"\n               Width=\"200\" Height=\"200\" Fill=\"Blue\" \n               ManipulationMode=\"All\"/>\n</Grid>\n```\n\n```XAML\n<Grid Background=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\">\n    <Rectangle Name=\"touchRectangle\"\n               Width=\"200\" Height=\"200\" Fill=\"Blue\" \n               ManipulationMode=\"All\"/>\n</Grid>\n```\n\n```XAML\n<Grid Background=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\">\n    <Rectangle Name=\"touchRectangle\"\n           Width=\"200\" Height=\"200\" Fill=\"Blue\" \n           ManipulationMode=\"All\"/>\n</Grid>\n```\n\nNext, a global [**TranslateTransform**](https://msdn.microsoft.com/library/windows/apps/br243027) named `dragTranslation` is created for translating the [**Rectangle**](https://msdn.microsoft.com/library/windows/apps/br243371). A [**ManipulationDelta**](https://msdn.microsoft.com/library/windows/apps/br208946) event listener is specified on the **Rectangle**, and `dragTranslation` is added to the [**RenderTransform**](https://msdn.microsoft.com/library/windows/apps/br208980) of the **Rectangle**.\n\n```ManagedCPlusPlus\n// Global translation transform used for changing the position of \n// the Rectangle based on input data from the touch contact.\nWindows::UI::Xaml::Media::TranslateTransform^ dragTranslation;\n```\n\n```CSharp\n// Global translation transform used for changing the position of \n// the Rectangle based on input data from the touch contact.\nprivate TranslateTransform dragTranslation;\n```\n\n```VisualBasic\n&#39; Global translation transform used for changing the position of \n&#39; the Rectangle based on input data from the touch contact.\nPrivate dragTranslation As TranslateTransform\n```\n\n```ManagedCPlusPlus\nMainPage::MainPage()\n{\n    InitializeComponent();\n\n    // Listener for the ManipulationDelta event.\n    touchRectangle->ManipulationDelta += \n        ref new ManipulationDeltaEventHandler(\n            this, \n            &amp;MainPage::touchRectangle_ManipulationDelta);\n    // New translation transform populated in \n    // the ManipulationDelta handler.\n    dragTranslation = ref new TranslateTransform();\n    // Apply the translation to the Rectangle.\n    touchRectangle->RenderTransform = dragTranslation;\n}\n```\n\n```CSharp\npublic MainPage()\n{\n    this.InitializeComponent();\n\n    // Listener for the ManipulationDelta event.\n    touchRectangle.ManipulationDelta += touchRectangle_ManipulationDelta;\n    // New translation transform populated in \n    // the ManipulationDelta handler.\n    dragTranslation = new TranslateTransform();\n    // Apply the translation to the Rectangle.\n    touchRectangle.RenderTransform = this.dragTranslation;\n}\n```\n\n```VisualBasic\nPublic Sub New()\n\n    &#39; This call is required by the designer.\n    InitializeComponent()\n\n    &#39; Listener for the ManipulationDelta event.\n    AddHandler touchRectangle.ManipulationDelta,\n        AddressOf testRectangle_ManipulationDelta\n    &#39; New translation transform populated in \n    &#39; the ManipulationDelta handler.\n    dragTranslation = New TranslateTransform()\n    &#39; Apply the translation to the Rectangle.\n    touchRectangle.RenderTransform = dragTranslation\n\nEnd Sub\n```\n\nFinally, in the [**ManipulationDelta**](https://msdn.microsoft.com/library/windows/apps/br208946) event handler, the position of the [**Rectangle**](https://msdn.microsoft.com/library/windows/apps/br243371) is updated by using the [**TranslateTransform**](https://msdn.microsoft.com/library/windows/apps/br243027) on the [**Delta**](https://msdn.microsoft.com/library/windows/apps/hh702058) property.\n\n```ManagedCPlusPlus\n// Handler for the ManipulationDelta event.\n// ManipulationDelta data is loaded into the\n// translation transform and applied to the Rectangle.\nvoid MainPage::touchRectangle_ManipulationDelta(Object^ sender,\n    ManipulationDeltaRoutedEventArgs^ e)\n{\n    // Move the rectangle.\n    dragTranslation->X += e->Delta.Translation.X;\n    dragTranslation->Y += e->Delta.Translation.Y;\n    \n}\n```\n\n```CSharp\n// Handler for the ManipulationDelta event.\n// ManipulationDelta data is loaded into the\n// translation transform and applied to the Rectangle.\nvoid touchRectangle_ManipulationDelta(object sender,\n    ManipulationDeltaRoutedEventArgs e)\n{\n    // Move the rectangle.\n    dragTranslation.X += e.Delta.Translation.X;\n    dragTranslation.Y += e.Delta.Translation.Y;\n}\n```\n\n```VisualBasic\n&#39; Handler for the ManipulationDelta event.\n&#39; ManipulationDelta data Is loaded into the\n&#39; translation transform And applied to the Rectangle.\nPrivate Sub testRectangle_ManipulationDelta(\n    sender As Object,\n    e As ManipulationDeltaRoutedEventArgs)\n\n    &#39; Move the rectangle.\n    dragTranslation.X = (dragTranslation.X + e.Delta.Translation.X)\n    dragTranslation.Y = (dragTranslation.Y + e.Delta.Translation.Y)\n\nEnd Sub\n```\n\n## <span id=\"Routed_events\"></span><span id=\"routed_events\"></span><span id=\"ROUTED_EVENTS\"></span>Routed events\n\n\nAll of the pointer events, gesture events and manipulation events mentioned here are implemented as *routed events*. This means that the event can potentially be handled by objects other than the one that originally raised the event. Successive parents in an object tree, such as the parent containers of a [**UIElement**](https://msdn.microsoft.com/library/windows/apps/br208911) or the root [**Page**](https://msdn.microsoft.com/library/windows/apps/br227503) of your app, can choose to handle these events even if the original element does not. Conversely, any object that does handle the event can mark the event handled so that it no longer reaches any parent element. For more info about the routed event concept and how it affects how you write handlers for routed events, see [Events and routed events overview](https://msdn.microsoft.com/library/windows/apps/hh758286).\n\n## <span id=\"Dos_and_don_ts\"></span><span id=\"dos_and_don_ts\"></span><span id=\"DOS_AND_DON_TS\"></span>Dos and don'ts\n\n\n-   Design applications with touch interaction as the primary expected input method.\n-   Provide visual feedback for interactions of all types (touch, pen, stylus, mouse, etc.)\n-   Optimize targeting by adjusting touch target size, contact geometry, scrubbing and rocking.\n-   Optimize accuracy through the use of snap points and directional \"rails\".\n-   Provide tooltips and handles to help improve touch accuracy for tightly packed UI items.\n-   Don't use timed interactions whenever possible (example of appropriate use: touch and hold).\n-   Don't use the number of fingers used to distinguish the manipulation whenever possible.\n\n\n## <span id=\"related_topics\"></span>Related articles\n\n* [Handle pointer input](handle-pointer-input.md)\n* [Identify input devices](identify-input-devices.md)\n**Samples**\n* [Basic input sample](http://go.microsoft.com/fwlink/p/?LinkID=620302)\n* [Low latency input sample](http://go.microsoft.com/fwlink/p/?LinkID=620304)\n* [User interaction mode sample](http://go.microsoft.com/fwlink/p/?LinkID=619894)\n* [Focus visuals sample](http://go.microsoft.com/fwlink/p/?LinkID=619895)\n**Archive Samples**\n* [Input: Device capabilities sample](http://go.microsoft.com/fwlink/p/?linkid=231530)\n* [Input: XAML user input events sample](http://go.microsoft.com/fwlink/p/?linkid=226855)\n* [XAML scrolling, panning, and zooming sample](http://go.microsoft.com/fwlink/p/?linkid=251717)\n* [Input: Gestures and manipulations with GestureRecognizer](http://go.microsoft.com/fwlink/p/?LinkID=231605)\n \n\n \n\n\n\n\n"}