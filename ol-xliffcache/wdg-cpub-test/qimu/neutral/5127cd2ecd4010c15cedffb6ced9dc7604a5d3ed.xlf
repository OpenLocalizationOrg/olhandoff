<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="fr-fr">
    <header>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
      </xliffext:oltranslationpriority>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">wdg-cpub-test\ndolci2\input-and-devices\enable-continuous-dictation.md</xliffext:olfilepath>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">5127cd2ecd4010c15cedffb6ced9dc7604a5d3ed</xliffext:olfilehash>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-e58fd48" tool-company="Microsoft" />
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Learn how to capture and recognize long-form, continuous dictation speech input.</source>
          <target state="new">Learn how to capture and recognize long-form, continuous dictation speech input.</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Enable continuous dictation</source>
          <target state="new">Enable continuous dictation</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Continuous dictation</source>
          <target state="new">Continuous dictation</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Updated for UWP apps on Windows 10.</source>
          <target state="new">Updated for UWP apps on Windows 10.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>For Windows 8.x articles, see the <bpt id="p1">[</bpt>archive<ept id="p1">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept></source>
          <target state="new">For Windows 8.x articles, see the <bpt id="p1">[</bpt>archive<ept id="p1">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept></target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Learn how to capture and recognize long-form, continuous dictation speech input.</source>
          <target state="new">Learn how to capture and recognize long-form, continuous dictation speech input.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Important APIs</source>
          <target state="new">Important APIs</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>SpeechContinuousRecognitionSession</source>
          <target state="new">SpeechContinuousRecognitionSession</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>ContinuousRecognitionSession</source>
          <target state="new">ContinuousRecognitionSession</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>In <bpt id="p1">[</bpt>Speech recognition<ept id="p1">](speech-recognition.md)</ept>, you learned how to capture and recognize relatively short speech input using the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>RecognizeAsync<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn653244)</ept> or <bpt id="p4">[</bpt><bpt id="p5">**</bpt>RecognizeWithUIAsync<ept id="p5">**</ept><ept id="p4">](https://msdn.microsoft.com/library/windows/apps/dn653245)</ept> methods of a <bpt id="p6">[</bpt><bpt id="p7">**</bpt>SpeechRecognizer<ept id="p7">**</ept><ept id="p6">](https://msdn.microsoft.com/library/windows/apps/dn653226)</ept> object, for example, when composing a short message service (SMS) message or when asking a question.</source>
          <target state="new">In <bpt id="p1">[</bpt>Speech recognition<ept id="p1">](speech-recognition.md)</ept>, you learned how to capture and recognize relatively short speech input using the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>RecognizeAsync<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn653244)</ept> or <bpt id="p4">[</bpt><bpt id="p5">**</bpt>RecognizeWithUIAsync<ept id="p5">**</ept><ept id="p4">](https://msdn.microsoft.com/library/windows/apps/dn653245)</ept> methods of a <bpt id="p6">[</bpt><bpt id="p7">**</bpt>SpeechRecognizer<ept id="p7">**</ept><ept id="p6">](https://msdn.microsoft.com/library/windows/apps/dn653226)</ept> object, for example, when composing a short message service (SMS) message or when asking a question.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>For longer, continuous speech recognition sessions, such as dictation or email, use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ContinuousRecognitionSession<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913913)</ept> property of a <bpt id="p3">[</bpt><bpt id="p4">**</bpt>SpeechRecognizer<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn653226)</ept> to obtain a <bpt id="p5">[</bpt><bpt id="p6">**</bpt>SpeechContinuousRecognitionSession<ept id="p6">**</ept><ept id="p5">](https://msdn.microsoft.com/library/windows/apps/dn913896)</ept> object.</source>
          <target state="new">For longer, continuous speech recognition sessions, such as dictation or email, use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ContinuousRecognitionSession<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913913)</ept> property of a <bpt id="p3">[</bpt><bpt id="p4">**</bpt>SpeechRecognizer<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn653226)</ept> to obtain a <bpt id="p5">[</bpt><bpt id="p6">**</bpt>SpeechContinuousRecognitionSession<ept id="p6">**</ept><ept id="p5">](https://msdn.microsoft.com/library/windows/apps/dn913896)</ept> object.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Set up</source>
          <target state="new">Set up</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Your app needs a few objects to manage a continuous dictation session:</source>
          <target state="new">Your app needs a few objects to manage a continuous dictation session:</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>An instance of a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognizer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653226)</ept> object.</source>
          <target state="new">An instance of a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognizer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653226)</ept> object.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>A reference to a UI dispatcher to update the UI during dictation.</source>
          <target state="new">A reference to a UI dispatcher to update the UI during dictation.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>A way to track the accumulated words spoken by the user.</source>
          <target state="new">A way to track the accumulated words spoken by the user.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Here, we declare a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognizer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653226)</ept> instance as a private field of the code-behind class.</source>
          <target state="new">Here, we declare a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognizer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653226)</ept> instance as a private field of the code-behind class.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Your app needs to store a reference elsewhere if you want continuous dictation to persist beyond a single Extensible Application Markup Language (XAML) page.</source>
          <target state="new">Your app needs to store a reference elsewhere if you want continuous dictation to persist beyond a single Extensible Application Markup Language (XAML) page.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>During dictation, the recognizer raises events from a background thread.</source>
          <target state="new">During dictation, the recognizer raises events from a background thread.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Because a background thread cannot directly update the UI in XAML, your app must use a dispatcher to update the UI in response to recognition events.</source>
          <target state="new">Because a background thread cannot directly update the UI in XAML, your app must use a dispatcher to update the UI in response to recognition events.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Here, we declare a private field that will be initialized later with the UI dispatcher.</source>
          <target state="new">Here, we declare a private field that will be initialized later with the UI dispatcher.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>To track what the user is saying, you need to handle recognition events raised by the speech recognizer.</source>
          <target state="new">To track what the user is saying, you need to handle recognition events raised by the speech recognizer.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>These events provide the recognition results for chunks of user utterances.</source>
          <target state="new">These events provide the recognition results for chunks of user utterances.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Here, we use a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>StringBuilder<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/system.text.stringbuilder.aspx)</ept> object to hold all the recognition results obtained during the session.</source>
          <target state="new">Here, we use a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>StringBuilder<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/system.text.stringbuilder.aspx)</ept> object to hold all the recognition results obtained during the session.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>New results are appended to the <bpt id="p1">**</bpt>StringBuilder<ept id="p1">**</ept> as they are processed.</source>
          <target state="new">New results are appended to the <bpt id="p1">**</bpt>StringBuilder<ept id="p1">**</ept> as they are processed.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Initialization</source>
          <target state="new">Initialization</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>During the initialization of continuous speech recognition, you must:</source>
          <target state="new">During the initialization of continuous speech recognition, you must:</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Fetch the dispatcher for the UI thread if you update the UI of your app in the continuous recognition event handlers.</source>
          <target state="new">Fetch the dispatcher for the UI thread if you update the UI of your app in the continuous recognition event handlers.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Initialize the speech recognizer.</source>
          <target state="new">Initialize the speech recognizer.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Compile the built-in dictation grammar.</source>
          <target state="new">Compile the built-in dictation grammar.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Note<ept id="p1">**</ept>   Speech recognition requires at least one constraint to define a recognizable vocabulary.</source>
          <target state="new"><bpt id="p1">**</bpt>Note<ept id="p1">**</ept>   Speech recognition requires at least one constraint to define a recognizable vocabulary.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>If no constraint is specified, a predefined dictation grammar is used.</source>
          <target state="new">If no constraint is specified, a predefined dictation grammar is used.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Speech recognition<ept id="p1">](speech-recognition.md)</ept>.</source>
          <target state="new">See <bpt id="p1">[</bpt>Speech recognition<ept id="p1">](speech-recognition.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Set up the event listeners for recognition events.</source>
          <target state="new">Set up the event listeners for recognition events.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>We initialize speech recognition in the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>OnNavigatedTo<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br227508)</ept> page event.</source>
          <target state="new">We initialize speech recognition in the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>OnNavigatedTo<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br227508)</ept> page event.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Because events raised by the speech recognizer occur on a background thread, create a reference to the dispatcher for updates to the UI thread.</source>
          <target state="new">Because events raised by the speech recognizer occur on a background thread, create a reference to the dispatcher for updates to the UI thread.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>OnNavigatedTo<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br227508)</ept> is always invoked on the UI thread.</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>OnNavigatedTo<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br227508)</ept> is always invoked on the UI thread.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>We then initialize the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognizer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653226)</ept> instance.</source>
          <target state="new">We then initialize the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognizer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653226)</ept> instance.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>We then add and compile the grammar that defines all of the words and phrases that can be recognized by the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognizer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653226)</ept>.</source>
          <target state="new">We then add and compile the grammar that defines all of the words and phrases that can be recognized by the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognizer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653226)</ept>.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>If you don't specify a grammar explicitly, a predefined dictation grammar is used by default.</source>
          <target state="new">If you don't specify a grammar explicitly, a predefined dictation grammar is used by default.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Typically, the default grammar is best for general dictation.</source>
          <target state="new">Typically, the default grammar is best for general dictation.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Here, we call <bpt id="p1">[</bpt><bpt id="p2">**</bpt>CompileConstraintsAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653240)</ept> immediately without adding a grammar.</source>
          <target state="new">Here, we call <bpt id="p1">[</bpt><bpt id="p2">**</bpt>CompileConstraintsAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653240)</ept> immediately without adding a grammar.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>Handle recognition events</source>
          <target state="new">Handle recognition events</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Here, you can capture a single, brief utterance or phrase by calling <bpt id="p1">[</bpt><bpt id="p2">**</bpt>RecognizeAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653244)</ept> or <bpt id="p3">[</bpt><bpt id="p4">**</bpt>RecognizeWithUIAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn653245)</ept>.</source>
          <target state="new">Here, you can capture a single, brief utterance or phrase by calling <bpt id="p1">[</bpt><bpt id="p2">**</bpt>RecognizeAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653244)</ept> or <bpt id="p3">[</bpt><bpt id="p4">**</bpt>RecognizeWithUIAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn653245)</ept>.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>However, we want to capture a longer, continuous recognition session.</source>
          <target state="new">However, we want to capture a longer, continuous recognition session.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>To do this, we specify event listeners to run in the background as the user speaks and define handlers to build the dictation string.</source>
          <target state="new">To do this, we specify event listeners to run in the background as the user speaks and define handlers to build the dictation string.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>We then use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ContinuousRecognitionSession<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913913)</ept> property of our recognizer to obtain a <bpt id="p3">[</bpt><bpt id="p4">**</bpt>SpeechContinuousRecognitionSession<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913896)</ept> object that provides methods and events for managing a continuous recognition session.</source>
          <target state="new">We then use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ContinuousRecognitionSession<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913913)</ept> property of our recognizer to obtain a <bpt id="p3">[</bpt><bpt id="p4">**</bpt>SpeechContinuousRecognitionSession<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913896)</ept> object that provides methods and events for managing a continuous recognition session.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Two events in particular are critical:</source>
          <target state="new">Two events in particular are critical:</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept>, which occurs when the recognizer has generated some results.</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept>, which occurs when the recognizer has generated some results.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>Completed<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913899)</ept>, which occurs when the continuous recognition session has ended.</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>Completed<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913899)</ept>, which occurs when the continuous recognition session has ended.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event is raised as the user speaks.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event is raised as the user speaks.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>The recognizer continuously listens to the user and periodically raises an event that passes a chunk of speech input.</source>
          <target state="new">The recognizer continuously listens to the user and periodically raises an event that passes a chunk of speech input.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>You must examine the speech input, using the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Result<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913895)</ept> property of the event argument, and take appropriate action in the event handler, such as appending the text to a StringBuilder object.</source>
          <target state="new">You must examine the speech input, using the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Result<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913895)</ept> property of the event argument, and take appropriate action in the event handler, such as appending the text to a StringBuilder object.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>As an instance of <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognitionResult<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631432)</ept>, the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>Result<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913895)</ept> property is useful for determining whether you want to accept the speech input:</source>
          <target state="new">As an instance of <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SpeechRecognitionResult<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631432)</ept>, the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>Result<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913895)</ept> property is useful for determining whether you want to accept the speech input:</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>Status<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631440)</ept> indicates whether the recognition was successful.</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>Status<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631440)</ept> indicates whether the recognition was successful.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Recognition can fail for a variety of reasons.</source>
          <target state="new">Recognition can fail for a variety of reasons.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>Confidence<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631434)</ept> indicates the relative confidence that the recognizer understood the correct words.</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>Confidence<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631434)</ept> indicates the relative confidence that the recognizer understood the correct words.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>Here, we register the handler for the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> continuous recognition event in the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>OnNavigatedTo<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/br227508)</ept> page event.</source>
          <target state="new">Here, we register the handler for the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> continuous recognition event in the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>OnNavigatedTo<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/br227508)</ept> page event.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>We then check the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Confidence<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631434)</ept> property.</source>
          <target state="new">We then check the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Confidence<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631434)</ept> property.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>If the value of Confidence is <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Medium<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631409)</ept> or better, we append the text to the StringBuilder.</source>
          <target state="new">If the value of Confidence is <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Medium<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631409)</ept> or better, we append the text to the StringBuilder.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>We also update the UI as we collect input.</source>
          <target state="new">We also update the UI as we collect input.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Note<ept id="p1">**</ept>  the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>ResultGenerated<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event is raised on a background thread that cannot update the UI directly.</source>
          <target state="new"><bpt id="p1">**</bpt>Note<ept id="p1">**</ept>  the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>ResultGenerated<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event is raised on a background thread that cannot update the UI directly.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>If a handler needs to update the UI (as the <ph id="ph1">\[</ph>Speech and TTS sample<ph id="ph2">\]</ph> does), you must dispatch the updates to the UI thread through the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>RunAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/hh750317)</ept> method of the dispatcher.</source>
          <target state="new">If a handler needs to update the UI (as the <ph id="ph1">\[</ph>Speech and TTS sample<ph id="ph2">\]</ph> does), you must dispatch the updates to the UI thread through the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>RunAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/hh750317)</ept> method of the dispatcher.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>We then handle the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Completed<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913899)</ept> event, which indicates the end of continuous dictation.</source>
          <target state="new">We then handle the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Completed<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913899)</ept> event, which indicates the end of continuous dictation.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>The session ends when you call the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>StopAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913908)</ept> or <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CancelAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913898)</ept> methods (described the next section).</source>
          <target state="new">The session ends when you call the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>StopAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913908)</ept> or <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CancelAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913898)</ept> methods (described the next section).</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>The session can also end when an error occurs, or when the user has stopped speaking.</source>
          <target state="new">The session can also end when an error occurs, or when the user has stopped speaking.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Check the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Status<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631440)</ept> property of the event argument to determine why the session ended (<bpt id="p3">[</bpt><bpt id="p4">**</bpt>SpeechRecognitionResultStatus<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn631433)</ept>).</source>
          <target state="new">Check the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Status<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631440)</ept> property of the event argument to determine why the session ended (<bpt id="p3">[</bpt><bpt id="p4">**</bpt>SpeechRecognitionResultStatus<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn631433)</ept>).</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Here, we register the handler for the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Completed<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913899)</ept> continuous recognition event in the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>OnNavigatedTo<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/br227508)</ept> page event.</source>
          <target state="new">Here, we register the handler for the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Completed<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913899)</ept> continuous recognition event in the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>OnNavigatedTo<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/br227508)</ept> page event.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>The event handler checks the Status property to determine whether the recognition was successful.</source>
          <target state="new">The event handler checks the Status property to determine whether the recognition was successful.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>It also handles the case where the user has stopped speaking.</source>
          <target state="new">It also handles the case where the user has stopped speaking.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Often, a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>TimeoutExceeded<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631433)</ept> is considered successful recognition as it means the user has finished speaking.</source>
          <target state="new">Often, a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>TimeoutExceeded<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn631433)</ept> is considered successful recognition as it means the user has finished speaking.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>You should handle this case in your code for a good experience.</source>
          <target state="new">You should handle this case in your code for a good experience.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Note<ept id="p1">**</ept>  the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>ResultGenerated<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event is raised on a background thread that cannot update the UI directly.</source>
          <target state="new"><bpt id="p1">**</bpt>Note<ept id="p1">**</ept>  the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>ResultGenerated<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event is raised on a background thread that cannot update the UI directly.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>If a handler needs to update the UI (as the <ph id="ph1">\[</ph>Speech and TTS sample<ph id="ph2">\]</ph> does), you must dispatch the updates to the UI thread through the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>RunAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/hh750317)</ept> method of the dispatcher.</source>
          <target state="new">If a handler needs to update the UI (as the <ph id="ph1">\[</ph>Speech and TTS sample<ph id="ph2">\]</ph> does), you must dispatch the updates to the UI thread through the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>RunAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/hh750317)</ept> method of the dispatcher.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>Provide ongoing recognition feedback</source>
          <target state="new">Provide ongoing recognition feedback</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>When people converse, they often rely on context to fully understand what is being said.</source>
          <target state="new">When people converse, they often rely on context to fully understand what is being said.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>Similarly, the speech recognizer often needs context to provide high-confidence recognition results.</source>
          <target state="new">Similarly, the speech recognizer often needs context to provide high-confidence recognition results.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>For example, by themselves, the words "weight" and "wait" are indistinguishable until more context can be gleaned from surrounding words.</source>
          <target state="new">For example, by themselves, the words "weight" and "wait" are indistinguishable until more context can be gleaned from surrounding words.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>Until the recognizer has some confidence that a word, or words, have been recognized correctly, it will not raise the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event.</source>
          <target state="new">Until the recognizer has some confidence that a word, or words, have been recognized correctly, it will not raise the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>This can result in a less than ideal experience for the user as they continue speaking and no results are provided until the recognizer has high enough confidence to raise the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event.</source>
          <target state="new">This can result in a less than ideal experience for the user as they continue speaking and no results are provided until the recognizer has high enough confidence to raise the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>Handle the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>HypothesisGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913914)</ept> event to improve this apparent lack of responsiveness.</source>
          <target state="new">Handle the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>HypothesisGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913914)</ept> event to improve this apparent lack of responsiveness.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>This event is raised whenever the recognizer generates a new set of potential matches for the word being processed.</source>
          <target state="new">This event is raised whenever the recognizer generates a new set of potential matches for the word being processed.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>The event argument provides an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Hypothesis<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913911)</ept> property that contains the current matches.</source>
          <target state="new">The event argument provides an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Hypothesis<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913911)</ept> property that contains the current matches.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>Show these to the user as they continue speaking and reassure them that processing is still active.</source>
          <target state="new">Show these to the user as they continue speaking and reassure them that processing is still active.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>Once confidence is high and a recognition result has been determined, replace the interim <bpt id="p1">**</bpt>Hypothesis<ept id="p1">**</ept> results with the final <bpt id="p2">[</bpt><bpt id="p3">**</bpt>Result<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn913895)</ept> provided in the <bpt id="p4">[</bpt><bpt id="p5">**</bpt>ResultGenerated<ept id="p5">**</ept><ept id="p4">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event.</source>
          <target state="new">Once confidence is high and a recognition result has been determined, replace the interim <bpt id="p1">**</bpt>Hypothesis<ept id="p1">**</ept> results with the final <bpt id="p2">[</bpt><bpt id="p3">**</bpt>Result<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn913895)</ept> provided in the <bpt id="p4">[</bpt><bpt id="p5">**</bpt>ResultGenerated<ept id="p5">**</ept><ept id="p4">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>Here, we append the hypothetical text and an ellipsis ("…") to the current value of the output <bpt id="p1">[</bpt><bpt id="p2">**</bpt>TextBox<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br209683)</ept>.</source>
          <target state="new">Here, we append the hypothetical text and an ellipsis ("…") to the current value of the output <bpt id="p1">[</bpt><bpt id="p2">**</bpt>TextBox<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br209683)</ept>.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>The contents of the text box are updated as new hypotheses are generated and until the final results are obtained from the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event.</source>
          <target state="new">The contents of the text box are updated as new hypotheses are generated and until the final results are obtained from the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>Start and stop recognition</source>
          <target state="new">Start and stop recognition</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>Before starting a recognition session, check the value of the speech recognizer <bpt id="p1">[</bpt><bpt id="p2">**</bpt>State<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913915)</ept> property.</source>
          <target state="new">Before starting a recognition session, check the value of the speech recognizer <bpt id="p1">[</bpt><bpt id="p2">**</bpt>State<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913915)</ept> property.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>The speech recognizer must be in an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Idle<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653227)</ept> state.</source>
          <target state="new">The speech recognizer must be in an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Idle<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn653227)</ept> state.</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>After checking the state of the speech recognizer, we start the session by calling the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>StartAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913901)</ept> method of the speech recognizer's <bpt id="p3">[</bpt><bpt id="p4">**</bpt>ContinuousRecognitionSession<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913913)</ept> property.</source>
          <target state="new">After checking the state of the speech recognizer, we start the session by calling the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>StartAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913901)</ept> method of the speech recognizer's <bpt id="p3">[</bpt><bpt id="p4">**</bpt>ContinuousRecognitionSession<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913913)</ept> property.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>Recognition can be stopped in two ways:</source>
          <target state="new">Recognition can be stopped in two ways:</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>StopAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913908)</ept> lets any pending recognition events complete (<bpt id="p3">[</bpt><bpt id="p4">**</bpt>ResultGenerated<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> continues to be raised until all pending recognition operations are complete).</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>StopAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913908)</ept> lets any pending recognition events complete (<bpt id="p3">[</bpt><bpt id="p4">**</bpt>ResultGenerated<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> continues to be raised until all pending recognition operations are complete).</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>CancelAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913898)</ept> terminates the recognition session immediately and discards any pending results.</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>CancelAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913898)</ept> terminates the recognition session immediately and discards any pending results.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>After checking the state of the speech recognizer, we stop the session by calling the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>CancelAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913898)</ept> method of the speech recognizer's <bpt id="p3">[</bpt><bpt id="p4">**</bpt>ContinuousRecognitionSession<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913913)</ept> property.</source>
          <target state="new">After checking the state of the speech recognizer, we stop the session by calling the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>CancelAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913898)</ept> method of the speech recognizer's <bpt id="p3">[</bpt><bpt id="p4">**</bpt>ContinuousRecognitionSession<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913913)</ept> property.</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>Note</source>
          <target state="new">Note</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>A <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event can occur after a call to <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CancelAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913898)</ept>.</source>
          <target state="new">A <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event can occur after a call to <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CancelAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913898)</ept>.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>Because of multithreading, a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event might still remain on the stack when <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CancelAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913898)</ept> is called.</source>
          <target state="new">Because of multithreading, a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> event might still remain on the stack when <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CancelAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn913898)</ept> is called.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>If so, the <bpt id="p1">**</bpt>ResultGenerated<ept id="p1">**</ept> event still fires.</source>
          <target state="new">If so, the <bpt id="p1">**</bpt>ResultGenerated<ept id="p1">**</ept> event still fires.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>If you set any private fields when canceling the recognition session, always confirm their values in the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> handler.</source>
          <target state="new">If you set any private fields when canceling the recognition session, always confirm their values in the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResultGenerated<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn913900)</ept> handler.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>For example, don't assume a field is initialized in your handler if you set them to null when you cancel the session.</source>
          <target state="new">For example, don't assume a field is initialized in your handler if you set them to null when you cancel the session.</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>Related articles</source>
          <target state="new">Related articles</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>Speech interactions</source>
          <target state="new">Speech interactions</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>Samples</source>
          <target state="new">Samples</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>Speech recognition and speech synthesis sample</source>
          <target state="new">Speech recognition and speech synthesis sample</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>