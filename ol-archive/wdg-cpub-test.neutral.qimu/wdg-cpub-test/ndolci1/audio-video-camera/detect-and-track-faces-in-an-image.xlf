<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="fr-fr">
    <header>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
      </xliffext:oltranslationpriority>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">wdg-cpub-test\ndolci1\audio-video-camera\detect-and-track-faces-in-an-image.md</xliffext:olfilepath>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">df58c3033a77f6763ef86f7d3ea13320ac805335</xliffext:olfilehash>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-e58fd48" tool-company="Microsoft" />
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>This topic shows how to use the FaceDetector to detect faces in an image.</source>
          <target state="new">This topic shows how to use the FaceDetector to detect faces in an image.</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>The FaceTracker is optimized for tracking faces over time in a sequence of video frames.</source>
          <target state="new">The FaceTracker is optimized for tracking faces over time in a sequence of video frames.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Detect faces in images or videos</source>
          <target state="new">Detect faces in images or videos</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Detect faces in images or videos</source>
          <target state="new">Detect faces in images or videos</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Updated for UWP apps on Windows 10.</source>
          <target state="new">Updated for UWP apps on Windows 10.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>For Windows 8.x articles, see the <bpt id="p1">[</bpt>archive<ept id="p1">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept></source>
          <target state="new">For Windows 8.x articles, see the <bpt id="p1">[</bpt>archive<ept id="p1">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept></target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Some information relates to pre-released product which may be substantially modified before it's commercially released.</source>
          <target state="new">Some information relates to pre-released product which may be substantially modified before it's commercially released.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Microsoft makes no warranties, express or implied, with respect to the information provided here.</source>
          <target state="new">Microsoft makes no warranties, express or implied, with respect to the information provided here.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>This topic shows how to use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceDetector<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974129)</ept> to detect faces in an image.</source>
          <target state="new">This topic shows how to use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceDetector<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974129)</ept> to detect faces in an image.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceTracker<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974150)</ept> is optimized for tracking faces over time in a sequence of video frames.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceTracker<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974150)</ept> is optimized for tracking faces over time in a sequence of video frames.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>For an alternative method of tracking faces using the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceDetectionEffect<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn948776)</ept>, see <bpt id="p3">[</bpt>Scene analysis for media capture<ept id="p3">](scene-analysis-for-media-capture.md)</ept>.</source>
          <target state="new">For an alternative method of tracking faces using the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceDetectionEffect<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn948776)</ept>, see <bpt id="p3">[</bpt>Scene analysis for media capture<ept id="p3">](scene-analysis-for-media-capture.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>The code in this article was adapted from the <bpt id="p1">[</bpt>Basic Face Detection<ept id="p1">](http://go.microsoft.com/fwlink/p/?LinkId=620512&amp;clcid=0x409)</ept> and <bpt id="p2">[</bpt>Basic Face Tracking<ept id="p2">](http://go.microsoft.com/fwlink/p/?LinkId=620513&amp;clcid=0x409)</ept> samples.</source>
          <target state="new">The code in this article was adapted from the <bpt id="p1">[</bpt>Basic Face Detection<ept id="p1">](http://go.microsoft.com/fwlink/p/?LinkId=620512&amp;clcid=0x409)</ept> and <bpt id="p2">[</bpt>Basic Face Tracking<ept id="p2">](http://go.microsoft.com/fwlink/p/?LinkId=620513&amp;clcid=0x409)</ept> samples.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>You can download these samples to see the code used in context or to use the sample as a starting point for your own app.</source>
          <target state="new">You can download these samples to see the code used in context or to use the sample as a starting point for your own app.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Detect faces in a single image</source>
          <target state="new">Detect faces in a single image</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceDetector<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974129)</ept> class allows you to detect one or more faces in a still image.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceDetector<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974129)</ept> class allows you to detect one or more faces in a still image.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>This example uses APIs from the following namespaces.</source>
          <target state="new">This example uses APIs from the following namespaces.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>FaceDetectionUsing</source>
          <target state="new">FaceDetectionUsing</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Declare a class member variable for the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceDetector<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974129)</ept> object and for the list of <bpt id="p3">[</bpt><bpt id="p4">**</bpt>DetectedFace<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn974123)</ept> objects that will be detected in the image.</source>
          <target state="new">Declare a class member variable for the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceDetector<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974129)</ept> object and for the list of <bpt id="p3">[</bpt><bpt id="p4">**</bpt>DetectedFace<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn974123)</ept> objects that will be detected in the image.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>ClassVariables1</source>
          <target state="new">ClassVariables1</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Face detection operates on a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SoftwareBitmap<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn887358)</ept> object which can be created in a variety of ways.</source>
          <target state="new">Face detection operates on a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SoftwareBitmap<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn887358)</ept> object which can be created in a variety of ways.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>In this example a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FileOpenPicker<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br207847)</ept> is used to allow the user to pick an image file in which faces will be detected.</source>
          <target state="new">In this example a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FileOpenPicker<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br207847)</ept> is used to allow the user to pick an image file in which faces will be detected.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>For more information on working with software bitmaps, see <bpt id="p1">[</bpt>Imaging<ept id="p1">](imaging.md)</ept>.</source>
          <target state="new">For more information on working with software bitmaps, see <bpt id="p1">[</bpt>Imaging<ept id="p1">](imaging.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Picker</source>
          <target state="new">Picker</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>BitmapDecoder<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br226176)</ept> class to decode the image file into a <bpt id="p3">**</bpt>SoftwareBitmap<ept id="p3">**</ept>.</source>
          <target state="new">Use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>BitmapDecoder<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br226176)</ept> class to decode the image file into a <bpt id="p3">**</bpt>SoftwareBitmap<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>The face detection process is quicker with a smaller image and so you may want to scale the source image down to a smaller size.</source>
          <target state="new">The face detection process is quicker with a smaller image and so you may want to scale the source image down to a smaller size.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>This can be performed during decoding by creating a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>BitmapTransform<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br226254)</ept> object, setting the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>ScaledWidth<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/br226261)</ept> and <bpt id="p5">[</bpt><bpt id="p6">**</bpt>ScaledHeight<ept id="p6">**</ept><ept id="p5">](https://msdn.microsoft.com/library/windows/apps/br226260)</ept> properties and passing it into the call to <bpt id="p7">[</bpt><bpt id="p8">**</bpt>GetSoftwareBitmapAsync<ept id="p8">**</ept><ept id="p7">](https://msdn.microsoft.com/library/windows/apps/dn887332)</ept>, which returns the decoded and scaled <bpt id="p9">**</bpt>SoftwareBitmap<ept id="p9">**</ept>.</source>
          <target state="new">This can be performed during decoding by creating a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>BitmapTransform<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br226254)</ept> object, setting the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>ScaledWidth<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/br226261)</ept> and <bpt id="p5">[</bpt><bpt id="p6">**</bpt>ScaledHeight<ept id="p6">**</ept><ept id="p5">](https://msdn.microsoft.com/library/windows/apps/br226260)</ept> properties and passing it into the call to <bpt id="p7">[</bpt><bpt id="p8">**</bpt>GetSoftwareBitmapAsync<ept id="p8">**</ept><ept id="p7">](https://msdn.microsoft.com/library/windows/apps/dn887332)</ept>, which returns the decoded and scaled <bpt id="p9">**</bpt>SoftwareBitmap<ept id="p9">**</ept>.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Decode</source>
          <target state="new">Decode</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>In the current version, the <bpt id="p1">**</bpt>FaceDetector<ept id="p1">**</ept> class only supports images in Gray8 or Nv12.</source>
          <target state="new">In the current version, the <bpt id="p1">**</bpt>FaceDetector<ept id="p1">**</ept> class only supports images in Gray8 or Nv12.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>SoftwareBitmap<ept id="p1">**</ept> class provides the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>Convert<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn887362)</ept> method, which converts a bitmap from one format to another.</source>
          <target state="new">The <bpt id="p1">**</bpt>SoftwareBitmap<ept id="p1">**</ept> class provides the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>Convert<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn887362)</ept> method, which converts a bitmap from one format to another.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>This example converts the source image into the Gray8 pixel format if it is not already in that format.</source>
          <target state="new">This example converts the source image into the Gray8 pixel format if it is not already in that format.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>If you want, you can use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>GetSupportedBitmapPixelFormats<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974140)</ept> and <bpt id="p3">[</bpt><bpt id="p4">**</bpt>IsBitmapPixelFormatSupported<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn974142)</ept> methods to determine at runtime if a pixel format is supported, in case the set of supported formats is expanded in future versions.</source>
          <target state="new">If you want, you can use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>GetSupportedBitmapPixelFormats<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974140)</ept> and <bpt id="p3">[</bpt><bpt id="p4">**</bpt>IsBitmapPixelFormatSupported<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn974142)</ept> methods to determine at runtime if a pixel format is supported, in case the set of supported formats is expanded in future versions.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Format</source>
          <target state="new">Format</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Instantiate the <bpt id="p1">**</bpt>FaceDetector<ept id="p1">**</ept> object by calling <bpt id="p2">[</bpt><bpt id="p3">**</bpt>CreateAsync<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn974132)</ept> and then call <bpt id="p4">[</bpt><bpt id="p5">**</bpt>DetectFacesAsync<ept id="p5">**</ept><ept id="p4">](https://msdn.microsoft.com/library/windows/apps/dn974134)</ept>, passing in the bitmap that has been scaled to a reasonable size and converted to a supported pixel format.</source>
          <target state="new">Instantiate the <bpt id="p1">**</bpt>FaceDetector<ept id="p1">**</ept> object by calling <bpt id="p2">[</bpt><bpt id="p3">**</bpt>CreateAsync<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn974132)</ept> and then call <bpt id="p4">[</bpt><bpt id="p5">**</bpt>DetectFacesAsync<ept id="p5">**</ept><ept id="p4">](https://msdn.microsoft.com/library/windows/apps/dn974134)</ept>, passing in the bitmap that has been scaled to a reasonable size and converted to a supported pixel format.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>This method returns a list of <bpt id="p1">[</bpt><bpt id="p2">**</bpt>DetectedFace<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974123)</ept> objects.</source>
          <target state="new">This method returns a list of <bpt id="p1">[</bpt><bpt id="p2">**</bpt>DetectedFace<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974123)</ept> objects.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>ShowDetectedFaces<ept id="p1">**</ept> is a helper method, shown below, that draws squares around the faces in the image.</source>
          <target state="new"><bpt id="p1">**</bpt>ShowDetectedFaces<ept id="p1">**</ept> is a helper method, shown below, that draws squares around the faces in the image.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Detect</source>
          <target state="new">Detect</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Be sure to dispose of the objects that were created during the face detection process.</source>
          <target state="new">Be sure to dispose of the objects that were created during the face detection process.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Dispose</source>
          <target state="new">Dispose</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>To display the image and draw boxes around the detected faces, add a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Canvas<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br209267)</ept> element to your XAML page.</source>
          <target state="new">To display the image and draw boxes around the detected faces, add a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Canvas<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br209267)</ept> element to your XAML page.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Canvas</source>
          <target state="new">Canvas</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Define some member variables to style the squares that will be drawn.</source>
          <target state="new">Define some member variables to style the squares that will be drawn.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>ClassVariables2</source>
          <target state="new">ClassVariables2</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>ShowDetectedFaces<ept id="p1">**</ept> helper method, a new <bpt id="p2">[</bpt><bpt id="p3">**</bpt>ImageBrush<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/br210101)</ept> is created and the source is set to a <bpt id="p4">[</bpt><bpt id="p5">**</bpt>SoftwareBitmapSource<ept id="p5">**</ept><ept id="p4">](https://msdn.microsoft.com/library/windows/apps/dn997854)</ept> created from the <bpt id="p6">**</bpt>SoftwareBitmap<ept id="p6">**</ept> representing the source image.</source>
          <target state="new">In the <bpt id="p1">**</bpt>ShowDetectedFaces<ept id="p1">**</ept> helper method, a new <bpt id="p2">[</bpt><bpt id="p3">**</bpt>ImageBrush<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/br210101)</ept> is created and the source is set to a <bpt id="p4">[</bpt><bpt id="p5">**</bpt>SoftwareBitmapSource<ept id="p5">**</ept><ept id="p4">](https://msdn.microsoft.com/library/windows/apps/dn997854)</ept> created from the <bpt id="p6">**</bpt>SoftwareBitmap<ept id="p6">**</ept> representing the source image.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>The background of the XAML <bpt id="p1">**</bpt>Canvas<ept id="p1">**</ept> control is set to the image brush.</source>
          <target state="new">The background of the XAML <bpt id="p1">**</bpt>Canvas<ept id="p1">**</ept> control is set to the image brush.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>If the list of faces passed into the helper method isn't empty, loop through each face in the list and use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceBox<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974126)</ept> property of the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>DetectedFace<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn974123)</ept> class to determine the position and size of the rectangle within the image that contains the face.</source>
          <target state="new">If the list of faces passed into the helper method isn't empty, loop through each face in the list and use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceBox<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974126)</ept> property of the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>DetectedFace<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn974123)</ept> class to determine the position and size of the rectangle within the image that contains the face.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Because the <bpt id="p1">**</bpt>Canvas<ept id="p1">**</ept> control is very likely to be a different size than the source image, you should multiply both the X and Y coordinates and the width and height of the <bpt id="p2">**</bpt>FaceBox<ept id="p2">**</ept> by a scaling value which is the ratio of the source image size to the actual size of the <bpt id="p3">**</bpt>Canvas<ept id="p3">**</ept> control.</source>
          <target state="new">Because the <bpt id="p1">**</bpt>Canvas<ept id="p1">**</ept> control is very likely to be a different size than the source image, you should multiply both the X and Y coordinates and the width and height of the <bpt id="p2">**</bpt>FaceBox<ept id="p2">**</ept> by a scaling value which is the ratio of the source image size to the actual size of the <bpt id="p3">**</bpt>Canvas<ept id="p3">**</ept> control.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>ShowDetectedFaces</source>
          <target state="new">ShowDetectedFaces</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Track faces in a sequence of frames</source>
          <target state="new">Track faces in a sequence of frames</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>If you want to detect faces in video, it is more efficient to use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceTracker<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974150)</ept> class rather than the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>FaceDetector<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn974129)</ept> class, although the implementation steps are very similar.</source>
          <target state="new">If you want to detect faces in video, it is more efficient to use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceTracker<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974150)</ept> class rather than the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>FaceDetector<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn974129)</ept> class, although the implementation steps are very similar.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>FaceTracker<ept id="p1">**</ept> uses information about previously processed frames to optimize the detection process.</source>
          <target state="new">The <bpt id="p1">**</bpt>FaceTracker<ept id="p1">**</ept> uses information about previously processed frames to optimize the detection process.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>FaceTrackingUsing</source>
          <target state="new">FaceTrackingUsing</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Declare a class variable for the <bpt id="p1">**</bpt>FaceTracker<ept id="p1">**</ept> object.</source>
          <target state="new">Declare a class variable for the <bpt id="p1">**</bpt>FaceTracker<ept id="p1">**</ept> object.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>This example uses a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ThreadPoolTimer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br230587)</ept> to initiate face tracking on a defined interval.</source>
          <target state="new">This example uses a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ThreadPoolTimer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br230587)</ept> to initiate face tracking on a defined interval.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>A <bpt id="p1">[</bpt>SemaphoreSlim<ept id="p1">](https://msdn.microsoft.com/library/system.threading.semaphoreslim.aspx)</ept> is used to make sure that only one face tracking operation is running at a time.</source>
          <target state="new">A <bpt id="p1">[</bpt>SemaphoreSlim<ept id="p1">](https://msdn.microsoft.com/library/system.threading.semaphoreslim.aspx)</ept> is used to make sure that only one face tracking operation is running at a time.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>ClassVariables3</source>
          <target state="new">ClassVariables3</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>To initialize the face tracking operation, create a new <bpt id="p1">**</bpt>FaceTracker<ept id="p1">**</ept> object by calling <bpt id="p2">[</bpt><bpt id="p3">**</bpt>CreateAsync<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn974151)</ept>.</source>
          <target state="new">To initialize the face tracking operation, create a new <bpt id="p1">**</bpt>FaceTracker<ept id="p1">**</ept> object by calling <bpt id="p2">[</bpt><bpt id="p3">**</bpt>CreateAsync<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn974151)</ept>.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Initialize the desired timer interval and then create the timer.</source>
          <target state="new">Initialize the desired timer interval and then create the timer.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>ProcessCurrentVideoFrame<ept id="p1">**</ept> helper method will be called every time the specified interval elapses.</source>
          <target state="new">The <bpt id="p1">**</bpt>ProcessCurrentVideoFrame<ept id="p1">**</ept> helper method will be called every time the specified interval elapses.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>TrackingInit</source>
          <target state="new">TrackingInit</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>ProcessCurrentVideoFrame<ept id="p1">**</ept> helper is called asynchronously by the timer, so the method first calls the semaphore's <bpt id="p2">**</bpt>Wait<ept id="p2">**</ept> method to see if a tracking operation is ongoing, and if it is the method returns without trying to detect faces.</source>
          <target state="new">The <bpt id="p1">**</bpt>ProcessCurrentVideoFrame<ept id="p1">**</ept> helper is called asynchronously by the timer, so the method first calls the semaphore's <bpt id="p2">**</bpt>Wait<ept id="p2">**</ept> method to see if a tracking operation is ongoing, and if it is the method returns without trying to detect faces.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>At the end of this method, the semaphore's <bpt id="p1">**</bpt>Release<ept id="p1">**</ept> method is called, which allows the subsequent call to <bpt id="p2">**</bpt>ProcessCurrentVideoFrame<ept id="p2">**</ept> to continue.</source>
          <target state="new">At the end of this method, the semaphore's <bpt id="p1">**</bpt>Release<ept id="p1">**</ept> method is called, which allows the subsequent call to <bpt id="p2">**</bpt>ProcessCurrentVideoFrame<ept id="p2">**</ept> to continue.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceTracker<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974150)</ept> class operates on <bpt id="p3">[</bpt><bpt id="p4">**</bpt>VideoFrame<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn930917)</ept> objects.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FaceTracker<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974150)</ept> class operates on <bpt id="p3">[</bpt><bpt id="p4">**</bpt>VideoFrame<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn930917)</ept> objects.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>There are multiple ways you can obtain a <bpt id="p1">**</bpt>VideoFrame<ept id="p1">**</ept> including capturing a preview frame from a running <bpt id="p2">[</bpt>MediaCapture<ept id="p2">](capture-photos-and-video-with-mediacapture.md)</ept> object or by implementing the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>ProcessFrame<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn764784)</ept> method of the <bpt id="p5">[</bpt><bpt id="p6">**</bpt>IBasicVideoEffect<ept id="p6">**</ept><ept id="p5">](https://msdn.microsoft.com/library/windows/apps/dn764788)</ept>.</source>
          <target state="new">There are multiple ways you can obtain a <bpt id="p1">**</bpt>VideoFrame<ept id="p1">**</ept> including capturing a preview frame from a running <bpt id="p2">[</bpt>MediaCapture<ept id="p2">](capture-photos-and-video-with-mediacapture.md)</ept> object or by implementing the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>ProcessFrame<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn764784)</ept> method of the <bpt id="p5">[</bpt><bpt id="p6">**</bpt>IBasicVideoEffect<ept id="p6">**</ept><ept id="p5">](https://msdn.microsoft.com/library/windows/apps/dn764788)</ept>.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>This example uses an undefined helper method that returns a video frame, <bpt id="p1">**</bpt>GetLatestFrame<ept id="p1">**</ept>, as a placeholder for this operation.</source>
          <target state="new">This example uses an undefined helper method that returns a video frame, <bpt id="p1">**</bpt>GetLatestFrame<ept id="p1">**</ept>, as a placeholder for this operation.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>For information on getting video frames from the preview stream of a running media capture device, see <bpt id="p1">[</bpt>Get a preview frame<ept id="p1">](get-a-preview-frame.md)</ept>.</source>
          <target state="new">For information on getting video frames from the preview stream of a running media capture device, see <bpt id="p1">[</bpt>Get a preview frame<ept id="p1">](get-a-preview-frame.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>As with <bpt id="p1">**</bpt>FaceDetector<ept id="p1">**</ept>, the <bpt id="p2">**</bpt>FaceTracker<ept id="p2">**</ept> supports a limited set of pixel formats.</source>
          <target state="new">As with <bpt id="p1">**</bpt>FaceDetector<ept id="p1">**</ept>, the <bpt id="p2">**</bpt>FaceTracker<ept id="p2">**</ept> supports a limited set of pixel formats.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>This example abandons face detection if the supplied frame is not in the Nv12 format.</source>
          <target state="new">This example abandons face detection if the supplied frame is not in the Nv12 format.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Call <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ProcessNextFrameAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974157)</ept> to retrieve a list of <bpt id="p3">[</bpt><bpt id="p4">**</bpt>DetectedFace<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn974123)</ept> objects representing the faces in the frame.</source>
          <target state="new">Call <bpt id="p1">[</bpt><bpt id="p2">**</bpt>ProcessNextFrameAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn974157)</ept> to retrieve a list of <bpt id="p3">[</bpt><bpt id="p4">**</bpt>DetectedFace<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn974123)</ept> objects representing the faces in the frame.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Once you have the list of faces, you can display them in the same manner described above for face detection.</source>
          <target state="new">Once you have the list of faces, you can display them in the same manner described above for face detection.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Note that, because the face tracking helper method is not called on the UI thread, you must make any UI updates in within a call <bpt id="p1">[</bpt><bpt id="p2">**</bpt>CoredDispatcher.RunAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/hh750317)</ept>.</source>
          <target state="new">Note that, because the face tracking helper method is not called on the UI thread, you must make any UI updates in within a call <bpt id="p1">[</bpt><bpt id="p2">**</bpt>CoredDispatcher.RunAsync<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/hh750317)</ept>.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>ProcessCurrentVideoFrame</source>
          <target state="new">ProcessCurrentVideoFrame</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>Related topics</source>
          <target state="new">Related topics</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Scene analysis for media capture</source>
          <target state="new">Scene analysis for media capture</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>Basic Face Detection sample</source>
          <target state="new">Basic Face Detection sample</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>Basic Face Tracking sample</source>
          <target state="new">Basic Face Tracking sample</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Capture photos and video with MediaCapture</source>
          <target state="new">Capture photos and video with MediaCapture</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>