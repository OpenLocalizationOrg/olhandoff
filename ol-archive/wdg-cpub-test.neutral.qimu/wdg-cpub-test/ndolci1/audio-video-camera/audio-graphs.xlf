<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="fr-fr">
    <header>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
      </xliffext:oltranslationpriority>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">wdg-cpub-test\ndolci1\audio-video-camera\audio-graphs.md</xliffext:olfilepath>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">78a88cfc48d10aa7fe99b85eee7daa1a0984d9eb</xliffext:olfilehash>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-e58fd48" tool-company="Microsoft" />
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>This article shows how to use the APIs in the Windows.Media.Audio namespace to create audio graphs for audio routing, mixing, and processing scenarios.</source>
          <target state="new">This article shows how to use the APIs in the Windows.Media.Audio namespace to create audio graphs for audio routing, mixing, and processing scenarios.</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Audio Graphs</source>
          <target state="new">Audio Graphs</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Audio Graphs</source>
          <target state="new">Audio Graphs</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Updated for UWP apps on Windows 10.</source>
          <target state="new">Updated for UWP apps on Windows 10.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>For Windows 8.x articles, see the <bpt id="p1">[</bpt>archive<ept id="p1">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept></source>
          <target state="new">For Windows 8.x articles, see the <bpt id="p1">[</bpt>archive<ept id="p1">](http://go.microsoft.com/fwlink/p/?linkid=619132)</ept></target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>This article shows how to use the APIs in the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Windows.Media.Audio<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914341)</ept> namespace to create audio graphs for audio routing, mixing, and processing scenarios.</source>
          <target state="new">This article shows how to use the APIs in the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Windows.Media.Audio<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914341)</ept> namespace to create audio graphs for audio routing, mixing, and processing scenarios.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>An audio graph is a set of interconnected audio nodes through which audio data flows.</source>
          <target state="new">An audio graph is a set of interconnected audio nodes through which audio data flows.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Audio input nodes supply audio data to the graph from audio input devices, audio files, or from custom code.</source>
          <target state="new">Audio input nodes supply audio data to the graph from audio input devices, audio files, or from custom code.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Audio output nodes are the destination for audio processed by the graph.</source>
          <target state="new">Audio output nodes are the destination for audio processed by the graph.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Audio can be routed out of the graph to audio output devices, audio files, or custom code.</source>
          <target state="new">Audio can be routed out of the graph to audio output devices, audio files, or custom code.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>The last type of node is a submix node which takes audio from one or more nodes and combines them into a single output that can be routed to other nodes in the graph.</source>
          <target state="new">The last type of node is a submix node which takes audio from one or more nodes and combines them into a single output that can be routed to other nodes in the graph.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>After all of the nodes have been created and the connections between them set up, you simply start the audio graph and the audio data flows from the input nodes, through any submix nodes, to the output nodes.</source>
          <target state="new">After all of the nodes have been created and the connections between them set up, you simply start the audio graph and the audio data flows from the input nodes, through any submix nodes, to the output nodes.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>This model makes scenarios like recording from a device's microphone to an audio file, playing audio from a file to a device's speaker, or mixing audio from multiple sources quick and easy to implement.</source>
          <target state="new">This model makes scenarios like recording from a device's microphone to an audio file, playing audio from a file to a device's speaker, or mixing audio from multiple sources quick and easy to implement.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Additional scenarios are enabled with the addition of audio effects to the audio graph.</source>
          <target state="new">Additional scenarios are enabled with the addition of audio effects to the audio graph.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Every node in an audio graph can be populated with zero or more audio effects that perform audio processing on the audio passing through the node.</source>
          <target state="new">Every node in an audio graph can be populated with zero or more audio effects that perform audio processing on the audio passing through the node.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>There are several built-in effects such as echo, equalizer, limiting, and reverb that can be attached to an audio node with just a few lines of code.</source>
          <target state="new">There are several built-in effects such as echo, equalizer, limiting, and reverb that can be attached to an audio node with just a few lines of code.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>You can also create your own custom audio effects that work exactly the same as the built-in effects.</source>
          <target state="new">You can also create your own custom audio effects that work exactly the same as the built-in effects.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Note</source>
          <target state="new">Note</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt>AudioGraph UWP sample<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=619481)</ept> implements the code discussed in this overview.</source>
          <target state="new">The <bpt id="p1">[</bpt>AudioGraph UWP sample<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=619481)</ept> implements the code discussed in this overview.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>You can download the sample to see the code in context or to use as a starting point for your own app.</source>
          <target state="new">You can download the sample to see the code in context or to use as a starting point for your own app.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Choosing Windows Runtime AudioGraph or XAudio2</source>
          <target state="new">Choosing Windows Runtime AudioGraph or XAudio2</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>The Windows Runtime audio graph APIs offer functionality that can also be implemented using the COM-based <bpt id="p1">[</bpt>XAudio2 APIs<ept id="p1">](https://msdn.microsoft.com/library/windows/desktop/hh405049)</ept>.</source>
          <target state="new">The Windows Runtime audio graph APIs offer functionality that can also be implemented using the COM-based <bpt id="p1">[</bpt>XAudio2 APIs<ept id="p1">](https://msdn.microsoft.com/library/windows/desktop/hh405049)</ept>.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>The following are features of the Windows Runtime audio graph framework that differ from XAudio2.</source>
          <target state="new">The following are features of the Windows Runtime audio graph framework that differ from XAudio2.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>The Windows Runtime audio graph APIs are significantly easier to use than XAudio2.</source>
          <target state="new">The Windows Runtime audio graph APIs are significantly easier to use than XAudio2.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>The Windows Runtime audio graph APIs can be used from C# - in addition to being supported for C++.</source>
          <target state="new">The Windows Runtime audio graph APIs can be used from C# - in addition to being supported for C++.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>The Windows Runtime audio graph APIs can use audio files, including compressed file formats, directly.</source>
          <target state="new">The Windows Runtime audio graph APIs can use audio files, including compressed file formats, directly.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>XAudio2 only operates on audio buffers and does not provide any file I/O capabilities.</source>
          <target state="new">XAudio2 only operates on audio buffers and does not provide any file I/O capabilities.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>The Windows Runtime audio graph APIs can use the low-latency audio pipeline in Windows 10.</source>
          <target state="new">The Windows Runtime audio graph APIs can use the low-latency audio pipeline in Windows 10.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>The Windows Runtime audio graph APIs supports automatic endpoint switching when default endpoint parameters are used.</source>
          <target state="new">The Windows Runtime audio graph APIs supports automatic endpoint switching when default endpoint parameters are used.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>For example, if the user switches from a device's speaker to a headset, the audio is automatically redirected to the new input.</source>
          <target state="new">For example, if the user switches from a device's speaker to a headset, the audio is automatically redirected to the new input.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>AudioGraph class</source>
          <target state="new">AudioGraph class</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraph<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914176)</ept> class is the parent of all nodes that make up the graph.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraph<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914176)</ept> class is the parent of all nodes that make up the graph.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Use this object to create instances of all of the audio node types.</source>
          <target state="new">Use this object to create instances of all of the audio node types.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Create an instance of the <bpt id="p1">**</bpt>AudioGraph<ept id="p1">**</ept> class by initializing an <bpt id="p2">[</bpt><bpt id="p3">**</bpt>AudioGraphSettings<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn914185)</ept> object, containing configuration settings for the graph, and then calling <bpt id="p4">[</bpt><bpt id="p5">**</bpt>AudioGraph.CreateAsync<ept id="p5">**</ept><ept id="p4">](https://msdn.microsoft.com/library/windows/apps/dn914216)</ept>.</source>
          <target state="new">Create an instance of the <bpt id="p1">**</bpt>AudioGraph<ept id="p1">**</ept> class by initializing an <bpt id="p2">[</bpt><bpt id="p3">**</bpt>AudioGraphSettings<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn914185)</ept> object, containing configuration settings for the graph, and then calling <bpt id="p4">[</bpt><bpt id="p5">**</bpt>AudioGraph.CreateAsync<ept id="p5">**</ept><ept id="p4">](https://msdn.microsoft.com/library/windows/apps/dn914216)</ept>.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>The returned <bpt id="p1">[</bpt><bpt id="p2">**</bpt>CreateAudioGraphResult<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914273)</ept> gives access to the created audio graph or provides an error value if audio graph creation fails.</source>
          <target state="new">The returned <bpt id="p1">[</bpt><bpt id="p2">**</bpt>CreateAudioGraphResult<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914273)</ept> gives access to the created audio graph or provides an error value if audio graph creation fails.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>DeclareAudioGraph</source>
          <target state="new">DeclareAudioGraph</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>InitAudioGraph</source>
          <target state="new">InitAudioGraph</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>All audio node types are created by using the Create<ph id="ph1">\*</ph> methods of the <bpt id="p1">**</bpt>AudioGraph<ept id="p1">**</ept> class.</source>
          <target state="new">All audio node types are created by using the Create<ph id="ph1">\*</ph> methods of the <bpt id="p1">**</bpt>AudioGraph<ept id="p1">**</ept> class.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraph.Start<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914244)</ept> method causes the audio graph to start processing audio data.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraph.Start<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914244)</ept> method causes the audio graph to start processing audio data.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraph.Stop<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914245)</ept> method stops audio processing.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraph.Stop<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914245)</ept> method stops audio processing.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Each node in the graph can be started and stopped independently while the graph is running, but no nodes are active when the graph is stopped.</source>
          <target state="new">Each node in the graph can be started and stopped independently while the graph is running, but no nodes are active when the graph is stopped.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResetAllNodes<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914242)</ept> causes all nodes in the graph to discard any data currently in their audio buffers.</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>ResetAllNodes<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914242)</ept> causes all nodes in the graph to discard any data currently in their audio buffers.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>QuantumStarted<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914241)</ept> event occurs when the graph is starting the processing of a new quantum of audio data.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>QuantumStarted<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914241)</ept> event occurs when the graph is starting the processing of a new quantum of audio data.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>QuantumProcessed<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914240)</ept> event occurs when the processing of a quantum is completed.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>QuantumProcessed<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914240)</ept> event occurs when the processing of a quantum is completed.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>The only <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraphSettings<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914185)</ept> property that is required is <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AudioRenderCategory<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn297724)</ept>.</source>
          <target state="new">The only <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraphSettings<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914185)</ept> property that is required is <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AudioRenderCategory<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn297724)</ept>.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Specifying this value allows the system to optimize the audio pipeline for the specified category.</source>
          <target state="new">Specifying this value allows the system to optimize the audio pipeline for the specified category.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>The quantum size of the audio graph determines the number of samples that are processed at one time.</source>
          <target state="new">The quantum size of the audio graph determines the number of samples that are processed at one time.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>By default, the quantum size is 10 ms based at the default sample rate.</source>
          <target state="new">By default, the quantum size is 10 ms based at the default sample rate.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>If you specify a custom quantum size by setting the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>DesiredSamplesPerQuantum<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914205)</ept> property, you must also set the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>QuantumSizeSelectionMode<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914208)</ept> property to <bpt id="p5">**</bpt>ClosestToDesired<ept id="p5">**</ept> or the supplied value is ignored.</source>
          <target state="new">If you specify a custom quantum size by setting the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>DesiredSamplesPerQuantum<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914205)</ept> property, you must also set the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>QuantumSizeSelectionMode<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914208)</ept> property to <bpt id="p5">**</bpt>ClosestToDesired<ept id="p5">**</ept> or the supplied value is ignored.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>If this value is used, the system will choose a quantum size as close as possible to the one you specify.</source>
          <target state="new">If this value is used, the system will choose a quantum size as close as possible to the one you specify.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>To determine the actual quantum size, check the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SamplesPerQuantum<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914243)</ept> of the <bpt id="p3">**</bpt>AudioGraph<ept id="p3">**</ept> after it has been created.</source>
          <target state="new">To determine the actual quantum size, check the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SamplesPerQuantum<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914243)</ept> of the <bpt id="p3">**</bpt>AudioGraph<ept id="p3">**</ept> after it has been created.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>If you only plan to use the audio graph with files and don't plan to output to an audio device, it is recommended that you use the default quantum size by not setting the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>DesiredSamplesPerQuantum<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914205)</ept> property.</source>
          <target state="new">If you only plan to use the audio graph with files and don't plan to output to an audio device, it is recommended that you use the default quantum size by not setting the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>DesiredSamplesPerQuantum<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914205)</ept> property.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>DesiredRenderDeviceAudioProcessing<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958522)</ept> property determines the amount of processing the primary render device performs on the output of the audio graph.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>DesiredRenderDeviceAudioProcessing<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958522)</ept> property determines the amount of processing the primary render device performs on the output of the audio graph.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>Default<ept id="p1">**</ept> setting allows the system to use the default audio processing for the specified audio render category.</source>
          <target state="new">The <bpt id="p1">**</bpt>Default<ept id="p1">**</ept> setting allows the system to use the default audio processing for the specified audio render category.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>This processing can significantly improve the sound of audio on some devices, particularly mobile devices with small speakers.</source>
          <target state="new">This processing can significantly improve the sound of audio on some devices, particularly mobile devices with small speakers.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>Raw<ept id="p1">**</ept> setting can improve performance by minimizing the amount of signal processing performed, but can result in inferior sound quality on some devices.</source>
          <target state="new">The <bpt id="p1">**</bpt>Raw<ept id="p1">**</ept> setting can improve performance by minimizing the amount of signal processing performed, but can result in inferior sound quality on some devices.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>If the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>QuantumSizeSelectionMode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914208)</ept> is set to <bpt id="p3">**</bpt>LowestLatency<ept id="p3">**</ept>, the audio graph will automatically use <bpt id="p4">**</bpt>Raw<ept id="p4">**</ept> for <bpt id="p5">[</bpt><bpt id="p6">**</bpt>DesiredRenderDeviceAudioProcessing<ept id="p6">**</ept><ept id="p5">](https://msdn.microsoft.com/library/windows/apps/dn958522)</ept>.</source>
          <target state="new">If the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>QuantumSizeSelectionMode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914208)</ept> is set to <bpt id="p3">**</bpt>LowestLatency<ept id="p3">**</ept>, the audio graph will automatically use <bpt id="p4">**</bpt>Raw<ept id="p4">**</ept> for <bpt id="p5">[</bpt><bpt id="p6">**</bpt>DesiredRenderDeviceAudioProcessing<ept id="p6">**</ept><ept id="p5">](https://msdn.microsoft.com/library/windows/apps/dn958522)</ept>.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>EncodingProperties<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958523)</ept> determines the audio format used by the graph.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>EncodingProperties<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958523)</ept> determines the audio format used by the graph.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Only 32-bit float formats are supported.</source>
          <target state="new">Only 32-bit float formats are supported.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>PrimaryRenderDevice<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958524)</ept> sets the primary render device for the audio graph.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>PrimaryRenderDevice<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958524)</ept> sets the primary render device for the audio graph.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>If you don't set this, the default system device is used.</source>
          <target state="new">If you don't set this, the default system device is used.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>The primary render device is used to calculate the quantum sizes for other nodes in the graph.</source>
          <target state="new">The primary render device is used to calculate the quantum sizes for other nodes in the graph.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>If there are no audio render devices present on the system, audio graph creation will fail.</source>
          <target state="new">If there are no audio render devices present on the system, audio graph creation will fail.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>You can let the audio graph use the default audio render device or use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Windows.Devices.Enumeration.DeviceInformation<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br225393)</ept> class to get a list of the system's available audio render devices by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>FindAllAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/br225432)</ept> and passing in the audio render device selector returned by <bpt id="p5">[</bpt><bpt id="p6">**</bpt>Windows.Media.Devices.MediaDevice.GetAudioRenderSelector<ept id="p6">**</ept><ept id="p5">](https://msdn.microsoft.com/library/windows/apps/br226817)</ept>.</source>
          <target state="new">You can let the audio graph use the default audio render device or use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Windows.Devices.Enumeration.DeviceInformation<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br225393)</ept> class to get a list of the system's available audio render devices by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>FindAllAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/br225432)</ept> and passing in the audio render device selector returned by <bpt id="p5">[</bpt><bpt id="p6">**</bpt>Windows.Media.Devices.MediaDevice.GetAudioRenderSelector<ept id="p6">**</ept><ept id="p5">](https://msdn.microsoft.com/library/windows/apps/br226817)</ept>.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>You can choose one of the returned <bpt id="p1">**</bpt>DeviceInformation<ept id="p1">**</ept> objects programatically or show UI to allow the user to select a device and then use it to set the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>PrimaryRenderDevice<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn958524)</ept> property.</source>
          <target state="new">You can choose one of the returned <bpt id="p1">**</bpt>DeviceInformation<ept id="p1">**</ept> objects programatically or show UI to allow the user to select a device and then use it to set the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>PrimaryRenderDevice<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn958524)</ept> property.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>EnumerateAudioRenderDevices</source>
          <target state="new">EnumerateAudioRenderDevices</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Device input node</source>
          <target state="new">Device input node</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>A device input node feeds audio into the graph from an audio capture device connected to the system, such as a microphone.</source>
          <target state="new">A device input node feeds audio into the graph from an audio capture device connected to the system, such as a microphone.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Create a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>DeviceInputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914082)</ept> object that uses the system's default audio capture device by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CreateDeviceInputNodeAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914218)</ept>.</source>
          <target state="new">Create a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>DeviceInputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914082)</ept> object that uses the system's default audio capture device by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CreateDeviceInputNodeAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914218)</ept>.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Provide an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioRenderCategory<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn297724)</ept> to allow the system to optimize the audio pipeline for the specified category.</source>
          <target state="new">Provide an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioRenderCategory<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn297724)</ept> to allow the system to optimize the audio pipeline for the specified category.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>DeclareDeviceInputNode</source>
          <target state="new">DeclareDeviceInputNode</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>CreateDeviceInputNode</source>
          <target state="new">CreateDeviceInputNode</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>If you want to specify a specific audio capture device for the device input node, you can use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Windows.Devices.Enumeration.DeviceInformation<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br225393)</ept> class to get a list of the system's available audio capture devices by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>FindAllAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/br225432)</ept> and passing in the audio render device selector returned by <bpt id="p5">[</bpt><bpt id="p6">**</bpt>Windows.Media.Devices.MediaDevice.GetAudioRenderSelector<ept id="p6">**</ept><ept id="p5">](https://msdn.microsoft.com/library/windows/apps/br226817)</ept>.</source>
          <target state="new">If you want to specify a specific audio capture device for the device input node, you can use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Windows.Devices.Enumeration.DeviceInformation<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/br225393)</ept> class to get a list of the system's available audio capture devices by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>FindAllAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/br225432)</ept> and passing in the audio render device selector returned by <bpt id="p5">[</bpt><bpt id="p6">**</bpt>Windows.Media.Devices.MediaDevice.GetAudioRenderSelector<ept id="p6">**</ept><ept id="p5">](https://msdn.microsoft.com/library/windows/apps/br226817)</ept>.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>You can choose one of the returned <bpt id="p1">**</bpt>DeviceInformation<ept id="p1">**</ept> objects programmatically or show UI to allow the user to select a device and then pass it into <bpt id="p2">[</bpt><bpt id="p3">**</bpt>CreateDeviceInputNodeAsync<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn914218)</ept>.</source>
          <target state="new">You can choose one of the returned <bpt id="p1">**</bpt>DeviceInformation<ept id="p1">**</ept> objects programmatically or show UI to allow the user to select a device and then pass it into <bpt id="p2">[</bpt><bpt id="p3">**</bpt>CreateDeviceInputNodeAsync<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn914218)</ept>.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>EnumerateAudioCaptureDevices</source>
          <target state="new">EnumerateAudioCaptureDevices</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Device output node</source>
          <target state="new">Device output node</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>A device output node pushes audio from the graph to an audio render device, such as speakers or a headset.</source>
          <target state="new">A device output node pushes audio from the graph to an audio render device, such as speakers or a headset.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>Create a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>DeviceOutputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914098)</ept> by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CreateDeviceOutputNodeAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn958525)</ept>.</source>
          <target state="new">Create a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>DeviceOutputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914098)</ept> by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CreateDeviceOutputNodeAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn958525)</ept>.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>The output node uses the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>PrimaryRenderDevice<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958524)</ept> of the audio graph.</source>
          <target state="new">The output node uses the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>PrimaryRenderDevice<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958524)</ept> of the audio graph.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>DeclareDeviceOutputNode</source>
          <target state="new">DeclareDeviceOutputNode</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>CreateDeviceOutputNode</source>
          <target state="new">CreateDeviceOutputNode</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>File input node</source>
          <target state="new">File input node</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>A file input node allows you to feed data from an audio file into the graph.</source>
          <target state="new">A file input node allows you to feed data from an audio file into the graph.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>Create an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFileInputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914108)</ept> by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CreateFileInputNodeAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914226)</ept>.</source>
          <target state="new">Create an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFileInputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914108)</ept> by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CreateFileInputNodeAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914226)</ept>.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>DeclareFileInputNode</source>
          <target state="new">DeclareFileInputNode</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>CreateFileInputNode</source>
          <target state="new">CreateFileInputNode</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>File input nodes support the following file formats: mp3, wav, wma, m4a</source>
          <target state="new">File input nodes support the following file formats: mp3, wav, wma, m4a</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>Set the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>StartTime<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914130)</ept> property to specify the time offset into the file where playback should begin.</source>
          <target state="new">Set the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>StartTime<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914130)</ept> property to specify the time offset into the file where playback should begin.</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>If this property is null, the beginning of the file is used.</source>
          <target state="new">If this property is null, the beginning of the file is used.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>Set the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>EndTime<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914118)</ept> property to specify the time offset into the file where playback should end.</source>
          <target state="new">Set the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>EndTime<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914118)</ept> property to specify the time offset into the file where playback should end.</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>If this property is null, the end of the file is used.</source>
          <target state="new">If this property is null, the end of the file is used.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>The start time value must be lower than the end time value, and the end time value must be less than or equal to the duration of the audio file, which can be determined by checking the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Duration<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914116)</ept> property value.</source>
          <target state="new">The start time value must be lower than the end time value, and the end time value must be less than or equal to the duration of the audio file, which can be determined by checking the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Duration<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914116)</ept> property value.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>Seek to a position in the audio file by calling <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Seek<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914127)</ept> and specifying the time offset into the file to which the playback position should be moved.</source>
          <target state="new">Seek to a position in the audio file by calling <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Seek<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914127)</ept> and specifying the time offset into the file to which the playback position should be moved.</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>The specified value must be within the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>StartTime<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914130)</ept> and <bpt id="p3">[</bpt><bpt id="p4">**</bpt>EndTime<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914118)</ept> range.</source>
          <target state="new">The specified value must be within the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>StartTime<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914130)</ept> and <bpt id="p3">[</bpt><bpt id="p4">**</bpt>EndTime<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914118)</ept> range.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>Get the current playback position of the node with the read-only <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Position<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914124)</ept> property.</source>
          <target state="new">Get the current playback position of the node with the read-only <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Position<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914124)</ept> property.</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>Enable looping of the audio file by setting the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>LoopCount<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914120)</ept> property.</source>
          <target state="new">Enable looping of the audio file by setting the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>LoopCount<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914120)</ept> property.</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>When non-null, this value indicates the number of times the file will be played in after the initial playback.</source>
          <target state="new">When non-null, this value indicates the number of times the file will be played in after the initial playback.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>So, for example, setting <bpt id="p1">**</bpt>LoopCount<ept id="p1">**</ept> to 1 will cause the file to be played 2 times in total, and setting it to 5 will cause the file to be played 6 times in total.</source>
          <target state="new">So, for example, setting <bpt id="p1">**</bpt>LoopCount<ept id="p1">**</ept> to 1 will cause the file to be played 2 times in total, and setting it to 5 will cause the file to be played 6 times in total.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>Setting <bpt id="p1">**</bpt>LoopCount<ept id="p1">**</ept> to null causes the file to be looped indefinitely.</source>
          <target state="new">Setting <bpt id="p1">**</bpt>LoopCount<ept id="p1">**</ept> to null causes the file to be looped indefinitely.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>To stop looping, set the value to 0.</source>
          <target state="new">To stop looping, set the value to 0.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>Adjust the speed at which the audio file is played back by setting the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>PlaybackSpeedFactor<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914123)</ept>.</source>
          <target state="new">Adjust the speed at which the audio file is played back by setting the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>PlaybackSpeedFactor<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914123)</ept>.</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>A value of 1 indicates the original speed of the file, .5 is half-speed, and 2 is double speed.</source>
          <target state="new">A value of 1 indicates the original speed of the file, .5 is half-speed, and 2 is double speed.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>File output node</source>
          <target state="new">File output node</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>A file output node lets you direct audio data from the graph into an audio file.</source>
          <target state="new">A file output node lets you direct audio data from the graph into an audio file.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>Create an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFileOutputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914133)</ept> by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CreateFileOutputNodeAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914227)</ept>.</source>
          <target state="new">Create an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFileOutputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914133)</ept> by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CreateFileOutputNodeAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914227)</ept>.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>DeclareFileOutputNode</source>
          <target state="new">DeclareFileOutputNode</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>CreateFileOutputNode</source>
          <target state="new">CreateFileOutputNode</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>File output nodes support the following file formats: mp3, wav, wma, m4a</source>
          <target state="new">File output nodes support the following file formats: mp3, wav, wma, m4a</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>You must call <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFileOutputNode.Stop<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914144)</ept> to stop the node's processing before calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AudioFileOutputNode.FinalizeAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914140)</ept> or an exception will be thrown.</source>
          <target state="new">You must call <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFileOutputNode.Stop<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914144)</ept> to stop the node's processing before calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AudioFileOutputNode.FinalizeAsync<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914140)</ept> or an exception will be thrown.</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>Audio frame input node</source>
          <target state="new">Audio frame input node</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>An audio frame input node allows you to push audio data that you generate in your own code into the audio graph.</source>
          <target state="new">An audio frame input node allows you to push audio data that you generate in your own code into the audio graph.</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>This enables scenarios like creating a custom software synthesizer.</source>
          <target state="new">This enables scenarios like creating a custom software synthesizer.</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>Create an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFrameInputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914147)</ept> by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CreateFrameInputNode<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914230)</ept>.</source>
          <target state="new">Create an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFrameInputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914147)</ept> by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CreateFrameInputNode<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914230)</ept>.</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>DeclareFrameInputNode</source>
          <target state="new">DeclareFrameInputNode</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>CreateFrameInputNode</source>
          <target state="new">CreateFrameInputNode</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FrameInputNode.QuantumStarted<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958507)</ept> event is raised when the audio graph is ready to begin processing the next quantum of audio data.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FrameInputNode.QuantumStarted<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958507)</ept> event is raised when the audio graph is ready to begin processing the next quantum of audio data.</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>You supply your custom generated audio data from within the handler to this event.</source>
          <target state="new">You supply your custom generated audio data from within the handler to this event.</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>QuantumStarted</source>
          <target state="new">QuantumStarted</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FrameInputNodeQuantumStartedEventArgs<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958533)</ept> object passed into the <bpt id="p3">**</bpt>QuantumStarted<ept id="p3">**</ept> event handler exposes the <bpt id="p4">[</bpt><bpt id="p5">**</bpt>RequiredSamples<ept id="p5">**</ept><ept id="p4">](https://msdn.microsoft.com/library/windows/apps/dn958534)</ept> property that indicates how many samples the audio graph needs to fill up the quantum to be processed.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>FrameInputNodeQuantumStartedEventArgs<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958533)</ept> object passed into the <bpt id="p3">**</bpt>QuantumStarted<ept id="p3">**</ept> event handler exposes the <bpt id="p4">[</bpt><bpt id="p5">**</bpt>RequiredSamples<ept id="p5">**</ept><ept id="p4">](https://msdn.microsoft.com/library/windows/apps/dn958534)</ept> property that indicates how many samples the audio graph needs to fill up the quantum to be processed.</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>Call <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFrameInputNode.AddFrame<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914148)</ept> to pass an <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AudioFrame<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn930871)</ept> object filled with audio data into the graph.</source>
          <target state="new">Call <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFrameInputNode.AddFrame<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914148)</ept> to pass an <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AudioFrame<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn930871)</ept> object filled with audio data into the graph.</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>An example implementation of the <bpt id="p1">**</bpt>GenerateAudioData<ept id="p1">**</ept> helper method is shown below.</source>
          <target state="new">An example implementation of the <bpt id="p1">**</bpt>GenerateAudioData<ept id="p1">**</ept> helper method is shown below.</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>To populate an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFrame<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn930871)</ept> with audio data, you must get access to the underlying memory buffer of the audio frame.</source>
          <target state="new">To populate an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFrame<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn930871)</ept> with audio data, you must get access to the underlying memory buffer of the audio frame.</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>To do this you must initialize the <bpt id="p1">**</bpt>IMemoryBufferByteAccess<ept id="p1">**</ept> COM interface by adding the following code within your namespace.</source>
          <target state="new">To do this you must initialize the <bpt id="p1">**</bpt>IMemoryBufferByteAccess<ept id="p1">**</ept> COM interface by adding the following code within your namespace.</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>ComImportIMemoryBufferByteAccess</source>
          <target state="new">ComImportIMemoryBufferByteAccess</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>The following code shows an example implementation of a <bpt id="p1">**</bpt>GenerateAudioData<ept id="p1">**</ept> helper method that creates an <bpt id="p2">[</bpt><bpt id="p3">**</bpt>AudioFrame<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn930871)</ept> and populates it with audio data.</source>
          <target state="new">The following code shows an example implementation of a <bpt id="p1">**</bpt>GenerateAudioData<ept id="p1">**</ept> helper method that creates an <bpt id="p2">[</bpt><bpt id="p3">**</bpt>AudioFrame<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn930871)</ept> and populates it with audio data.</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>GenerateAudioData</source>
          <target state="new">GenerateAudioData</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>Because this method accesses the raw buffer underlying the Windows Runtime types, it must be declared using the <bpt id="p1">**</bpt>unsafe<ept id="p1">**</ept> keyword.</source>
          <target state="new">Because this method accesses the raw buffer underlying the Windows Runtime types, it must be declared using the <bpt id="p1">**</bpt>unsafe<ept id="p1">**</ept> keyword.</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>You must also configure your project in Microsoft Visual Studio to allow the compilation of unsafe code by opening the project's <bpt id="p1">**</bpt>Properties<ept id="p1">**</ept> page, clicking the <bpt id="p2">**</bpt>Build<ept id="p2">**</ept> property page, and selecting the <bpt id="p3">**</bpt>Allow Unsafe Code<ept id="p3">**</ept> checkbox.</source>
          <target state="new">You must also configure your project in Microsoft Visual Studio to allow the compilation of unsafe code by opening the project's <bpt id="p1">**</bpt>Properties<ept id="p1">**</ept> page, clicking the <bpt id="p2">**</bpt>Build<ept id="p2">**</ept> property page, and selecting the <bpt id="p3">**</bpt>Allow Unsafe Code<ept id="p3">**</ept> checkbox.</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>Initialize a new instance of <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFrame<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn930871)</ept>, in the <bpt id="p3">**</bpt>Windows.Media<ept id="p3">**</ept> namespace, by passing in the desired buffer size to the constructor.</source>
          <target state="new">Initialize a new instance of <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFrame<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn930871)</ept>, in the <bpt id="p3">**</bpt>Windows.Media<ept id="p3">**</ept> namespace, by passing in the desired buffer size to the constructor.</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>The buffer size is the number of samples multiplied by the size of each sample.</source>
          <target state="new">The buffer size is the number of samples multiplied by the size of each sample.</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>Get the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioBuffer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958454)</ept> of the audio frame by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>LockBuffer<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn930878)</ept>.</source>
          <target state="new">Get the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioBuffer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958454)</ept> of the audio frame by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>LockBuffer<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn930878)</ept>.</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>Get an instance of the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>IMemoryBufferByteAccess<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/desktop/mt297505)</ept> COM interface from the audio buffer by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CreateReference<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn958457)</ept>.</source>
          <target state="new">Get an instance of the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>IMemoryBufferByteAccess<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/desktop/mt297505)</ept> COM interface from the audio buffer by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CreateReference<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn958457)</ept>.</target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source>Get a pointer to raw audio buffer data by calling <bpt id="p1">[</bpt><bpt id="p2">**</bpt>IMemoryBufferByteAccess.GetBuffer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/desktop/mt297506)</ept> and cast it to the sample data type of the audio data.</source>
          <target state="new">Get a pointer to raw audio buffer data by calling <bpt id="p1">[</bpt><bpt id="p2">**</bpt>IMemoryBufferByteAccess.GetBuffer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/desktop/mt297506)</ept> and cast it to the sample data type of the audio data.</target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source>Fill the buffer with data and return the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFrame<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn930871)</ept> for submission into the audio graph.</source>
          <target state="new">Fill the buffer with data and return the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFrame<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn930871)</ept> for submission into the audio graph.</target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>Audio frame output node</source>
          <target state="new">Audio frame output node</target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>An audio frame output node allows you to receive and process audio data output from the audio graph with custom code that you create.</source>
          <target state="new">An audio frame output node allows you to receive and process audio data output from the audio graph with custom code that you create.</target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>An example scenario for this is performing signal analysis on the audio output.</source>
          <target state="new">An example scenario for this is performing signal analysis on the audio output.</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>Create an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFrameOutputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914166)</ept> by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CreateFrameOutputNode<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914233)</ept>.</source>
          <target state="new">Create an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFrameOutputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914166)</ept> by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>CreateFrameOutputNode<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914233)</ept>.</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source>DeclareFrameOutputNode</source>
          <target state="new">DeclareFrameOutputNode</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>CreateFrameOutputNode</source>
          <target state="new">CreateFrameOutputNode</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraph.QuantumProcessed<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914240)</ept> event is raised when the audio graph has completed processing a quantum of audio data.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraph.QuantumProcessed<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914240)</ept> event is raised when the audio graph has completed processing a quantum of audio data.</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>You can access the audio data from within the handler for this event.</source>
          <target state="new">You can access the audio data from within the handler for this event.</target>
        </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>QuantumProcessed</source>
          <target state="new">QuantumProcessed</target>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>Call <bpt id="p1">[</bpt><bpt id="p2">**</bpt>GetFrame<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914171)</ept> to get an <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AudioFrame<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn930871)</ept> object filled with audio data from the graph.</source>
          <target state="new">Call <bpt id="p1">[</bpt><bpt id="p2">**</bpt>GetFrame<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914171)</ept> to get an <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AudioFrame<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn930871)</ept> object filled with audio data from the graph.</target>
        </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>An example implementation of the <bpt id="p1">**</bpt>ProcessFrameOutput<ept id="p1">**</ept> helper method is shown below.</source>
          <target state="new">An example implementation of the <bpt id="p1">**</bpt>ProcessFrameOutput<ept id="p1">**</ept> helper method is shown below.</target>
        </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source>ProcessFrameOutput</source>
          <target state="new">ProcessFrameOutput</target>
        </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source>Like the audio frame input node example above, you will need to declare the <bpt id="p1">**</bpt>IMemoryBufferByteAccess<ept id="p1">**</ept> COM interface and configure your project to allow unsafe code in order to access the underlying audio buffer.</source>
          <target state="new">Like the audio frame input node example above, you will need to declare the <bpt id="p1">**</bpt>IMemoryBufferByteAccess<ept id="p1">**</ept> COM interface and configure your project to allow unsafe code in order to access the underlying audio buffer.</target>
        </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source>Get the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioBuffer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958454)</ept> of the audio frame by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>LockBuffer<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn930878)</ept>.</source>
          <target state="new">Get the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioBuffer<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn958454)</ept> of the audio frame by calling <bpt id="p3">[</bpt><bpt id="p4">**</bpt>LockBuffer<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn930878)</ept>.</target>
        </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>Get an instance of the <bpt id="p1">**</bpt>IMemoryBufferByteAccess<ept id="p1">**</ept> COM interface from the audio buffer by calling <bpt id="p2">[</bpt><bpt id="p3">**</bpt>CreateReference<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn958457)</ept>.</source>
          <target state="new">Get an instance of the <bpt id="p1">**</bpt>IMemoryBufferByteAccess<ept id="p1">**</ept> COM interface from the audio buffer by calling <bpt id="p2">[</bpt><bpt id="p3">**</bpt>CreateReference<ept id="p3">**</ept><ept id="p2">](https://msdn.microsoft.com/library/windows/apps/dn958457)</ept>.</target>
        </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>Get a pointer to raw audio buffer data by calling <bpt id="p1">**</bpt>IMemoryBufferByteAccess.GetBuffer<ept id="p1">**</ept> and cast it to the sample data type of the audio data.</source>
          <target state="new">Get a pointer to raw audio buffer data by calling <bpt id="p1">**</bpt>IMemoryBufferByteAccess.GetBuffer<ept id="p1">**</ept> and cast it to the sample data type of the audio data.</target>
        </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve">
          <source>Node connections and submix nodes</source>
          <target state="new">Node connections and submix nodes</target>
        </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve">
          <source>All input nodes types expose the <bpt id="p1">**</bpt>AddOutgoingConnection<ept id="p1">**</ept> method that routes the audio produced by the node to the node that is passed into the method.</source>
          <target state="new">All input nodes types expose the <bpt id="p1">**</bpt>AddOutgoingConnection<ept id="p1">**</ept> method that routes the audio produced by the node to the node that is passed into the method.</target>
        </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve">
          <source>The following example connects an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFileInputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914108)</ept> to an <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AudioDeviceOutputNode<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914098)</ept>, which is a simple setup for playing an audio file on the device's speaker.</source>
          <target state="new">The following example connects an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFileInputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914108)</ept> to an <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AudioDeviceOutputNode<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914098)</ept>, which is a simple setup for playing an audio file on the device's speaker.</target>
        </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve">
          <source>AddOutgoingConnection1</source>
          <target state="new">AddOutgoingConnection1</target>
        </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve">
          <source>You can create more than one connection from an input node to other nodes.</source>
          <target state="new">You can create more than one connection from an input node to other nodes.</target>
        </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source>The following example adds another connection from the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFileInputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914108)</ept> to an <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AudioFileOutputNode<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914133)</ept>.</source>
          <target state="new">The following example adds another connection from the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioFileInputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914108)</ept> to an <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AudioFileOutputNode<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914133)</ept>.</target>
        </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>Now, the audio from the audio file is played to the device's speaker and is also written out to an audio file.</source>
          <target state="new">Now, the audio from the audio file is played to the device's speaker and is also written out to an audio file.</target>
        </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve">
          <source>AddOutgoingConnection2</source>
          <target state="new">AddOutgoingConnection2</target>
        </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve">
          <source>Output nodes can also receive more than one connection from other nodes.</source>
          <target state="new">Output nodes can also receive more than one connection from other nodes.</target>
        </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve">
          <source>In the following example a connection is made from a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioDeviceInputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914082)</ept> to the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AudioDeviceOutput<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914098)</ept> node.</source>
          <target state="new">In the following example a connection is made from a <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioDeviceInputNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914082)</ept> to the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AudioDeviceOutput<ept id="p4">**</ept><ept id="p3">](https://msdn.microsoft.com/library/windows/apps/dn914098)</ept> node.</target>
        </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve">
          <source>Because the output node has connections from the file input node and the device input node, the output will contain a mix of audio from both sources.</source>
          <target state="new">Because the output node has connections from the file input node and the device input node, the output will contain a mix of audio from both sources.</target>
        </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>AddOutgoingConnection<ept id="p1">**</ept> provides an overload that lets you specify a gain value for the signal passing through the connection.</source>
          <target state="new"><bpt id="p1">**</bpt>AddOutgoingConnection<ept id="p1">**</ept> provides an overload that lets you specify a gain value for the signal passing through the connection.</target>
        </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve">
          <source>AddOutgoingConnection3</source>
          <target state="new">AddOutgoingConnection3</target>
        </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve">
          <source>Although output nodes can accept connections from multiple nodes, you may want to create an intermediate mix of signals from one or more nodes before passing the mix to an output.</source>
          <target state="new">Although output nodes can accept connections from multiple nodes, you may want to create an intermediate mix of signals from one or more nodes before passing the mix to an output.</target>
        </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve">
          <source>For example, you may want to set the level or apply effects to a subset of the audio signals in a graph.</source>
          <target state="new">For example, you may want to set the level or apply effects to a subset of the audio signals in a graph.</target>
        </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve">
          <source>To do this, use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioSubmixNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914247)</ept>.</source>
          <target state="new">To do this, use the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioSubmixNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914247)</ept>.</target>
        </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve">
          <source>You can connect to a submix node from one or more input nodes or other submix nodes.</source>
          <target state="new">You can connect to a submix node from one or more input nodes or other submix nodes.</target>
        </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve">
          <source>In the following example, a new submix node is created with <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraph.CreateSubmixNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914236)</ept>.</source>
          <target state="new">In the following example, a new submix node is created with <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraph.CreateSubmixNode<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914236)</ept>.</target>
        </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve">
          <source>Then, connections are added from a file input node and a frame output node to the submix node.</source>
          <target state="new">Then, connections are added from a file input node and a frame output node to the submix node.</target>
        </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve">
          <source>Finally, the submix node is connected to a file output node.</source>
          <target state="new">Finally, the submix node is connected to a file output node.</target>
        </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve">
          <source>CreateSubmixNode</source>
          <target state="new">CreateSubmixNode</target>
        </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve">
          <source>Starting and stopping audio graph nodes</source>
          <target state="new">Starting and stopping audio graph nodes</target>
        </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve">
          <source>When <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraph.Start<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914244)</ept> is called, the audio graph begins processing audio data.</source>
          <target state="new">When <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraph.Start<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914244)</ept> is called, the audio graph begins processing audio data.</target>
        </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve">
          <source>Every node type provides <bpt id="p1">**</bpt>Start<ept id="p1">**</ept> and <bpt id="p2">**</bpt>Stop<ept id="p2">**</ept> methods that cause the individual node to start or stop processing data.</source>
          <target state="new">Every node type provides <bpt id="p1">**</bpt>Start<ept id="p1">**</ept> and <bpt id="p2">**</bpt>Stop<ept id="p2">**</ept> methods that cause the individual node to start or stop processing data.</target>
        </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve">
          <source>When <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraph.Stop<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914245)</ept> is called, all audio processing in the all nodes is stopped regardless of the state of individual nodes, but the state of each node can be set while the audio graph is stopped.</source>
          <target state="new">When <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AudioGraph.Stop<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn914245)</ept> is called, all audio processing in the all nodes is stopped regardless of the state of individual nodes, but the state of each node can be set while the audio graph is stopped.</target>
        </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve">
          <source>For example, you could call <bpt id="p1">**</bpt>Stop<ept id="p1">**</ept> on an individual node while the graph is stopped and then call <bpt id="p2">**</bpt>AudioGraph.Start<ept id="p2">**</ept>, and the individual node will remain in the stopped state.</source>
          <target state="new">For example, you could call <bpt id="p1">**</bpt>Stop<ept id="p1">**</ept> on an individual node while the graph is stopped and then call <bpt id="p2">**</bpt>AudioGraph.Start<ept id="p2">**</ept>, and the individual node will remain in the stopped state.</target>
        </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve">
          <source>All node types expose the <bpt id="p1">**</bpt>ConsumeInput<ept id="p1">**</ept> property that, when set to false, allows the node to continue audio processing but stops it from consuming any audio data being input from other nodes.</source>
          <target state="new">All node types expose the <bpt id="p1">**</bpt>ConsumeInput<ept id="p1">**</ept> property that, when set to false, allows the node to continue audio processing but stops it from consuming any audio data being input from other nodes.</target>
        </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve">
          <source>All node types expose the <bpt id="p1">**</bpt>Reset<ept id="p1">**</ept> method that causes the node to discard any audio data currently in its buffer.</source>
          <target state="new">All node types expose the <bpt id="p1">**</bpt>Reset<ept id="p1">**</ept> method that causes the node to discard any audio data currently in its buffer.</target>
        </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve">
          <source>Adding audio effects</source>
          <target state="new">Adding audio effects</target>
        </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve">
          <source>The audio graph API allows you to add audio effects to every type of node in a graph.</source>
          <target state="new">The audio graph API allows you to add audio effects to every type of node in a graph.</target>
        </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve">
          <source>Output nodes, input nodes, and submix nodes can each have an unlimited number of audio effects, limited only by the capabilities of the hardware.The following example demonstrates adding the built-in echo effect to a submix node.</source>
          <target state="new">Output nodes, input nodes, and submix nodes can each have an unlimited number of audio effects, limited only by the capabilities of the hardware.The following example demonstrates adding the built-in echo effect to a submix node.</target>
        </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve">
          <source>AddEffect</source>
          <target state="new">AddEffect</target>
        </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve">
          <source>All audio effects implement <bpt id="p1">[</bpt><bpt id="p2">**</bpt>IAudioEffectDefinition<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn608044)</ept>.</source>
          <target state="new">All audio effects implement <bpt id="p1">[</bpt><bpt id="p2">**</bpt>IAudioEffectDefinition<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn608044)</ept>.</target>
        </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve">
          <source>Every node exposes an <bpt id="p1">**</bpt>EffectDefinitions<ept id="p1">**</ept> property representing the list of effects applied to that node.</source>
          <target state="new">Every node exposes an <bpt id="p1">**</bpt>EffectDefinitions<ept id="p1">**</ept> property representing the list of effects applied to that node.</target>
        </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve">
          <source>Add an effect by adding it's definition object to the list.</source>
          <target state="new">Add an effect by adding it's definition object to the list.</target>
        </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve">
          <source>There are several effect definition classes that are provided in the <bpt id="p1">**</bpt>Windows.Media.Audio<ept id="p1">**</ept> namespace.</source>
          <target state="new">There are several effect definition classes that are provided in the <bpt id="p1">**</bpt>Windows.Media.Audio<ept id="p1">**</ept> namespace.</target>
        </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve">
          <source>These include:</source>
          <target state="new">These include:</target>
        </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve">
          <source>EchoEffectDefinition</source>
          <target state="new">EchoEffectDefinition</target>
        </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve">
          <source>EqualizerEffectDefinition</source>
          <target state="new">EqualizerEffectDefinition</target>
        </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve">
          <source>LimiterEffectDefinition</source>
          <target state="new">LimiterEffectDefinition</target>
        </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve">
          <source>ReverbEffectDefinition</source>
          <target state="new">ReverbEffectDefinition</target>
        </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve">
          <source>You can create your own audio effects that implement <bpt id="p1">[</bpt><bpt id="p2">**</bpt>IAudioEffectDefinition<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn608044)</ept> and apply them to any node in an audio graph.</source>
          <target state="new">You can create your own audio effects that implement <bpt id="p1">[</bpt><bpt id="p2">**</bpt>IAudioEffectDefinition<ept id="p2">**</ept><ept id="p1">](https://msdn.microsoft.com/library/windows/apps/dn608044)</ept> and apply them to any node in an audio graph.</target>
        </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve">
          <source>Every node type exposes a <bpt id="p1">**</bpt>DisableEffectsByDefinition<ept id="p1">**</ept> method that disables all effects in the node's <bpt id="p2">**</bpt>EffectDefinitions<ept id="p2">**</ept> list that were added using the specified definition.</source>
          <target state="new">Every node type exposes a <bpt id="p1">**</bpt>DisableEffectsByDefinition<ept id="p1">**</ept> method that disables all effects in the node's <bpt id="p2">**</bpt>EffectDefinitions<ept id="p2">**</ept> list that were added using the specified definition.</target>
        </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>EnableEffectsByDefinition<ept id="p1">**</ept> enables the effects with the specified definition.</source>
          <target state="new"><bpt id="p1">**</bpt>EnableEffectsByDefinition<ept id="p1">**</ept> enables the effects with the specified definition.</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>